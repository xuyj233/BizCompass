{"ID": 20, "Question": "### Background\n\nA researcher models the log output (`Y`) of a plant as a function of its own foreign equity share (`DFI_Plant`) and the foreign equity share in its sector (`DFI_Sector`). The goal is to distinguish the direct effects of receiving investment from the spillover effects of competition.\n\n### Data / Model Specification\n\nThe estimated log-linear production function is:\n\n  \nY_{ijt} = C + \\beta_{1} DFI\\_Plant_{ijt} + \\beta_{2} DFI\\_Sector_{jt} + \\beta_{3} (DFI\\_Plant_{ijt} \\cdot DFI\\_Sector_{jt}) + ...\n \n\n*Eq. (1)*\n\n---\n\nBased on the structure of Eq. (1), which of the following interpretations or derivations are **INCORRECT**? (Select all that apply)", "Options": {"A": "For a plant that is 100% domestically owned, the marginal effect of an increase in sectoral foreign presence on its productivity is given by `β₂`.", "B": "The marginal effect of increasing a plant's own foreign equity share on its productivity is constant and equal to `β₁`.", "C": "The coefficient `β₃` captures how the productivity effect of receiving foreign investment is moderated by the level of foreign presence in the surrounding sector.", "D": "If `β₃` is positive, it implies that the benefits of receiving foreign equity are dampened in sectors with a high concentration of other foreign firms."}, "Answer": ["B", "D"], "pi_justification": "This item assesses the user's ability to correctly interpret the parameters of a regression model with an interaction term. The core assessment objective (interpreting the marginal effect) has only one incorrect option among the plausible choices. Therefore, the Single-Correct-Answer Inversion Protocol was applied. The stem is inverted to ask for INCORRECT statements. Option A is a correct interpretation. Option B is incorrect because the marginal effect is `β₁ + β₃ * DFI_Sector`, which is not constant. Option C is a correct interpretation of the interaction term. Option D is incorrect because a positive `β₃` implies the benefits are amplified (the marginal effect increases with `DFI_Sector`), not dampened. Thus, B and D are the incorrect statements and the correct answers to the inverted question.", "qid": "20", "question": "### Background\n\nA researcher models the log output (`Y`) of a plant as a function of its own foreign equity share (`DFI_Plant`) and the foreign equity share in its sector (`DFI_Sector`). The goal is to distinguish the direct effects of receiving investment from the spillover effects of competition.\n\n### Data / Model Specification\n\nThe estimated log-linear production function is:\n\n  \nY_{ijt} = C + \\beta_{1} DFI\\_Plant_{ijt} + \\beta_{2} DFI\\_Sector_{jt} + \\beta_{3} (DFI\\_Plant_{ijt} \\cdot DFI\\_Sector_{jt}) + ...\n \n\n*Eq. (1)*\n\n---\n\nBased on the structure of Eq. (1), which of the following interpretations or derivations are **INCORRECT**? (Select all that apply)", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 5, "Question": "### Background\n\n**Research Question.** This problem explores the core theoretical mechanism from supergame theory used to test for tacit collusion. The central idea is that to sustain cooperation, firms must adjust current prices in response to expected future market conditions.\n\n**Setting / Institutional Environment.** The analysis is grounded in repeated game models where firms weigh the immediate gains from deviating from a collusive strategy against the future losses from a subsequent punishment phase (e.g., a price war).\n\n**Variables & Parameters.**\n- `π^C(k_t)`: Per-firm profit in period `t` under a collusive strategy, conditional on market state `k_t` (e.g., demand and cost).\n- `π^D(k_t)`: Per-firm profit in period `t` from optimally deviating (e.g., undercutting the price), conditional on market state `k_t`.\n- `π^P(k_t)`: Per-firm profit in period `t` during a punishment phase (e.g., reversion to a non-cooperative Nash equilibrium), conditional on market state `k_t`.\n- `δ`: The firm's discount factor, `0 < δ < 1`.\n\n---\n\n### Data / Model Specification\n\nThe fundamental condition for sustaining a tacitly collusive agreement in any period `t` is that the one-time gain from defection must be less than or equal to the discounted present value of the future losses incurred during the punishment phase. This is known as the incentive compatibility (IC) constraint for collusion:\n  \nπ^D(k_t) - π^C(k_t) ≤ ∑_{s=1}^{∞} δ^s [E_t(π^C(k_{t+s})) - E_t(π^P(k_{t+s}))] \\quad \\text{(Eq. (1))}\n \n\n---\n\nAccording to the logic of the incentive compatibility constraint in Eq. (1), which of the following statements correctly describe the mechanics of tacit collusion?\n", "Options": {"A": "If punishment-phase profits (`π^P`) are pro-cyclical, the model's predictions hold only if collusive profits (`π^C`) are more sensitive to demand changes than punishment-phase profits are.", "B": "An increase in the firm's discount factor (`δ`) tightens the IC constraint, making collusion harder to sustain because future punishment is valued less.", "C": "The gain from defection, represented by the left-hand side of the constraint, is primarily a function of expected future market conditions.", "D": "An increase in expected future demand, holding current conditions constant, relaxes the IC constraint by increasing the right-hand side, thus allowing for a higher current collusive margin."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item assesses understanding of the formal logic of the incentive compatibility constraint in supergame models, including comparative statics and the role of key assumptions. Depth Strategy: Reverse-Reasoning (identifying correct logical consequences of the model). Distractor Logic: Option C is a Conceptual Opposite; a higher discount factor makes future punishment more salient, relaxing the constraint. Option D is a Conceptual Opposite; the gain from defection is a function of *current* market conditions, while the loss from punishment depends on *future* conditions.", "qid": "5", "question": "### Background\n\n**Research Question.** This problem explores the core theoretical mechanism from supergame theory used to test for tacit collusion. The central idea is that to sustain cooperation, firms must adjust current prices in response to expected future market conditions.\n\n**Setting / Institutional Environment.** The analysis is grounded in repeated game models where firms weigh the immediate gains from deviating from a collusive strategy against the future losses from a subsequent punishment phase (e.g., a price war).\n\n**Variables & Parameters.**\n- `π^C(k_t)`: Per-firm profit in period `t` under a collusive strategy, conditional on market state `k_t` (e.g., demand and cost).\n- `π^D(k_t)`: Per-firm profit in period `t` from optimally deviating (e.g., undercutting the price), conditional on market state `k_t`.\n- `π^P(k_t)`: Per-firm profit in period `t` during a punishment phase (e.g., reversion to a non-cooperative Nash equilibrium), conditional on market state `k_t`.\n- `δ`: The firm's discount factor, `0 < δ < 1`.\n\n---\n\n### Data / Model Specification\n\nThe fundamental condition for sustaining a tacitly collusive agreement in any period `t` is that the one-time gain from defection must be less than or equal to the discounted present value of the future losses incurred during the punishment phase. This is known as the incentive compatibility (IC) constraint for collusion:\n  \nπ^D(k_t) - π^C(k_t) ≤ ∑_{s=1}^{∞} δ^s [E_t(π^C(k_{t+s})) - E_t(π^P(k_{t+s}))] \\quad \\text{(Eq. (1))}\n \n\n---\n\nAccording to the logic of the incentive compatibility constraint in Eq. (1), which of the following statements correctly describe the mechanics of tacit collusion?\n", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 19, "Question": "### Background\n\nAn econometrician is studying technology spillovers from direct foreign investment (DFI). A key challenge is that foreign investors may be attracted to inherently more productive industries. This selection process can bias the estimated spillover effect.\n\n### Data / Model Specification\n\nThe true data generating process for a domestic plant's log output (`Y`) is:\n\n  \nY_{ijt} = \\beta_0 + \\beta_2 Sector\\_DFI_{jt} + \\alpha_j + \\varepsilon_{ijt}\n \n\nwhere `Sector_DFI` is the foreign presence in sector `j`, and `αⱼ` is an unobserved, time-invariant component of productivity specific to industry `j`. A higher `αⱼ` means a more productive industry.\n\nTwo models are estimated:\n1.  **Model with Dummies:** Includes industry fixed effects, providing an unbiased estimate of the true spillover effect, `β₂`.\n2.  **Model without Dummies:** Omits industry fixed effects, mimicking earlier cross-section studies. It yields a potentially biased estimate, `b₂`.\n\nThe results are:\n\n| Variable | Model with Dummies (Unbiased) | Model without Dummies (Biased) |\n|:---|:---:|:---:|\n| `Sector_DFI` | -0.267 | 0.058 |\n\n---\n\nGiven the theoretical framework and the empirical results, which of the following statements are correct? (Select all that apply)", "Options": {"A": "The true causal effect of increased foreign presence on domestic firm productivity is positive, but smaller than what the biased model suggests.", "B": "The model without dummies incorrectly suggests that DFI generates positive spillovers, leading to policy advice opposite to that suggested by the unbiased model.", "C": "The omitted variable bias in the model without dummies is positive and large enough to change the sign of the estimated coefficient.", "D": "The fact that foreign investors gravitate towards more productive industries implies that the covariance between `Sector_DFI` and the unobserved productivity `αⱼ` is positive."}, "Answer": ["B", "C", "D"], "pi_justification": "This item uses a Reverse-Reasoning strategy. Given the empirical results (the outcome), the user must identify the plausible causes and logical consequences related to omitted variable bias. Option A correctly translates the paper's narrative ('gravitate towards more productive industries') into a formal statistical condition. Option B requires the user to calculate the bias (0.058 - (-0.267) = 0.325) and confirm it is positive and sign-flipping. Option C correctly identifies the conflicting policy implications. Option D is a Conceptual Opposite distractor; the true causal effect (`β₂ = -0.267`) is negative, not positive.", "qid": "19", "question": "### Background\n\nAn econometrician is studying technology spillovers from direct foreign investment (DFI). A key challenge is that foreign investors may be attracted to inherently more productive industries. This selection process can bias the estimated spillover effect.\n\n### Data / Model Specification\n\nThe true data generating process for a domestic plant's log output (`Y`) is:\n\n  \nY_{ijt} = \\beta_0 + \\beta_2 Sector\\_DFI_{jt} + \\alpha_j + \\varepsilon_{ijt}\n \n\nwhere `Sector_DFI` is the foreign presence in sector `j`, and `αⱼ` is an unobserved, time-invariant component of productivity specific to industry `j`. A higher `αⱼ` means a more productive industry.\n\nTwo models are estimated:\n1.  **Model with Dummies:** Includes industry fixed effects, providing an unbiased estimate of the true spillover effect, `β₂`.\n2.  **Model without Dummies:** Omits industry fixed effects, mimicking earlier cross-section studies. It yields a potentially biased estimate, `b₂`.\n\nThe results are:\n\n| Variable | Model with Dummies (Unbiased) | Model without Dummies (Biased) |\n|:---|:---:|:---:|\n| `Sector_DFI` | -0.267 | 0.058 |\n\n---\n\nGiven the theoretical framework and the empirical results, which of the following statements are correct? (Select all that apply)", "model_evaluation_result": {"model_raw_response": "\"B,C,D\"", "model_answer": ["B", "C", "D"], "error": null}}
{"ID": 2, "Question": "### Background\n\nThis problem investigates the robustness of the paper's cyclic pricing model by examining its behavior in the limit as the time between price changes shrinks to zero. This transitions the model from discrete to continuous time. Let `T` be the calendar time between price changes and `L=nT` be the total calendar time of a cycle of `n` periods.\n\n### Data / Model Specification\n\nThe equilibrium cycle length in calendar time, `L`, is the root of a function `f(L,T)`. As the period length `T` approaches zero, this function has a well-defined limit, `f(L,0)`:\n\n  \nf(L,0) = -B(1-\\beta^{L})^{-2} \\left[ |\\log(\\beta)| L - (1-\\beta^{L}) \\right] + |\\log(\\beta)| L \\quad \\text{(Eq. (1))}\n \n\nHere, `B` is a parameter such that `0 < B < 1`. The paper establishes that `f(L,0)` is continuous, upward sloping in `L`, and becomes positive for large `L`.\n\n### Question\n\nSelect all statements that correctly describe the model's properties in the continuous-time limit (as the period length `T` approaches zero).", "Options": {"A": "The mathematical proof for a positive cycle length `L*` relies on showing that `lim_{L→0} f(L,0) = 0`, which ensures that for any infinitesimally small `L > 0`, the function is positive.", "B": "The existence of a positive equilibrium cycle length `L* > 0` in the limit is guaranteed because the function `f(L,0)` has a negative vertical intercept at `L=0` and is known to be upward sloping and eventually positive.", "C": "The model's prediction of cyclic pricing persists in continuous time because the continual influx of new high-valuation consumers supports high prices after the current cohort buys, unlike in single-cohort models.", "D": "As the period length `T` approaches zero, the calendar time of a cycle, `L`, also approaches zero, meaning the monopolist ultimately loses the ability to price discriminate."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: This item assesses the student's understanding of the model's robustness, its connection to the Coase conjecture literature, and the mathematical reasoning that supports its conclusions in the continuous-time limit.\n\nStrategy: Atomic Decomposition. The question presents statements about the economic intuition, the main result, the mathematical logic, and a plausible but incorrect mathematical detail.\n\nDistractor Logic:\n- Option B (Conceptual Opposite): This describes the outcome of many single-cohort models (related to the Coase conjecture) and is the direct opposite of what the paper proves. The paper shows `L` converges to a positive constant.\n- Option D (Step-Omission / Formula Misuse): This distractor presents an incorrect mathematical fact. The limit of `f(L,0)` as `L` approaches 0 is `-B/2`, not 0. The fact that the function starts *negative* is crucial for invoking the Intermediate Value Theorem to prove a positive root exists.", "qid": "2", "question": "### Background\n\nThis problem investigates the robustness of the paper's cyclic pricing model by examining its behavior in the limit as the time between price changes shrinks to zero. This transitions the model from discrete to continuous time. Let `T` be the calendar time between price changes and `L=nT` be the total calendar time of a cycle of `n` periods.\n\n### Data / Model Specification\n\nThe equilibrium cycle length in calendar time, `L`, is the root of a function `f(L,T)`. As the period length `T` approaches zero, this function has a well-defined limit, `f(L,0)`:\n\n  \nf(L,0) = -B(1-\\beta^{L})^{-2} \\left[ |\\log(\\beta)| L - (1-\\beta^{L}) \\right] + |\\log(\\beta)| L \\quad \\text{(Eq. (1))}\n \n\nHere, `B` is a parameter such that `0 < B < 1`. The paper establishes that `f(L,0)` is continuous, upward sloping in `L`, and becomes positive for large `L`.\n\n### Question\n\nSelect all statements that correctly describe the model's properties in the continuous-time limit (as the period length `T` approaches zero).", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 9, "Question": "### Background\n\n**Research Question.** This problem requires understanding the key properties of the country-level aggregate production function, which is derived from plant-level microfoundations.\n\n**Setting.** A country `i` consists of `N_i` production locations. Output can be produced at these locations by domestic firms or by foreign firms. The country optimally allocates its aggregate composite input, `Z_i`, across all active plants to maximize total output.\n\n### Data / Model Specification\n\nAt a single location, output from a domestic-owned plant (`y_d`) and a foreign-owned plant (`y_f`) are given by:\n  \ny_d = A_i z_d^{1-\\phi}\ny_f = \\sigma_i A_i z_f^{1-\\phi}\n \nwhere `z` is the composite input and `\\phi \\in (0,1)` governs diminishing returns at the plant level.\n\nThis micro-setup leads to the derived country aggregate production function:\n  \nY_i = A_i N_i^{\\phi} \\left( M_i + \\omega_i \\sum_{j \\ne i} M_j \\right)^{\\phi} (K_i^{\\alpha} L_i^{1-\\alpha})^{1-\\phi}\n \nwhere `{K_i, L_i, {M_j}}` are the productive inputs.\n\n### Question\n\nBased on the model's microfoundations and the resulting aggregate production function, select all statements that are correct.", "Options": {"A": "The aggregate production function exhibits constant returns to scale with respect to the productive inputs `{K_i, L_i, {M_j}}`.", "B": "The model implies that to maximize output, a country should allocate more of its composite input to foreign-owned plants than to domestic-owned plants (`z_f > z_d`).", "C": "A country's size, as measured by the number of locations `N_i`, generates a scale advantage because technology capital (`M`) is non-rival and can be leveraged across all `N_i` locations.", "D": "The aggregate production function exhibits increasing returns to scale with respect to the productive inputs `{K_i, L_i, {M_j}}`."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: Tests understanding of the key properties of the paper's central theoretical construct: the aggregate production function. Strategy: Atomic Decomposition. The question asks for all correct statements, testing multiple independent properties of the function. Correct options test the returns to scale w.r.t. inputs (A) and the economic intuition for the scale effect of country size `N_i` (B). Distractor Logic: (D) is a Conceptual Opposite to (A) and a common point of confusion. (C) is a Conceptual Opposite to the model's logic; since foreign plants are less productive (`sigma_i < 1`), they receive *less* input to equalize marginal products.", "qid": "9", "question": "### Background\n\n**Research Question.** This problem requires understanding the key properties of the country-level aggregate production function, which is derived from plant-level microfoundations.\n\n**Setting.** A country `i` consists of `N_i` production locations. Output can be produced at these locations by domestic firms or by foreign firms. The country optimally allocates its aggregate composite input, `Z_i`, across all active plants to maximize total output.\n\n### Data / Model Specification\n\nAt a single location, output from a domestic-owned plant (`y_d`) and a foreign-owned plant (`y_f`) are given by:\n  \ny_d = A_i z_d^{1-\\phi}\ny_f = \\sigma_i A_i z_f^{1-\\phi}\n \nwhere `z` is the composite input and `\\phi \\in (0,1)` governs diminishing returns at the plant level.\n\nThis micro-setup leads to the derived country aggregate production function:\n  \nY_i = A_i N_i^{\\phi} \\left( M_i + \\omega_i \\sum_{j \\ne i} M_j \\right)^{\\phi} (K_i^{\\alpha} L_i^{1-\\alpha})^{1-\\phi}\n \nwhere `{K_i, L_i, {M_j}}` are the productive inputs.\n\n### Question\n\nBased on the model's microfoundations and the resulting aggregate production function, select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 1, "Question": "### Background\n\nA monopolist sells an infinitely durable good to a market with a constant inflow of new consumers each period. A fraction `α` are high-valuation (per-period utility `b₁`), and `1-α` are low-valuation (per-period utility `b₂`). The monopolist cannot commit to a future price path, creating a time-consistency problem: a plan that is optimal today may be repudiated by the monopolist's future self, who will face a large accumulated stock of low-valuation consumers.\n\n### Data / Model Specification\n\nThe monopolist and consumers share the same discount factor, `ρ=β`. The monopolist's discounted profit, as viewed from the start of a cycle (`j=1`) for a cycle of length `n`, is denoted `π(n,1)`. The profitability of extending a cycle from `n` to `n+1` periods is governed by:\n\n  \n\\text{sign}[\\pi(n+1,1) - \\pi(n,1)] = \\text{sign}(\\alpha b_{1} - b_{2}) \\quad \\text{for all } n>0 \\quad \\text{(Eq. (1))}\n \n\nIn the no-commitment case, the subgame perfect equilibrium cycle length `n*` is the smallest positive integer such that `f(n*) ≥ 0`, where `f(j) = π(j,j) - π(j+1,j)` represents the marginal gain to the monopolist at period `j` of ending the cycle immediately versus continuing.\n\n### Question\n\nSelect all statements that correctly describe the monopolist's strategy and the resulting equilibrium under the paper's assumptions.", "Options": {"A": "The no-commitment equilibrium cycle length `n*` is the length that maximizes the profit `π(n,1)` for the monopolist at the start of the cycle (`j=1`).", "B": "The commitment strategy to never hold a sale is not time-consistent because as low-valuation consumers accumulate, a future monopolist self (`j`-man) has an incentive to deviate by cutting the price to `V₂` to capture a large immediate profit.", "C": "The condition `αb₁ > b₂` ensures a non-trivial price cycle (`n* > 1`) because it makes holding an immediate sale more profitable than continuing the cycle for the monopolist at `j=1`.", "D": "Under a credible commitment mechanism and assuming `αb₁ > b₂`, the monopolist's profit-maximizing strategy is to set an infinite cycle length, effectively charging the high reservation price `V₁` forever."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item tests the student's understanding of the paper's core theoretical tension between the optimal strategy under commitment and the time-consistent equilibrium without it.\n\nStrategy: Atomic Decomposition. The question breaks down the paper's central argument into four distinct propositions, requiring the student to evaluate each one.\n\nDistractor Logic:\n- Option C (Conceptual Opposite): This is incorrect because the monopolist at `j=1` (`one-man`) would prefer an infinite cycle length if `αb₁ > b₂`, as shown by Eq. (1). The finite `n*` is a result of the time-consistency constraint, not `one-man`'s unconstrained preference.\n- Option D (Almost Right / Reversed Logic): This is incorrect because the condition `αb₁ > b₂` implies `f(1) < 0`, meaning the monopolist at `j=1` prefers to *continue* the cycle, not end it. This preference to continue is what initiates a cycle longer than one period.", "qid": "1", "question": "### Background\n\nA monopolist sells an infinitely durable good to a market with a constant inflow of new consumers each period. A fraction `α` are high-valuation (per-period utility `b₁`), and `1-α` are low-valuation (per-period utility `b₂`). The monopolist cannot commit to a future price path, creating a time-consistency problem: a plan that is optimal today may be repudiated by the monopolist's future self, who will face a large accumulated stock of low-valuation consumers.\n\n### Data / Model Specification\n\nThe monopolist and consumers share the same discount factor, `ρ=β`. The monopolist's discounted profit, as viewed from the start of a cycle (`j=1`) for a cycle of length `n`, is denoted `π(n,1)`. The profitability of extending a cycle from `n` to `n+1` periods is governed by:\n\n  \n\\text{sign}[\\pi(n+1,1) - \\pi(n,1)] = \\text{sign}(\\alpha b_{1} - b_{2}) \\quad \\text{for all } n>0 \\quad \\text{(Eq. (1))}\n \n\nIn the no-commitment case, the subgame perfect equilibrium cycle length `n*` is the smallest positive integer such that `f(n*) ≥ 0`, where `f(j) = π(j,j) - π(j+1,j)` represents the marginal gain to the monopolist at period `j` of ending the cycle immediately versus continuing.\n\n### Question\n\nSelect all statements that correctly describe the monopolist's strategy and the resulting equilibrium under the paper's assumptions.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 10, "Question": "### Background\n\n**Research Question.** A central challenge in empirical studies of social networks is identifying the nature of strategic interactions. An observed positive correlation between an agent's network connectivity (degree) and their propensity to take an action (e.g., vaccinate) could arise from fundamentally different strategic environments. This problem explores this observational equivalence and the risk of policy failure when the underlying mechanism is misspecified.\n\n**Setting / Institutional Environment.** A policymaker observes that individuals with a higher degree `$k$` are more likely to vaccinate (`$x=1$`). The policymaker is considering an intervention but is uncertain about the true model governing behavior. Two models are consistent with the data.\n\n### Data / Model Specification\n\nAn agent's payoff is given by `$\\Pi = f(x,s) - c(x)$`, where `$x \\in \\{0,1\\}$` is the agent's action, `$s$` is a statistic aggregating their neighbors' actions, and `$c$` is a cost. The probability that a random neighbor vaccinates is `$p_{\\sigma}$`.\n\n**Model A: Strategic Substitutes (Weakest-Link Game)**\n- An agent's payoff is `$\\Pi = 1-c$` if they vaccinate (`$x=1$`).\n- The payoff is `$\\Pi = s$` if they do not vaccinate (`$x=0$`), where `$s = \\min(\\text{neighbors' actions})$`.\n- This is a game of strategic substitutes, where another's contribution reduces one's own incentive to contribute.\n\n**Model B: Strategic Complements (Conformity Game)**\n- An agent's payoff is `$\\Pi = s-c$` if they vaccinate (`$x=1$`).\n- The payoff is `$\\Pi = 0$` if they do not vaccinate (`$x=0$`), where `$s = \\max(\\text{neighbors' actions})$`.\n- This is a game of strategic complements, where another's action increases one's own incentive to act.\n\n**Theoretical Primitives:**\n- A statistic `$s$` is **FOSD degree-increasing** if the distribution of `$s$` for a degree-`(k+1)` agent first-order stochastically dominates that for a degree-`$k$` agent. The 'maximum' is an example.\n- A statistic `$s$` is **FOSD degree-decreasing** if the distribution for a degree-`$k$` agent first-order stochastically dominates that for a degree-`(k+1)` agent. The 'minimum' is an example.\n\n### Question\n\nBased on the provided models and theoretical framework, select all statements that are correct.", "Options": {"A": "A policy that forces some low-degree agents to vaccinate is effective under both models because increasing the overall vaccination rate `$p_{\\sigma}$` universally strengthens the incentive for others to vaccinate.", "B": "The 'minimum' statistic (used in Model A) is classified as FOSD degree-increasing, which, when combined with the substitutes property, leads to a positive relationship between degree and action.", "C": "In Model A (Substitutes), an agent's incentive to vaccinate increases with degree `$k$` because the probability of successfully free-riding by having all neighbors vaccinate, `$p_{\\sigma}^k$`, decreases as `$k$` rises.", "D": "In Model B (Complements), an agent's incentive to vaccinate increases with degree `$k$` because the probability of gaining a positive payoff by having at least one neighbor vaccinate, `$1 - (1-p_{\\sigma})^k$`, increases as `$k$` rises."}, "Answer": ["C", "D"], "pi_justification": "This item assesses the understanding of the paper's core identification problem through **Atomic Decomposition**. It splits the complex original QA into testable propositions about the mechanisms of two observationally equivalent models. **Option A** and **Option B** are correct statements detailing these distinct mechanisms. The distractors are designed for high fidelity: **Option C** presents a plausible but incorrect policy generalization (Conceptual Opposite), failing to account for the free-riding incentive in the substitutes model. **Option D** introduces a specific factual error regarding the classification of the 'minimum' statistic (Conceptual Error), testing close reading of the theoretical primitives.", "qid": "10", "question": "### Background\n\n**Research Question.** A central challenge in empirical studies of social networks is identifying the nature of strategic interactions. An observed positive correlation between an agent's network connectivity (degree) and their propensity to take an action (e.g., vaccinate) could arise from fundamentally different strategic environments. This problem explores this observational equivalence and the risk of policy failure when the underlying mechanism is misspecified.\n\n**Setting / Institutional Environment.** A policymaker observes that individuals with a higher degree `$k$` are more likely to vaccinate (`$x=1$`). The policymaker is considering an intervention but is uncertain about the true model governing behavior. Two models are consistent with the data.\n\n### Data / Model Specification\n\nAn agent's payoff is given by `$\\Pi = f(x,s) - c(x)$`, where `$x \\in \\{0,1\\}$` is the agent's action, `$s$` is a statistic aggregating their neighbors' actions, and `$c$` is a cost. The probability that a random neighbor vaccinates is `$p_{\\sigma}$`.\n\n**Model A: Strategic Substitutes (Weakest-Link Game)**\n- An agent's payoff is `$\\Pi = 1-c$` if they vaccinate (`$x=1$`).\n- The payoff is `$\\Pi = s$` if they do not vaccinate (`$x=0$`), where `$s = \\min(\\text{neighbors' actions})$`.\n- This is a game of strategic substitutes, where another's contribution reduces one's own incentive to contribute.\n\n**Model B: Strategic Complements (Conformity Game)**\n- An agent's payoff is `$\\Pi = s-c$` if they vaccinate (`$x=1$`).\n- The payoff is `$\\Pi = 0$` if they do not vaccinate (`$x=0$`), where `$s = \\max(\\text{neighbors' actions})$`.\n- This is a game of strategic complements, where another's action increases one's own incentive to act.\n\n**Theoretical Primitives:**\n- A statistic `$s$` is **FOSD degree-increasing** if the distribution of `$s$` for a degree-`(k+1)` agent first-order stochastically dominates that for a degree-`$k$` agent. The 'maximum' is an example.\n- A statistic `$s$` is **FOSD degree-decreasing** if the distribution for a degree-`$k$` agent first-order stochastically dominates that for a degree-`(k+1)` agent. The 'minimum' is an example.\n\n### Question\n\nBased on the provided models and theoretical framework, select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 18, "Question": "### Background\n\nA government development agency wants to use a limited budget to subsidize a 100% foreign takeover of a single, currently domestic plant to maximize the net productivity of the *entire sector*. The sector contains one large domestic plant and ten small domestic plants.\n\n### Data / Model Specification\n\nThe agency uses the 'within' coefficients from a study on DFI, which are robust to selection bias.\n\n**Table 1: Causal Effects of DFI by Plant Size ('Within' Estimator)**\n\n| Effect | Small Plants (≤ 49 employees) | Large Plants (> 49 employees) |\n|:---|:---:|:---:|\n| Own-Plant Effect (`Plant_DFI`) | 0.100 | -0.018 |\n| Spillover Effect (`Sector_DFI`) | -0.340 | -0.214 |\n\n*Assumption: All plants have equal employment shares, so the takeover of any single plant increases the sector-level DFI (`Sector_DFI`) by 1/11.*\n\n---\n\nAn analyst calculates the net change in total sectoral log output for two policy choices: (1) subsidizing the takeover of one small plant, and (2) subsidizing the takeover of the large plant. Which of the following statements about this policy scenario are correct? (Select all that apply)", "Options": {"A": "The total negative spillover effect on all other plants in the sector is more severe if the large plant is acquired.", "B": "Subsidizing the takeover of the small plant is the superior policy choice, as it results in a less negative overall impact on the sector.", "C": "The direct productivity gain for the recipient plant is positive if a small plant is chosen, but negative if the large plant is chosen.", "D": "The overall net impact on total sectoral log output is negative regardless of which plant is chosen for the takeover."}, "Answer": ["B", "C", "D"], "pi_justification": "This item uses a Computational Judgment strategy, requiring the user to perform a multi-step calculation and comparison based on provided coefficients. It assesses the ability to synthesize different effects (own-plant vs. spillover, small vs. large) into a net policy impact. Option A is correct based on the signs of the `Plant_DFI` coefficients. Option C is correct because calculations show both net effects are negative (-0.198 for small, -0.327 for large). Option D is correct because -0.198 > -0.327. Option B is a Step-Omission Error distractor; a calculation shows the total negative spillover is `-0.298` if a small plant is acquired and `-0.309` if the large plant is acquired, making the latter slightly more severe, but the question asks about the *policy choice*, and the direct effect is the deciding factor.", "qid": "18", "question": "### Background\n\nA government development agency wants to use a limited budget to subsidize a 100% foreign takeover of a single, currently domestic plant to maximize the net productivity of the *entire sector*. The sector contains one large domestic plant and ten small domestic plants.\n\n### Data / Model Specification\n\nThe agency uses the 'within' coefficients from a study on DFI, which are robust to selection bias.\n\n**Table 1: Causal Effects of DFI by Plant Size ('Within' Estimator)**\n\n| Effect | Small Plants (≤ 49 employees) | Large Plants (> 49 employees) |\n|:---|:---:|:---:|\n| Own-Plant Effect (`Plant_DFI`) | 0.100 | -0.018 |\n| Spillover Effect (`Sector_DFI`) | -0.340 | -0.214 |\n\n*Assumption: All plants have equal employment shares, so the takeover of any single plant increases the sector-level DFI (`Sector_DFI`) by 1/11.*\n\n---\n\nAn analyst calculates the net change in total sectoral log output for two policy choices: (1) subsidizing the takeover of one small plant, and (2) subsidizing the takeover of the large plant. Which of the following statements about this policy scenario are correct? (Select all that apply)", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 15, "Question": "### Background\n\n**Research Question.** This problem investigates the theoretical and practical foundations of Bayesian point estimation, starting from the definition of the posterior distribution and culminating in the challenge of statistical inference with its numerical approximation.\n\n**Setting / Institutional Environment.** In a standard Bayesian framework, after combining a prior belief $\\pi(\\theta)$ with data evidence contained in summary statistics $T_n$, all information about an unknown parameter vector $\\theta$ is summarized by the posterior distribution. A key task is to choose a single value (a point estimate) to represent this distribution. In practice, this estimate is often computed via simulation.\n\n**Variables & Parameters.**\n- $\\theta$: A $d$-dimensional vector of unknown parameters.\n- $T_n$: A vector of summary statistics from a data sample of size $n$.\n- $l_n(\\theta)$: The log-likelihood function.\n- $\\pi(\\theta)$: The prior probability density function of $\\theta$.\n- $m$: The number of draws from the posterior distribution used for numerical approximation.\n- $\\{\\theta_{jn}\\}_{j=1}^m$: A sequence of $m$ draws from the posterior density $f_n(\\theta|T_n)$, often from an MCMC algorithm.\n\n---\n\n### Data / Model Specification\n\nThe posterior density of $\\theta$ given $T_n$ is defined as:\n\n  \nf_{n}(\\theta|T_{n})=\\frac{e^{l_{n}(\\theta)}\\pi(\\theta)}{\\int e^{l_{n}(\\theta)}\\pi(\\theta)d\\theta} \\quad \\text{(Eq. (1))}\n \n\nThe posterior mean is the expectation of $\\theta$ with respect to this density:\n\n  \n\\mathbb{E}[\\theta|T_{n}]=\\int\\theta f_{n}(\\theta|T_{n})d\\theta \\quad \\text{(Eq. (2))}\n \n\nWhen Eq. (2) is intractable, it is approximated by the Conditional Mean Estimator (CME):\n\n  \n\\widehat{\\theta}_{m n}=\\frac{1}{m}\\sum_{j=1}^{m}\\theta_{j n} \\quad \\text{(Eq. (3))}\n \n\n---\n\n### Question\n\nIn the context of Bayesian estimation described, select all statements that are INCORRECT.", "Options": {"A": "The posterior mean, $\\mathbb{E}[\\theta|T_n]$, is the optimal point estimate under expected posterior squared error loss.", "B": "The data sample size ($n$) primarily controls the numerical approximation error, while the number of MCMC iterations ($m$) controls the statistical uncertainty.", "C": "The denominator in Eq. (1), $\\int e^{l_{n}(\\theta)}\\pi(\\theta)d\\theta$, is the marginal likelihood and serves to ensure the posterior is a proper probability distribution.", "D": "If MCMC draws {$\\theta_{jn}$} are positively serially correlated, the standard variance formula $\\text{Var}(\\theta|T_n)/m$ provides a conservative (overestimated) variance for the CME, $\\widehat{\\theta}_{mn}$."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item tests foundational knowledge of Bayesian estimation, including decision theory, the distinction between statistical and numerical error, and the practical challenges of MCMC-based inference. Strategy: Complement-set selection. The question asks students to identify all *incorrect* statements, which forces a careful evaluation of each proposition. The incorrect statements (B, C) are designed as high-fidelity distractors that directly reverse the correct conceptual relationships regarding the roles of $n$ and $m$ (B) and the effect of serial correlation on variance estimation (C). The other two options (A, D) are verifiably correct statements from the original QA.", "qid": "15", "question": "### Background\n\n**Research Question.** This problem investigates the theoretical and practical foundations of Bayesian point estimation, starting from the definition of the posterior distribution and culminating in the challenge of statistical inference with its numerical approximation.\n\n**Setting / Institutional Environment.** In a standard Bayesian framework, after combining a prior belief $\\pi(\\theta)$ with data evidence contained in summary statistics $T_n$, all information about an unknown parameter vector $\\theta$ is summarized by the posterior distribution. A key task is to choose a single value (a point estimate) to represent this distribution. In practice, this estimate is often computed via simulation.\n\n**Variables & Parameters.**\n- $\\theta$: A $d$-dimensional vector of unknown parameters.\n- $T_n$: A vector of summary statistics from a data sample of size $n$.\n- $l_n(\\theta)$: The log-likelihood function.\n- $\\pi(\\theta)$: The prior probability density function of $\\theta$.\n- $m$: The number of draws from the posterior distribution used for numerical approximation.\n- $\\{\\theta_{jn}\\}_{j=1}^m$: A sequence of $m$ draws from the posterior density $f_n(\\theta|T_n)$, often from an MCMC algorithm.\n\n---\n\n### Data / Model Specification\n\nThe posterior density of $\\theta$ given $T_n$ is defined as:\n\n  \nf_{n}(\\theta|T_{n})=\\frac{e^{l_{n}(\\theta)}\\pi(\\theta)}{\\int e^{l_{n}(\\theta)}\\pi(\\theta)d\\theta} \\quad \\text{(Eq. (1))}\n \n\nThe posterior mean is the expectation of $\\theta$ with respect to this density:\n\n  \n\\mathbb{E}[\\theta|T_{n}]=\\int\\theta f_{n}(\\theta|T_{n})d\\theta \\quad \\text{(Eq. (2))}\n \n\nWhen Eq. (2) is intractable, it is approximated by the Conditional Mean Estimator (CME):\n\n  \n\\widehat{\\theta}_{m n}=\\frac{1}{m}\\sum_{j=1}^{m}\\theta_{j n} \\quad \\text{(Eq. (3))}\n \n\n---\n\n### Question\n\nIn the context of Bayesian estimation described, select all statements that are INCORRECT.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 12, "Question": "### Background\n\n**Research Question.** This problem analyzes how rational, forward-looking voters trade off the desire to influence the current election's outcome against the desire to communicate private information that influences future elections.\n\n**Setting / Institutional Environment.** The setting is a two-period voting game. In period 1, candidates A and C compete. In period 2, the winner of period 1 competes against a new candidate, B. A subset of voters, called \"type-1,\" prefer A to C, but their preference between A and B depends on an unknown state of the world, `s ∈ {s_A, s_B}`. Specifically, they prefer A in state `s_A` and B in state `s_B`. These voters receive private signals about the true state. A \"type-B\" voter is a type-1 voter whose signal indicates state `s_B` is more likely. By voting for C in period 1 (an act of \"communicative voting\"), type-B voters can lower A's vote share, signaling to others that `s_B` is the likely state and thus helping to coordinate votes for B in period 2.\n\n**Variables & Parameters.**\n- `γ`: The probability that a type-B voter votes for C in period 1 (dimensionless).\n- `α_s(γ)`: The expected vote share for candidate A in state `s`, which depends on `γ`.\n- `P_n^{d-m}`: The probability of a voter being pivotal for decision-making (i.e., changing the winner of the period-1 election).\n- `P_n^{com}`: The probability of a voter being pivotal for communication (i.e., changing the collective inference about the state `s` for the period-2 election).\n\n### Data / Model Specification\n\nIn large electorates (`n → +∞`), the probabilities of being pivotal for decision-making (`P_n^{d-m}`) and communication (`P_n^{com}`) both converge to zero. The equilibrium voting strategy is determined by their relative rates of convergence. These rates are captured by `r^{d-m}` and `r^{com}` in the following asymptotic approximations:\n\n  \n\\lim_{n \\to +\\infty} \\frac{\\log(P_n^{d-m})}{n} = \\log(r^{d-m}(\\beta)) \\quad \\text{(Eq. (1))}\n \n\n  \n\\lim_{n \\to +\\infty} \\frac{\\log(P_n^{com})}{n} = \\log(r^{com}(\\beta, \\beta')) \\quad \\text{(Eq. (2))}\n \n\nThe functional forms for these rates are:\n\n  \nr^{d-m}(\\beta) = 2(\\beta(1-\\beta))^{1/2} \\quad \\text{(Eq. (3))}\n \n\nA stable equilibrium level of communicative voting, `γ^*`, occurs when the rates of convergence are equalized: `r_{com}(γ^*) = r_{d-m}(γ^*)`, where `r_{com}(γ) = r^{com}(α_A(γ), α_B(γ))` and `r_{d-m}(γ) = \\max[r^{d-m}(α_A(γ)), r^{d-m}(α_B(γ))]`.\n\n### Question\n\nBased on the model, which of the following statements correctly describe the logic of communicative voting and the factors influencing its equilibrium level?\n", "Options": {"A": "The model predicts that as the number of voters `n` increases, the absolute probability of being pivotal for communication, `P_n^{com}`, increases, making communicative voting more prevalent in larger electorates.", "B": "An increase in the quality of private signals (i.e., making `α_A(γ)` and `α_B(γ)` more distinct) decreases the communicative pivot rate `r_{com}(γ)`, thereby reducing the equilibrium level of communicative voting `γ^*`.", "C": "The decision-making pivot rate, `r^{d-m}(β)`, is maximized when the expected vote share `β` is 0.5, implying that the incentive to vote strategically (rather than communicatively) is strongest when the election is expected to be very close.", "D": "A stable mixed-strategy equilibrium (`0 < γ^* < 1`) requires the exponential convergence rates of the decision-making and communicative pivot probabilities to be equal, ensuring that the expected utility gains from both motives are of the same order of magnitude for large `n`."}, "Answer": ["B", "C", "D"], "pi_justification": "This item assesses the core mechanism of the model. It uses a Reverse-Reasoning strategy, asking for the conditions and comparative statics that lead to the observed equilibrium. \n- **A (Correct):** This correctly synthesizes the equilibrium condition `r_{com} = r_{d-m}` with the voter's utility calculation, as explained in the source QA's second part. \n- **B (Correct):** This tests understanding of the `r^{d-m}` function from Eq. (3). A simple maximization shows the peak is at `β=0.5`, which has a clear strategic interpretation. \n- **C (Correct):** This captures the comparative statics insight from the source QA's third part. Better private information reduces the need for public information aggregation via voting. \n- **D (Distractor - Conceptual Opposite):** This is a fundamental misunderstanding. All pivot probabilities, including `P_n^{com}`, converge to zero as `n` increases. The equilibrium is determined by their relative rates of convergence, not their absolute levels.", "qid": "12", "question": "### Background\n\n**Research Question.** This problem analyzes how rational, forward-looking voters trade off the desire to influence the current election's outcome against the desire to communicate private information that influences future elections.\n\n**Setting / Institutional Environment.** The setting is a two-period voting game. In period 1, candidates A and C compete. In period 2, the winner of period 1 competes against a new candidate, B. A subset of voters, called \"type-1,\" prefer A to C, but their preference between A and B depends on an unknown state of the world, `s ∈ {s_A, s_B}`. Specifically, they prefer A in state `s_A` and B in state `s_B`. These voters receive private signals about the true state. A \"type-B\" voter is a type-1 voter whose signal indicates state `s_B` is more likely. By voting for C in period 1 (an act of \"communicative voting\"), type-B voters can lower A's vote share, signaling to others that `s_B` is the likely state and thus helping to coordinate votes for B in period 2.\n\n**Variables & Parameters.**\n- `γ`: The probability that a type-B voter votes for C in period 1 (dimensionless).\n- `α_s(γ)`: The expected vote share for candidate A in state `s`, which depends on `γ`.\n- `P_n^{d-m}`: The probability of a voter being pivotal for decision-making (i.e., changing the winner of the period-1 election).\n- `P_n^{com}`: The probability of a voter being pivotal for communication (i.e., changing the collective inference about the state `s` for the period-2 election).\n\n### Data / Model Specification\n\nIn large electorates (`n → +∞`), the probabilities of being pivotal for decision-making (`P_n^{d-m}`) and communication (`P_n^{com}`) both converge to zero. The equilibrium voting strategy is determined by their relative rates of convergence. These rates are captured by `r^{d-m}` and `r^{com}` in the following asymptotic approximations:\n\n  \n\\lim_{n \\to +\\infty} \\frac{\\log(P_n^{d-m})}{n} = \\log(r^{d-m}(\\beta)) \\quad \\text{(Eq. (1))}\n \n\n  \n\\lim_{n \\to +\\infty} \\frac{\\log(P_n^{com})}{n} = \\log(r^{com}(\\beta, \\beta')) \\quad \\text{(Eq. (2))}\n \n\nThe functional forms for these rates are:\n\n  \nr^{d-m}(\\beta) = 2(\\beta(1-\\beta))^{1/2} \\quad \\text{(Eq. (3))}\n \n\nA stable equilibrium level of communicative voting, `γ^*`, occurs when the rates of convergence are equalized: `r_{com}(γ^*) = r_{d-m}(γ^*)`, where `r_{com}(γ) = r^{com}(α_A(γ), α_B(γ))` and `r_{d-m}(γ) = \\max[r^{d-m}(α_A(γ)), r^{d-m}(α_B(γ))]`.\n\n### Question\n\nBased on the model, which of the following statements correctly describe the logic of communicative voting and the factors influencing its equilibrium level?\n", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 4, "Question": "### Background\n\n**Research Question.** This problem requires the interpretation and quantification of the main empirical findings regarding tacit collusion in retail gasoline markets.\n\n**Setting / Institutional Environment.** The analysis uses a two-stage least squares (2SLS) estimation of a dynamic price model on a monthly panel of 43 U.S. cities. The goal is to estimate the causal effect of expected future market conditions on current retail margins.\n\n**Variables & Parameters.**\n- `MARGIN_{it}`: Retail-terminal margin (units: cents per gallon).\n- `EXPNVOLUME_{it+1}`: Expected next-period normalized volume (dimensionless).\n- `EXPTERMINAL_{it+1}`: Expected next-period terminal price (units: cents per gallon).\n- Unit of observation: City-month panel (`i` indexes city, `t` indexes month).\n\n---\n\n### Data / Model Specification\n\nThe core estimating equation is a dynamic model for the retail margin, including controls for current conditions and lagged price adjustments.\n  \nMARGIN_{it} = ... + \\alpha_{2}EXPNVOLUME_{it+1} + \\alpha_{4}EXPTERMINAL_{it+1} + ... + \\epsilon_{it} \\quad \\text{(Eq. (1))}\n \nKey results from the 2SLS estimation of this model and relevant sample means are provided below.\n\n**Table 1: 2SLS Estimation Results for Key Variables**\n\n| Variable | Coefficient | Std. Error |\n| :--- | :--- | :--- |\n| `EXPNVOLUME_{t+1}` | 4.158 | 1.533 |\n| `EXPTERMINAL_{t+1}` | -0.063 | 0.022 |\n\n**Table 2: Descriptive Statistics**\n\n| Variable | Mean |\n| :--- | :--- |\n| `MARGIN` | 10.99 |\n| `NVOLUME` | 1.004 |\n| `TERMINAL` | 61.82 |\n\n---\n\nBased on the provided data, which of the following statements are valid quantitative or qualitative inferences?\n", "Options": {"A": "The coefficient on `EXPTERMINAL_{t+1}` is statistically significant at the 1% level.", "B": "If a firm anticipates a 10% increase in next-period normalized volume (from its mean), the model predicts the current retail margin will increase by approximately 0.42 cents per gallon.", "C": "The elasticity of the retail margin with respect to the expected next-period terminal price, evaluated at the sample means, is approximately -0.36.", "D": "The negative sign on the `EXPTERMINAL_{t+1}` coefficient is inconsistent with the tacit collusion hypothesis, which predicts firms raise current margins to offset expected future cost increases."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: This item assesses the ability to perform multi-step calculations (elasticity, counterfactuals) and statistical inference using regression output and descriptive statistics. Depth Strategy: Computational Judgment. Distractor Logic: Option B is a conceptual distractor (Almost Right); the t-stat is ~2.86, which is significant at 5% but not 1%. Option D is a Conceptual Opposite, misstating the prediction of the tacit collusion model.", "qid": "4", "question": "### Background\n\n**Research Question.** This problem requires the interpretation and quantification of the main empirical findings regarding tacit collusion in retail gasoline markets.\n\n**Setting / Institutional Environment.** The analysis uses a two-stage least squares (2SLS) estimation of a dynamic price model on a monthly panel of 43 U.S. cities. The goal is to estimate the causal effect of expected future market conditions on current retail margins.\n\n**Variables & Parameters.**\n- `MARGIN_{it}`: Retail-terminal margin (units: cents per gallon).\n- `EXPNVOLUME_{it+1}`: Expected next-period normalized volume (dimensionless).\n- `EXPTERMINAL_{it+1}`: Expected next-period terminal price (units: cents per gallon).\n- Unit of observation: City-month panel (`i` indexes city, `t` indexes month).\n\n---\n\n### Data / Model Specification\n\nThe core estimating equation is a dynamic model for the retail margin, including controls for current conditions and lagged price adjustments.\n  \nMARGIN_{it} = ... + \\alpha_{2}EXPNVOLUME_{it+1} + \\alpha_{4}EXPTERMINAL_{it+1} + ... + \\epsilon_{it} \\quad \\text{(Eq. (1))}\n \nKey results from the 2SLS estimation of this model and relevant sample means are provided below.\n\n**Table 1: 2SLS Estimation Results for Key Variables**\n\n| Variable | Coefficient | Std. Error |\n| :--- | :--- | :--- |\n| `EXPNVOLUME_{t+1}` | 4.158 | 1.533 |\n| `EXPTERMINAL_{t+1}` | -0.063 | 0.022 |\n\n**Table 2: Descriptive Statistics**\n\n| Variable | Mean |\n| :--- | :--- |\n| `MARGIN` | 10.99 |\n| `NVOLUME` | 1.004 |\n| `TERMINAL` | 61.82 |\n\n---\n\nBased on the provided data, which of the following statements are valid quantitative or qualitative inferences?\n", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 16, "Question": "### Background\n\nThis problem analyzes the core mechanism of the paper's static general equilibrium model. The economy consists of a continuum of penniless entrepreneurs, each characterized by an observable risk type `p ∈ [0, 1]`, a competitive banking sector, and investors who provide a fixed aggregate supply of savings, `w`.\n\n### Data / Model Specification\n\n- **Monitoring Cost:** The cost of monitoring is quadratic: `c(m) = (γ/2)m²`, where `γ > 0`.\n- **Equilibrium Conditions:** The equilibrium safe rate, `R_0*`, is determined by the market clearing condition, which equates the aggregate demand for investment to the total supply of savings `w`. A marginal entrepreneur type, `p*`, separates the non-monitoring (`p ≤ p*`) and monitoring (`p > p*`) sectors. The failure probability for all monitoring banks is equal to `p*`.\n\n### Question\n\nAccording to the model, which of the following effects occur in the new equilibrium after an exogenous increase in the aggregate supply of savings `w`? Select all that apply.", "Options": {"A": "Credit spreads `R_p* - R_0*` for monitoring banks increase.", "B": "The equilibrium safe rate `R_0*` falls.", "C": "The probability of failure for every monitoring bank increases.", "D": "The range of entrepreneurs funded by non-monitoring banks, `[0, p*]`, shrinks."}, "Answer": ["B", "C"], "pi_justification": "Assesses the student's ability to synthesize the full 'search for yield' causal chain. Strategy: Scenario Application. Correct options A and C trace the core mechanism. Distractor B is a Conceptual Opposite (the non-monitoring sector expands). Distractor D is also a Conceptual Opposite and a common misconception (lower rates and compressed spreads, not wider ones, drive the increase in risk).", "qid": "16", "question": "### Background\n\nThis problem analyzes the core mechanism of the paper's static general equilibrium model. The economy consists of a continuum of penniless entrepreneurs, each characterized by an observable risk type `p ∈ [0, 1]`, a competitive banking sector, and investors who provide a fixed aggregate supply of savings, `w`.\n\n### Data / Model Specification\n\n- **Monitoring Cost:** The cost of monitoring is quadratic: `c(m) = (γ/2)m²`, where `γ > 0`.\n- **Equilibrium Conditions:** The equilibrium safe rate, `R_0*`, is determined by the market clearing condition, which equates the aggregate demand for investment to the total supply of savings `w`. A marginal entrepreneur type, `p*`, separates the non-monitoring (`p ≤ p*`) and monitoring (`p > p*`) sectors. The failure probability for all monitoring banks is equal to `p*`.\n\n### Question\n\nAccording to the model, which of the following effects occur in the new equilibrium after an exogenous increase in the aggregate supply of savings `w`? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 7, "Question": "### Background\n\n**Research Question.** This problem examines the equilibrium determination of technology capital stocks and the resulting specialization patterns, focusing on why smaller or later-opening countries might optimally choose to produce no technology capital of their own.\n\n**Setting.** In a multi-country world, each country `i` endogenously chooses its stock of technology capital, `M_i`. The equilibrium is characterized by a no-arbitrage condition: the total return on `M_i` must equal its user cost. This framework is used to analyze a scenario where one country unilaterally opens to a world of `I` closed, identical countries.\n\n### Data / Model Specification\n\nThe total world return on country `i`'s technology capital is the sum of its marginal products in all countries `j` where it can be used:\n  \nr_i(M) = \\sum_{j=1}^I \\frac{\\partial F_j}{\\partial M_i}\n \nThe steady-state equilibrium for `M` is defined by the complementary slackness conditions:\n  \nr_i(M) \\le \\rho + \\delta_m, \\quad \\text{with equality if } M_i > 0 \\quad \\text{(Eq. (1))}\n \nwhere `\\rho + \\delta_m` is the user cost of technology capital.\n\nFor a set of identical countries, the steady-state output can be expressed as:\n  \nY_i = \\psi (AN)_i \\left( M_i + \\omega_i \\sum_{j \\ne i} M_j \\right)^{\\phi / (1 - \\alpha(1-\\phi))}\n \nwhere `psi` is a constant incorporating underlying parameters.\n\n### Question\n\nConsider a world of `I+1` identical countries. One country (`o`) unilaterally becomes fully open (`omega_o=1`), while the other `I` countries (`c`) remain closed (`omega_c=0`). The open country finds it optimal to set its own technology capital to zero (`M_o=0`) and rely on FDI from the `I` closed countries. Based on the model, select all statements that correctly describe this equilibrium.", "Options": {"A": "In equilibrium, every country, including the open one, must invest in technology capital until its total return `r_i(M)` exactly equals the user cost `\\rho + \\delta_m`.", "B": "The open country chooses `M_o=0` because the return to investing in its first unit of domestic technology capital is less than the user cost (`\\rho + \\delta_m`).", "C": "The ratio of the open country's output to a closed country's output is given by `Y_o / Y_c = I^{\\phi / (1 - \\alpha(1-\\phi))}`.", "D": "The output gain for the open country is proportional to `I`, the number of closed countries it can access, because technology capital exhibits increasing returns to scale."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: Tests understanding of the quantitative predictions and the economic logic of specialization in the unilateral opening scenario. Strategy: Atomic Decomposition. The original QA problem's core result is split into independently verifiable statements about the output ratio (A) and the condition for specialization (B). Distractor Logic: (C) is a Conceptual Opposite, ignoring the inequality/corner solution in the equilibrium condition (Eq. 1). (D) is Almost Right; the gain depends on `I`, but the reason is the non-rival nature of technology capital, not increasing returns to scale in the production function (which is CRS).", "qid": "7", "question": "### Background\n\n**Research Question.** This problem examines the equilibrium determination of technology capital stocks and the resulting specialization patterns, focusing on why smaller or later-opening countries might optimally choose to produce no technology capital of their own.\n\n**Setting.** In a multi-country world, each country `i` endogenously chooses its stock of technology capital, `M_i`. The equilibrium is characterized by a no-arbitrage condition: the total return on `M_i` must equal its user cost. This framework is used to analyze a scenario where one country unilaterally opens to a world of `I` closed, identical countries.\n\n### Data / Model Specification\n\nThe total world return on country `i`'s technology capital is the sum of its marginal products in all countries `j` where it can be used:\n  \nr_i(M) = \\sum_{j=1}^I \\frac{\\partial F_j}{\\partial M_i}\n \nThe steady-state equilibrium for `M` is defined by the complementary slackness conditions:\n  \nr_i(M) \\le \\rho + \\delta_m, \\quad \\text{with equality if } M_i > 0 \\quad \\text{(Eq. (1))}\n \nwhere `\\rho + \\delta_m` is the user cost of technology capital.\n\nFor a set of identical countries, the steady-state output can be expressed as:\n  \nY_i = \\psi (AN)_i \\left( M_i + \\omega_i \\sum_{j \\ne i} M_j \\right)^{\\phi / (1 - \\alpha(1-\\phi))}\n \nwhere `psi` is a constant incorporating underlying parameters.\n\n### Question\n\nConsider a world of `I+1` identical countries. One country (`o`) unilaterally becomes fully open (`omega_o=1`), while the other `I` countries (`c`) remain closed (`omega_c=0`). The open country finds it optimal to set its own technology capital to zero (`M_o=0`) and rely on FDI from the `I` closed countries. Based on the model, select all statements that correctly describe this equilibrium.", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 17, "Question": "### Background\n\nAn analysis of Venezuelan manufacturing plants splits the sample into 'small' (≤ 49 employees) and 'large' (> 49 employees) to explore how the effects of direct foreign investment (DFI) differ by firm size. A 'within' (plant fixed effects) estimator is used to control for the possibility that foreign investors 'cherry-pick' already productive plants.\n\n### Data / Model Specification\n\nThe following table presents the key coefficients from the 'within' estimation, which are robust to plant-level selection bias.\n\n**Table 1: Impact of Foreign Ownership by Plant Size ('Within' Estimator Results)**\n\n| Variable | Small Plants (≤ 49 employees) | Large Plants (> 49 employees) |\n|:---|:---:|:---:|\n| `Plant_DFI` | 0.100 | -0.018 |\n| | (0.055) | (0.049) |\n| `Sector_DFI` | -0.340 | -0.214 |\n| | (0.074) | (0.111) |\n\n*Notes: Standard errors in parentheses. `Plant_DFI` measures the 'own-plant' effect of receiving foreign equity. `Sector_DFI` measures the 'spillover' effect from foreign presence in the sector on domestically-owned firms.*\n\n---\n\nBased on the results in Table 1, which of the following conclusions are supported by the evidence? (Select all that apply)", "Options": {"A": "For large plants, the apparent productivity gains from foreign investment are likely due to selection bias, with no true causal effect.", "B": "Large domestic plants experience a net positive spillover from increased foreign presence in their sector.", "C": "The negative competitive 'market-stealing' effect from foreign presence is more severe for small domestic plants than for large ones.", "D": "For small plants, receiving foreign equity is associated with a genuine, statistically significant increase in productivity."}, "Answer": ["A", "C", "D"], "pi_justification": "This item assesses the ability to interpret regression coefficients for different subgroups and draw nuanced conclusions about heterogeneous treatment effects. It uses a Scenario Application strategy, asking the user to apply the findings from the table to specific claims. Option A is correct because the coefficient on `Plant_DFI` for small plants (0.100) is positive and statistically significant. Option B is correct because the coefficient for large plants (-0.018) is statistically insignificant, implying no causal gain. Option C is correct because the negative coefficient on `Sector_DFI` is much larger in magnitude for small plants (-0.340) than for large plants (-0.214). Option D is a Conceptual Opposite distractor, as the spillover effect for large plants is negative (-0.214), not positive.", "qid": "17", "question": "### Background\n\nAn analysis of Venezuelan manufacturing plants splits the sample into 'small' (≤ 49 employees) and 'large' (> 49 employees) to explore how the effects of direct foreign investment (DFI) differ by firm size. A 'within' (plant fixed effects) estimator is used to control for the possibility that foreign investors 'cherry-pick' already productive plants.\n\n### Data / Model Specification\n\nThe following table presents the key coefficients from the 'within' estimation, which are robust to plant-level selection bias.\n\n**Table 1: Impact of Foreign Ownership by Plant Size ('Within' Estimator Results)**\n\n| Variable | Small Plants (≤ 49 employees) | Large Plants (> 49 employees) |\n|:---|:---:|:---:|\n| `Plant_DFI` | 0.100 | -0.018 |\n| | (0.055) | (0.049) |\n| `Sector_DFI` | -0.340 | -0.214 |\n| | (0.074) | (0.111) |\n\n*Notes: Standard errors in parentheses. `Plant_DFI` measures the 'own-plant' effect of receiving foreign equity. `Sector_DFI` measures the 'spillover' effect from foreign presence in the sector on domestically-owned firms.*\n\n---\n\nBased on the results in Table 1, which of the following conclusions are supported by the evidence? (Select all that apply)", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 21, "Question": "### Background\n\n**Research Question.** This problem develops the theoretical foundation for the paper's central hypothesis: that community college enrollment is countercyclical. It uses a lifetime income maximization framework to model educational choice and explores how this choice is affected by economic recessions.\n\n**Setting / Institutional Environment.** An 18-year-old high school graduate `i` with innate ability `a_i` chooses one of three educational paths (`ED`) to maximize the expected present value (`PV`) of lifetime income. Higher ability is assumed to yield a higher economic return to education.\n\n**Variables & Parameters.**\n- `ED`: Educational path chosen. `ED=12` (work immediately), `ED=14` (2-year community college), `ED=16` (4-year college).\n- `PV_{ED}`: Expected present value of lifetime income for path `ED`.\n- `a_i`: Innate ability of individual `i`.\n\n---\n\n### Data / Model Specification\n\nAn individual `i` chooses `ED ∈ {12, 14, 16}` to maximize `PV_{ED}`. The choice between working immediately (`ED=12`) and attending community college (`ED=14`) depends on a comparison of their present values. The model implies that there is a threshold ability level, `a*`, such that individuals with `a_i > a*` choose to enroll in community college.\n\n---\n\n### Question\n\nAccording to the lifetime income maximization model presented, which of the following statements correctly describe the primary mechanism through which an economic recession increases the demand for community college enrollment? Select all that apply.", "Options": {"A": "A recession lowers the expected wages for high school graduates, which reduces the opportunity cost of forgoing work to attend college.", "B": "The reduction in the opportunity cost of attending college causes the threshold ability level (`a*`) of the marginal student indifferent between working and enrolling to decrease.", "C": "A recession makes four-year colleges more expensive, forcing students to substitute towards community colleges.", "D": "A recession increases the long-term wage premium for community college graduates relative to high school graduates, making the investment more attractive."}, "Answer": ["A", "B"], "pi_justification": "REWRITE (from General QA): This item assesses the core theoretical mechanism of the paper—the opportunity cost channel driving countercyclical enrollment. The rewrite uses an **Atomic Decomposition** strategy, breaking the original multi-part reasoning question into distinct, verifiable propositions. This format sharpens the assessment by forcing a choice between the primary mechanism and other plausible but secondary economic channels. Distractor (B) tests confusion between the opportunity cost channel and the returns-to-education channel. Distractor (D) tests confusion with a separate substitution effect.", "qid": "21", "question": "### Background\n\n**Research Question.** This problem develops the theoretical foundation for the paper's central hypothesis: that community college enrollment is countercyclical. It uses a lifetime income maximization framework to model educational choice and explores how this choice is affected by economic recessions.\n\n**Setting / Institutional Environment.** An 18-year-old high school graduate `i` with innate ability `a_i` chooses one of three educational paths (`ED`) to maximize the expected present value (`PV`) of lifetime income. Higher ability is assumed to yield a higher economic return to education.\n\n**Variables & Parameters.**\n- `ED`: Educational path chosen. `ED=12` (work immediately), `ED=14` (2-year community college), `ED=16` (4-year college).\n- `PV_{ED}`: Expected present value of lifetime income for path `ED`.\n- `a_i`: Innate ability of individual `i`.\n\n---\n\n### Data / Model Specification\n\nAn individual `i` chooses `ED ∈ {12, 14, 16}` to maximize `PV_{ED}`. The choice between working immediately (`ED=12`) and attending community college (`ED=14`) depends on a comparison of their present values. The model implies that there is a threshold ability level, `a*`, such that individuals with `a_i > a*` choose to enroll in community college.\n\n---\n\n### Question\n\nAccording to the lifetime income maximization model presented, which of the following statements correctly describe the primary mechanism through which an economic recession increases the demand for community college enrollment? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B\"", "model_answer": ["A", "B"], "error": null}}
{"ID": 14, "Question": "### Background\n\n**Research Question.** This problem investigates the large-sample properties of the Conditional Mean Estimator (CME), establishing its asymptotic equivalence to the Maximum Likelihood Estimator (MLE) and its limiting distribution for inference.\n\n**Setting / Institutional Environment.** We are in a large-sample asymptotic framework where both the data sample size, $n$, and the number of MCMC draws, $m$, go to infinity. The goal is to understand the behavior of the CME, a Bayesian estimator, and relate it to its frequentist counterpart, the MLE.\n\n**Variables & Parameters.**\n- $\\theta_0$: The true, unknown $d$-dimensional parameter vector.\n- $\\widehat{\\theta}_n$: The Maximum Likelihood Estimator of $\\theta$.\n- $\\widehat{\\theta}_{mn}$: The Conditional Mean Estimator (CME) based on a sample of size $n$ and $m$ MCMC draws.\n- $\\Delta_n(\\widehat{\\theta}_n)$: The observed Fisher information, defined as $-l_n^{(2)}(\\widehat{\\theta}_n)$, where $l_n^{(2)}$ is the second derivative of the log-likelihood.\n- $\\pi(\\theta)$: The prior density for $\\theta$.\n- $\\pi^{(1)}(\\theta_0)$: The gradient (first derivative) of the prior density, evaluated at the true parameter $\\theta_0$.\n\n---\n\n### Data / Model Specification\n\nTheorem 2 of the paper provides the key asymptotic results for the CME, $\\widehat{\\theta}_{mn}$:\n\n  \n\\Delta_{n}^{1/2}(\\widehat{\\theta}_{n})\\left(\\widehat{\\theta}_{m n}-\\widehat{\\theta}_{n}\\right) = o_{P}(1) \\quad \\text{(Eq. (1))}\n \n\nUnder stronger assumptions, this can be refined to:\n\n  \n\\varDelta_{n}(\\widehat{\\theta}_{n})\\left(\\widehat{\\theta}_{m n}-\\widehat{\\theta}_{n}\\right) \\rightarrow_P \\frac{\\pi^{(1)}(\\theta_{0})}{\\pi\\left(\\theta_{0}\\right)} \\quad \\text{(Eq. (2))}\n \n\nThe limiting distribution of the CME, which allows for statistical inference, is given by:\n\n  \n\\varDelta_{n}^{1/2}(\\widehat{\\theta}_{n})\\left(\\widehat{\\theta}_{m n}-\\theta_{0}\\right) \\rightarrow_{D} N(0,I_{d}) \\quad \\text{(Eq. (3))}\n \n\n---\n\n### Question\n\nBased on the provided asymptotic results, select all statements that are correct.", "Options": {"A": "Eq. (1) implies that for first-order asymptotic inference, the CME and MLE are not interchangeable because the prior always induces a first-order bias.", "B": "The asymptotic normality result in Eq. (3) holds only if the number of MCMC draws ($m$) is equal to the sample size ($n$).", "C": "The asymptotic difference between the CME and the MLE, $(\\widehat{\\theta}_{mn} - \\widehat{\\theta}_n)$, is of order $O_p(1/n)$ when $\\Delta_n(\\widehat{\\theta}_n)$ is proportional to $n$.", "D": "If the prior for a scalar parameter $\\theta$ is Normal, $\\pi(\\theta) \\sim N(\\mu, \\tau^2)$, and the prior mean is misspecified such that $\\mu < \\theta_0$, the CME ($\\widehat{\\theta}_{mn}$) will be asymptotically smaller than the MLE ($\\widehat{\\theta}_n$)."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: This item tests the ability to interpret the higher-order asymptotic relationship between the CME and MLE, and to derive the practical implications for asymptotic bias. Strategy: Atomic Decomposition. The question asks students to select all correct statements derived from the paper's key theoretical results. Correct options (A, B) are derived from the high-difficulty part of the original QA, testing the direction and order of the asymptotic bias. Distractors are designed based on common misconceptions: C confuses higher-order and first-order effects, and D misinterprets the required relationship between simulation draws ($m$) and sample size ($n$).", "qid": "14", "question": "### Background\n\n**Research Question.** This problem investigates the large-sample properties of the Conditional Mean Estimator (CME), establishing its asymptotic equivalence to the Maximum Likelihood Estimator (MLE) and its limiting distribution for inference.\n\n**Setting / Institutional Environment.** We are in a large-sample asymptotic framework where both the data sample size, $n$, and the number of MCMC draws, $m$, go to infinity. The goal is to understand the behavior of the CME, a Bayesian estimator, and relate it to its frequentist counterpart, the MLE.\n\n**Variables & Parameters.**\n- $\\theta_0$: The true, unknown $d$-dimensional parameter vector.\n- $\\widehat{\\theta}_n$: The Maximum Likelihood Estimator of $\\theta$.\n- $\\widehat{\\theta}_{mn}$: The Conditional Mean Estimator (CME) based on a sample of size $n$ and $m$ MCMC draws.\n- $\\Delta_n(\\widehat{\\theta}_n)$: The observed Fisher information, defined as $-l_n^{(2)}(\\widehat{\\theta}_n)$, where $l_n^{(2)}$ is the second derivative of the log-likelihood.\n- $\\pi(\\theta)$: The prior density for $\\theta$.\n- $\\pi^{(1)}(\\theta_0)$: The gradient (first derivative) of the prior density, evaluated at the true parameter $\\theta_0$.\n\n---\n\n### Data / Model Specification\n\nTheorem 2 of the paper provides the key asymptotic results for the CME, $\\widehat{\\theta}_{mn}$:\n\n  \n\\Delta_{n}^{1/2}(\\widehat{\\theta}_{n})\\left(\\widehat{\\theta}_{m n}-\\widehat{\\theta}_{n}\\right) = o_{P}(1) \\quad \\text{(Eq. (1))}\n \n\nUnder stronger assumptions, this can be refined to:\n\n  \n\\varDelta_{n}(\\widehat{\\theta}_{n})\\left(\\widehat{\\theta}_{m n}-\\widehat{\\theta}_{n}\\right) \\rightarrow_P \\frac{\\pi^{(1)}(\\theta_{0})}{\\pi\\left(\\theta_{0}\\right)} \\quad \\text{(Eq. (2))}\n \n\nThe limiting distribution of the CME, which allows for statistical inference, is given by:\n\n  \n\\varDelta_{n}^{1/2}(\\widehat{\\theta}_{n})\\left(\\widehat{\\theta}_{m n}-\\theta_{0}\\right) \\rightarrow_{D} N(0,I_{d}) \\quad \\text{(Eq. (3))}\n \n\n---\n\n### Question\n\nBased on the provided asymptotic results, select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 3, "Question": "### Background\n\nThis problem focuses on the microfoundations of the cyclic pricing model. A monopolist sells an infinitely durable good to infinitely-lived consumers who discount the future with factor `β`. The monopolist sets prices over a known cycle of length `n`, which ends with a sale at price `p_n = V₂`, where `V₂` is the reservation price of low-valuation consumers.\n\n### Data / Model Specification\n\nThe reservation price `V_i` for a consumer with per-period utility flow `b_i` is the discounted sum of all future flows, `V_i = b_i / (1-β)`. To induce a high-valuation consumer entering at period `j` to purchase immediately rather than wait `h` periods, the monopolist must satisfy the no-arbitrage condition:\n\n  \nV_{1} - p_{j} \\ge \\beta^{h}(V_{1} - p_{j+h}) \\quad \\text{for } h=1, ..., n-j \\quad \\text{(Eq. (1))}\n \n\nThe profit-maximizing price `p_j` is set by making the consumer indifferent between buying now and waiting for the most attractive future option, which is the final sale at period `n`.\n\n### Question\n\nConsider the derivation of the price path `p_j` and a counterfactual scenario where all consumers incur a small, non-monetary transaction cost `c > 0` at the time of purchase. Select all correct statements.", "Options": {"A": "The price `p_j` is set to make a high-valuation consumer indifferent between buying now and waiting for the sale, which implies `V₁ - p_j = V₁ - p_n` and simplifies to `p_j = p_n = V₂` for all `j`.", "B": "With a transaction cost `c`, the monopolist fully absorbs the cost by lowering the price such that `p'_j = p_j - c`, leaving the consumer's net cost (price plus transaction cost) unchanged.", "C": "In the presence of the transaction cost `c`, the new profit-maximizing price `p'_j` is strictly lower than the original price `p_j`, and the economic incidence of the cost is shared between the monopolist and the consumer.", "D": "The equilibrium price `p_j` for `j < n` is `(1 - β^(n-j))V₁ + β^(n-j)V₂`. This represents a weighted average of the high and low reservation prices, with the weight on `V₂` increasing as the sale date (`n`) gets closer."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: This item tests the student's ability to derive and interpret the model's foundational price path and to conduct a correct comparative static analysis (a policy counterfactual).\n\nStrategy: Computational Judgment. The student must derive/verify the price formula and then re-derive it under a new condition to judge the outcome.\n\nDistractor Logic:\n- Option B (Formula Misuse / Conceptual Error): This distractor represents a common and fundamental error in intertemporal models: ignoring the time value of money (discounting). It leads to the incorrect conclusion that prices must be constant.\n- Option D (Conceptual Opposite / Incorrect Incidence): This distractor proposes an incorrect economic incidence of the transaction cost. The monopolist lowers the price, but by `c(1-β^(n-j))`, which is less than the full cost `c`. Therefore, the monopolist does not fully absorb the cost; it is shared.", "qid": "3", "question": "### Background\n\nThis problem focuses on the microfoundations of the cyclic pricing model. A monopolist sells an infinitely durable good to infinitely-lived consumers who discount the future with factor `β`. The monopolist sets prices over a known cycle of length `n`, which ends with a sale at price `p_n = V₂`, where `V₂` is the reservation price of low-valuation consumers.\n\n### Data / Model Specification\n\nThe reservation price `V_i` for a consumer with per-period utility flow `b_i` is the discounted sum of all future flows, `V_i = b_i / (1-β)`. To induce a high-valuation consumer entering at period `j` to purchase immediately rather than wait `h` periods, the monopolist must satisfy the no-arbitrage condition:\n\n  \nV_{1} - p_{j} \\ge \\beta^{h}(V_{1} - p_{j+h}) \\quad \\text{for } h=1, ..., n-j \\quad \\text{(Eq. (1))}\n \n\nThe profit-maximizing price `p_j` is set by making the consumer indifferent between buying now and waiting for the most attractive future option, which is the final sale at period `n`.\n\n### Question\n\nConsider the derivation of the price path `p_j` and a counterfactual scenario where all consumers incur a small, non-monetary transaction cost `c > 0` at the time of purchase. Select all correct statements.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 8, "Question": "### Background\n\n**Research Question.** This problem analyzes the full dynamic consequences of economic opening, focusing on the crucial distinction between a country's true economic output and its measured GDP, and the role of endogenous TFP growth in amplifying long-run gains.\n\n**Setting.** The model's transition analysis reveals that when a small country opens to a large economic bloc, its short-run performance as measured by official statistics can be misleading. This is due to the accounting treatment of intangible investment. Furthermore, the total gains from opening are significantly larger if openness itself fosters productivity growth.\n\n### Data / Model Specification\n\nThe economy-wide resource constraint defines the allocation of true output `Y_i`:\n  \nY_i = C_i + X_{ik} + X_{im}\n \nwhere `C_i` is consumption, `X_{ik}` is investment in tangible (plant-specific) capital, and `X_{im}` is investment in intangible (technology) capital.\n\nStandard national accounting treats intangible investment `X_{im}` as an intermediate business expense, so it is excluded from measured GDP, `Y_i^{\\text{meas}}`:\n  \nY_i^{\\text{meas}} = Y_i - X_{im} = C_i + X_{ik}\n \nIn an extension, the model considers that opening can cause a country's TFP to rise. The paper reports that for a small country, the direct long-run consumption gain (holding TFP fixed) is 30%, while the total gain (with TFP diffusion) is 50%.\n\n### Question\n\nAccording to the paper's transition analysis for a small country opening up, select all statements that are **INCORRECT** or **NOT supported** by the model's predictions.", "Options": {"A": "The indirect benefits of opening, which stem from endogenous TFP growth, are quantitatively larger than the direct benefits from accessing foreign technology capital.", "B": "In the long run, the small country is predicted to specialize completely in technology capital investment, while the large country focuses on plant-specific capital.", "C": "Measured productivity is predicted to fall in the short run because the surge in productive, intangible investment (`X_im`) is subtracted from true output in national accounts.", "D": "The initial drop in consumption following opening is a sign that the liberalization policy is failing, as households are made worse off."}, "Answer": ["A", "B", "D"], "pi_justification": "Assessment Target: Tests understanding of the subtle, policy-relevant dynamics of opening, including the measurement-vs-reality gap and the sources of gains. Strategy: Complement-set selection. The question asks for incorrect statements, forcing the user to identify multiple common misconceptions. The correct answer set consists of three such statements. Distractor Logic: (A) is the single correct statement, representing the core insight about measured productivity; it is a tempting but incorrect choice for the 'select all that are incorrect' prompt. (B) is a Numerical Error; the indirect gain (20%) is smaller than the direct gain (30%). (C) is a Conceptual Opposite; the consumption drop is a rational investment trade-off for future gains. (D) is also a Conceptual Opposite; the model predicts the small country stops investing in technology capital and the large country specializes in it.", "qid": "8", "question": "### Background\n\n**Research Question.** This problem analyzes the full dynamic consequences of economic opening, focusing on the crucial distinction between a country's true economic output and its measured GDP, and the role of endogenous TFP growth in amplifying long-run gains.\n\n**Setting.** The model's transition analysis reveals that when a small country opens to a large economic bloc, its short-run performance as measured by official statistics can be misleading. This is due to the accounting treatment of intangible investment. Furthermore, the total gains from opening are significantly larger if openness itself fosters productivity growth.\n\n### Data / Model Specification\n\nThe economy-wide resource constraint defines the allocation of true output `Y_i`:\n  \nY_i = C_i + X_{ik} + X_{im}\n \nwhere `C_i` is consumption, `X_{ik}` is investment in tangible (plant-specific) capital, and `X_{im}` is investment in intangible (technology) capital.\n\nStandard national accounting treats intangible investment `X_{im}` as an intermediate business expense, so it is excluded from measured GDP, `Y_i^{\\text{meas}}`:\n  \nY_i^{\\text{meas}} = Y_i - X_{im} = C_i + X_{ik}\n \nIn an extension, the model considers that opening can cause a country's TFP to rise. The paper reports that for a small country, the direct long-run consumption gain (holding TFP fixed) is 30%, while the total gain (with TFP diffusion) is 50%.\n\n### Question\n\nAccording to the paper's transition analysis for a small country opening up, select all statements that are **INCORRECT** or **NOT supported** by the model's predictions.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 11, "Question": "### Background\n\n**Research Question.** In many empirical models of peer effects, an agent's payoff is assumed to depend on the *average* action of their neighbors. This problem explores the novel theoretical finding that for such statistics, the nature of the equilibrium relationship between degree and action depends not on standard strategic complementarity/substitutability, but on higher-order properties of the payoff function and the stability of the resulting equilibria.\n\n**Setting / Institutional Environment.** Consider a symmetric Bayesian network game where the relevant statistic `$s$` is the average of neighbors' actions. Agents choose an action `$x \\in \\{0,1\\}$` to maximize their payoff.\n\n### Data / Model Specification\n\nThe 'average' statistic `$s$` has two key properties under degree independence:\n1.  **Degree-stable:** The expected value `$E_k(s)` is constant for all degrees `$k$`.\n2.  **Satisfies SOSD:** The distribution of `$s$` undergoes a mean-preserving contraction as `$k$` increases, meaning its variance `$\\text{Var}_k(s)$` is strictly decreasing in `$k$`.\n\nAn agent's payoff is `$\\Pi = f(x,s) - c(x)$`. The key theoretical results are:\n- **Proposition 1 (part 2a):** If `$s$` is degree-stable and satisfies SOSD, the equilibrium strategy `$\\sigma^*_k$` is FOSD increasing if `$f_{xss} < 0$` and FOSD decreasing if `$f_{xss} > 0$`.\n- **Proposition 2:** If `$s$` is degree-stable, satisfies SOSD, and `$f_{xss} \\neq 0$`, then an 'all equal' equilibrium in *mixed strategies* cannot exist.\n\nFor an agent to be willing to play a mixed strategy with payoff function `$f(x,s) = x(-\\alpha s^2 - \\beta s + 1)$` and cost `$c(x)=c \\cdot x$`, the indifference condition is:\n  \n\\alpha\\mathrm{Var}_{k}(s)+\\alpha{(E_{k}(s))}^{2}+\\beta E_{k}(s)=1-c \\quad \\text{(Eq. (1))}\n \n\n### Question\n\nBased on the provided model specifications and theoretical results for the 'average' statistic, select all statements that are correct.", "Options": {"A": "An 'all equal' equilibrium where all agents play the same *mixed strategy* is impossible if `$f_{xss} \\neq 0$`. This is because the indifference condition, such as Eq. (1), includes a `$\\mathrm{Var}_k(s)$` term that varies with `$k$`, making it impossible for the equality to hold for multiple degrees simultaneously.", "B": "The standard strategic substitutes/complements condition, `$f_{xs}$`, determines the equilibrium's monotonicity because even though `$E_k(s)` is constant, the change in variance affects the expected marginal benefit through this first-order term.", "C": "An 'all equal' equilibrium where all agents play the same *pure strategy* is robust because the weak inequality condition for optimality can hold for all degrees `$k$`, even if the expected marginal benefit is not constant.", "D": "The relationship between degree `$k$` and action depends on `$f_{xss}$` because a higher degree reduces the variance of the 'average' statistic. If `$f_{xss} < 0$` (concave marginal benefit), agents are averse to uncertainty in their marginal payoff, so higher `$k$` (less uncertainty) increases their expected marginal benefit and thus their action."}, "Answer": ["A", "D"], "pi_justification": "This item assesses understanding of the paper's most novel theoretical finding (the role of higher-order payoff effects) using **Atomic Decomposition**. It breaks down the original QA into propositions about intuition, mechanism, and stability. **Option A** correctly states the economic intuition linking variance reduction, the sign of `$f_{xss}$`, and agent behavior. **Option C** correctly explains the formal proof for why 'all equal' mixed equilibria are ruled out. The distractors target common errors: **Option B** incorrectly reasserts the primacy of the first-order condition `$f_{xs}$` (Conceptual Opposite). **Option D** incorrectly claims the pure strategy pooling equilibrium is robust, testing the subtle but critical concept of equilibrium refinement discussed in the paper (Conceptual Opposite).", "qid": "11", "question": "### Background\n\n**Research Question.** In many empirical models of peer effects, an agent's payoff is assumed to depend on the *average* action of their neighbors. This problem explores the novel theoretical finding that for such statistics, the nature of the equilibrium relationship between degree and action depends not on standard strategic complementarity/substitutability, but on higher-order properties of the payoff function and the stability of the resulting equilibria.\n\n**Setting / Institutional Environment.** Consider a symmetric Bayesian network game where the relevant statistic `$s$` is the average of neighbors' actions. Agents choose an action `$x \\in \\{0,1\\}$` to maximize their payoff.\n\n### Data / Model Specification\n\nThe 'average' statistic `$s$` has two key properties under degree independence:\n1.  **Degree-stable:** The expected value `$E_k(s)` is constant for all degrees `$k$`.\n2.  **Satisfies SOSD:** The distribution of `$s$` undergoes a mean-preserving contraction as `$k$` increases, meaning its variance `$\\text{Var}_k(s)$` is strictly decreasing in `$k$`.\n\nAn agent's payoff is `$\\Pi = f(x,s) - c(x)$`. The key theoretical results are:\n- **Proposition 1 (part 2a):** If `$s$` is degree-stable and satisfies SOSD, the equilibrium strategy `$\\sigma^*_k$` is FOSD increasing if `$f_{xss} < 0$` and FOSD decreasing if `$f_{xss} > 0$`.\n- **Proposition 2:** If `$s$` is degree-stable, satisfies SOSD, and `$f_{xss} \\neq 0$`, then an 'all equal' equilibrium in *mixed strategies* cannot exist.\n\nFor an agent to be willing to play a mixed strategy with payoff function `$f(x,s) = x(-\\alpha s^2 - \\beta s + 1)$` and cost `$c(x)=c \\cdot x$`, the indifference condition is:\n  \n\\alpha\\mathrm{Var}_{k}(s)+\\alpha{(E_{k}(s))}^{2}+\\beta E_{k}(s)=1-c \\quad \\text{(Eq. (1))}\n \n\n### Question\n\nBased on the provided model specifications and theoretical results for the 'average' statistic, select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 23, "Question": "### Background\n\nA monopolist produces a good that can be stored as inventory. The firm's technology is characterized by the cost of adjusting production (via a convex production cost function) and the cost of adjusting inventories (via a convex inventory carrying cost function). The firm faces demand shocks with varying degrees of persistence.\n\n### Data / Model Specification\n\nThe firm's optimal responses of production (`y_0`) and price (`p_0`) to an expected demand shock (`ε_0`) are functions of the response of the shadow value of inventories, `λ_0`.\n\n  \n\\frac{\\partial y_{0}}{\\partial\\varepsilon_{0}}=c\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} \n\\quad \\text{(Eq. (1))}\n \n  \n\\frac{\\partial p_{0}}{\\partial\\varepsilon_{0}}=\\frac{1}{2}\\left(1+\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}}\\right) \n\\quad \\text{(Eq. (2))}\n \n\nThe key to the model's comparative statics is the expression for the response of the shadow value of inventories:\n\n  \n\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} = \\left(\\frac{d}{c+d}\\right)\\left(\\frac{z_{2}-(1+r)}{z_{2}-\\rho}\\right) \n\\quad \\text{(Eq. (3))}\n \n\nWhere:\n- `c` is a parameter of the quadratic production cost function. A larger `c` implies a flatter marginal cost curve.\n- `d` is a parameter from the linear demand curve.\n- `ρ` is the persistence of demand shocks (`0 ≤ ρ ≤ 1`). A lower `ρ` means shocks are more transitory.\n- `r` is the interest rate.\n- `z_2` is the unstable root of the model's characteristic equation. It is an increasing function of `b`, the convexity of the inventory cost function. A lower `b` means output is more \"inventoriable\".\n\n### Question\n\nAccording to the model, which of the following statements correctly describe the conditions that lead to \"sticky\" prices and production (i.e., smaller responses to demand shocks)? Select all that apply.", "Options": {"A": "A firm with a highly convex inventory cost function (high `b`) will exhibit smaller price and output responses.", "B": "A firm facing very transitory demand shocks (low `ρ`) will exhibit smaller price and output responses.", "C": "A firm whose output is highly \"inventoriable\" (low `b`) will exhibit smaller price and output responses.", "D": "A firm facing highly persistent demand shocks (high `ρ`) will exhibit smaller price and output responses."}, "Answer": ["B", "C"], "pi_justification": "This item assesses the student's understanding of Theorem 1, the paper's central result. It uses a Reverse-Reasoning strategy: given the outcome (sticky prices), identify the correct preconditions. The correct options (C, D) are direct statements of the theorem. The distractors (A, B) are the conceptual opposites, representing conditions that lead to *larger* price and output responses. This forces the student to correctly recall and apply the main comparative statics of the model.", "qid": "23", "question": "### Background\n\nA monopolist produces a good that can be stored as inventory. The firm's technology is characterized by the cost of adjusting production (via a convex production cost function) and the cost of adjusting inventories (via a convex inventory carrying cost function). The firm faces demand shocks with varying degrees of persistence.\n\n### Data / Model Specification\n\nThe firm's optimal responses of production (`y_0`) and price (`p_0`) to an expected demand shock (`ε_0`) are functions of the response of the shadow value of inventories, `λ_0`.\n\n  \n\\frac{\\partial y_{0}}{\\partial\\varepsilon_{0}}=c\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} \n\\quad \\text{(Eq. (1))}\n \n  \n\\frac{\\partial p_{0}}{\\partial\\varepsilon_{0}}=\\frac{1}{2}\\left(1+\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}}\\right) \n\\quad \\text{(Eq. (2))}\n \n\nThe key to the model's comparative statics is the expression for the response of the shadow value of inventories:\n\n  \n\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} = \\left(\\frac{d}{c+d}\\right)\\left(\\frac{z_{2}-(1+r)}{z_{2}-\\rho}\\right) \n\\quad \\text{(Eq. (3))}\n \n\nWhere:\n- `c` is a parameter of the quadratic production cost function. A larger `c` implies a flatter marginal cost curve.\n- `d` is a parameter from the linear demand curve.\n- `ρ` is the persistence of demand shocks (`0 ≤ ρ ≤ 1`). A lower `ρ` means shocks are more transitory.\n- `r` is the interest rate.\n- `z_2` is the unstable root of the model's characteristic equation. It is an increasing function of `b`, the convexity of the inventory cost function. A lower `b` means output is more \"inventoriable\".\n\n### Question\n\nAccording to the model, which of the following statements correctly describe the conditions that lead to \"sticky\" prices and production (i.e., smaller responses to demand shocks)? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 28, "Question": "### Background\n\n**Research Question.** This problem addresses the econometric challenges of modeling a limited dependent variable, specifically weekly work hours, and deriving marginal effects from a non-linear model.\n\n**Setting / Institutional Environment.** The data is a cross-sectional survey of individuals. A significant fraction of the sample reports zero weekly work hours. This feature of the data requires a modeling approach that can accommodate a mass point at zero and distinguish between the decision to work at all and the decision of how many hours to work.\n\n**Variables & Parameters.**\n*   `H_i`: Observed weekly hours worked by individual `i`, `H_i ≥ 0`.\n*   `D_i`: An indicator variable such that `D_i = 1` if `H_i > 0` and `D_i = 0` if `H_i = 0`.\n*   `X_i`: A vector of explanatory variables.\n*   `α`, `β`: Parameter vectors for the first and second parts of the model.\n\n---\n\n### Data / Model Specification\n\nThe study employs a two-part model to estimate the determinants of work hours (`H_i`):\n\n1.  **Part 1 (Participation Decision):** A probit model for the binary outcome of working positive hours.\n      \n    P(D_i = 1 | X_i) = \\Phi(X_i'\\alpha) \\quad \\text{(Eq. (1))}\n     \n    where `Φ(·)` is the standard normal CDF.\n\n2.  **Part 2 (Hours Decision):** A linear regression model for the level of hours, conditional on working.\n      \n    E[H_i | D_i = 1, X_i] = X_i'\\beta \\quad \\text{(Eq. (2))}\n     \n\nThe unconditional expected value of hours is `E[H_i | X_i] = \\Phi(X_i'\\alpha) \\cdot (X_i'\\beta)`. The marginal effect of a continuous variable `X_{ik}` is `∂E[H_i | X_i] / ∂X_{ik} = \\phi(X_i'\\alpha) \\alpha_k \\cdot (X_i'\\beta) + \\Phi(X_i'\\alpha) \\cdot \\beta_k`.\n\nSuppose for a given individual, the model yields the following values: `X_i'α = 0.847`, `X_i'β = 40`, `α_k = 0.5`, and `β_k = -2`. You are given that `Φ(0.847) ≈ 0.80` and `φ(0.847) ≈ 0.28`. Select all correct statements about the marginal effect of the variable `X_{ik}` on this individual's expected weekly hours.", "Options": {"A": "The effect operating through the participation margin (the first term of the marginal effect formula) is +5.6 hours.", "B": "The marginal effect is simply the coefficient from the hours equation, `β_k = -2`, because this individual is already likely to be working.", "C": "The total marginal effect of `X_{ik}` on unconditional expected hours is positive.", "D": "The effect operating through the intensive margin (the second term of the marginal effect formula) is -2.0 hours."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: Tests the ability to correctly calculate and interpret the components of a marginal effect in a non-linear two-part model. Strategy: Computational Judgment & Atomic Decomposition. The question requires a multi-step calculation and then asks the user to identify multiple true statements about the result and its components. Distractor Logic: Option C omits a step in the formula (multiplying by `Φ(·)`). Option D reflects a common misunderstanding of marginal effects in non-linear models, incorrectly equating it with a single coefficient.", "qid": "28", "question": "### Background\n\n**Research Question.** This problem addresses the econometric challenges of modeling a limited dependent variable, specifically weekly work hours, and deriving marginal effects from a non-linear model.\n\n**Setting / Institutional Environment.** The data is a cross-sectional survey of individuals. A significant fraction of the sample reports zero weekly work hours. This feature of the data requires a modeling approach that can accommodate a mass point at zero and distinguish between the decision to work at all and the decision of how many hours to work.\n\n**Variables & Parameters.**\n*   `H_i`: Observed weekly hours worked by individual `i`, `H_i ≥ 0`.\n*   `D_i`: An indicator variable such that `D_i = 1` if `H_i > 0` and `D_i = 0` if `H_i = 0`.\n*   `X_i`: A vector of explanatory variables.\n*   `α`, `β`: Parameter vectors for the first and second parts of the model.\n\n---\n\n### Data / Model Specification\n\nThe study employs a two-part model to estimate the determinants of work hours (`H_i`):\n\n1.  **Part 1 (Participation Decision):** A probit model for the binary outcome of working positive hours.\n      \n    P(D_i = 1 | X_i) = \\Phi(X_i'\\alpha) \\quad \\text{(Eq. (1))}\n     \n    where `Φ(·)` is the standard normal CDF.\n\n2.  **Part 2 (Hours Decision):** A linear regression model for the level of hours, conditional on working.\n      \n    E[H_i | D_i = 1, X_i] = X_i'\\beta \\quad \\text{(Eq. (2))}\n     \n\nThe unconditional expected value of hours is `E[H_i | X_i] = \\Phi(X_i'\\alpha) \\cdot (X_i'\\beta)`. The marginal effect of a continuous variable `X_{ik}` is `∂E[H_i | X_i] / ∂X_{ik} = \\phi(X_i'\\alpha) \\alpha_k \\cdot (X_i'\\beta) + \\Phi(X_i'\\alpha) \\cdot \\beta_k`.\n\nSuppose for a given individual, the model yields the following values: `X_i'α = 0.847`, `X_i'β = 40`, `α_k = 0.5`, and `β_k = -2`. You are given that `Φ(0.847) ≈ 0.80` and `φ(0.847) ≈ 0.28`. Select all correct statements about the marginal effect of the variable `X_{ik}` on this individual's expected weekly hours.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 22, "Question": "### Background\n\n**Research Question.** This problem develops the theoretical foundation for the paper's central hypothesis: that community college enrollment is countercyclical. It uses a lifetime income maximization framework to model educational choice and explores how this choice is affected by economic recessions and institutional supply constraints.\n\n**Setting / Institutional Environment.** An 18-year-old high school graduate `i` with innate ability `a_i` chooses one of three educational paths (`ED`) to maximize the expected present value (`PV`) of lifetime income. Higher ability is assumed to yield a higher economic return to education.\n\n**Variables & Parameters.**\n- `ED`: Educational path chosen. `ED=12` (work immediately), `ED=14` (2-year community college), `ED=16` (4-year college).\n- `PV_{ED}`: Expected present value of lifetime income for path `ED`.\n- `a_i`: Innate ability of individual `i`.\n\n---\n\n### Data / Model Specification\n\nAn individual `i` chooses `ED ∈ {12, 14, 16}` to maximize `PV_{ED}`. The choice between working immediately (`ED=12`) and attending community college (`ED=14`) depends on a comparison of their present values. The model implies that there is a threshold ability level, `a*`, such that individuals with `a_i > a*` choose to enroll in community college. During a recession, `a*` falls, increasing demand.\n\n---\n\n### Question\n\nNow, consider the policy context discussed in the paper: during a recession, demand for community college surges, but state funding cuts impose a binding enrollment cap, `N_max`, which is less than the number of potential applicants. Assuming the college admits the highest-ability applicants, which of the following are correct statements about the resulting market equilibrium? Select all that apply.", "Options": {"A": "The observed level of enrollment will be fixed at `N_max`, potentially understating the true countercyclical demand in empirical data.", "B": "To meet the surge in demand, colleges will be forced to lower their admission standards, resulting in a lower average ability of enrolled students.", "C": "The effective ability cutoff for admission will be higher than the indifference threshold `a*`, leading to an increase in the average ability of the student body compared to an unconstrained scenario.", "D": "The average ability of enrolled students will fall, as the decline in opportunity cost makes enrollment attractive to a wider range of individuals."}, "Answer": ["A", "C"], "pi_justification": "REWRITE (from General QA): This item assesses a high-level application of the paper's theoretical model to a real-world policy constraint (rationing due to funding cuts). The strategy is a mix of **Scenario Application** and **Atomic Decomposition**. The question tests the counter-intuitive equilibrium effects on student composition. The distractors (B and D) are designed around a classic, high-frequency misconception: failing to distinguish between the shift in the underlying demand curve (which includes lower-ability individuals) and the characteristics of the constrained equilibrium allocation (which favors higher-ability individuals).", "qid": "22", "question": "### Background\n\n**Research Question.** This problem develops the theoretical foundation for the paper's central hypothesis: that community college enrollment is countercyclical. It uses a lifetime income maximization framework to model educational choice and explores how this choice is affected by economic recessions and institutional supply constraints.\n\n**Setting / Institutional Environment.** An 18-year-old high school graduate `i` with innate ability `a_i` chooses one of three educational paths (`ED`) to maximize the expected present value (`PV`) of lifetime income. Higher ability is assumed to yield a higher economic return to education.\n\n**Variables & Parameters.**\n- `ED`: Educational path chosen. `ED=12` (work immediately), `ED=14` (2-year community college), `ED=16` (4-year college).\n- `PV_{ED}`: Expected present value of lifetime income for path `ED`.\n- `a_i`: Innate ability of individual `i`.\n\n---\n\n### Data / Model Specification\n\nAn individual `i` chooses `ED ∈ {12, 14, 16}` to maximize `PV_{ED}`. The choice between working immediately (`ED=12`) and attending community college (`ED=14`) depends on a comparison of their present values. The model implies that there is a threshold ability level, `a*`, such that individuals with `a_i > a*` choose to enroll in community college. During a recession, `a*` falls, increasing demand.\n\n---\n\n### Question\n\nNow, consider the policy context discussed in the paper: during a recession, demand for community college surges, but state funding cuts impose a binding enrollment cap, `N_max`, which is less than the number of potential applicants. Assuming the college admits the highest-ability applicants, which of the following are correct statements about the resulting market equilibrium? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 25, "Question": "### Background\n\nThe firm's optimal plan is characterized by a system of linear difference equations. The solution requires finding a unique, non-explosive path for the state variables. This is achieved by imposing a stability condition that restricts the solution to the \"stable arm\" of the system's saddle-point dynamics.\n\n### Data / Model Specification\n\nThe solution for the initial shadow value of inventories, `λ_0`, is a function of the initial inventory disequilibrium (`n-bar - n_0`) and the initial expected demand shock (`ε_0`):\n\n  \n\\lambda_{0}=\\left(\\frac{1-z_{1}}{c+d}\\right)\\left[\\bar{n}-n_{0}+\\frac{d}{1-\\theta\\rho}\\varepsilon_{0}\\right] \n\\quad \\text{(Eq. (1))}\n \n\nWhere:\n- `λ_0`: Deviation of the shadow value of inventories from its steady state.\n- `n_0`: Initial deviation of inventories from the long-run steady state `n-bar`.\n- `ε_0`: Initial expected demand shock.\n- `z_1`: The stable root (`0 < z_1 < 1`) of the system's characteristic equation.\n- `b`: Convexity of the inventory cost function. As `b` approaches 0, `z_1` approaches 1.\n\n### Question\n\nBased on the solution for the shadow value of inventories (`λ_0`) in Eq. (1), which of the following statements are valid interpretations or implications of the model? Select all that apply.", "Options": {"A": "In the special case of linear inventory costs (`b=0`), the shadow value of inventories becomes independent of the initial inventory level `n_0`.", "B": "A positive expected demand shock (`ε_0 > 0`) increases the shadow value of inventories, signaling a higher marginal value for goods on hand.", "C": "An initial inventory surplus (`n_0 > n-bar`) increases the shadow value of inventories, motivating the firm to produce more.", "D": "A higher initial level of inventories (`n_0`) leads the firm to produce less and charge a lower price."}, "Answer": ["A", "B", "D"], "pi_justification": "This item assesses the student's ability to interpret the model's key solution equation and its implications, including a special limiting case. It uses a combination of direct interpretation and reverse-reasoning. Option A is a direct interpretation of the `ε_0` term. Option C tests the understanding of the limiting case where `b` approaches 0, causing `z_1` to approach 1, which makes the `n_0` term vanish. Option D requires reverse-reasoning: a higher `n_0` lowers `λ_0`, which in turn leads to lower production and a lower price (to stimulate sales). Distractor B is a conceptual opposite, incorrectly stating the effect of an inventory surplus. The Single-Correct-Answer Inversion Protocol was applied here. The original single correct answer was A. To create a compliant item, the stem was changed from asking for an INCORRECT statement to asking for valid statements, making the former distractors (now A, C, D) the correct answers.", "qid": "25", "question": "### Background\n\nThe firm's optimal plan is characterized by a system of linear difference equations. The solution requires finding a unique, non-explosive path for the state variables. This is achieved by imposing a stability condition that restricts the solution to the \"stable arm\" of the system's saddle-point dynamics.\n\n### Data / Model Specification\n\nThe solution for the initial shadow value of inventories, `λ_0`, is a function of the initial inventory disequilibrium (`n-bar - n_0`) and the initial expected demand shock (`ε_0`):\n\n  \n\\lambda_{0}=\\left(\\frac{1-z_{1}}{c+d}\\right)\\left[\\bar{n}-n_{0}+\\frac{d}{1-\\theta\\rho}\\varepsilon_{0}\\right] \n\\quad \\text{(Eq. (1))}\n \n\nWhere:\n- `λ_0`: Deviation of the shadow value of inventories from its steady state.\n- `n_0`: Initial deviation of inventories from the long-run steady state `n-bar`.\n- `ε_0`: Initial expected demand shock.\n- `z_1`: The stable root (`0 < z_1 < 1`) of the system's characteristic equation.\n- `b`: Convexity of the inventory cost function. As `b` approaches 0, `z_1` approaches 1.\n\n### Question\n\nBased on the solution for the shadow value of inventories (`λ_0`) in Eq. (1), which of the following statements are valid interpretations or implications of the model? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 26, "Question": "### Background\n\n**Research Question.** This problem analyzes the economic efficiency of policies for long-term care, focusing on the distortion created by subsidizing formal care while ignoring the opportunity cost of informal care.\n\n**Setting / Institutional Environment.** A family must provide long-term care for a parent with disabilities. This care can be sourced from the formal market (e.g., hiring a nurse) or provided informally by an adult child. The adult child faces an opportunity cost, in the form of forgone wages, if they choose to provide informal care. This paper's empirical findings show that this opportunity cost is large and causally linked to caregiving.\n\n**Variables & Parameters.**\n*   `P_F`: The market price per hour of formal care.\n*   `w_i`: The hourly wage (opportunity cost) of the adult child `i`.\n*   `s`: The fraction of formal care costs subsidized by the government, `0 ≤ s < 1`.\n\n---\n\n### Data / Model Specification\n\nAssume a family needs to provide one unit of care, which can be met by one hour of formal care or one hour of informal care. A cost-minimizing family will choose the cheaper option. An efficient allocation of resources requires that care be provided by the source with the lower social cost.\n\nSuppose the market price of formal care (`P_F`) is $20 per hour and the government introduces a policy that subsidizes 25% of this cost (`s = 0.25`). Based on the model, select all of the following statements that are correct.", "Options": {"A": "A family with a child whose opportunity cost (`w_i`) is $18 per hour will be induced by the subsidy to make a socially inefficient choice.", "B": "The policy is socially efficient because it lowers the cost of care for families.", "C": "The private cost of formal care for the family is now $15 per hour.", "D": "For a family with a child whose opportunity cost (`w_i`) is $12 per hour, the subsidy distorts their choice toward formal care."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: Tests the ability to apply a microeconomic model of subsidies to calculate price changes and identify the conditions for deadweight loss. Strategy: Scenario Application & Atomic Decomposition. The question provides concrete parameters (`P_F`, `s`) and asks for multiple correct conclusions to be identified. Distractor Logic: Option C presents a scenario outside the distortionary range. Option D makes a common but incorrect claim, confusing lower private cost with social efficiency.", "qid": "26", "question": "### Background\n\n**Research Question.** This problem analyzes the economic efficiency of policies for long-term care, focusing on the distortion created by subsidizing formal care while ignoring the opportunity cost of informal care.\n\n**Setting / Institutional Environment.** A family must provide long-term care for a parent with disabilities. This care can be sourced from the formal market (e.g., hiring a nurse) or provided informally by an adult child. The adult child faces an opportunity cost, in the form of forgone wages, if they choose to provide informal care. This paper's empirical findings show that this opportunity cost is large and causally linked to caregiving.\n\n**Variables & Parameters.**\n*   `P_F`: The market price per hour of formal care.\n*   `w_i`: The hourly wage (opportunity cost) of the adult child `i`.\n*   `s`: The fraction of formal care costs subsidized by the government, `0 ≤ s < 1`.\n\n---\n\n### Data / Model Specification\n\nAssume a family needs to provide one unit of care, which can be met by one hour of formal care or one hour of informal care. A cost-minimizing family will choose the cheaper option. An efficient allocation of resources requires that care be provided by the source with the lower social cost.\n\nSuppose the market price of formal care (`P_F`) is $20 per hour and the government introduces a policy that subsidizes 25% of this cost (`s = 0.25`). Based on the model, select all of the following statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 24, "Question": "### Background\n\nA monopolist produces a good that can be stored as inventory. The firm's technology is characterized by the cost of adjusting production (via a convex production cost function) and the cost of adjusting inventories (via a convex inventory carrying cost function). The firm faces demand shocks with varying degrees of persistence.\n\n### Data / Model Specification\n\nThe firm's optimal responses of production (`y_0`) and price (`p_0`) to an expected demand shock (`ε_0`) are functions of the response of the shadow value of inventories, `λ_0`.\n\n  \n\\frac{\\partial y_{0}}{\\partial\\varepsilon_{0}}=c\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} \n\\quad \\text{(Eq. (1))}\n \n  \n\\frac{\\partial p_{0}}{\\partial\\varepsilon_{0}}=\\frac{1}{2}\\left(1+\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}}\\right) \n\\quad \\text{(Eq. (2))}\n \n\nThe key to the model's comparative statics is the expression for the response of the shadow value of inventories:\n\n  \n\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} = \\left(\\frac{d}{c+d}\\right)\\left(\\frac{z_{2}-(1+r)}{z_{2}-\\rho}\\right) \n\\quad \\text{(Eq. (3))}\n \n\nWhere:\n- `c` and `d` are positive parameters from the cost and demand functions.\n- `ρ` is the persistence of demand shocks (`0 ≤ ρ ≤ 1`).\n- `r` is the interest rate.\n- `z_2` is the unstable root of the model's characteristic equation, and it is known that `z_2 > 1+r`.\n\n### Question\n\nConsider two industries, Durable Goods (low inventory cost convexity, `b_D`) and Perishable Goods (high inventory cost convexity, `b_P`). An economy-wide, temporary positive demand shock (`ε_0 > 0`) occurs. Based on the model, which of the following outcomes are expected? Select all that apply.", "Options": {"A": "The Durable Goods industry will exhibit a larger production response than the Perishable Goods industry.", "B": "The Perishable Goods industry will exhibit a larger production response than the Durable Goods industry.", "C": "The shadow value of inventories (`λ_0`) will be more responsive to the shock in the Durable Goods industry than in the Perishable Goods industry.", "D": "The Perishable Goods industry will exhibit a larger price response than the Durable Goods industry."}, "Answer": ["B", "D"], "pi_justification": "This item uses a Scenario Application strategy to test the core causal logic of the paper. It requires a multi-step reasoning chain: (1) Map the scenario (Durable vs. Perishable) to the model parameter `b`. (2) Trace the effect of `b` on `z_2`. (3) Trace the effect of `z_2` on `∂λ_0/∂ε_0`. (4) Trace the effect of `∂λ_0/∂ε_0` on the final price and production responses. The correct options (B, D) identify the correct final outcomes. Distractor A gets the intermediate step wrong (λ_0 is *less* responsive for durables). Distractor C is the conceptual opposite of D. This structure diagnoses whether a student can execute the full causal chain presented in the paper.", "qid": "24", "question": "### Background\n\nA monopolist produces a good that can be stored as inventory. The firm's technology is characterized by the cost of adjusting production (via a convex production cost function) and the cost of adjusting inventories (via a convex inventory carrying cost function). The firm faces demand shocks with varying degrees of persistence.\n\n### Data / Model Specification\n\nThe firm's optimal responses of production (`y_0`) and price (`p_0`) to an expected demand shock (`ε_0`) are functions of the response of the shadow value of inventories, `λ_0`.\n\n  \n\\frac{\\partial y_{0}}{\\partial\\varepsilon_{0}}=c\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} \n\\quad \\text{(Eq. (1))}\n \n  \n\\frac{\\partial p_{0}}{\\partial\\varepsilon_{0}}=\\frac{1}{2}\\left(1+\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}}\\right) \n\\quad \\text{(Eq. (2))}\n \n\nThe key to the model's comparative statics is the expression for the response of the shadow value of inventories:\n\n  \n\\frac{\\partial\\lambda_{0}}{\\partial\\varepsilon_{0}} = \\left(\\frac{d}{c+d}\\right)\\left(\\frac{z_{2}-(1+r)}{z_{2}-\\rho}\\right) \n\\quad \\text{(Eq. (3))}\n \n\nWhere:\n- `c` and `d` are positive parameters from the cost and demand functions.\n- `ρ` is the persistence of demand shocks (`0 ≤ ρ ≤ 1`).\n- `r` is the interest rate.\n- `z_2` is the unstable root of the model's characteristic equation, and it is known that `z_2 > 1+r`.\n\n### Question\n\nConsider two industries, Durable Goods (low inventory cost convexity, `b_D`) and Perishable Goods (high inventory cost convexity, `b_P`). An economy-wide, temporary positive demand shock (`ε_0 > 0`) occurs. Based on the model, which of the following outcomes are expected? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 27, "Question": "### Background\n\n**Research Question.** This problem analyzes the economic efficiency of policies for long-term care, focusing on the distortion created by subsidizing formal care while ignoring the opportunity cost of informal care.\n\n**Setting / Institutional Environment.** A family must provide long-term care for a parent with disabilities. This care can be sourced from the formal market (e.g., hiring a nurse) or provided informally by an adult child. The adult child faces an opportunity cost, in the form of forgone wages, if they choose to provide informal care. This paper's empirical findings show that this opportunity cost is large and causally linked to caregiving.\n\n**Variables & Parameters.**\n*   `P_F`: The market price per hour of formal care.\n*   `w_i`: The hourly wage (opportunity cost) of the adult child `i`.\n*   `s`: The fraction of formal care costs subsidized by the government, `0 ≤ s < 1`.\n\n---\n\n### Data / Model Specification\n\nAssume a family needs to provide one unit of care, which can be met by one hour of formal care or one hour of informal care. A cost-minimizing family will choose the cheaper option. An efficient allocation of resources requires that care be provided by the source with the lower social cost.\n\nThe paper's author discusses alternative policies to the formal care subsidy. Select all statements below that correctly describe these alternatives and their associated challenges.", "Options": {"A": "A lump-sum transfer is inefficient because it provides a subsidy even to families who would have chosen the efficient care option without it.", "B": "Subsidizing informal care would likely be less expensive than subsidizing formal care because family members have lower opportunity costs than professional caregivers.", "C": "A key implementation challenge for subsidizing informal care is the difficulty in verifying the actual hours and quality of non-market care provided.", "D": "A lump-sum transfer is considered a 'neutral' policy because it does not alter the relative private costs of formal versus informal care."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: Tests understanding of policy design principles, specifically the distinction between price-distorting subsidies and non-distorting transfers, and the practical challenges of policy implementation. Strategy: Premise/assumption packaging. The question asks the user to select all valid statements about policy design. Distractor Logic: Option C presents a plausible but incomplete argument, ignoring the critical moral hazard issue. Option D misattributes the source of inefficiency to the transfer itself rather than to price distortion.", "qid": "27", "question": "### Background\n\n**Research Question.** This problem analyzes the economic efficiency of policies for long-term care, focusing on the distortion created by subsidizing formal care while ignoring the opportunity cost of informal care.\n\n**Setting / Institutional Environment.** A family must provide long-term care for a parent with disabilities. This care can be sourced from the formal market (e.g., hiring a nurse) or provided informally by an adult child. The adult child faces an opportunity cost, in the form of forgone wages, if they choose to provide informal care. This paper's empirical findings show that this opportunity cost is large and causally linked to caregiving.\n\n**Variables & Parameters.**\n*   `P_F`: The market price per hour of formal care.\n*   `w_i`: The hourly wage (opportunity cost) of the adult child `i`.\n*   `s`: The fraction of formal care costs subsidized by the government, `0 ≤ s < 1`.\n\n---\n\n### Data / Model Specification\n\nAssume a family needs to provide one unit of care, which can be met by one hour of formal care or one hour of informal care. A cost-minimizing family will choose the cheaper option. An efficient allocation of resources requires that care be provided by the source with the lower social cost.\n\nThe paper's author discusses alternative policies to the formal care subsidy. Select all statements below that correctly describe these alternatives and their associated challenges.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 32, "Question": "### Background\n\n**Research Question.** This problem analyzes a firm's optimal investment strategy when growth requires not only physical investment but also costly recruitment of skilled labor from a competitive market.\n\n**Setting / Institutional Environment.** In the Entry Job Competition (EJC) model, a firm's growth is constrained by its ability to hire newly educated workers for its primary labor force. To do so, it must pay a market-determined education premium, `x(t)`, for each new hire. This premium is an additional cost of growth, on top of physical investment costs.\n\n**Variables & Parameters.**\n- `V(t)`: The value of the firm at time `t`.\n- `r(t)`: Net rate of quasi-rent per unit of capital (profit flow before growth costs).\n- `g(τ)`: Firm's growth rate at time `τ`.\n- `φ(g)`: Physical investment and adjustment cost per unit of capital, with `φ''(g) > 0`.\n- `x(t)`: The education premium per new hire, taken as given by the firm.\n- `a`: The fixed number of primary workers per unit of capital.\n- `K(τ)`: The firm's capital stock at time `τ`.\n- `ρ`: The constant market rate of discount.\n\n---\n\n### Data / Model Specification\n\nThe firm chooses a growth path `g(τ)` for `τ ≥ t` to maximize its value `V(t)`:\n\n  \nV(t) = \\int_{t}^{\\infty} \\{ r(t) - [\\phi(g(\\tau)) + a \\cdot x(t) \\cdot g(\\tau)] \\} K(\\tau) e^{-\\rho(\\tau-t)} d\\tau \\quad \\text{(Eq. (1))}\n \n\nsubject to the capital accumulation equation `\\dot{K}(\\tau) = g(\\tau)K(\\tau)` and an initial stock `K(t)`. The firm operates under static expectations, treating the current rent `r(t)` and premium `x(t)` as permanent.\n\nThe optimal growth rate `g` is constant for all `τ ≥ t` and satisfies the condition:\n\n  \n\\frac{r(t) - (\\phi(g) + a \\cdot x(t) \\cdot g)}{\\rho - g} = \\phi'(g) + a \\cdot x(t) \\quad \\text{(Eq. (2))}\n \n\n---\n\nBased on the firm's optimization problem, which of the following statements are valid interpretations or consequences of the model?\n", "Options": {"A": "The term `a · x(t) · g(τ)` in Eq. (1) represents the total education premium cost per unit of the firm's existing capital stock.", "B": "The left-hand side of Eq. (2) represents the firm's net cash flow per unit of capital after accounting for growth-related costs.", "C": "An increase in the education premium `x(t)` raises the marginal cost of investment, leading the firm to choose a lower optimal growth rate `g`.", "D": "The right-hand side of Eq. (2), `φ'(g) + a · x(t)`, represents the full marginal cost of installing one new unit of productive capacity, including both physical and human capital components."}, "Answer": ["A", "C", "D"], "pi_justification": "Assessment Target: This item assesses the ability to interpret the components of a dynamic optimization problem, including the objective function and the first-order condition (Tobin's q). Depth Strategy: Reverse-Reasoning. The user is given the model and must identify the correct economic interpretations of its mathematical components. Distractor Logic: Option A is a correct interpretation of the cost term, requiring the user to trace the units. Option B correctly identifies the RHS of the optimality condition as the marginal cost of investment. Option C correctly identifies the comparative static result `∂g/∂x < 0` and its intuition. Option D is a Step-Omission Error distractor; the LHS is the *present value* of future net cash flows (Tobin's q), not the current net cash flow itself, which is only the numerator of the LHS expression.", "qid": "32", "question": "### Background\n\n**Research Question.** This problem analyzes a firm's optimal investment strategy when growth requires not only physical investment but also costly recruitment of skilled labor from a competitive market.\n\n**Setting / Institutional Environment.** In the Entry Job Competition (EJC) model, a firm's growth is constrained by its ability to hire newly educated workers for its primary labor force. To do so, it must pay a market-determined education premium, `x(t)`, for each new hire. This premium is an additional cost of growth, on top of physical investment costs.\n\n**Variables & Parameters.**\n- `V(t)`: The value of the firm at time `t`.\n- `r(t)`: Net rate of quasi-rent per unit of capital (profit flow before growth costs).\n- `g(τ)`: Firm's growth rate at time `τ`.\n- `φ(g)`: Physical investment and adjustment cost per unit of capital, with `φ''(g) > 0`.\n- `x(t)`: The education premium per new hire, taken as given by the firm.\n- `a`: The fixed number of primary workers per unit of capital.\n- `K(τ)`: The firm's capital stock at time `τ`.\n- `ρ`: The constant market rate of discount.\n\n---\n\n### Data / Model Specification\n\nThe firm chooses a growth path `g(τ)` for `τ ≥ t` to maximize its value `V(t)`:\n\n  \nV(t) = \\int_{t}^{\\infty} \\{ r(t) - [\\phi(g(\\tau)) + a \\cdot x(t) \\cdot g(\\tau)] \\} K(\\tau) e^{-\\rho(\\tau-t)} d\\tau \\quad \\text{(Eq. (1))}\n \n\nsubject to the capital accumulation equation `\\dot{K}(\\tau) = g(\\tau)K(\\tau)` and an initial stock `K(t)`. The firm operates under static expectations, treating the current rent `r(t)` and premium `x(t)` as permanent.\n\nThe optimal growth rate `g` is constant for all `τ ≥ t` and satisfies the condition:\n\n  \n\\frac{r(t) - (\\phi(g) + a \\cdot x(t) \\cdot g)}{\\rho - g} = \\phi'(g) + a \\cdot x(t) \\quad \\text{(Eq. (2))}\n \n\n---\n\nBased on the firm's optimization problem, which of the following statements are valid interpretations or consequences of the model?\n", "model_evaluation_result": {"model_raw_response": "\"A,B,C,D\"", "model_answer": ["A", "B", "C", "D"], "error": null}}
{"ID": 13, "Question": "### Background\n\n**Research Question.** This problem develops a rational choice explanation for why voters cast ballots for third-party candidates with no chance of winning, providing a dynamic alternative to Duverger's Law.\n\n**Setting / Institutional Environment.** The setting is a two-period, three-candidate (A, B, C) election under plurality rule. A majority of voters (type-1) prefer A and B to C, but are split between A and B. A minority (type-2) supports C. In period 1, type-B voters (those who prefer B to A) face a choice: vote strategically for A to defeat C, or vote communicatively for their true preference B. A vote for B, while unable to win the current election, provides information to other type-1 voters about B's underlying support, which is valuable for coordinating in the period 2 election.\n\n### Data / Model Specification\n\nThe paper's model of communicative voting in a three-candidate race (Proposition 6) shows that it can be rational for voters to support a third candidate (e.g., B) even if that candidate has no chance of winning the current election. This occurs because the vote serves a communicative purpose for future elections. However, this can lead to an inefficient outcome in period 1 if candidate C (the least preferred candidate of the majority) wins because the majority splits its vote between A and B.\n\n### Question\n\nConsider the implications of this model for electoral system design. Which of the following statements accurately describe the model's findings or logical extensions regarding the efficiency of different voting systems?\n", "Options": {"A": "The model implies that under plurality rule, rational voters will never vote for a third candidate, thus upholding Duverger's Law even in a dynamic, two-period setting.", "B": "A two-round system with a runoff is identified as potentially more efficient because it allows voters to use the first round for communication (sincere voting) and the second round for decisive choice between the top contenders.", "C": "The model suggests that a one-round, first-past-the-post system can be inefficient because it forces voters to conflate the decision-making and communicative functions of their vote into a single action.", "D": "The introduction of a second period and a communicative motive provides a rational choice explanation for the failure of Duverger's Law, as a 'wasted' vote in period 1 generates valuable information for coordination in period 2."}, "Answer": ["B", "C", "D"], "pi_justification": "This item assesses the policy implications of the model, specifically its application to electoral system design. It uses a Scenario Application strategy, asking the user to apply the model's logic to evaluate different institutional arrangements.\n- **A (Correct):** This is a direct conclusion from the paper (Section III.B), stating that one-round systems mix up the two functions of the vote.\n- **B (Correct):** This is the paper's proposed solution (Section III.B), highlighting how two-round systems can separate the communicative and decision-making functions.\n- **C (Correct):** This captures the core theoretical contribution regarding Duverger's Law, as explained in the source QA's first part. The 'wasted' vote is an investment in information.\n- **D (Distractor - Conceptual Opposite):** This is the direct opposite of the paper's central argument in the three-candidate case. The entire point of Proposition 6 is to show why rational voters *do* vote for third candidates in this dynamic setting.", "qid": "13", "question": "### Background\n\n**Research Question.** This problem develops a rational choice explanation for why voters cast ballots for third-party candidates with no chance of winning, providing a dynamic alternative to Duverger's Law.\n\n**Setting / Institutional Environment.** The setting is a two-period, three-candidate (A, B, C) election under plurality rule. A majority of voters (type-1) prefer A and B to C, but are split between A and B. A minority (type-2) supports C. In period 1, type-B voters (those who prefer B to A) face a choice: vote strategically for A to defeat C, or vote communicatively for their true preference B. A vote for B, while unable to win the current election, provides information to other type-1 voters about B's underlying support, which is valuable for coordinating in the period 2 election.\n\n### Data / Model Specification\n\nThe paper's model of communicative voting in a three-candidate race (Proposition 6) shows that it can be rational for voters to support a third candidate (e.g., B) even if that candidate has no chance of winning the current election. This occurs because the vote serves a communicative purpose for future elections. However, this can lead to an inefficient outcome in period 1 if candidate C (the least preferred candidate of the majority) wins because the majority splits its vote between A and B.\n\n### Question\n\nConsider the implications of this model for electoral system design. Which of the following statements accurately describe the model's findings or logical extensions regarding the efficiency of different voting systems?\n", "model_evaluation_result": {"model_raw_response": "\"B,C,D\"", "model_answer": ["B", "C", "D"], "error": null}}
{"ID": 31, "Question": "### Background\n\n**Research Question.** This problem analyzes the long-run comparative statics of two alternative models of a dual labor market: the Entry Job Competition (EJC) model, where a market-clearing wage premium exists for new hires, and the Entry Job Rationing (EJR) model, where it does not. The analysis focuses on how the economy responds to changes in union power and the accessibility of education.\n\n**Setting / Institutional Environment.** The economy can be in one of three long-run states:\n1.  **EJC Model:** A competitive market for new entrants determines an education premium `x*` that equates the supply of and demand for educated workers.\n2.  **EJR Model (Supply Constrained):** Demand for educated workers exceeds supply. Firms' growth is constrained by the availability of new talent. All educated workers find primary sector jobs.\n3.  **EJR Model (Demand Constrained):** Supply of educated workers exceeds demand. Firms' growth is determined by their profitability, and some educated workers are rationed out of primary sector jobs.\n\n**Variables & Parameters.**\n- `m`: Trade unions' relative bargaining power.\n- `h(α)` or `c(α)`: Factors determining the accessibility of education (a favorable change means more people get educated for any given return).\n- `x*`: The long-run equilibrium education premium in the EJC model.\n- `w_1*`, `w_2*`: Long-run real wages in the primary and secondary sectors.\n- `r*`: Long-run net rate of quasi-rent on capital.\n- `p*`: Long-run proportion of a cohort that gets educated.\n- `θ*`: Long-run proportion of educated workers who find a primary sector job.\n- `k*`: Long-run capital-general labor ratio.\n\n---\n\n### Data / Model Specification\n\nThe following tables summarize the long-run effects of an increase in union bargaining power (`m`) and an improvement in the accessibility of education on key economic variables across the different models and regimes. A `+` indicates an increase, a `-` indicates a decrease, and a `0` indicates no change.\n\n**Table 1: EJC Model**\n| Cause of Change | Permanent Wage Differential | Secondary Wage `w_2*` | Net Quasi-Rent `r*` | Primary Employment Share `p*` |\n| :--- | :---: | :---: | :---: | :---: |\n| Union Power (`m`) | 0 | 0 | 0 | 0 |\n| Accessibility of Education | - | + | 0 | + |\n\n**Table 2: EJR Model - Supply Constrained Regime**\n| Cause of Change | Wage Differential `w_1* - w_2*` | Secondary Wage `w_2*` | Net Quasi-Rent `r*` | Primary Employment Share `p*` |\n| :--- | :---: | :---: | :---: | :---: |\n| Union Power (`m`) | + | + | - | + |\n| Accessibility of Education | - | + | - | + |\n\n**Table 3: EJR Model - Demand Constrained Regime**\n| Cause of Change | Wage Differential `w_1* - w_2*` | Secondary Wage `w_2*` | Net Quasi-Rent `r*` | Primary Employment Share `p*θ*` |\n| :--- | :---: | :---: | :---: | :---: |\n| Union Power (`m`) | + | - | 0 | - |\n| Accessibility of Education | 0 | 0 | 0 | 0 |\n\n---\n\nAccording to the models and results presented, which of the following statements accurately describe the long-run effects of policy or environmental changes?", "Options": {"A": "Improving the accessibility of education increases the primary employment share in the EJC model and the EJR supply-constrained regime, but has no effect in the EJR demand-constrained regime.", "B": "In the EJR demand-constrained regime, increasing union power (`m`) leads to a decrease in the share of workers employed in the primary sector.", "C": "Across all three possible economic states (EJC, EJR-Supply, EJR-Demand), an increase in union power (`m`) consistently leads to a higher wage differential between the primary and secondary sectors.", "D": "In the EJC model, an increase in union power (`m`) is neutralized by a decrease in the education premium (`x*`), leaving real variables like the secondary wage and primary employment share unchanged."}, "Answer": ["A", "B", "D"], "pi_justification": "Assessment Target: This item assesses the ability to perform comparative statics analysis across multiple economic models and regimes, synthesizing results from three tables. Depth Strategy: Scenario Application. The user must apply the general findings from the tables to evaluate specific policy outcomes. Distractor Logic: Option A is a direct reading from Table 3. Option B requires recalling the mechanism (the education premium) that neutralizes the effect of union power in the EJC model. Option C requires comparing the effect of education accessibility across all three tables. Option D is a conceptual distractor (True but Irrelevant/False Generalization); while union power increases the wage differential in two EJR regimes, it has no effect in the EJC model, making the statement false.", "qid": "31", "question": "### Background\n\n**Research Question.** This problem analyzes the long-run comparative statics of two alternative models of a dual labor market: the Entry Job Competition (EJC) model, where a market-clearing wage premium exists for new hires, and the Entry Job Rationing (EJR) model, where it does not. The analysis focuses on how the economy responds to changes in union power and the accessibility of education.\n\n**Setting / Institutional Environment.** The economy can be in one of three long-run states:\n1.  **EJC Model:** A competitive market for new entrants determines an education premium `x*` that equates the supply of and demand for educated workers.\n2.  **EJR Model (Supply Constrained):** Demand for educated workers exceeds supply. Firms' growth is constrained by the availability of new talent. All educated workers find primary sector jobs.\n3.  **EJR Model (Demand Constrained):** Supply of educated workers exceeds demand. Firms' growth is determined by their profitability, and some educated workers are rationed out of primary sector jobs.\n\n**Variables & Parameters.**\n- `m`: Trade unions' relative bargaining power.\n- `h(α)` or `c(α)`: Factors determining the accessibility of education (a favorable change means more people get educated for any given return).\n- `x*`: The long-run equilibrium education premium in the EJC model.\n- `w_1*`, `w_2*`: Long-run real wages in the primary and secondary sectors.\n- `r*`: Long-run net rate of quasi-rent on capital.\n- `p*`: Long-run proportion of a cohort that gets educated.\n- `θ*`: Long-run proportion of educated workers who find a primary sector job.\n- `k*`: Long-run capital-general labor ratio.\n\n---\n\n### Data / Model Specification\n\nThe following tables summarize the long-run effects of an increase in union bargaining power (`m`) and an improvement in the accessibility of education on key economic variables across the different models and regimes. A `+` indicates an increase, a `-` indicates a decrease, and a `0` indicates no change.\n\n**Table 1: EJC Model**\n| Cause of Change | Permanent Wage Differential | Secondary Wage `w_2*` | Net Quasi-Rent `r*` | Primary Employment Share `p*` |\n| :--- | :---: | :---: | :---: | :---: |\n| Union Power (`m`) | 0 | 0 | 0 | 0 |\n| Accessibility of Education | - | + | 0 | + |\n\n**Table 2: EJR Model - Supply Constrained Regime**\n| Cause of Change | Wage Differential `w_1* - w_2*` | Secondary Wage `w_2*` | Net Quasi-Rent `r*` | Primary Employment Share `p*` |\n| :--- | :---: | :---: | :---: | :---: |\n| Union Power (`m`) | + | + | - | + |\n| Accessibility of Education | - | + | - | + |\n\n**Table 3: EJR Model - Demand Constrained Regime**\n| Cause of Change | Wage Differential `w_1* - w_2*` | Secondary Wage `w_2*` | Net Quasi-Rent `r*` | Primary Employment Share `p*θ*` |\n| :--- | :---: | :---: | :---: | :---: |\n| Union Power (`m`) | + | - | 0 | - |\n| Accessibility of Education | 0 | 0 | 0 | 0 |\n\n---\n\nAccording to the models and results presented, which of the following statements accurately describe the long-run effects of policy or environmental changes?", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 36, "Question": "### Background\n\n**Research Question.** This problem examines the structure of the policymaker's dynamic optimization problem, which is the foundation of the sovereign default model with political turnover.\n\n**Setting.** A policymaker of a given type `j` (patient or impatient) makes decisions to maximize the expected present value of utility. In each period, the policymaker first decides whether to default on existing debt. Then, they choose a new level of borrowing/saving. The type of policymaker in power may change next period with probability `π`.\n\n**Variables & Parameters.**\n*   `V_j(b,y,h)`: Value function for a type-`j` policymaker who is in power.\n*   `W_j(b,y,h)`: Value function for a type-`j` policymaker who is *not* in power.\n*   `b, y, h`: State variables for debt, endowment, and past default history.\n*   `β_j`: Discount factor for a type-`j` policymaker.\n*   `π`: Probability of political turnover.\n\n---\n\n### Data / Model Specification\n\nThe policymaker's decision problem is characterized by a set of Bellman equations. The overall value for a type-`j` policymaker in power is the maximum of the value of repaying and the value of defaulting:\n  \nV_{j}(b,y,h)=\\max\\{V_{j1}(y,h),V_{j0}(b,y,h)\\}\n \n**(Eq. 1)**\n\nThe value of repaying (`d=0`) is:\n  \nV_{j0}(b,y,h) = \\max_{b'}\\left\\{u(c_0) + \\beta_{j}\\left[(1-\\pi)E[V_{j}(b',y',0)] + \\pi E[W_{j}(b',y',0)]\\right]\\right\\}\n \n**(Eq. 2)**\nwhere `c_0` is consumption under repayment. The policymaker types are distinguished by their discount factors, as shown in Table 1.\n\n**Table 1: Discount Factor Parameters**\n| Parameter | Symbol | Value |\n| :--- | :--- | :--- |\n| Higher Discount Factor | `β_H` | 0.9 |\n| Lower Discount Factor | `β_L` | 0.6 |\n\n\n---\n\n### Question\n\nBased on the policymaker's dynamic optimization problem described by Eq. (1) and Eq. (2), select all statements that are correct.", "Options": {"A": "In equilibrium, it must be that `V_j ≥ W_j` because a policymaker in power (`V_j`) can always choose the same actions that the other policymaker would have chosen, guaranteeing at least the same utility flow as being out of power (`W_j`).", "B": "A policymaker with a lower `β` (e.g., `β_L = 0.6`) is less likely to default because they place a lower value on the future output losses caused by defaulting.", "C": "The value function `W_j` represents the utility of the *other* policymaker (type `-j`) when type `j` is in power.", "D": "The term `π * E[W_j(b',y',0)]` in Eq. (2) represents the expected value for the current policymaker (type `j`) if they repay their debt but are then replaced by the other type, who will make the subsequent decisions."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: Tests understanding of the structure of the Bellman equation and the fundamental properties of the model's equilibrium. Strategy: Atomic Decomposition. The options test distinct components of the dynamic programming problem. Distractor Logic: Option C (Conceptual Opposite) reverses the core relationship between impatience and default propensity. Option D (Conceptual Confusion) targets a frequent misunderstanding of the notation in models with heterogeneous agents, confusing whose utility is being evaluated.", "qid": "36", "question": "### Background\n\n**Research Question.** This problem examines the structure of the policymaker's dynamic optimization problem, which is the foundation of the sovereign default model with political turnover.\n\n**Setting.** A policymaker of a given type `j` (patient or impatient) makes decisions to maximize the expected present value of utility. In each period, the policymaker first decides whether to default on existing debt. Then, they choose a new level of borrowing/saving. The type of policymaker in power may change next period with probability `π`.\n\n**Variables & Parameters.**\n*   `V_j(b,y,h)`: Value function for a type-`j` policymaker who is in power.\n*   `W_j(b,y,h)`: Value function for a type-`j` policymaker who is *not* in power.\n*   `b, y, h`: State variables for debt, endowment, and past default history.\n*   `β_j`: Discount factor for a type-`j` policymaker.\n*   `π`: Probability of political turnover.\n\n---\n\n### Data / Model Specification\n\nThe policymaker's decision problem is characterized by a set of Bellman equations. The overall value for a type-`j` policymaker in power is the maximum of the value of repaying and the value of defaulting:\n  \nV_{j}(b,y,h)=\\max\\{V_{j1}(y,h),V_{j0}(b,y,h)\\}\n \n**(Eq. 1)**\n\nThe value of repaying (`d=0`) is:\n  \nV_{j0}(b,y,h) = \\max_{b'}\\left\\{u(c_0) + \\beta_{j}\\left[(1-\\pi)E[V_{j}(b',y',0)] + \\pi E[W_{j}(b',y',0)]\\right]\\right\\}\n \n**(Eq. 2)**\nwhere `c_0` is consumption under repayment. The policymaker types are distinguished by their discount factors, as shown in Table 1.\n\n**Table 1: Discount Factor Parameters**\n| Parameter | Symbol | Value |\n| :--- | :--- | :--- |\n| Higher Discount Factor | `β_H` | 0.9 |\n| Lower Discount Factor | `β_L` | 0.6 |\n\n\n---\n\n### Question\n\nBased on the policymaker's dynamic optimization problem described by Eq. (1) and Eq. (2), select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 41, "Question": "### Background\n\nThis problem characterizes the optimal agreement between a buyer and a Preferred Supplier (PS) when the buyer has full commitment power to design the trading mechanism. The objective of the agreement is to maximize the buyer-PS coalition's expected joint surplus.\n\nThe model considers a buyer and `n` Competing Suppliers (CS). Each supplier's cost `c_i` is an independent draw from a distribution `G(c)` with density `g(c)` on `[0,1]`. The PS's cost `c_p` is her private information.\n\n### Data / Model Specification\n\nTo make the optimal mechanism incentive-compatible, the paper proposes a revelation mechanism. A PS with true cost `c_p` reports a cost `z` to the buyer. Her expected utility from this report is:\n\n  \nU(z; c_p) = \\underbrace{\\int_{z}^{1} [1 - G(r(x))]^n dx}_{\\text{Payment } P(z)} + \\underbrace{(z - c_p) \\cdot [1 - G(r(z))]^n}_{\\text{Expected Production Profit}}\n \n\nwhere `r(x)` is the optimal reserve price set in a subsequent auction among CSs, defined by `r + G(r)/g(r) = x`. The paper assumes `G(c)/g(c)` is increasing, which ensures `r'(x) > 0`.\n\n### Question\n\nSelect all statements that are mathematically correct regarding the PS's incentive compatibility problem of choosing a report `z` to maximize `U(z; c_p)`.", "Options": {"A": "The mechanism is incentive-compatible because the payment `P(z)` is designed to be maximized when the PS truthfully reports `z=c_p`.", "B": "The derivative of the payment term `P(z)` with respect to `z` is `+[1 - G(r(z))]^n`.", "C": "The first-order condition for the maximization problem with respect to `z` simplifies to `-(z - c_p) \\cdot n \\cdot [1 - G(r(z))]^{n-1} \\cdot g(r(z)) \\cdot r'(z) = 0`.", "D": "The condition `r'(z) > 0` is crucial for ensuring the second-order condition for a maximum is satisfied at `z=c_p`, as it makes the expression multiplying `(z-c_p)` in the first-order condition positive."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: Tests the student's ability to verify the incentive compatibility of the proposed revelation mechanism. This requires applying the product rule and Leibniz rule correctly and understanding the role of the second-order condition.\nStrategy: Atomic Decomposition. The original multi-part derivation question is broken down into verifiable statements about the first-order condition (A), the calculus of the payment term (B), the role of the second-order condition (C), and the overall logic of the mechanism (D).\nDistractor Logic:\n- (B) is a classic Leibniz rule error (Sign Error).\n- (D) misidentifies the logic; the *entire utility function* `U(z; c_p)` is maximized at `z=c_p`, not just the payment part. The payment is structured to exactly offset the PS's incentive to misreport.", "qid": "41", "question": "### Background\n\nThis problem characterizes the optimal agreement between a buyer and a Preferred Supplier (PS) when the buyer has full commitment power to design the trading mechanism. The objective of the agreement is to maximize the buyer-PS coalition's expected joint surplus.\n\nThe model considers a buyer and `n` Competing Suppliers (CS). Each supplier's cost `c_i` is an independent draw from a distribution `G(c)` with density `g(c)` on `[0,1]`. The PS's cost `c_p` is her private information.\n\n### Data / Model Specification\n\nTo make the optimal mechanism incentive-compatible, the paper proposes a revelation mechanism. A PS with true cost `c_p` reports a cost `z` to the buyer. Her expected utility from this report is:\n\n  \nU(z; c_p) = \\underbrace{\\int_{z}^{1} [1 - G(r(x))]^n dx}_{\\text{Payment } P(z)} + \\underbrace{(z - c_p) \\cdot [1 - G(r(z))]^n}_{\\text{Expected Production Profit}}\n \n\nwhere `r(x)` is the optimal reserve price set in a subsequent auction among CSs, defined by `r + G(r)/g(r) = x`. The paper assumes `G(c)/g(c)` is increasing, which ensures `r'(x) > 0`.\n\n### Question\n\nSelect all statements that are mathematically correct regarding the PS's incentive compatibility problem of choosing a report `z` to maximize `U(z; c_p)`.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 30, "Question": "### Background\n\nThe paper's main empirical model is a quantile regression where the key explanatory variables (permanent income and income risk) are themselves estimates generated from a first-stage regression on panel data.\n\nThe authors state that the standard errors of the parameter estimates are calculated using bootstrapping techniques.\n\n### Question\n\nIn this specific context, which of the following statistical problems make the use of bootstrapping essential for valid inference? Select all that apply.", "Options": {"A": "The use of generated regressors from the first-stage income model introduces estimation error that standard formulas for standard errors ignore.", "B": "The analytical formula for the variance of quantile regression coefficients requires estimating the conditional density of the error term, which is complex and often unreliable.", "C": "The exclusion of occupation dummies from the second stage could lead to omitted variable bias if the identifying assumption is false.", "D": "The presence of a time trend in the income regression could induce multicollinearity with other demographic variables."}, "Answer": ["A", "B"], "pi_justification": "This item assesses understanding of advanced statistical inference methods used in the paper. It uses a Reverse-Reasoning strategy. The correct answers, (A) and (B), identify the two distinct and complex problems—the generated regressor problem and the difficulty of calculating the asymptotic variance for quantile regression—that bootstrapping is uniquely suited to solve simultaneously. The distractors represent other valid econometric concerns that are not solved by bootstrapping: (C) omitted variable bias is a problem of model specification, not variance estimation (True but Irrelevant); (D) multicollinearity is a data problem that affects the precision of estimates, but bootstrapping does not resolve it (True but Irrelevant).", "qid": "30", "question": "### Background\n\nThe paper's main empirical model is a quantile regression where the key explanatory variables (permanent income and income risk) are themselves estimates generated from a first-stage regression on panel data.\n\nThe authors state that the standard errors of the parameter estimates are calculated using bootstrapping techniques.\n\n### Question\n\nIn this specific context, which of the following statistical problems make the use of bootstrapping essential for valid inference? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B\"", "model_answer": ["A", "B"], "error": null}}
{"ID": 40, "Question": "### Background\n\nIn the paper's theoretical framework, a wife's non-participation in the labor market is a corner solution. The household's behavior is then described by a 'rationed' cost function, which depends on her reservation wage (`w_f^*`) rather than the market wage (`w_f`). The reservation wage is the shadow price of her time.\n\n### The Question\n\nAssuming preferences between male and female non-market time are *not* separable, which of the following statements are correct implications of this framework? (Select all that apply)", "Options": {"A": "The household's total expenditure on goods will necessarily be lower in the non-participation regime than in the participation regime, holding utility constant.", "B": "The husband's labor supply becomes independent of his own wage when his wife is not working.", "C": "The wife's reservation wage (`w_f^*`) depends on other variables in the model, such as her husband's wage.", "D": "The functional form of the husband's labor supply equation will be different depending on whether his wife works or not."}, "Answer": ["C", "D"], "pi_justification": "This question assesses understanding of the theoretical model of corner solutions and non-separability. Option A is a key insight: non-separability means the form of one agent's supply function depends on the regime of the other. Option C correctly defines the reservation wage as an endogenous shadow price that depends on other prices (like the husband's wage) when preferences are linked. Options B and D are plausible but incorrect statements designed to trap superficial understanding.", "qid": "40", "question": "### Background\n\nIn the paper's theoretical framework, a wife's non-participation in the labor market is a corner solution. The household's behavior is then described by a 'rationed' cost function, which depends on her reservation wage (`w_f^*`) rather than the market wage (`w_f`). The reservation wage is the shadow price of her time.\n\n### The Question\n\nAssuming preferences between male and female non-market time are *not* separable, which of the following statements are correct implications of this framework? (Select all that apply)", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 39, "Question": "### Background\n\n**Research Question.** This problem assesses the long-run properties of the paper's wage-setting model. The simple model used for the main analysis implies that a permanent fall in productivity growth leads to a permanent rise in unemployment. This motivates a more complex \"fully adaptive\" model where real wage aspirations adjust over time.\n\n**Setting.** The authors estimate a fully adaptive wage equation and use it to simulate the dynamic path of unemployment following a shock.\n\n### Data / Model Specification\n\nThe authors simulate the dynamic impact on unemployment of a one-time, permanent 1% fall in the growth rate of real wages that occurs at time `t=0`. The results are in Table 1.\n\n**Table 1: Simulated Unemployment Effect of a 1% Permanent Fall in Real Wage Growth**\n(Effect on `U - U_0` in percentage points)\n\n| Year `t` after shock | Unemployment Effect `100(U - U_0)` |\n| :--- | :--- |\n| 1 | 0.703 |\n| 2 | 0.714 |\n| 3 | 0.685 |\n| 5 | 0.578 |\n| 7 | 0.463 |\n| 10 | 0.319 |\n| 20 | 0.086 |\n\n### Question\n\nBased on the fully adaptive wage model and the simulation results in Table 1, select all statements that are **INCORRECT** or **NOT supported** by the authors' analysis.\n", "Options": {"A": "The authors conclude their simple model is invalid for medium-term analysis because its predictions differ significantly from the adaptive model's path over the first 7 years.", "B": "The simulation shows that unemployment permanently increases to a new, higher level after the shock, never returning toward its baseline.", "C": "The authors note that OLS estimates of persistence parameters (like `\\phi`) are biased downwards in small samples. If this bias were corrected, their justification for using the simple model as a medium-term approximation would be weakened.", "D": "The peak effect of the shock on unemployment occurs in the second year, after which the effect begins a slow decay, indicating a protracted adjustment process."}, "Answer": ["A", "B", "C"], "pi_justification": "Assessment Target: Tests comprehensive understanding of the paper's advanced model, including interpretation of simulation results, the rationale for using a simpler model, and the subtle implications of econometric bias.\nStrategy: Complement-set selection (\"select all incorrect\"). This forces the student to evaluate each statement against the text, identifying multiple distinct errors.\nDistractor Logic:\n- A (Correct Answer, Incorrect Statement): Misrepresents the long-run properties of the adaptive model shown in the table (which shows decay) by stating the properties of the simple model.\n- B (Correct Answer, Incorrect Statement): Is the conceptual opposite of the authors' conclusion. They argue the simple model is a *good* approximation because the adaptive path is \"fairly flat\" in the medium term.\n- C (Incorrect Answer, Correct Statement): This is a correct interpretation of the table and serves as a foil.\n- D (Correct Answer, Incorrect Statement): This is a sophisticated reverse-reasoning error. Correcting the downward bias would mean true persistence is even higher, making the adjustment even slower and thus *strengthening* the authors' justification for using the simple model.", "qid": "39", "question": "### Background\n\n**Research Question.** This problem assesses the long-run properties of the paper's wage-setting model. The simple model used for the main analysis implies that a permanent fall in productivity growth leads to a permanent rise in unemployment. This motivates a more complex \"fully adaptive\" model where real wage aspirations adjust over time.\n\n**Setting.** The authors estimate a fully adaptive wage equation and use it to simulate the dynamic path of unemployment following a shock.\n\n### Data / Model Specification\n\nThe authors simulate the dynamic impact on unemployment of a one-time, permanent 1% fall in the growth rate of real wages that occurs at time `t=0`. The results are in Table 1.\n\n**Table 1: Simulated Unemployment Effect of a 1% Permanent Fall in Real Wage Growth**\n(Effect on `U - U_0` in percentage points)\n\n| Year `t` after shock | Unemployment Effect `100(U - U_0)` |\n| :--- | :--- |\n| 1 | 0.703 |\n| 2 | 0.714 |\n| 3 | 0.685 |\n| 5 | 0.578 |\n| 7 | 0.463 |\n| 10 | 0.319 |\n| 20 | 0.086 |\n\n### Question\n\nBased on the fully adaptive wage model and the simulation results in Table 1, select all statements that are **INCORRECT** or **NOT supported** by the authors' analysis.\n", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 6, "Question": "### Background\n\n**Research Question.** This problem examines the empirical strategy for estimating the causal effect of expected future demand and cost on current retail gasoline margins, as a test for tacitly collusive behavior.\n\n**Setting / Institutional Environment.** The analysis uses a monthly panel of data for 43 U.S. cities. The core idea is to regress the current retail margin on measures of current and expected future market conditions.\n\n**Variables & Parameters.**\n- `MARGIN_{it}`: Retail price minus terminal (wholesale) price in city `i` at time `t`.\n- `NVOLUME_{it}`: Normalized gasoline volume in city `i` at time `t`.\n- `TERMINAL_{it}`: Terminal price in city `i` at time `t`.\n- `EXPTERMINAL_{it+1}`: Expected next-period terminal price.\n\n---\n\n### Data / Model Specification\n\nThe primary empirical model is specified as:\n  \nMARGIN_{it} = \\alpha_{1}NVOLUME_{it} + \\alpha_{2}EXPNVOLUME_{it+1} + \\alpha_{3}TERMINAL_{it} + \\alpha_{4}EXPTERMINAL_{it+1} + ... + \\epsilon_{it} \\quad \\text{(Eq. (1))}\n \nAll estimations include city and time fixed effects and are estimated via two-stage least squares (2SLS) to address endogeneity.\n\n---\n\nWhich of the following statements describe valid identification challenges or strategies related to Eq. (1)?\n", "Options": {"A": "The use of city-specific responses to global crude oil price changes as instruments is valid under the assumption that these local pass-through dynamics are uncorrelated with unobserved local shocks to retail collusion.", "B": "Ordinary Least Squares (OLS) is a consistent estimator for the model's parameters because the inclusion of city and time fixed effects fully controls for all sources of endogeneity.", "C": "The predicted sign for `α₄` (the coefficient on `EXPTERMINAL_{it+1}`) is positive, as firms increase current margins to preemptively pass through expected future cost increases.", "D": "The current terminal price (`TERMINAL_{it}`) is likely endogenous because unobserved shocks to retail market profitability (`ε_{it}`) could influence refiners' wholesale pricing decisions or reflect common demand shocks."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item assesses the ability to identify sources of endogeneity and understand the logic of an instrumental variable (IV) strategy in the context of the paper's empirical model. Depth Strategy: Reverse-Reasoning (identifying valid econometric problems and solutions). Distractor Logic: Option C is a Conceptual Opposite; it misstates the theoretical prediction for `α₄`. Option D is a Conceptual Opposite; fixed effects do not resolve simultaneity or omitted variable bias from time-varying shocks, which is why 2SLS is necessary.", "qid": "6", "question": "### Background\n\n**Research Question.** This problem examines the empirical strategy for estimating the causal effect of expected future demand and cost on current retail gasoline margins, as a test for tacitly collusive behavior.\n\n**Setting / Institutional Environment.** The analysis uses a monthly panel of data for 43 U.S. cities. The core idea is to regress the current retail margin on measures of current and expected future market conditions.\n\n**Variables & Parameters.**\n- `MARGIN_{it}`: Retail price minus terminal (wholesale) price in city `i` at time `t`.\n- `NVOLUME_{it}`: Normalized gasoline volume in city `i` at time `t`.\n- `TERMINAL_{it}`: Terminal price in city `i` at time `t`.\n- `EXPTERMINAL_{it+1}`: Expected next-period terminal price.\n\n---\n\n### Data / Model Specification\n\nThe primary empirical model is specified as:\n  \nMARGIN_{it} = \\alpha_{1}NVOLUME_{it} + \\alpha_{2}EXPNVOLUME_{it+1} + \\alpha_{3}TERMINAL_{it} + \\alpha_{4}EXPTERMINAL_{it+1} + ... + \\epsilon_{it} \\quad \\text{(Eq. (1))}\n \nAll estimations include city and time fixed effects and are estimated via two-stage least squares (2SLS) to address endogeneity.\n\n---\n\nWhich of the following statements describe valid identification challenges or strategies related to Eq. (1)?\n", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 37, "Question": "### Background\n\n**Research Question.** This problem explores the theoretical core of the paper's model of stagflation, analyzing how different assumptions about expectations formation alter the trade-off between unemployment and inflation.\n\n**Setting.** The analysis is based on a macroeconomic model for a national economy, built from a wage-setting curve (an expectations-augmented Phillips curve) and a price-setting curve derived from a labor demand function.\n\n**Variables & Parameters.**\n- `w`, `p`: Logarithm of hourly wages and the price level, respectively.\n- `\\dot{w}`, `\\dot{p}`: First difference (annual growth rate) of the corresponding log variable.\n- `\\dot{p}^e`: Expected rate of price inflation.\n- `U`: Unemployment rate.\n- `U_0`: Baseline unemployment rate corresponding to zero labor market slack.\n- `\\dot{x}^e`: Target rate of growth of real wages sought in wage settlements when slack is zero.\n- `x`: Trend level of log value-added per worker (productivity).\n- `\\dot{x}`: Growth rate of trend productivity.\n- `p_m`: Log of import prices relative to domestic prices.\n- `\\dot{p}_m`: Growth rate of relative import prices.\n- `\\beta, \\mu, \\gamma`: Positive structural parameters of the model.\n\n### Data / Model Specification\n\nThe model consists of a wage equation and a price-change equation:\n\n  \n\\dot{w} = \\dot{p}^e - \\beta(U - U_0) + \\dot{x}^e \\quad \\text{(Eq. (1))}\n \n\n  \n\\dot{p} = \\dot{w} - \\dot{x} + \\mu\\dot{p}_m - \\gamma\\dot{U} \\quad \\text{(Eq. (2))}\n \n\n### Question\n\nAssuming price expectations are correct (`\\dot{p} = \\dot{p}^e`) and unemployment is stable (`\\dot{U} = 0`), select all of the following statements that are mathematically correct and consistent with the paper's framework for the medium-term equilibrium (NAIRU).\n", "Options": {"A": "A country with a higher `\\beta` (more wage flexibility) will experience a smaller increase in its NAIRU following a negative productivity shock (a fall in `\\dot{x}`).", "B": "The NAIRU is given by the expression: `U = U_0 + (1/\\beta)(\\dot{x}^e - \\dot{x} + \\mu\\dot{p}_m)`.", "C": "The NAIRU is given by the expression: `U = U_0 + \\beta(\\dot{x}^e - \\dot{x} + \\mu\\dot{p}_m)`.", "D": "A country with a higher `\\beta` (more wage flexibility) will experience a larger increase in its NAIRU following a negative productivity shock (a fall in `\\dot{x}`)."}, "Answer": ["A", "B"], "pi_justification": "Assessment Target: Tests the ability to derive the medium-term equilibrium (NAIRU) from the model's core equations and perform comparative statics on its determinants.\nStrategy: Atomic Decomposition. The original QA problem's derivation and comparative statics are broken into two distinct, verifiable statements (A and B).\nDistractor Logic:\n- C (Formula Misuse): Inverts the role of `\\beta` in the NAIRU equation, a common algebraic error.\n- D (Conceptual Opposite): Reverses the conclusion of the comparative static analysis, directly testing the understanding of how wage flexibility (`\\beta`) mediates supply shocks.", "qid": "37", "question": "### Background\n\n**Research Question.** This problem explores the theoretical core of the paper's model of stagflation, analyzing how different assumptions about expectations formation alter the trade-off between unemployment and inflation.\n\n**Setting.** The analysis is based on a macroeconomic model for a national economy, built from a wage-setting curve (an expectations-augmented Phillips curve) and a price-setting curve derived from a labor demand function.\n\n**Variables & Parameters.**\n- `w`, `p`: Logarithm of hourly wages and the price level, respectively.\n- `\\dot{w}`, `\\dot{p}`: First difference (annual growth rate) of the corresponding log variable.\n- `\\dot{p}^e`: Expected rate of price inflation.\n- `U`: Unemployment rate.\n- `U_0`: Baseline unemployment rate corresponding to zero labor market slack.\n- `\\dot{x}^e`: Target rate of growth of real wages sought in wage settlements when slack is zero.\n- `x`: Trend level of log value-added per worker (productivity).\n- `\\dot{x}`: Growth rate of trend productivity.\n- `p_m`: Log of import prices relative to domestic prices.\n- `\\dot{p}_m`: Growth rate of relative import prices.\n- `\\beta, \\mu, \\gamma`: Positive structural parameters of the model.\n\n### Data / Model Specification\n\nThe model consists of a wage equation and a price-change equation:\n\n  \n\\dot{w} = \\dot{p}^e - \\beta(U - U_0) + \\dot{x}^e \\quad \\text{(Eq. (1))}\n \n\n  \n\\dot{p} = \\dot{w} - \\dot{x} + \\mu\\dot{p}_m - \\gamma\\dot{U} \\quad \\text{(Eq. (2))}\n \n\n### Question\n\nAssuming price expectations are correct (`\\dot{p} = \\dot{p}^e`) and unemployment is stable (`\\dot{U} = 0`), select all of the following statements that are mathematically correct and consistent with the paper's framework for the medium-term equilibrium (NAIRU).\n", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 42, "Question": "### Background\n\nThis problem characterizes the optimal agreement between a buyer and a Preferred Supplier (PS) when the buyer has full commitment power. The agreement involves the PS reporting her cost `c_p`, which is then used to set an optimal reserve price `r(c_p)` for an auction among `n` Competing Suppliers (CS).\n\n### Data / Model Specification\n\nStandard auction theory states that to maximize surplus from `n` bidders when the auctioneer's valuation is `x`, the optimal reserve price `r(x)` is defined by:\n\n  \nr + \\frac{G(r)}{g(r)} = x \\quad \\text{(Eq. (1))}\n \n\nIn the absence of an agreement, the buyer's optimal mechanism is a first-price auction with a reserve price `r(v)`, where `v` is the buyer's own valuation.\n\n### Question\n\nConsider the specific case of a uniform cost distribution `G(c)=c` on `[0,1]`, `n=1` competing supplier, and a buyer value `v=1`. Select all of the following conclusions that are correct.", "Options": {"A": "The buyer-PS agreement increases expected total surplus (the sum of payoffs for the buyer, PS, and CS).", "B": "The buyer, acting unilaterally without an agreement, would set a reserve price of `1/2`.", "C": "The optimal reserve price function for the buyer-PS coalition is `r(c_p) = c_p / 2`.", "D": "The optimal reserve price function for the buyer-PS coalition is `r(c_p) = 2c_p`."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: Tests the ability to apply the general optimal reserve price formula to a specific distribution and compare the outcome of the buyer-PS agreement to the buyer's unilateral strategy.\nStrategy: Computational Judgment. The student must perform two separate calculations using Eq. (1) and then compare the results.\nDistractor Logic:\n- (D) is a common algebraic error (Formula Misuse) when solving `2r = x`.\n- (C) is a subtle conceptual error (True but Irrelevant / Misconception). The paper explicitly states that the effect on total surplus is ambiguous. For the `v=1` case, it happens to be positive (9/12 vs 7/12), but for `v=2` it is negative. The primary gain is for the *coalition's* joint surplus, not necessarily total surplus in general. This distractor tests for over-generalization from the specific example.", "qid": "42", "question": "### Background\n\nThis problem characterizes the optimal agreement between a buyer and a Preferred Supplier (PS) when the buyer has full commitment power. The agreement involves the PS reporting her cost `c_p`, which is then used to set an optimal reserve price `r(c_p)` for an auction among `n` Competing Suppliers (CS).\n\n### Data / Model Specification\n\nStandard auction theory states that to maximize surplus from `n` bidders when the auctioneer's valuation is `x`, the optimal reserve price `r(x)` is defined by:\n\n  \nr + \\frac{G(r)}{g(r)} = x \\quad \\text{(Eq. (1))}\n \n\nIn the absence of an agreement, the buyer's optimal mechanism is a first-price auction with a reserve price `r(v)`, where `v` is the buyer's own valuation.\n\n### Question\n\nConsider the specific case of a uniform cost distribution `G(c)=c` on `[0,1]`, `n=1` competing supplier, and a buyer value `v=1`. Select all of the following conclusions that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 29, "Question": "### Background\n\n**Research Question.** This problem addresses the econometric challenges of modeling a limited dependent variable, specifically weekly work hours, and deriving marginal effects from a non-linear model.\n\n**Setting / Institutional Environment.** The data is a cross-sectional survey of individuals. A significant fraction of the sample reports zero weekly work hours. This feature of the data requires a modeling approach that can accommodate a mass point at zero and distinguish between the decision to work at all and the decision of how many hours to work.\n\n**Variables & Parameters.**\n*   `H_i`: Observed weekly hours worked by individual `i`, `H_i ≥ 0`.\n*   `D_i`: An indicator variable such that `D_i = 1` if `H_i > 0` and `D_i = 0` if `H_i = 0`.\n*   `X_i`: A vector of explanatory variables.\n*   `α`, `β`: Parameter vectors for the first and second parts of the model.\n\n---\n\n### Data / Model Specification\n\nThe study employs a two-part model to estimate the determinants of work hours (`H_i`):\n\n1.  **Part 1 (Participation Decision):** A probit model for the binary outcome of working positive hours.\n      \n    P(D_i = 1 | X_i) = \\Phi(X_i'\\alpha) \\quad \\text{(Eq. (1))}\n     \n    where `Φ(·)` is the standard normal CDF.\n\n2.  **Part 2 (Hours Decision):** A linear regression model for the level of hours, conditional on working.\n      \n    E[H_i | D_i = 1, X_i] = X_i'\\beta \\quad \\text{(Eq. (2))}\n     \n\nAn analyst is choosing between a Tobit and a two-part model for weekly work hours. The Tobit model imposes the restriction that a variable must affect the participation decision and the hours decision in the same direction. Select all empirical findings below that would provide strong evidence *against* this restriction, thus favoring the more flexible two-part model.", "Options": {"A": "The error terms of the probit model and the linear hours model are found to be uncorrelated.", "B": "The coefficient for 'has a graduate degree' is positive in the probit model but statistically insignificant (zero) in the linear hours model.", "C": "The coefficient for 'presence of a child under 6' is negative in the probit (participation) model but positive in the linear (hours) model.", "D": "The coefficient for 'full-time work experience' is positive and significant in both the probit and the linear hours models."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: Tests the conceptual understanding of the key identifying restriction that differentiates the Tobit model from the two-part model. Strategy: Reverse-Reasoning. The question asks the user to infer which evidence would invalidate a specific model's assumptions. Distractor Logic: Option C describes a scenario perfectly consistent with the Tobit model. Option D introduces a concept (correlated errors) relevant to a different type of model (Heckman selection) to test for conceptual confusion.", "qid": "29", "question": "### Background\n\n**Research Question.** This problem addresses the econometric challenges of modeling a limited dependent variable, specifically weekly work hours, and deriving marginal effects from a non-linear model.\n\n**Setting / Institutional Environment.** The data is a cross-sectional survey of individuals. A significant fraction of the sample reports zero weekly work hours. This feature of the data requires a modeling approach that can accommodate a mass point at zero and distinguish between the decision to work at all and the decision of how many hours to work.\n\n**Variables & Parameters.**\n*   `H_i`: Observed weekly hours worked by individual `i`, `H_i ≥ 0`.\n*   `D_i`: An indicator variable such that `D_i = 1` if `H_i > 0` and `D_i = 0` if `H_i = 0`.\n*   `X_i`: A vector of explanatory variables.\n*   `α`, `β`: Parameter vectors for the first and second parts of the model.\n\n---\n\n### Data / Model Specification\n\nThe study employs a two-part model to estimate the determinants of work hours (`H_i`):\n\n1.  **Part 1 (Participation Decision):** A probit model for the binary outcome of working positive hours.\n      \n    P(D_i = 1 | X_i) = \\Phi(X_i'\\alpha) \\quad \\text{(Eq. (1))}\n     \n    where `Φ(·)` is the standard normal CDF.\n\n2.  **Part 2 (Hours Decision):** A linear regression model for the level of hours, conditional on working.\n      \n    E[H_i | D_i = 1, X_i] = X_i'\\beta \\quad \\text{(Eq. (2))}\n     \n\nAn analyst is choosing between a Tobit and a two-part model for weekly work hours. The Tobit model imposes the restriction that a variable must affect the participation decision and the hours decision in the same direction. Select all empirical findings below that would provide strong evidence *against* this restriction, thus favoring the more flexible two-part model.", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 46, "Question": "### Background\n\nTwo banks compete for High-ability (H) and Low-ability (L) traders, whose types are private information. Banks offer contracts defined by a total compensation (`u^j`) and a bonus ratio (`r^j = w_1^j/w_0^j`) that governs project risk. The first-best, profit-maximizing bonus ratio is `R*`. However, if the market for H-traders is very competitive, banks must offer them a high utility, `u^{H*}`. This high utility might tempt L-traders to mimic H-traders, violating the L-type's incentive compatibility (IC) constraint.\n\n### Data / Model Specification\n\nThe model establishes two equilibrium regimes based on a key threshold condition. The first-best utilities under symmetric information are:\n\n  \nu^{L*} = \\pi^{L}(R^{*}) - \\tau^{L} \\quad \\text{(Eq. 1)}\n \n\n  \nu^{H*} = \\pi^{H}(R^{*}) - \\tau^{H} \\quad \\text{(Eq. 2)}\n \n\nwhere `\\pi^j(R*)` is the maximum gross profit from a type-`j` trader and `\\tau^j` is a parameter inversely related to competition intensity (lower `\\tau^j` means more competition).\n\nAn L-type mimicking an H-type with contract `(u^H, r^H)` gets a payoff of `u^H f(r^H)`, where `f(r^H) \\le 1` measures the L-type's relative inefficiency. The switch to an excessive-risk regime occurs if the L-type's IC constraint is violated at the first-best contract offer, i.e., if `f(R^{*}) u^{H*} > u^{L*}`.\n\n### Question\n\nAssume the system is in the excessive-risk regime, where banks must distort the H-type contract by setting `r^H > R*` to satisfy the L-type's incentive compatibility constraint. According to the model, which of the following statements accurately describe the mechanisms and consequences of this situation? Select all that apply.", "Options": {"A": "If competition for H-type traders intensifies (i.e., `\\tau^H` falls), banks are forced to offer a higher utility `u^H`, which tightens the L-type's IC constraint and compels banks to further increase `r^H` to maintain separation.", "B": "The primary benefit to a bank of setting `r^H > R*` is that it makes the H-type contract less attractive to a mimicking L-type, thereby reducing the information rents the bank must pay to L-types.", "C": "The distortion `r^H > R*` is necessary because the high utility `u^{H*}` required to attract H-traders makes their contract irresistibly tempting to L-traders under the first-best bonus ratio `R*`.", "D": "A primary cost to a bank of setting `r^H > R*` is that it induces its most productive (H-type) traders to choose projects that are sub-optimally risky from the bank's perspective, reducing gross profits `\\pi^H`."}, "Answer": ["A", "B", "C", "D"], "pi_justification": "Assessment Target: This item assesses the student's comprehensive understanding of the paper's core mechanism: why excessive risk arises, the costs and benefits of the distortion, and how competition exacerbates the problem. It synthesizes multiple parts of the original QA problem into a single, holistic check.\nDepth Strategy: Reverse-Reasoning. Given the outcome (excessive risk regime), the student must identify all the valid causes, costs, benefits, and comparative statics that define this regime.\nDistractor Logic: All options provided are correct statements derived directly from the paper's central argument. The challenge is not to find a single correct answer but to recognize the validity of each piece of the mechanism, testing for a complete and integrated understanding rather than isolated facts. An incorrect response would indicate a misunderstanding of a key part of the model's logic.", "qid": "46", "question": "### Background\n\nTwo banks compete for High-ability (H) and Low-ability (L) traders, whose types are private information. Banks offer contracts defined by a total compensation (`u^j`) and a bonus ratio (`r^j = w_1^j/w_0^j`) that governs project risk. The first-best, profit-maximizing bonus ratio is `R*`. However, if the market for H-traders is very competitive, banks must offer them a high utility, `u^{H*}`. This high utility might tempt L-traders to mimic H-traders, violating the L-type's incentive compatibility (IC) constraint.\n\n### Data / Model Specification\n\nThe model establishes two equilibrium regimes based on a key threshold condition. The first-best utilities under symmetric information are:\n\n  \nu^{L*} = \\pi^{L}(R^{*}) - \\tau^{L} \\quad \\text{(Eq. 1)}\n \n\n  \nu^{H*} = \\pi^{H}(R^{*}) - \\tau^{H} \\quad \\text{(Eq. 2)}\n \n\nwhere `\\pi^j(R*)` is the maximum gross profit from a type-`j` trader and `\\tau^j` is a parameter inversely related to competition intensity (lower `\\tau^j` means more competition).\n\nAn L-type mimicking an H-type with contract `(u^H, r^H)` gets a payoff of `u^H f(r^H)`, where `f(r^H) \\le 1` measures the L-type's relative inefficiency. The switch to an excessive-risk regime occurs if the L-type's IC constraint is violated at the first-best contract offer, i.e., if `f(R^{*}) u^{H*} > u^{L*}`.\n\n### Question\n\nAssume the system is in the excessive-risk regime, where banks must distort the H-type contract by setting `r^H > R*` to satisfy the L-type's incentive compatibility constraint. According to the model, which of the following statements accurately describe the mechanisms and consequences of this situation? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 34, "Question": "### Background\n\n**Research Question.** This problem analyzes the paper's central theoretical contribution: how political stability interacts with policymaker heterogeneity to determine the price of sovereign debt and the likelihood of default.\n\n**Setting.** A small open economy issues one-period bonds to risk-neutral lenders. The government is run by one of two policymaker types: patient (`H`) or impatient (`L`), with `β_H > β_L`. The types have different default thresholds: for a given income level, there are 'intermediate' debt levels that a patient type would repay but an impatient type would default on. At the end of each period, the incumbent policymaker is replaced by the other type with a constant probability `π`.\n\n**Variables & Parameters.**\n*   `b'`: End-of-period net bond position (assets); `-b'` is debt issuance.\n*   `q_j(b', y)`: The price of a bond issued by a type-`j` policymaker.\n*   `π`: The probability of political turnover; `1-π` is a measure of political stability.\n*   `r`: The risk-free interest rate.\n*   `d_j(b', y')`: Default decision rule for type `j` (1 if default, 0 if repay).\n\n---\n\n### Data / Model Specification\n\nThe bond price is determined by the lenders' zero-profit condition, which states that the price equals the discounted expected repayment probability:\n  \nq_{j}(b',y)=\\frac{1}{1+r} \\left( 1 - E[\\text{default on } b'] \\right)\n \n**(Eq. 1)**\n\nThe expectation accounts for the probability `π` that the other policymaker type (`-j`) will be in power next period to make the repayment decision.\n\n---\n\n### Question\n\nThe paper's central mechanism links political stability (`1-π`) to default risk via the bond price schedule. Select all statements that correctly describe this mechanism.", "Options": {"A": "The relationship between stability and default risk is non-monotonic because at low stability, increasing it encourages patient types to take on risky debt (raising risk), while at high stability, increasing it simply lowers the chance of a political turnover on already-risky debt (lowering risk).", "B": "The model predicts a strictly negative relationship between political stability and default risk, as a lower `π` always reduces the probability of a political default.", "C": "For 'intermediate' debt levels that only an impatient type would default on, the price a patient policymaker receives is `(1-π)/(1+r)`. A lower `π` (more stability) increases this price, making such debt more attractive.", "D": "For 'intermediate' debt levels, the price a patient policymaker receives is `π/(1+r)`, reflecting the probability that the patient policymaker remains in power."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: Tests a comprehensive understanding of the paper's core theoretical mechanism, from the derivation of the bond price to the resulting non-monotonic relationship between stability and risk. Strategy: Atomic Decomposition. The options break down the multi-step argument into two key testable propositions. Distractor Logic: Option C (Formula Misuse) presents the price formula for the *other* policymaker, a key confusion. Option D (Step-Omission Error) presents a simplified, monotonic logic that ignores the crucial 'choice channel' emphasized in the paper.", "qid": "34", "question": "### Background\n\n**Research Question.** This problem analyzes the paper's central theoretical contribution: how political stability interacts with policymaker heterogeneity to determine the price of sovereign debt and the likelihood of default.\n\n**Setting.** A small open economy issues one-period bonds to risk-neutral lenders. The government is run by one of two policymaker types: patient (`H`) or impatient (`L`), with `β_H > β_L`. The types have different default thresholds: for a given income level, there are 'intermediate' debt levels that a patient type would repay but an impatient type would default on. At the end of each period, the incumbent policymaker is replaced by the other type with a constant probability `π`.\n\n**Variables & Parameters.**\n*   `b'`: End-of-period net bond position (assets); `-b'` is debt issuance.\n*   `q_j(b', y)`: The price of a bond issued by a type-`j` policymaker.\n*   `π`: The probability of political turnover; `1-π` is a measure of political stability.\n*   `r`: The risk-free interest rate.\n*   `d_j(b', y')`: Default decision rule for type `j` (1 if default, 0 if repay).\n\n---\n\n### Data / Model Specification\n\nThe bond price is determined by the lenders' zero-profit condition, which states that the price equals the discounted expected repayment probability:\n  \nq_{j}(b',y)=\\frac{1}{1+r} \\left( 1 - E[\\text{default on } b'] \\right)\n \n**(Eq. 1)**\n\nThe expectation accounts for the probability `π` that the other policymaker type (`-j`) will be in power next period to make the repayment decision.\n\n---\n\n### Question\n\nThe paper's central mechanism links political stability (`1-π`) to default risk via the bond price schedule. Select all statements that correctly describe this mechanism.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 45, "Question": "### Background\nThe stability of a generalized Cournot oligopoly model with `n` firms, adjustment speed `K`, demand parameter `b`, and marginal cost slope `d` is determined by the following condition:\n\n  \nK < 2 \\left( \\frac{2b+d}{(n+1)b+d} \\right)\n \n\nFor the system to be stable, this inequality must be satisfied.\n\n### Question\nAccording to the stability condition provided, which of the following changes are **stabilizing** factors (i.e., they relax the condition, making stability more likely)? Select all that apply.", "Options": {"A": "A decrease in the number of firms, `n`.", "B": "An increase in the slope of the marginal cost curve, `d`.", "C": "An increase in the demand parameter, `b`.", "D": "A decrease in the speed of adjustment, `K`."}, "Answer": ["A", "B", "D"], "pi_justification": "Judgment: REPLACE with Choice Questions (Score: 9.0). This item uses the 'Scenario Application' strategy. It assesses the ability to correctly interpret the mathematical stability condition in terms of its economic parameters. Students must analyze how changes in `n`, `d`, and `K` affect the inequality. A, B, and C are correct interpretations of the formula and reflect the paper's core economic intuitions. Distractor D is incorrect; an increase in `b` makes the right-hand side smaller (for n>1), thus tightening the condition and being destabilizing. This tests a full understanding of the comparative statics of the stability condition.", "qid": "45", "question": "### Background\nThe stability of a generalized Cournot oligopoly model with `n` firms, adjustment speed `K`, demand parameter `b`, and marginal cost slope `d` is determined by the following condition:\n\n  \nK < 2 \\left( \\frac{2b+d}{(n+1)b+d} \\right)\n \n\nFor the system to be stable, this inequality must be satisfied.\n\n### Question\nAccording to the stability condition provided, which of the following changes are **stabilizing** factors (i.e., they relax the condition, making stability more likely)? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 38, "Question": "### Background\n\n**Research Question.** This problem explores the theoretical core of the paper's model of stagflation, analyzing how different assumptions about expectations formation alter the trade-off between unemployment and inflation.\n\n**Setting.** The analysis is based on a macroeconomic model for a national economy, built from a wage-setting curve (an expectations-augmented Phillips curve) and a price-setting curve derived from a labor demand function.\n\n**Variables & Parameters.**\n- `w`, `p`: Logarithm of hourly wages and the price level, respectively.\n- `\\dot{w}`, `\\dot{p}`: First difference (annual growth rate) of the corresponding log variable.\n- `\\dot{p}^e`: Expected rate of price inflation.\n- `U`: Unemployment rate.\n- `U_0`: Baseline unemployment rate corresponding to zero labor market slack.\n- `\\dot{x}^e`: Target rate of growth of real wages sought in wage settlements when slack is zero.\n- `x`: Trend level of log value-added per worker (productivity).\n- `\\dot{x}`: Growth rate of trend productivity.\n- `p_m`: Log of import prices relative to domestic prices.\n- `\\dot{p}_m`: Growth rate of relative import prices.\n- `\\beta, \\mu, \\gamma`: Positive structural parameters of the model.\n\n### Data / Model Specification\n\nThe model consists of a wage equation and a price-change equation:\n\n  \n\\dot{w} = \\dot{p}^e - \\beta(U - U_0) + \\dot{x}^e \\quad \\text{(Eq. (1))}\n \n\n  \n\\dot{p} = \\dot{w} - \\dot{x} + \\mu\\dot{p}_m - \\gamma\\dot{U} \\quad \\text{(Eq. (2))}\n \n\n### Question\n\nAssuming wage setters have adaptive expectations (`\\dot{p}^e = \\dot{p}_{-1}`), select all statements that correctly describe the short-run dynamics of inflation and the associated policy trade-offs.\n", "Options": {"A": "The short-run \"accelerationist\" Phillips curve is given by: `\\dot{p} - \\dot{p}_{-1} = -\\beta(U - U_0) + (\\dot{x}^e - \\dot{x} + \\mu\\dot{p}_m) - \\gamma\\dot{U}`.", "B": "A higher `\\beta` (more wage flexibility) implies a more favorable short-run trade-off for disinflation (a lower sacrifice ratio).", "C": "A fall in productivity growth (`\\dot{x}`) shifts the short-run Phillips curve down, creating a more favorable trade-off between unemployment and changes in inflation.", "D": "The NAIRU is defined as the unemployment rate required to keep the inflation rate (`\\dot{p}`) equal to zero."}, "Answer": ["A", "B"], "pi_justification": "Assessment Target: Tests the ability to derive the short-run dynamic equation for inflation (the accelerationist Phillips curve) and interpret its policy implications, particularly the sacrifice ratio.\nStrategy: Atomic Decomposition. The original QA problem's derivation and policy dilemma are split into distinct, verifiable statements (A and C).\nDistractor Logic:\n- B (Conceptual Opposite): Incorrectly describes the effect of an adverse supply shock, which worsens the trade-off, not improves it.\n- D (Almost Right): Presents a common but incorrect definition of the NAIRU. The NAIRU stabilizes the inflation rate (i.e., `\\dot{p} - \\dot{p}_{-1} = 0`), it does not necessarily drive it to zero.", "qid": "38", "question": "### Background\n\n**Research Question.** This problem explores the theoretical core of the paper's model of stagflation, analyzing how different assumptions about expectations formation alter the trade-off between unemployment and inflation.\n\n**Setting.** The analysis is based on a macroeconomic model for a national economy, built from a wage-setting curve (an expectations-augmented Phillips curve) and a price-setting curve derived from a labor demand function.\n\n**Variables & Parameters.**\n- `w`, `p`: Logarithm of hourly wages and the price level, respectively.\n- `\\dot{w}`, `\\dot{p}`: First difference (annual growth rate) of the corresponding log variable.\n- `\\dot{p}^e`: Expected rate of price inflation.\n- `U`: Unemployment rate.\n- `U_0`: Baseline unemployment rate corresponding to zero labor market slack.\n- `\\dot{x}^e`: Target rate of growth of real wages sought in wage settlements when slack is zero.\n- `x`: Trend level of log value-added per worker (productivity).\n- `\\dot{x}`: Growth rate of trend productivity.\n- `p_m`: Log of import prices relative to domestic prices.\n- `\\dot{p}_m`: Growth rate of relative import prices.\n- `\\beta, \\mu, \\gamma`: Positive structural parameters of the model.\n\n### Data / Model Specification\n\nThe model consists of a wage equation and a price-change equation:\n\n  \n\\dot{w} = \\dot{p}^e - \\beta(U - U_0) + \\dot{x}^e \\quad \\text{(Eq. (1))}\n \n\n  \n\\dot{p} = \\dot{w} - \\dot{x} + \\mu\\dot{p}_m - \\gamma\\dot{U} \\quad \\text{(Eq. (2))}\n \n\n### Question\n\nAssuming wage setters have adaptive expectations (`\\dot{p}^e = \\dot{p}_{-1}`), select all statements that correctly describe the short-run dynamics of inflation and the associated policy trade-offs.\n", "model_evaluation_result": {"model_raw_response": "\"A,B\"", "model_answer": ["A", "B"], "error": null}}
{"ID": 47, "Question": "### Background\n\nTwo banks compete for High-ability (H) and Low-ability (L) traders. The system is in an equilibrium where banks induce excessive risk-taking (`r^H > R*`) from H-traders as a screening device. A regulator considers two policies to mitigate this risk: a direct cap on the bonus ratio (`\\bar{R}`) and an indirect increase in bank capital requirements (modeled as an increase in the loss parameter `x_{-1}`).\n\n### Data / Model Specification\n\n**Policy 1: Bonus Cap.** A binding cap `\\bar{R}` is imposed, so `r^H = \\bar{R}`. Total welfare is the sum of gross profits:\n\n  \nW = \\phi\\pi^{L}(R^{\\ast}) + (1-\\phi)\\pi^{H}(r^{H}) \\quad \\text{(Eq. 1)}\n \n\nGross profit `\\pi^H(r^H)` is maximized at `r^H = R*`.\n\n**Policy 2: Capital Requirements.** An increase in bank equity `E` is equivalent to increasing the loss parameter `x_{-1}`. The bank's gross profit from a type-`j` trader is `\\pi^j = q_1^j x_1 + q_0^j x_0 - q_{-1}^j x_{-1}`. The partial derivative of profit with respect to this loss is:\n\n  \n\\frac{\\partial \\pi^j}{\\partial x_{-1}} = -q_{-1}^j \\quad \\text{(Eq. 2)}\n \n\nUnder the simplifying assumption that H-type projects are inelastic to the bonus ratio (`\\partial \\pi^H / \\partial r^H = 0`), the equilibrium condition is:\n\n  \n\\left(\\pi^{H}(r^{H}, x_{-1})-\\tau^{H}\\right)f(r^{H}) = \\pi^{L}(R^{*}, x_{-1})-\\tau^{L} \\quad \\text{(Eq. 3)}\n \n\n### Question\n\nBased on the model's analysis of these two regulatory policies, which of the following statements are valid conclusions? Select all that apply.", "Options": {"A": "Increasing capital requirements will always reduce risk-taking (`r^H`) because it makes banks more averse to losses, and `r^H` is the primary driver of risk.", "B": "Increasing capital requirements (raising `x_{-1}`) can perversely increase risk-taking (`r^H`) if L-type traders are perceived as the primary source of downside risk (e.g., `q_{-1}^L` is sufficiently high relative to `q_{-1}^H`).", "C": "The effect of a tighter bonus cap on bank profits is ambiguous, as it creates a positive effect by mitigating a competitive externality but a negative effect by weakening the contract's screening power.", "D": "A reduction in a binding bonus cap `\\bar{R}` (bringing it closer to `R*`) unambiguously increases total welfare because it moves the H-trader's project choice closer to the socially optimal level."}, "Answer": ["B", "C", "D"], "pi_justification": "Assessment Target: This item assesses the student's understanding of the paper's policy implications, requiring them to differentiate the effects of two distinct regulatory interventions and identify the conditions under which they are effective or counter-productive.\nDepth Strategy: Scenario Application. The student must apply the model's logic to evaluate the outcomes of two different policy scenarios.\nDistractor Logic:\n- **A (Correct):** Directly tests the welfare implication of the bonus cap, a key result.\n- **B (Correct):** Tests the paper's main counter-intuitive finding about capital requirements, requiring recall of the underlying condition.\n- **C (Correct):** Tests the nuanced trade-off affecting bank profits under a bonus cap, assessing deeper understanding beyond the welfare effect.\n- **D (Incorrect - Conceptual Opposite):** This is the 'naive' or intuitive answer that the paper explicitly argues against. It ignores the adverse selection channel, where banks might increase `r^H` to shed L-type traders, which is the central point of the capital requirement analysis. Selecting this indicates a superficial understanding of the paper's policy argument.", "qid": "47", "question": "### Background\n\nTwo banks compete for High-ability (H) and Low-ability (L) traders. The system is in an equilibrium where banks induce excessive risk-taking (`r^H > R*`) from H-traders as a screening device. A regulator considers two policies to mitigate this risk: a direct cap on the bonus ratio (`\\bar{R}`) and an indirect increase in bank capital requirements (modeled as an increase in the loss parameter `x_{-1}`).\n\n### Data / Model Specification\n\n**Policy 1: Bonus Cap.** A binding cap `\\bar{R}` is imposed, so `r^H = \\bar{R}`. Total welfare is the sum of gross profits:\n\n  \nW = \\phi\\pi^{L}(R^{\\ast}) + (1-\\phi)\\pi^{H}(r^{H}) \\quad \\text{(Eq. 1)}\n \n\nGross profit `\\pi^H(r^H)` is maximized at `r^H = R*`.\n\n**Policy 2: Capital Requirements.** An increase in bank equity `E` is equivalent to increasing the loss parameter `x_{-1}`. The bank's gross profit from a type-`j` trader is `\\pi^j = q_1^j x_1 + q_0^j x_0 - q_{-1}^j x_{-1}`. The partial derivative of profit with respect to this loss is:\n\n  \n\\frac{\\partial \\pi^j}{\\partial x_{-1}} = -q_{-1}^j \\quad \\text{(Eq. 2)}\n \n\nUnder the simplifying assumption that H-type projects are inelastic to the bonus ratio (`\\partial \\pi^H / \\partial r^H = 0`), the equilibrium condition is:\n\n  \n\\left(\\pi^{H}(r^{H}, x_{-1})-\\tau^{H}\\right)f(r^{H}) = \\pi^{L}(R^{*}, x_{-1})-\\tau^{L} \\quad \\text{(Eq. 3)}\n \n\n### Question\n\nBased on the model's analysis of these two regulatory policies, which of the following statements are valid conclusions? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"B,C,D\"", "model_answer": ["B", "C", "D"], "error": null}}
{"ID": 49, "Question": "### Background\n\n**Research Question:** In a sequential public goods game, how does a player's position in the sequence of moves causally affect their contribution level, and what behavioral mechanisms drive this effect?\n\n**Setting / Institutional Environment:** Subjects play a sequential Voluntary Contribution Mechanism (VCM) game in groups of seven. The experiment reveals two key findings: (1) overall cooperation is higher in simultaneous-move games than in sequential-move games, and (2) within sequential games, there is a 'diminution effect' where contributions are highest for the first mover and decline for later positions.\n\n**Variables & Parameters.**\n- **First Mover:** The player in position 1, who acts with no information about others' choices. Mean contribution was 4.9 tokens.\n- **Subsequent Movers:** Players in positions 2-7. Their overall mean contribution was 2.1 tokens.\n\n---\n\n### Data / Model Specification\n\nThe payoff function for individual `i` in a group of `n=7` is given by:\n  \nC_{i} = 10 - w_{i} + \\frac{2 \\sum_{h=1}^{n} w_{h}}{n}\n \n(Eq. (1))\n\nwhere `w_i` is player `i`'s contribution from a 10-token endowment.\n\n---\n\n### Question\n\nBased on the provided model and experimental findings, select all statements that correctly analyze the behavior of first movers in the sequential game.", "Options": {"A": "The observed average contribution of 2.1 tokens from subsequent movers implies that the average first mover incurred a significant financial loss on their contribution.", "B": "For a first mover contributing 4.9 tokens to break even (i.e., earn at least their 10-token endowment), the average contribution from the other six players must be at least 2.04 tokens.", "C": "The 'overconfidence' mechanism suggests that contributions are higher in simultaneous games because subjects can act on optimistic beliefs, whereas in sequential games, these beliefs are often invalidated by observing others' actual, lower contributions.", "D": "A first mover contributing 4.9 tokens would need the other six players to contribute an average of at least 4.9 tokens to break even."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: This item tests the ability to connect a behavioral theory (overconfidence) to empirical results and verify it with a quantitative calculation based on the model.\nStrategy: Computational Judgment & Atomic Decomposition. The item combines the conceptual reasoning from Part 1 of the source QA with the specific calculation from Part 2.\nDistractor Logic:\n- C (Formula Misuse): This distractor arises from incorrectly assuming a 1-for-1 return on investment or misapplying the payoff function, a common error.\n- D (Computational Judgment Error): This distractor requires performing the calculation correctly and then interpreting the result. Since the breakeven point (2.04) was met by the observed average (2.1), the statement of a 'significant financial loss' is false.", "qid": "49", "question": "### Background\n\n**Research Question:** In a sequential public goods game, how does a player's position in the sequence of moves causally affect their contribution level, and what behavioral mechanisms drive this effect?\n\n**Setting / Institutional Environment:** Subjects play a sequential Voluntary Contribution Mechanism (VCM) game in groups of seven. The experiment reveals two key findings: (1) overall cooperation is higher in simultaneous-move games than in sequential-move games, and (2) within sequential games, there is a 'diminution effect' where contributions are highest for the first mover and decline for later positions.\n\n**Variables & Parameters.**\n- **First Mover:** The player in position 1, who acts with no information about others' choices. Mean contribution was 4.9 tokens.\n- **Subsequent Movers:** Players in positions 2-7. Their overall mean contribution was 2.1 tokens.\n\n---\n\n### Data / Model Specification\n\nThe payoff function for individual `i` in a group of `n=7` is given by:\n  \nC_{i} = 10 - w_{i} + \\frac{2 \\sum_{h=1}^{n} w_{h}}{n}\n \n(Eq. (1))\n\nwhere `w_i` is player `i`'s contribution from a 10-token endowment.\n\n---\n\n### Question\n\nBased on the provided model and experimental findings, select all statements that correctly analyze the behavior of first movers in the sequential game.", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 44, "Question": "### Background\n\nThis problem investigates the welfare implications in a first-price procurement auction where one supplier is granted a Right of First Refusal (ROFR). The analysis compares this 'preference auction' (PA) to a standard first-price auction (FPA).\n\n### Data / Model Specification\n\nThe paper's Proposition 2 states that if the inverse hazard rate `[1-G(c)]/g(c)` is decreasing and convex, the expected joint surplus of the buyer and the Preferred Supplier (PS) is higher in the PA than the FPA. This gain for the buyer-PS coalition is achieved because the Competing Suppliers (CSs) are induced to bid more aggressively.\n\n### Question\n\nAccording to the paper's analysis, select all correct statements about the welfare implications of granting a ROFR in a first-price auction.", "Options": {"A": "The ROFR is always allocatively efficient because the contract is awarded to the party (either the PS or a CS) willing to accept the lowest price in stage 3.", "B": "The buyer-PS coalition's joint surplus increases because the expected price paid by the buyer decreases, and the PS's expected profit increases, relative to a standard first-price auction.", "C": "The increase in the buyer-PS coalition's surplus is a direct result of an increase in total social surplus (the sum of surplus for the buyer and all `n+1` suppliers).", "D": "The ROFR mechanism can be allocatively inefficient. This occurs when the lowest-cost CS has a cost `c_k`, the PS has a cost `c_p`, and the winning CS bid `b(c_k)` satisfies `c_k < c_p < b(c_k)`."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: Tests the student's ability to distinguish between the welfare of the buyer-PS coalition and total social welfare, and to identify the specific source of allocative inefficiency created by the ROFR.\nStrategy: Atomic Decomposition. The question asks for correct statements regarding the decomposition of the coalition's surplus gain (A) and the nature of the allocative inefficiency (B).\nDistractor Logic:\n- (C) is a classic misconception, confusing a transfer of surplus (from CSs to the coalition) with the creation of new surplus. The paper shows the coalition's gain comes at the expense of CSs and can coincide with a decrease in total surplus.\n- (D) is a Conceptual Opposite that misinterprets the ROFR mechanism. The PS matches the price, but her underlying cost may be higher than the most efficient CS's cost, which is the source of the inefficiency.", "qid": "44", "question": "### Background\n\nThis problem investigates the welfare implications in a first-price procurement auction where one supplier is granted a Right of First Refusal (ROFR). The analysis compares this 'preference auction' (PA) to a standard first-price auction (FPA).\n\n### Data / Model Specification\n\nThe paper's Proposition 2 states that if the inverse hazard rate `[1-G(c)]/g(c)` is decreasing and convex, the expected joint surplus of the buyer and the Preferred Supplier (PS) is higher in the PA than the FPA. This gain for the buyer-PS coalition is achieved because the Competing Suppliers (CSs) are induced to bid more aggressively.\n\n### Question\n\nAccording to the paper's analysis, select all correct statements about the welfare implications of granting a ROFR in a first-price auction.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 50, "Question": "### Background\n\n**Research Question:** How do individual incentives conflict with group welfare in a public goods game with a Voluntary Contribution Mechanism (VCM)?\n\n**Setting / Institutional Environment:** Subjects participate in a VCM public good experiment. Each subject is part of a group of `n=7` and must decide how to allocate a 10-token endowment between a private account (which they keep) and a public account (which benefits all group members).\n\n---\n\n### Data / Model Specification\n\nThe payoff function for individual `i` is given by:\n  \nC_{i} = 10 - w_{i} + \\frac{2 \\sum_{h=1}^{n} w_{h}}{n}\n \n(Eq. (1))\n\nwhere `w_i` is individual `i`'s contribution to the public good (`w_i ∈ [0, 10]`) and `n=7`.\n\n---\n\n### Question\n\nBased on a formal analysis of the payoff function provided in Eq. (1) for a group of `n=7`, select all statements that are mathematically correct.", "Options": {"A": "The marginal social return for contributing one token is constant and positive (+1), making a contribution of `w_i = 10` from all players the socially optimal outcome.", "B": "To align private and social incentives in a modified function `C_i(α) = 10 - w_i + (α / n) * Σw_h`, the productivity parameter `α` must be greater than 1.", "C": "The social dilemma can be resolved by increasing the group size `n`, as a larger group makes the marginal private return `(2/n - 1)` positive.", "D": "The marginal private return for contributing one token is constant and negative (–5/7), making a contribution of `w_i = 0` the dominant strategy for a self-interested player."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item tests the ability to derive and interpret the core incentive structure of the VCM game, distinguishing between private and social optima.\nStrategy: Computational Judgment & Atomic Decomposition. The item converts the multi-part derivation from the source QA into a set of verifiable conclusions.\nDistractor Logic:\n- C (Calculation Error): This distractor represents a common error in the comparative statics exercise, where the condition `α > n` is incorrectly simplified to `α > 1`.\n- D (Conceptual Opposite): This distractor posits the exact opposite of the model's prediction. Increasing `n` makes the marginal private return `2/n - 1` more negative, exacerbating the social dilemma rather than resolving it.", "qid": "50", "question": "### Background\n\n**Research Question:** How do individual incentives conflict with group welfare in a public goods game with a Voluntary Contribution Mechanism (VCM)?\n\n**Setting / Institutional Environment:** Subjects participate in a VCM public good experiment. Each subject is part of a group of `n=7` and must decide how to allocate a 10-token endowment between a private account (which they keep) and a public account (which benefits all group members).\n\n---\n\n### Data / Model Specification\n\nThe payoff function for individual `i` is given by:\n  \nC_{i} = 10 - w_{i} + \\frac{2 \\sum_{h=1}^{n} w_{h}}{n}\n \n(Eq. (1))\n\nwhere `w_i` is individual `i`'s contribution to the public good (`w_i ∈ [0, 10]`) and `n=7`.\n\n---\n\n### Question\n\nBased on a formal analysis of the payoff function provided in Eq. (1) for a group of `n=7`, select all statements that are mathematically correct.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 43, "Question": "### Background\n\nThis problem investigates the equilibrium bidding behavior in a first-price procurement auction where one supplier is granted a Right of First Refusal (ROFR). This 'preference auction' (PA) is compared to a standard first-price auction (FPA).\n\n### Data / Model Specification\n\nIn a PA, `n` Competing Suppliers (CS) submit bids. A CS with true cost `c` chooses a bid `b(z)` (corresponding to a pretended cost `z`) to maximize expected profit:\n\n  \n\\max_{z} \\Pi_{k}[b(z);c] = (b(z)-c) \\cdot [1-G(b(z))] \\cdot [1-G(z)]^{n-1} \\quad \\text{(Eq. (1))}\n \n\nThe paper shows that if the inverse hazard rate `[1-G(c)]/g(c)` is decreasing and convex, CSs bid more aggressively (lower their bids) in a PA compared to an FPA.\n\n### Question\n\nSelect all statements that correctly describe the strategic environment faced by a Competing Supplier (CS) and the resulting bidding behavior.", "Options": {"A": "Faced with a PS holding a ROFR, CSs will bid less aggressively (submit higher bids) to increase their profit margin, since their probability of winning is already lower.", "B": "The presence of the ROFR introduces an additional losing condition for any given bid, which, under certain distributional assumptions, incentivizes CSs to bid more aggressively (lower) to increase their overall win probability.", "C": "The term `[1-G(b(z))]` in Eq. (1) represents the probability that the CS's bid `b(z)` is lower than the costs of the other `n-1` CSs.", "D": "For a CS to win the contract, their bid must be the lowest among all CSs, and the Preferred Supplier's (PS) cost must be higher than that bid."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: Tests the student's understanding of the micro-foundations of the Competing Supplier's bidding strategy in a preference auction.\nStrategy: Atomic Decomposition. The question breaks down the strategic problem into interpreting the profit function (A, C) and explaining the resulting behavioral change (B, D).\nDistractor Logic:\n- (C) is a direct misinterpretation of the model's terms (Conceptual Error), confusing the condition for winning against the PS with the condition for winning against other CSs.\n- (D) represents a plausible but incorrect line of reasoning (Conceptual Opposite). It posits the opposite behavioral reaction to the lowered win probability, which contradicts the paper's core finding.", "qid": "43", "question": "### Background\n\nThis problem investigates the equilibrium bidding behavior in a first-price procurement auction where one supplier is granted a Right of First Refusal (ROFR). This 'preference auction' (PA) is compared to a standard first-price auction (FPA).\n\n### Data / Model Specification\n\nIn a PA, `n` Competing Suppliers (CS) submit bids. A CS with true cost `c` chooses a bid `b(z)` (corresponding to a pretended cost `z`) to maximize expected profit:\n\n  \n\\max_{z} \\Pi_{k}[b(z);c] = (b(z)-c) \\cdot [1-G(b(z))] \\cdot [1-G(z)]^{n-1} \\quad \\text{(Eq. (1))}\n \n\nThe paper shows that if the inverse hazard rate `[1-G(c)]/g(c)` is decreasing and convex, CSs bid more aggressively (lower their bids) in a PA compared to an FPA.\n\n### Question\n\nSelect all statements that correctly describe the strategic environment faced by a Competing Supplier (CS) and the resulting bidding behavior.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 54, "Question": "### Background\n\n**Research Question.** This problem investigates how uncertainty in knowledge spillovers affects a household's optimal investment decision, with a focus on how this effect is mediated by preferences.\n\n**Setting.** The analysis is based on a Romer-style endogenous growth model with learning-by-doing and knowledge spillovers. A representative agent with a Constant Elasticity of Substitution (CES) utility function chooses consumption and investment to maximize expected lifetime utility. The productivity of knowledge spillovers is stochastic.\n\n### Data / Model Specification\n\nThe agent's preferences are represented by the CES utility function:\n  \nU(c) = \\frac{c^{1-\\theta}}{1-\\theta} \\quad \\text{(Eq. 1)}\n \nwhere `θ ≥ 0` is the coefficient of relative risk aversion.\n\nThe optimal investment policy is linear in output, `x_t = S \\cdot y_t`, where the investment share `S` is:\n  \nS = \\left\\{ \\delta\\beta\\eta^{1-\\theta} E\\left[ (\\gamma_t L)^{(1-\\theta)(1-\\beta)} \\right] \\right\\}^{1/\\theta} \\quad \\text{(Eq. 2)}\n \nwhere `γ` is a random productivity shock, `δ` is the discount factor, `L` is the constant labor force, and `β ∈ (0,1)`.\n\n### Question\n\nAccording to the model, which of the following statements correctly describe how an increase in the volatility of the productivity shock `γ` (i.e., a mean-preserving spread) affects the optimal investment share `S`?", "Options": {"A": "If `θ > 1`, the investment share `S` increases because the agent's precautionary savings motive outweighs the negative effect of diminishing returns to knowledge.", "B": "If `θ = 1` (logarithmic utility), the investment share `S` decreases because the precautionary savings motive is absent, leaving only the negative return effect.", "C": "For any `θ > 0`, the investment share `S` is unaffected because the random shock `γ` is i.i.d. and agents cannot learn from it.", "D": "If `0 < θ < 1`, the investment share `S` decreases because the negative effect of diminishing returns to knowledge outweighs the agent's incentive to smooth consumption."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item tests the student's ability to dissect the two opposing effects of uncertainty on investment—the technology-driven 'return effect' and the preference-driven 'precautionary savings effect'—and determine which dominates based on the coefficient of relative risk aversion, `θ`.\n\nChosen Strategy: Atomic Decomposition. The original QA problem's core logic is decomposed into distinct, testable propositions corresponding to different preference regimes (`θ > 1` and `0 < θ < 1`). This structure creates a genuine multi-select question where each correct option validates understanding of a specific case.\n\nDistractor Logic:\n- **Option C (Almost Right):** Correctly identifies that the precautionary motive is absent at `θ=1`, but incorrectly concludes that the return effect causes a decrease. The paper shows the two effects exactly cancel, leaving the investment share unchanged. This targets a partial understanding of the mechanism.\n- **Option D (Conceptual Opposite):** This distractor conflates the statistical properties of the shock (i.i.d.) with the agent's behavioral response to risk. The i.i.d. nature of the shock is a modeling assumption, but it does not nullify the agent's reaction to its variance. This tests for a deeper conceptual error.", "qid": "54", "question": "### Background\n\n**Research Question.** This problem investigates how uncertainty in knowledge spillovers affects a household's optimal investment decision, with a focus on how this effect is mediated by preferences.\n\n**Setting.** The analysis is based on a Romer-style endogenous growth model with learning-by-doing and knowledge spillovers. A representative agent with a Constant Elasticity of Substitution (CES) utility function chooses consumption and investment to maximize expected lifetime utility. The productivity of knowledge spillovers is stochastic.\n\n### Data / Model Specification\n\nThe agent's preferences are represented by the CES utility function:\n  \nU(c) = \\frac{c^{1-\\theta}}{1-\\theta} \\quad \\text{(Eq. 1)}\n \nwhere `θ ≥ 0` is the coefficient of relative risk aversion.\n\nThe optimal investment policy is linear in output, `x_t = S \\cdot y_t`, where the investment share `S` is:\n  \nS = \\left\\{ \\delta\\beta\\eta^{1-\\theta} E\\left[ (\\gamma_t L)^{(1-\\theta)(1-\\beta)} \\right] \\right\\}^{1/\\theta} \\quad \\text{(Eq. 2)}\n \nwhere `γ` is a random productivity shock, `δ` is the discount factor, `L` is the constant labor force, and `β ∈ (0,1)`.\n\n### Question\n\nAccording to the model, which of the following statements correctly describe how an increase in the volatility of the productivity shock `γ` (i.e., a mean-preserving spread) affects the optimal investment share `S`?", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 33, "Question": "### Background\n\n**Research Question.** This problem examines how wages are determined in a non-competitive primary labor market through a formal bargaining process between a firm and a union.\n\n**Setting / Institutional Environment.** The wage for organization-specific (primary) labor, `w_1`, is not set by market clearing but by collective bargaining. The bargaining occurs over the quasi-rent generated by the firm's fixed factors. The secondary market wage, `w_2`, serves as the workers' outside option, forming the floor of the bargaining range. The ceiling is the maximum wage the firm can sustain without ceasing to grow.\n\n**Variables & Parameters.**\n- `w_1(t)`: Real wage in the primary market.\n- `w_2(t)`: Real wage in the secondary market (workers' outside option).\n- `w_1^{\\max}(t)`: Maximum sustainable wage (firm's reservation point).\n- `m`: A positive parameter representing the trade union's relative bargaining power.\n- `r_c(t)`: Gross organizational quasi-rent per unit of capital.\n- `r^{\\min}(t)`: Minimum net rate of quasi-rent required by the firm to achieve zero growth.\n- `a`: The fixed number of primary workers per unit of capital.\n- `r(t)`: The net rate of quasi-rent per unit of capital accruing to shareholders.\n\n---\n\n### Data / Model Specification\n\nThe outcome of the wage bargain is modeled as a weighted average of the upper and lower bounds of the bargaining range:\n\n  \nw_1(t) = \\frac{m}{1+m}w_1^{\\max}(t) + \\frac{1}{1+m}w_2(t) \\quad \\text{(Eq. (1))}\n \n\nThe maximum wage is determined by the firm's viability constraint:\n\n  \nw_1^{\\max}(t) = \\frac{r_c(t) - r^{\\min}(t)}{a} \\quad \\text{(Eq. (2))}\n \n\nThe net return to capital is defined as the residual after paying primary workers:\n\n  \nr(t) = r_c(t) - a \\cdot w_1(t) \\quad \\text{(Eq. (3))}\n \n\n---\n\nConsider a scenario where an exogenous shock increases the minimum required return on capital, `r^{\\min}(t)`, while holding `r_c(t)` and `w_2(t)` constant. Based on the bargaining model, which of the following outcomes are **INCORRECT** descriptions of how the burden of this shock is distributed?\n", "Options": {"A": "The primary wage `w_1` will increase because the firm must offer higher pay to retain its specialized workforce during a period of financial stress.", "B": "The net return to capital `r` will decrease as the firm is forced to absorb the entire shock to its required return.", "C": "The union bears none of the burden, as the wage bargain `w_1` is independent of the firm's minimum profitability constraint `r^{\\min}`.", "D": "The primary wage `w_1` will decrease, and the net return to capital `r` will increase, with the burden of the shock being shared between workers and shareholders."}, "Answer": ["A", "B", "C"], "pi_justification": "Assessment Target: This item assesses the ability to perform comparative statics on a bargaining model to understand how an exogenous shock is distributed between labor and capital. Depth Strategy: Computational Judgment and Reverse-Reasoning. The user must first derive the effects of the shock and then identify the incorrect statements. The Single-Correct-Answer Inversion Protocol was applied because there is only one correct description of the outcome (Option D), making it a suitable distractor in a 'select all that are NOT correct' format. Distractor Logic: The correct answer (and thus the distractor here) is Option D, which accurately describes the outcome: `∂w_1/∂r^min < 0` and `∂r/∂r^min > 0`. Options A, B, and C represent plausible but incorrect reasoning paths. A is a Sign Error. B is a Step-Omission Error (ignores that wages adjust). C is a Conceptual Error (ignores the link between `r^min` and `w_1^max`). By inverting the question, the three incorrect statements become the correct answers to select.", "qid": "33", "question": "### Background\n\n**Research Question.** This problem examines how wages are determined in a non-competitive primary labor market through a formal bargaining process between a firm and a union.\n\n**Setting / Institutional Environment.** The wage for organization-specific (primary) labor, `w_1`, is not set by market clearing but by collective bargaining. The bargaining occurs over the quasi-rent generated by the firm's fixed factors. The secondary market wage, `w_2`, serves as the workers' outside option, forming the floor of the bargaining range. The ceiling is the maximum wage the firm can sustain without ceasing to grow.\n\n**Variables & Parameters.**\n- `w_1(t)`: Real wage in the primary market.\n- `w_2(t)`: Real wage in the secondary market (workers' outside option).\n- `w_1^{\\max}(t)`: Maximum sustainable wage (firm's reservation point).\n- `m`: A positive parameter representing the trade union's relative bargaining power.\n- `r_c(t)`: Gross organizational quasi-rent per unit of capital.\n- `r^{\\min}(t)`: Minimum net rate of quasi-rent required by the firm to achieve zero growth.\n- `a`: The fixed number of primary workers per unit of capital.\n- `r(t)`: The net rate of quasi-rent per unit of capital accruing to shareholders.\n\n---\n\n### Data / Model Specification\n\nThe outcome of the wage bargain is modeled as a weighted average of the upper and lower bounds of the bargaining range:\n\n  \nw_1(t) = \\frac{m}{1+m}w_1^{\\max}(t) + \\frac{1}{1+m}w_2(t) \\quad \\text{(Eq. (1))}\n \n\nThe maximum wage is determined by the firm's viability constraint:\n\n  \nw_1^{\\max}(t) = \\frac{r_c(t) - r^{\\min}(t)}{a} \\quad \\text{(Eq. (2))}\n \n\nThe net return to capital is defined as the residual after paying primary workers:\n\n  \nr(t) = r_c(t) - a \\cdot w_1(t) \\quad \\text{(Eq. (3))}\n \n\n---\n\nConsider a scenario where an exogenous shock increases the minimum required return on capital, `r^{\\min}(t)`, while holding `r_c(t)` and `w_2(t)` constant. Based on the bargaining model, which of the following outcomes are **INCORRECT** descriptions of how the burden of this shock is distributed?\n", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 57, "Question": "### Background\n\nIn a duopoly market, consumers are situated in social networks where each person has `k` links. Consumers endogenously choose to be active searchers (fraction `q`) or passive waiters. Firms' incentive to lower prices depends on the ratio (`η`) of non-price-comparing to price-comparing consumers. Price dispersion persists as long as `η` is a finite, positive number.\n\n### Data / Model Specification\n\nThe ratio `η` is given by:\n\n  \n\\eta = \\frac{q/2 + \\delta\\mu_1}{\\delta\\mu_2}\n \n\nwhere `δ` is the discount factor for passive consumers, and `μ_1` and `μ_2` are the fractions of passive consumers who see only one price or both prices, respectively. These fractions are functions of `q` and `k`:\n\n- `μ_1 = (1-q)[(1-q/2)^k - (1-q)^k]`\n- `μ_2 = (1-q)[1 + (1-q)^k - 2(1-q/2)^k]`\n\nAn equilibrium with positive sales requires that the fraction of searchers `q` is between 0 and 1, which is sustained by a positive search cost, `s > 0`.\n\n### Question\n\nConsider the limiting case where networks become infinitely dense (`k → ∞`) while the equilibrium fraction of searchers `q` remains fixed in the interval `(0, 1)`. Which of the following statements are valid conclusions for this scenario? Select all that apply.", "Options": {"A": "The fraction of passive consumers who are informed of only one price (`μ_1`) converges to zero.", "B": "The ratio `η` converges to `q / (2δ(1-q))`, a finite and positive value.", "C": "Price dispersion disappears and prices converge to marginal cost because all passive consumers become perfectly informed.", "D": "The continued existence of a positive fraction `q` of active searchers, who do not compare prices, is essential for sustaining price dispersion in the limit."}, "Answer": ["A", "B", "D"], "pi_justification": "This item assesses the understanding of a key comparative static result regarding network density. It uses a Computational Judgment strategy, requiring the user to evaluate limits and interpret their economic meaning.\n- **Correct Options (A, B, D):** These options correctly describe the mathematical limits and their economic interpretation. (A) is a direct calculation. (B) is the calculation for the main variable `η`. (D) correctly identifies the crucial economic mechanism (the role of active searchers) that sustains the result in (B).\n- **Distractor (C):** This is a Conceptual Distractor (Almost Right). While it's true that passive consumers become perfectly informed, this option ignores the persistent non-price-comparing segment of *active* searchers, leading to the incorrect conclusion that price dispersion disappears.", "qid": "57", "question": "### Background\n\nIn a duopoly market, consumers are situated in social networks where each person has `k` links. Consumers endogenously choose to be active searchers (fraction `q`) or passive waiters. Firms' incentive to lower prices depends on the ratio (`η`) of non-price-comparing to price-comparing consumers. Price dispersion persists as long as `η` is a finite, positive number.\n\n### Data / Model Specification\n\nThe ratio `η` is given by:\n\n  \n\\eta = \\frac{q/2 + \\delta\\mu_1}{\\delta\\mu_2}\n \n\nwhere `δ` is the discount factor for passive consumers, and `μ_1` and `μ_2` are the fractions of passive consumers who see only one price or both prices, respectively. These fractions are functions of `q` and `k`:\n\n- `μ_1 = (1-q)[(1-q/2)^k - (1-q)^k]`\n- `μ_2 = (1-q)[1 + (1-q)^k - 2(1-q/2)^k]`\n\nAn equilibrium with positive sales requires that the fraction of searchers `q` is between 0 and 1, which is sustained by a positive search cost, `s > 0`.\n\n### Question\n\nConsider the limiting case where networks become infinitely dense (`k → ∞`) while the equilibrium fraction of searchers `q` remains fixed in the interval `(0, 1)`. Which of the following statements are valid conclusions for this scenario? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 53, "Question": "### Background\n\n**Research Question.** To identify the causal effect of the SME sector on economic growth, the paper employs an instrumental variables (IV) strategy. The validity of this strategy rests on two key assumptions: instrument relevance and the exclusion restriction.\n\n**Variables & Parameters.**\n- `SME250`: The endogenous regressor (share of SME employment).\n- `Growth`: The outcome variable (GDP per capita growth).\n- `Z`: A vector of instrumental variables, including `Ethnic fractionalization` and regional/transition dummies.\n- `ε`: The error term in the growth regression.\n\n---\n\n### Data / Model Specification\n\nThe two key assumptions for IV validity are:\n1.  **Relevance:** `Cov(Z, SME250) ≠ 0`\n2.  **Exclusion Restriction:** `Cov(Z, ε) = 0` (The instruments affect growth *only* through their effect on `SME250` and other controls).\n\nThe paper argues that the instruments are valid because they are deep-rooted national characteristics that shape the business environment, which in turn influences firm size distribution.\n\n---\n\nWhich of the following statements represent valid critiques or considerations regarding the IV strategy used in the paper?\n\nSelect all that apply.", "Options": {"A": "The exclusion restriction could be violated if ethnic fractionalization directly harms growth through channels like political instability or poor public policy, independent of its effect on firm size.", "B": "The Hansen test of overidentifying restrictions (OIR test) proves that the exclusion restriction holds, making the IV estimates definitively unbiased.", "C": "If the exclusion restriction is violated such that `Cov(Ethnic fractionalization, ε) < 0`, and given the paper's finding that `Cov(Ethnic fractionalization, SME250) < 0`, the IV estimate for the effect of SMEs on growth would be biased upwards.", "D": "The paper's argument for instrument relevance is that deep-rooted factors like legal origin and ethnic diversity shape the institutional environment, which in turn determines the optimal firm size distribution."}, "Answer": ["A", "C", "D"], "pi_justification": "This item assesses a deep understanding of the instrumental variables method and the ability to critically evaluate its application. It uses a 'Reverse-Reasoning' strategy by asking for valid critiques of the methodology. Option A presents a plausible violation of the exclusion restriction, a key skill in applied econometrics. Option B correctly summarizes the paper's own logic for why the instruments should be relevant. Option C requires a multi-step 'Computational Judgment' to correctly sign the asymptotic bias resulting from a specific violation of the exclusion restriction. The distractor (D) is a 'Conceptual Distractor' that overstates the power of the OIR test; failing to reject the null hypothesis is not proof that the null is true, a crucial nuance in econometrics.", "qid": "53", "question": "### Background\n\n**Research Question.** To identify the causal effect of the SME sector on economic growth, the paper employs an instrumental variables (IV) strategy. The validity of this strategy rests on two key assumptions: instrument relevance and the exclusion restriction.\n\n**Variables & Parameters.**\n- `SME250`: The endogenous regressor (share of SME employment).\n- `Growth`: The outcome variable (GDP per capita growth).\n- `Z`: A vector of instrumental variables, including `Ethnic fractionalization` and regional/transition dummies.\n- `ε`: The error term in the growth regression.\n\n---\n\n### Data / Model Specification\n\nThe two key assumptions for IV validity are:\n1.  **Relevance:** `Cov(Z, SME250) ≠ 0`\n2.  **Exclusion Restriction:** `Cov(Z, ε) = 0` (The instruments affect growth *only* through their effect on `SME250` and other controls).\n\nThe paper argues that the instruments are valid because they are deep-rooted national characteristics that shape the business environment, which in turn influences firm size distribution.\n\n---\n\nWhich of the following statements represent valid critiques or considerations regarding the IV strategy used in the paper?\n\nSelect all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 48, "Question": "### Background\n\n**Research Question:** How can experimental designs ensure validity when the underlying behavioral assumptions of rationality are violated? This question explores the methodological foundation of the Conditional Information Lottery (CIL) design.\n\n**Setting / Institutional Environment:** The validity of the CIL design rests on the 'isolation hypothesis'—the assumption that subjects treat each of a series of tasks as if it were the only real one. This hypothesis is guaranteed if subjects' preferences satisfy the independence axiom of Expected Utility Theory (EUT).\n\n---\n\n### Data / Model Specification\n\n**The Isolation Hypothesis:** The rational argument for the isolation hypothesis is represented by the following act/event matrix for a given Task X:\n\n**Table 1. Act/Event Matrix for Task X**\n\n| | Event 1: Task X is Fictional | Event 2: Task X is Real |\n| :--- | :--- | :--- |\n| **Action 1:** Treat task X as real | No consequence | Preferred outcome |\n| **Action 2:** Treat task X as fictional | No consequence | Less preferred outcome |\n\n**A Threat to the Isolation Hypothesis:** Violations of the independence axiom can threaten the isolation hypothesis. Consider a choice between two pairs of prospects:\n\nPair 1: A choice between prospect `J` and prospect `K`.\n  \nJ: (x, p; 0, 1-p) \\quad \\text{vs.} \\quad K: (y, q; 0, 1-q)\n \n\nPair 2: A choice between prospect `M` and prospect `N`.\n  \nM: (x, \\lambda p; 0, 1 - \\lambda p) \\quad \\text{vs.} \\quad N: (y, \\lambda q; 0, 1 - \\lambda q)\n \n(Eq. (1))\n\nwhere `y` is preferred to `x`, `p > q`, and `0 < λ < 1`. The 'common ratio effect' is the empirical finding that subjects often exhibit the preference pattern `J ≻ K` but `N ≻ M`, which violates EUT.\n\n---\n\n### Question\n\nSelect all statements that accurately describe the methodological foundations and potential challenges of the Conditional Information Lottery (CIL) design, based on the provided information.", "Options": {"A": "Holt's conjecture suggests that the CIL design structurally transforms the choice problem into one with scaled-down probabilities, where the scaling factor λ equals the reciprocal of the total number of tasks (e.g., 1/30 in this experiment).", "B": "The validity of the CIL design is guaranteed by the common ratio effect, which shows that subjects consistently apply the independence axiom.", "C": "According to the act/event matrix (Table 1), treating each task as real is a weakly dominant strategy because it yields an outcome that is never worse, and potentially better, than treating the task as fictional.", "D": "The normative rational choice argument (Table 1) and the descriptive behavioral argument (Holt's conjecture) are mutually reinforcing, both concluding that the isolation hypothesis will hold in practice."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: This item tests the understanding of the core methodological justification for the CIL design and its primary behavioral critique.\nStrategy: Atomic Decomposition. The original QA problem's three parts are broken down into independently verifiable statements about weak dominance (Part 1), Holt's conjecture (Part 2), and the tension between them (Part 3).\nDistractor Logic:\n- C (Conceptual Opposite): Claims the common ratio effect *guarantees* validity, when in fact it *threatens* it by violating the independence axiom.\n- D (Conceptual Opposite): Claims the normative and descriptive arguments are mutually reinforcing, when the paper presents them as being in fundamental tension.", "qid": "48", "question": "### Background\n\n**Research Question:** How can experimental designs ensure validity when the underlying behavioral assumptions of rationality are violated? This question explores the methodological foundation of the Conditional Information Lottery (CIL) design.\n\n**Setting / Institutional Environment:** The validity of the CIL design rests on the 'isolation hypothesis'—the assumption that subjects treat each of a series of tasks as if it were the only real one. This hypothesis is guaranteed if subjects' preferences satisfy the independence axiom of Expected Utility Theory (EUT).\n\n---\n\n### Data / Model Specification\n\n**The Isolation Hypothesis:** The rational argument for the isolation hypothesis is represented by the following act/event matrix for a given Task X:\n\n**Table 1. Act/Event Matrix for Task X**\n\n| | Event 1: Task X is Fictional | Event 2: Task X is Real |\n| :--- | :--- | :--- |\n| **Action 1:** Treat task X as real | No consequence | Preferred outcome |\n| **Action 2:** Treat task X as fictional | No consequence | Less preferred outcome |\n\n**A Threat to the Isolation Hypothesis:** Violations of the independence axiom can threaten the isolation hypothesis. Consider a choice between two pairs of prospects:\n\nPair 1: A choice between prospect `J` and prospect `K`.\n  \nJ: (x, p; 0, 1-p) \\quad \\text{vs.} \\quad K: (y, q; 0, 1-q)\n \n\nPair 2: A choice between prospect `M` and prospect `N`.\n  \nM: (x, \\lambda p; 0, 1 - \\lambda p) \\quad \\text{vs.} \\quad N: (y, \\lambda q; 0, 1 - \\lambda q)\n \n(Eq. (1))\n\nwhere `y` is preferred to `x`, `p > q`, and `0 < λ < 1`. The 'common ratio effect' is the empirical finding that subjects often exhibit the preference pattern `J ≻ K` but `N ≻ M`, which violates EUT.\n\n---\n\n### Question\n\nSelect all statements that accurately describe the methodological foundations and potential challenges of the Conditional Information Lottery (CIL) design, based on the provided information.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 51, "Question": "### Background\n\n**Research Question.** This problem interrogates the causal relationship between the size of a country's SME sector and its economic growth by comparing Ordinary Least Squares (OLS) and Instrumental Variable (IV) estimates from a cross-country growth regression for the 1990s.\n\n**Variables & Parameters.**\n- `GDP per capita growth`: The dependent variable, averaged over 1990-2000.\n- `SME250`: The key independent variable, representing the share of SME employment in manufacturing.\n- Unit of observation: Country `i`.\n\n---\n\n### Data / Model Specification\n\nThe estimated growth regression is:\n  \n\\text{GDP per capita growth}_i = \\beta_0 + \\beta_1 \\mathrm{SME250}_{i} + \\text{Controls}_i + \\varepsilon_{i} \n \n\n**Table 1: SME Employment and Growth Regressions**\n(Corresponds to Table 5 in the source)\n\n| | (1) OLS | (3) IV |\n| :--- | :---: | :---: |\n| **Outliers** | **Full Sample** | **Full Sample** |\n| `SME250` | 2.197*** | 1.863* |\n| | (0.687) | (1.047) |\n| **IV Diagnostics** | | |\n| F-Test (p-value) | | 0.000 |\n| OIR Test (p-value) | | 0.118 |\n| Observations | 45 | 45 |\n\n*Note: Robust standard errors in parentheses. *** p<0.01, * p<0.10. F-test is for the joint significance of excluded instruments in the first stage. OIR is the Hansen test of overidentifying restrictions.* \n\n---\n\nBased on the regression results and the paper's discussion, which of the following statements are valid interpretations of the findings?\n\nSelect all that apply.", "Options": {"A": "The OLS estimate is highly statistically significant (p<0.01), while the IV estimate is only marginally significant (p<0.10), indicating that the evidence for a causal link is weaker than the evidence for a simple correlation.", "B": "The IV diagnostic tests in Column (3) indicate that the instruments are both relevant (F-test p-value < 0.01) and satisfy the exclusion restriction (OIR Test p-value > 0.10).", "C": "The IV estimate is statistically insignificant at the 5% level, which definitively proves that the true causal effect of SMEs on growth is zero.", "D": "The OLS estimate (2.197) is larger than the IV estimate (1.863), suggesting the presence of a positive endogeneity bias, consistent with reverse causality where faster growth fosters a larger SME sector."}, "Answer": ["A", "B", "D"], "pi_justification": "This item assesses the ability to interpret and compare OLS and IV regression results, including diagnostic tests. It uses a 'Scenario Application' strategy by asking for valid interpretations of the provided table. Option A correctly identifies the direction of bias and links it to the paper's reverse causality argument. Option B correctly interprets the F-test and OIR test p-values. Option D correctly contrasts the significance levels. The distractor (C) is a 'Conceptual Distractor' (Almost Right) because it misinterprets 'failure to reject the null' as 'proof of the null,' a common statistical fallacy. The item requires a comprehensive understanding of the paper's central empirical finding.", "qid": "51", "question": "### Background\n\n**Research Question.** This problem interrogates the causal relationship between the size of a country's SME sector and its economic growth by comparing Ordinary Least Squares (OLS) and Instrumental Variable (IV) estimates from a cross-country growth regression for the 1990s.\n\n**Variables & Parameters.**\n- `GDP per capita growth`: The dependent variable, averaged over 1990-2000.\n- `SME250`: The key independent variable, representing the share of SME employment in manufacturing.\n- Unit of observation: Country `i`.\n\n---\n\n### Data / Model Specification\n\nThe estimated growth regression is:\n  \n\\text{GDP per capita growth}_i = \\beta_0 + \\beta_1 \\mathrm{SME250}_{i} + \\text{Controls}_i + \\varepsilon_{i} \n \n\n**Table 1: SME Employment and Growth Regressions**\n(Corresponds to Table 5 in the source)\n\n| | (1) OLS | (3) IV |\n| :--- | :---: | :---: |\n| **Outliers** | **Full Sample** | **Full Sample** |\n| `SME250` | 2.197*** | 1.863* |\n| | (0.687) | (1.047) |\n| **IV Diagnostics** | | |\n| F-Test (p-value) | | 0.000 |\n| OIR Test (p-value) | | 0.118 |\n| Observations | 45 | 45 |\n\n*Note: Robust standard errors in parentheses. *** p<0.01, * p<0.10. F-test is for the joint significance of excluded instruments in the first stage. OIR is the Hansen test of overidentifying restrictions.* \n\n---\n\nBased on the regression results and the paper's discussion, which of the following statements are valid interpretations of the findings?\n\nSelect all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 58, "Question": "### Background\n\nConsider a market with consumers organized in \"star networks.\" Each network has one \"core\" consumer with `k` links and `k` \"periphery\" consumers with one link each. All consumers have the same search cost `s`, willingness to pay `v`, and discount factor `δ`.\n\n### Data / Model Specification\n\nThe payoff from actively searching is `v - E[p] - s` for any consumer. The payoff from passively waiting depends on network position. For a periphery consumer, the waiting payoff is `δq_c(v-E[p])`, as they only get information if the core searches (with probability `q_c`). For the core consumer, the waiting payoff is higher because they can potentially receive information from all `k` periphery members.\n\nAn equilibrium where `0 < q_c = q_p < 1` (where `q_c` and `q_p` are the search probabilities for core and periphery consumers, respectively) is proposed.\n\n### Question\n\nWhich of the following statements are valid reasons why an equilibrium where both core and periphery consumers randomize their search decision (`0 < q_c = q_p < 1`) is IMPOSSIBLE in this model? Select all that apply.", "Options": {"A": "For both consumer types to be indifferent, their waiting payoffs must be equal, since their searching payoffs are identical.", "B": "The core consumer's waiting payoff is strictly greater than a periphery consumer's waiting payoff due to having more network links (`k > 1`).", "C": "The search cost `s` is prohibitively high for periphery consumers, forcing them to always wait.", "D": "The payoff from actively searching is strictly higher for the core consumer than for a periphery consumer."}, "Answer": ["A", "B"], "pi_justification": "This item assesses the ability to reason through the logic of equilibrium in a heterogeneous agent model. It uses a Reverse-Reasoning strategy, asking for the reasons why a specific state (a symmetric mixed-strategy equilibrium) cannot occur.\n- **Correct Options (B, C):** These two options form the core of the proof by contradiction. (B) establishes the necessary condition for the proposed equilibrium to hold (equal waiting payoffs). (C) shows that this necessary condition is violated because the core's structural advantage gives them a strictly higher waiting payoff. The contradiction between (B) and (C) proves the impossibility.\n- **Distractor (A):** This is a Conceptual Opposite. The paper explicitly states the payoff from searching is identical for all consumers as it does not depend on network position.\n- **Distractor (D):** This is a True but Irrelevant/False premise. The search cost `s` is the same for everyone, and the model analyzes cases where `s` is low enough for equilibria with searching to exist.", "qid": "58", "question": "### Background\n\nConsider a market with consumers organized in \"star networks.\" Each network has one \"core\" consumer with `k` links and `k` \"periphery\" consumers with one link each. All consumers have the same search cost `s`, willingness to pay `v`, and discount factor `δ`.\n\n### Data / Model Specification\n\nThe payoff from actively searching is `v - E[p] - s` for any consumer. The payoff from passively waiting depends on network position. For a periphery consumer, the waiting payoff is `δq_c(v-E[p])`, as they only get information if the core searches (with probability `q_c`). For the core consumer, the waiting payoff is higher because they can potentially receive information from all `k` periphery members.\n\nAn equilibrium where `0 < q_c = q_p < 1` (where `q_c` and `q_p` are the search probabilities for core and periphery consumers, respectively) is proposed.\n\n### Question\n\nWhich of the following statements are valid reasons why an equilibrium where both core and periphery consumers randomize their search decision (`0 < q_c = q_p < 1`) is IMPOSSIBLE in this model? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B\"", "model_answer": ["A", "B"], "error": null}}
{"ID": 55, "Question": "### Background\n\n**Research Question.** This problem traces the causal chain from increased uncertainty in human capital accumulation to its effect on agent behavior and the long-run growth rate of the economy.\n\n**Setting.** The analysis is based on a discrete-time Lucas-style model of endogenous growth. The representative agent has logarithmic utility, `U(c) = ln(c)`, and faces uncertainty about the productivity of time spent accumulating human capital.\n\n### Data / Model Specification\n\nThe technology for goods production and the law of motion for human capital are:\n  \ny_{t+1} = \\eta x_t^\\beta (s_t h_t)^{1-\\beta} \\quad \\text{(Eq. 1)}\n \n  \nh_{t+1} = [1+\\gamma_t(1-s_t)-\\zeta]h_t \\quad \\text{(Eq. 2)}\n \nwhere `s_t` is the fraction of time in production, `h_t` is human capital, `x_t` is physical investment, `γ_t` is a random productivity shock, and `ζ` is the depreciation rate.\n\nThe agent's optimal fraction of time devoted to production, `s̄`, is constant and implicitly defined by the first-order condition:\n  \n\\frac{1}{\\delta} = E\\left[\\frac{1+\\gamma-\\zeta}{1+\\gamma(1-\\bar{s})-\\zeta}\\right] \\quad \\text{(Eq. 3)}\n \nwhere `δ` is the discount factor. The optimal investment policy is `x_t = δβy_t`.\n\n### Question\n\nAccording to the model, which of the following statements are correct consequences of an increase in the volatility of the human capital productivity shock `γ` (i.e., a mean-preserving spread)?", "Options": {"A": "The growth rate of human capital (`g_h`) is first-order stochastically dominated by its distribution under lower volatility, which implies a higher expected value `E[g_h]`.", "B": "The agent responds by increasing the fraction of time allocated to production (`s̄`).", "C": "The optimal investment rate in physical capital (`x_t/y_t`) is reduced to offset the higher risk in human capital accumulation.", "D": "In the long-run stationary distribution, the expected growth rate of the economy (`E[g_y]`) is strictly lower than the expected growth rate of human capital (`E[g_h]`)."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item assesses the student's understanding of the complete causal mechanism in the human capital model, from the agent's immediate behavioral response to a key long-run dynamic property of the economy.\n\nChosen Strategy: Atomic Decomposition. The complex, multi-step argument from the original QA is broken down into independent, verifiable claims about the model's outcomes. This allows for precise testing of different links in the causal chain within a single question.\n\nDistractor Logic:\n- **Option C (Formula Misuse):** This distractor tests whether the student correctly recalls that the investment share is constant (`δβ`) due to the log-utility assumption and is not part of the behavioral response to uncertainty in this specific model. It tempts them with plausible but incorrect economic intuition.\n- **Option D (Conceptual Opposite):** This is a high-fidelity distractor. It correctly states that the new distribution of `g_h` is first-order stochastically dominated by the old one, but then incorrectly defines the implication of FOSD as a *higher* expected value. This precisely targets a common point of confusion regarding stochastic dominance.", "qid": "55", "question": "### Background\n\n**Research Question.** This problem traces the causal chain from increased uncertainty in human capital accumulation to its effect on agent behavior and the long-run growth rate of the economy.\n\n**Setting.** The analysis is based on a discrete-time Lucas-style model of endogenous growth. The representative agent has logarithmic utility, `U(c) = ln(c)`, and faces uncertainty about the productivity of time spent accumulating human capital.\n\n### Data / Model Specification\n\nThe technology for goods production and the law of motion for human capital are:\n  \ny_{t+1} = \\eta x_t^\\beta (s_t h_t)^{1-\\beta} \\quad \\text{(Eq. 1)}\n \n  \nh_{t+1} = [1+\\gamma_t(1-s_t)-\\zeta]h_t \\quad \\text{(Eq. 2)}\n \nwhere `s_t` is the fraction of time in production, `h_t` is human capital, `x_t` is physical investment, `γ_t` is a random productivity shock, and `ζ` is the depreciation rate.\n\nThe agent's optimal fraction of time devoted to production, `s̄`, is constant and implicitly defined by the first-order condition:\n  \n\\frac{1}{\\delta} = E\\left[\\frac{1+\\gamma-\\zeta}{1+\\gamma(1-\\bar{s})-\\zeta}\\right] \\quad \\text{(Eq. 3)}\n \nwhere `δ` is the discount factor. The optimal investment policy is `x_t = δβy_t`.\n\n### Question\n\nAccording to the model, which of the following statements are correct consequences of an increase in the volatility of the human capital productivity shock `γ` (i.e., a mean-preserving spread)?", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 52, "Question": "### Background\n\n**Research Question.** This problem assesses whether the size of a country's SME sector has a differential impact on the income growth of the poorest quintile of its population, beyond any effect operating through overall economic growth.\n\n**Variables & Parameters.**\n- `g_p`: Average annual growth rate of real GDP per capita for the lowest income quintile.\n- `g_y`: Average annual growth rate of real GDP per capita for the entire population.\n- `SME250`: The share of SME employment in manufacturing.\n\n---\n\n### Data / Model Specification\n\nThe model for the income growth of the poor is:\n  \n g_p = \\alpha y_{i,l,1990} + \\beta g_y + \\gamma \\mathrm{SME250}_{i} + \\varepsilon_{i} \n \n\n**Table 1: Regression Results for Income Growth of the Poor**\n(Corresponds to Table 8, Column 1 in the source)\n\n| Variable | Coefficient | Std. Error |\n| :--- | :---: | :---: |\n| GDP per capita Growth (`g_y`) | 1.169*** | (0.336) |\n| SME250 | 0.006 | (0.023) |\n\nThe paper's Instrumental Variable (IV) analysis of the SME-growth relationship finds that the causal effect of `SME250` on `g_y` is statistically insignificant.\n\n---\n\nBased on the model and results, which of the following conclusions about the total causal effect of `SME250` on the income growth of the poor (`g_p`) are supported by the paper's findings?\n\nSelect all that apply.", "Options": {"A": "The indirect causal effect of SMEs on the poor, which operates through overall economic growth, is statistically indistinguishable from zero because the causal link from SMEs to overall growth is not established.", "B": "Because the coefficient on overall GDP per capita growth (β = 1.169) is positive and significant, any policy that successfully promotes SMEs will automatically be pro-poor.", "C": "The total causal effect of SMEs on the income of the poor is the sum of a statistically insignificant direct effect and a statistically insignificant indirect effect, providing no evidence for a pro-poor impact.", "D": "The direct differential effect of SMEs on the income of the poor, represented by the coefficient γ, is statistically indistinguishable from zero."}, "Answer": ["A", "C", "D"], "pi_justification": "This item assesses the ability to synthesize results from different parts of the paper to evaluate a total causal effect. It uses a 'Reverse-Reasoning' strategy, asking the user to identify valid conclusions based on a set of findings. Options A, B, and C correctly break down the total effect into its direct and indirect components and evaluate each based on the provided evidence, leading to the correct overall conclusion. The distractor (D) is a 'Conceptual Distractor' that represents a plausible but flawed policy argument. It correctly notes that β > 0 but incorrectly assumes that the SME-growth link is causal, which is the central flaw the paper's IV analysis reveals. This requires synthesizing information from the poverty regression and the growth regression.", "qid": "52", "question": "### Background\n\n**Research Question.** This problem assesses whether the size of a country's SME sector has a differential impact on the income growth of the poorest quintile of its population, beyond any effect operating through overall economic growth.\n\n**Variables & Parameters.**\n- `g_p`: Average annual growth rate of real GDP per capita for the lowest income quintile.\n- `g_y`: Average annual growth rate of real GDP per capita for the entire population.\n- `SME250`: The share of SME employment in manufacturing.\n\n---\n\n### Data / Model Specification\n\nThe model for the income growth of the poor is:\n  \n g_p = \\alpha y_{i,l,1990} + \\beta g_y + \\gamma \\mathrm{SME250}_{i} + \\varepsilon_{i} \n \n\n**Table 1: Regression Results for Income Growth of the Poor**\n(Corresponds to Table 8, Column 1 in the source)\n\n| Variable | Coefficient | Std. Error |\n| :--- | :---: | :---: |\n| GDP per capita Growth (`g_y`) | 1.169*** | (0.336) |\n| SME250 | 0.006 | (0.023) |\n\nThe paper's Instrumental Variable (IV) analysis of the SME-growth relationship finds that the causal effect of `SME250` on `g_y` is statistically insignificant.\n\n---\n\nBased on the model and results, which of the following conclusions about the total causal effect of `SME250` on the income growth of the poor (`g_p`) are supported by the paper's findings?\n\nSelect all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 35, "Question": "### Background\n\n**Research Question.** This problem analyzes the model's key empirical predictions that distinguish 'political defaults' from standard 'economic defaults'.\n\n**Setting.** The model generates two types of defaults. 'Economic defaults' are driven by severe negative output shocks. 'Political defaults' are triggered by a change in power from a patient (`H`) to an impatient (`L`) policymaker, who then defaults on a large debt stock inherited from their predecessor.\n\n**Variables & Parameters.**\n*   `y`: The stochastic endowment (output).\n*   `-b'`: The volume of debt issuance.\n*   Sovereign Spread: The yield on sovereign bonds over the risk-free rate.\n*   `q_j(b', y)`: The bond price schedule faced by a type-`j` policymaker.\n\n---\n\n### Data / Model Specification\n\nThe model makes two distinctive predictions about the empirical footprint of political defaults:\n1.  **Weak Output Correlation:** Unlike economic defaults, political defaults are not necessarily preceded by poor concurrent economic conditions. Simulations show that with high political stability, 38% of defaults occur when output is above its long-run mean, matching historical data.\n2.  **Post-Default Dynamics:** After a political default, post-default debt issuance levels and equilibrium spreads are *lower* than their pre-default levels.\n\n---\n\n### Question\n\nThe model predicts several distinctive empirical features of 'political defaults' that differ from purely 'economic defaults'. Select all statements that are **INCORRECT** descriptions of the mechanisms or outcomes related to political defaults in the model.", "Options": {"A": "The weak correlation between default and output arises because the probability of political turnover (`π`) is assumed to be higher during economic booms.", "B": "A political default can occur when current output is high because the default is triggered by a political shock combined with a large debt stock inherited from a previous period of low output.", "C": "After a political default, the new impatient government borrows more than its patient predecessor because its high discount factor makes it prioritize current consumption.", "D": "Post-default spreads are lower than pre-default spreads because the new impatient government, facing a punitive bond price schedule for large debt, optimally chooses a small, safe issuance level that commands a low risk premium."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: Tests understanding of the key empirical predictions that distinguish political defaults, specifically the counter-intuitive post-default dynamics and the mechanism for weak output correlation. Strategy: Complement-set selection (choose the incorrect statements). This forces students to identify and reject common misconceptions. Distractor Logic: The correct answers (A and B) represent plausible but incorrect reasoning. Option A is the central paradox the paper resolves. Option B offers a plausible but factually incorrect explanation for the weak correlation. The incorrect answers (C and D) are correct statements of the model's logic, requiring careful reading to distinguish from the incorrect ones.", "qid": "35", "question": "### Background\n\n**Research Question.** This problem analyzes the model's key empirical predictions that distinguish 'political defaults' from standard 'economic defaults'.\n\n**Setting.** The model generates two types of defaults. 'Economic defaults' are driven by severe negative output shocks. 'Political defaults' are triggered by a change in power from a patient (`H`) to an impatient (`L`) policymaker, who then defaults on a large debt stock inherited from their predecessor.\n\n**Variables & Parameters.**\n*   `y`: The stochastic endowment (output).\n*   `-b'`: The volume of debt issuance.\n*   Sovereign Spread: The yield on sovereign bonds over the risk-free rate.\n*   `q_j(b', y)`: The bond price schedule faced by a type-`j` policymaker.\n\n---\n\n### Data / Model Specification\n\nThe model makes two distinctive predictions about the empirical footprint of political defaults:\n1.  **Weak Output Correlation:** Unlike economic defaults, political defaults are not necessarily preceded by poor concurrent economic conditions. Simulations show that with high political stability, 38% of defaults occur when output is above its long-run mean, matching historical data.\n2.  **Post-Default Dynamics:** After a political default, post-default debt issuance levels and equilibrium spreads are *lower* than their pre-default levels.\n\n---\n\n### Question\n\nThe model predicts several distinctive empirical features of 'political defaults' that differ from purely 'economic defaults'. Select all statements that are **INCORRECT** descriptions of the mechanisms or outcomes related to political defaults in the model.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 63, "Question": "### Background\n\n**Research Question.** This problem investigates the 'masquerading shocks' phenomenon in sign-identified Structural Vector Autoregressions (SVARs), where combinations of non-policy shocks can mimic the signature of a monetary policy shock, leading to flawed causal inference.\n\n**Setting.** The economy is described by a static, three-equation New Keynesian model. An econometrician attempts to identify a contractionary monetary policy shock by defining it as any shock that causes inflation to fall (or not rise) and the nominal interest rate to rise (or not fall) on impact. The response of output is left unrestricted.\n\n### Data / Model Specification\n\nThe model's closed-form solution for output (`y`), inflation (`π`), and the interest rate (`i`) in response to true demand (`ε^d`), supply (`ε^s`), and monetary policy (`ε^m`) shocks is:\n\n  \n\\begin{pmatrix} y_t \\\\ π_t \\\\ i_t \\end{pmatrix} = \\frac{1}{1+φ_y+φ_πκ} \\begin{pmatrix} σ^d & φ_πσ^s & -σ^m \\\\ κσ^d & -(1+φ_y)σ^s & -κσ^m \\\\ (φ_y+φ_πκ)σ^d & -φ_πσ^s & σ^m \\end{pmatrix} \\begin{pmatrix} ε_t^d \\\\ ε_t^s \\\\ ε_t^m \\end{pmatrix}\n \n\nAn SVAR-identified 'monetary policy shock', `e_t^m`, is a linear combination of the true shocks, `e_t^m = p_{md}ε_t^d + p_{ms}ε_t^s + p_{mm}ε_t^m`, where `p_m = (p_{md}, p_{ms}, p_{mm})'` is a unit-length vector of weights. The impact responses of inflation (`dπ`) and the interest rate (`di`) to `e_t^m` must satisfy the sign restrictions:\n\n  \ndπ = \\frac{1}{1+φ_y+φ_πκ} [p_{md}κσ^d - p_{ms}(1+φ_y)σ^s - p_{mm}κσ^m] \\le 0 \\quad \\text{(Eq. (1))}\n \n  \ndi = \\frac{1}{1+φ_y+φ_πκ} [p_{md}(φ_y+φ_πκ)σ^d - p_{ms}φ_πσ^s + p_{mm}σ^m] \\ge 0 \\quad \\text{(Eq. (2))}\n \n\nAll model parameters (`κ, φ_y, φ_π, σ^d, σ^s, σ^m`) are positive, and `φ_π > 1`.\n\n### Question\n\nConsider a 'pure masquerading shock' where the identified shock `e_t^m` is a combination of only a positive demand shock (`p_{md} > 0`) and a positive supply shock (`p_{ms} > 0`), with zero weight on the true monetary policy shock (`p_{mm} = 0`). According to the model and sign restrictions, which of the following statements are necessarily true for such a shock to be included in the identified set? Select all that apply.", "Options": {"A": "The ratio of the shock weights, `p_{md}/p_{ms}`, must be greater than or equal to `(φ_π σ^s) / ((φ_y + φ_π κ) σ^d)`.", "B": "The identified shock is only possible if the demand shock is more volatile than the supply shock (`σ^d > σ^s`).", "C": "The identified shock will cause output to increase.", "D": "The ratio of the shock weights, `p_{md}/p_{ms}`, must be less than or equal to `((1 + φ_y) σ^s) / (κ σ^d)`."}, "Answer": ["A", "C", "D"], "pi_justification": "Assessment Target: This item assesses the student's ability to derive and interpret the conditions under which the 'masquerading shocks' phenomenon occurs. It requires applying the model's equations to a specific scenario (a pure masquerading shock).\nDepth Strategy: Computational Judgment. The student must perform algebraic manipulations on the sign restriction inequalities (Eq. 1 and Eq. 2) to derive the valid interval for the ratio of shock weights and also calculate the resulting impact on output.\nDistractor Logic:\n- A (Correct): The output response is `p_{md}σ^d + p_{ms}φ_πσ^s`. Since all terms are positive, the response is positive. This is the core reason masquerading is problematic.\n- B (Correct): Derived directly from the interest rate restriction (Eq. 2) by setting `p_{mm}=0` and solving for `p_{md}/p_{ms}`.\n- C (Correct): Derived directly from the inflation restriction (Eq. 1) by setting `p_{mm}=0` and solving for `p_{md}/p_{ms}`.\n- D (Distractor - True but Irrelevant/Conceptual): The paper notes that relative volatilities matter for the *probability* of finding masquerading shocks under a Haar prior, but the *possibility* of such shocks exists regardless of relative volatilities, as shown by the existence of the interval in B and C. This tests a subtle distinction.", "qid": "63", "question": "### Background\n\n**Research Question.** This problem investigates the 'masquerading shocks' phenomenon in sign-identified Structural Vector Autoregressions (SVARs), where combinations of non-policy shocks can mimic the signature of a monetary policy shock, leading to flawed causal inference.\n\n**Setting.** The economy is described by a static, three-equation New Keynesian model. An econometrician attempts to identify a contractionary monetary policy shock by defining it as any shock that causes inflation to fall (or not rise) and the nominal interest rate to rise (or not fall) on impact. The response of output is left unrestricted.\n\n### Data / Model Specification\n\nThe model's closed-form solution for output (`y`), inflation (`π`), and the interest rate (`i`) in response to true demand (`ε^d`), supply (`ε^s`), and monetary policy (`ε^m`) shocks is:\n\n  \n\\begin{pmatrix} y_t \\\\ π_t \\\\ i_t \\end{pmatrix} = \\frac{1}{1+φ_y+φ_πκ} \\begin{pmatrix} σ^d & φ_πσ^s & -σ^m \\\\ κσ^d & -(1+φ_y)σ^s & -κσ^m \\\\ (φ_y+φ_πκ)σ^d & -φ_πσ^s & σ^m \\end{pmatrix} \\begin{pmatrix} ε_t^d \\\\ ε_t^s \\\\ ε_t^m \\end{pmatrix}\n \n\nAn SVAR-identified 'monetary policy shock', `e_t^m`, is a linear combination of the true shocks, `e_t^m = p_{md}ε_t^d + p_{ms}ε_t^s + p_{mm}ε_t^m`, where `p_m = (p_{md}, p_{ms}, p_{mm})'` is a unit-length vector of weights. The impact responses of inflation (`dπ`) and the interest rate (`di`) to `e_t^m` must satisfy the sign restrictions:\n\n  \ndπ = \\frac{1}{1+φ_y+φ_πκ} [p_{md}κσ^d - p_{ms}(1+φ_y)σ^s - p_{mm}κσ^m] \\le 0 \\quad \\text{(Eq. (1))}\n \n  \ndi = \\frac{1}{1+φ_y+φ_πκ} [p_{md}(φ_y+φ_πκ)σ^d - p_{ms}φ_πσ^s + p_{mm}σ^m] \\ge 0 \\quad \\text{(Eq. (2))}\n \n\nAll model parameters (`κ, φ_y, φ_π, σ^d, σ^s, σ^m`) are positive, and `φ_π > 1`.\n\n### Question\n\nConsider a 'pure masquerading shock' where the identified shock `e_t^m` is a combination of only a positive demand shock (`p_{md} > 0`) and a positive supply shock (`p_{ms} > 0`), with zero weight on the true monetary policy shock (`p_{mm} = 0`). According to the model and sign restrictions, which of the following statements are necessarily true for such a shock to be included in the identified set? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 66, "Question": "### Background\n\n**Research Question.** This problem analyzes the core policy implications of a dynamic model of influencer-follower relationships. It investigates the effects of a simple tax on advertising revenue, contrasts it with different forms of mandatory disclosure regulation, and evaluates a novel \"opt-in\" policy alternative.\n\n**Setting / Institutional Environment.** In a continuous-time principal-agent model, a follower designs a contract to incentivize an influencer. The relationship's value is summarized by a state variable `d`, the expected future duration of following. The optimal contract exhibits a \"reap and sow\" dynamic: for low `d` (sow phase), the influencer is incentivized to provide good advice (`a=0`); for high `d` (reap phase), the influencer is allowed to monetize their reputation (`a=1`). Policy interventions can alter the profitability of advertising, affecting both the temptation to shirk and the value of the ultimate reward.\n\n### Data / Model Specification\n\nThe influencer's choice `a` between providing good advice (`a=0`) and advertising (`a=1`) is governed by an incentive compatibility (IC) constraint. To induce `a=0`, the promised increase in the influencer's continuation value, `W(d^+) - W(d)`, must outweigh the normalized payoff from advertising, which is 1.\n\nWe consider three policy environments:\n1.  **Taxation:** Advertising revenue `λa` is taxed, so the influencer receives `xλa`, where `x ∈ (0, 1]`.\n2.  **Mandatory Disclosure:** The influencer can use disclosed ads (`a_r`) with return `r` or undisclosed ads (`a_u`) with return `u`. A \"weak\" policy has `u > r` (undisclosed is more profitable), while a \"strong\" policy has `u < r`.\n3.  **Opt-In Disclosure:** Influencers can choose to be subject to the disclosure regime. Followers demand they opt-in during the \"sow\" phase (`d ≤ d̂`) and allow them to opt-out during the \"reap\" phase (`d > d̂`).\n\n### Question\n\nBased on the model's analysis, select all statements that are correct characterizations of the policy effects.", "Options": {"A": "Under a \"strong\" mandatory disclosure policy (`u < r`), making the policy stricter (i.e., lowering `u`) benefits the follower by reducing the influencer's temptation, which makes it cheaper to satisfy the incentive constraint.", "B": "A \"weak\" mandatory disclosure policy (`u > r`) is equivalent to a proportional tax `x=u` on ad revenue and is therefore neutral to the influencer's advising behavior `a(d)`.", "C": "A proportional tax `x < 1` on ad revenue encourages more good advice (`a=0`) by reducing the immediate temptation to advertise, while leaving the future reward for good behavior unchanged.", "D": "An opt-in disclosure policy is superior to a strong mandatory policy primarily because it forces influencers to be regulated for a longer portion of the relationship's lifecycle."}, "Answer": ["A", "B"], "pi_justification": "Assessment Target: This item tests the student's ability to synthesize and compare the welfare and behavioral implications of three distinct policy regimes (taxation, mandatory disclosure, and opt-in disclosure) as predicted by the model.\n\nStrategy: The question uses 'Atomic Decomposition' to break down the complex policy analysis from the original QA problem into four distinct, testable propositions. This forces the user to evaluate each policy's mechanism independently.\n\nDistractor Logic:\n- A (Step-Omission Error): This is a common but incorrect intuition. It correctly identifies that the tax lowers the immediate temptation but omits the crucial second effect: the tax also proportionally lowers the value of the future reward (which consists of future advertising opportunities), leading to neutrality.\n- D (Conceptual Opposite / Almost Right): This distractor misidentifies the source of the opt-in policy's superiority. The policy is superior not because it extends regulation, but because it strategically *decouples* the incentive and reward mechanisms—using regulation to lower temptation in the 'sow' phase while allowing for a maximal, unregulated reward in the 'reap' phase, which strengthens overall incentives.", "qid": "66", "question": "### Background\n\n**Research Question.** This problem analyzes the core policy implications of a dynamic model of influencer-follower relationships. It investigates the effects of a simple tax on advertising revenue, contrasts it with different forms of mandatory disclosure regulation, and evaluates a novel \"opt-in\" policy alternative.\n\n**Setting / Institutional Environment.** In a continuous-time principal-agent model, a follower designs a contract to incentivize an influencer. The relationship's value is summarized by a state variable `d`, the expected future duration of following. The optimal contract exhibits a \"reap and sow\" dynamic: for low `d` (sow phase), the influencer is incentivized to provide good advice (`a=0`); for high `d` (reap phase), the influencer is allowed to monetize their reputation (`a=1`). Policy interventions can alter the profitability of advertising, affecting both the temptation to shirk and the value of the ultimate reward.\n\n### Data / Model Specification\n\nThe influencer's choice `a` between providing good advice (`a=0`) and advertising (`a=1`) is governed by an incentive compatibility (IC) constraint. To induce `a=0`, the promised increase in the influencer's continuation value, `W(d^+) - W(d)`, must outweigh the normalized payoff from advertising, which is 1.\n\nWe consider three policy environments:\n1.  **Taxation:** Advertising revenue `λa` is taxed, so the influencer receives `xλa`, where `x ∈ (0, 1]`.\n2.  **Mandatory Disclosure:** The influencer can use disclosed ads (`a_r`) with return `r` or undisclosed ads (`a_u`) with return `u`. A \"weak\" policy has `u > r` (undisclosed is more profitable), while a \"strong\" policy has `u < r`.\n3.  **Opt-In Disclosure:** Influencers can choose to be subject to the disclosure regime. Followers demand they opt-in during the \"sow\" phase (`d ≤ d̂`) and allow them to opt-out during the \"reap\" phase (`d > d̂`).\n\n### Question\n\nBased on the model's analysis, select all statements that are correct characterizations of the policy effects.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 56, "Question": "### Background\n\nIn a duopoly market for a homogeneous good, consumers endogenously sort into active searchers (fraction `q`) and passive waiters. Active searchers pay a cost `s` per price quote and use a reservation price `r`. Passive waiters receive information from their social network of `k` friends and discount future consumption by `δ`. Firms engage in mixed-strategy pricing.\n\n### Data / Model Specification\n\nThe consumer's indifference condition between searching and waiting, which defines the equilibrium fraction of searchers `q`, is given by:\n\n  \nv-E[p]-s = \\delta\\bigl(1-(1-q)^{k}\\bigr)(v-E[p]) +\\delta\\biggl(1+(1-q)^{k}-2\\Bigl(1-\\frac{q}{2}\\Bigr)^{k}\\biggr)(E[p]-E[\\operatorname*{min}\\{p_{1},p_{2}\\}]) \\quad \\text{(Eq. (1))}\n \n\nwhere `v` is willingness to pay, `E[p]` is the expected price, and `E[min{p1,p2}]` is the expected minimum price.\n\nTheorem 1 of the paper establishes that as the search cost `s` approaches zero, the equilibrium fraction of active searchers `q*` approaches 1, and prices converge to the monopoly level `v`.\n\n### Question\n\nGiven the model's framework and the result that `q* → 1` as `s → 0`, which of the following statements accurately describe the causal mechanisms that lead to monopoly pricing (`E[p] → v`) in this limit? Select all that apply.", "Options": {"A": "As `s → 0`, the payoff from active searching becomes overwhelmingly more attractive than waiting, causing the population of passive, price-comparing consumers to vanish.", "B": "The word-of-mouth (WOM) communication channel becomes inert because, with almost no passive consumers, there is no one left to receive and act upon the shared price information.", "C": "The ratio of non-price-comparing consumers to price-comparing consumers (`η`) approaches infinity, eliminating firms' incentive to lower prices to compete for the price-comparing segment.", "D": "As `s → 0`, the reservation price `r` of active searchers falls to zero, forcing firms to compete prices down to marginal cost."}, "Answer": ["A", "B", "C"], "pi_justification": "This item assesses understanding of the paper's most counter-intuitive result. It uses a Reverse-Reasoning strategy, asking for the causes of a given outcome (monopoly pricing as s→0).\n- **Correct Options (A, B, D):** These trace the complete causal chain. (A) explains the initial behavioral shift (q→1). (B) explains the consequence for firm strategy (η→∞). (D) provides the high-level interpretation of why the WOM mechanism fails.\n- **Distractor (C):** This is a Conceptual Opposite. As s→0, the reservation price `r` actually converges to `v`, not zero. A lower `r` would increase competition, which is the opposite of what happens.", "qid": "56", "question": "### Background\n\nIn a duopoly market for a homogeneous good, consumers endogenously sort into active searchers (fraction `q`) and passive waiters. Active searchers pay a cost `s` per price quote and use a reservation price `r`. Passive waiters receive information from their social network of `k` friends and discount future consumption by `δ`. Firms engage in mixed-strategy pricing.\n\n### Data / Model Specification\n\nThe consumer's indifference condition between searching and waiting, which defines the equilibrium fraction of searchers `q`, is given by:\n\n  \nv-E[p]-s = \\delta\\bigl(1-(1-q)^{k}\\bigr)(v-E[p]) +\\delta\\biggl(1+(1-q)^{k}-2\\Bigl(1-\\frac{q}{2}\\Bigr)^{k}\\biggr)(E[p]-E[\\operatorname*{min}\\{p_{1},p_{2}\\}]) \\quad \\text{(Eq. (1))}\n \n\nwhere `v` is willingness to pay, `E[p]` is the expected price, and `E[min{p1,p2}]` is the expected minimum price.\n\nTheorem 1 of the paper establishes that as the search cost `s` approaches zero, the equilibrium fraction of active searchers `q*` approaches 1, and prices converge to the monopoly level `v`.\n\n### Question\n\nGiven the model's framework and the result that `q* → 1` as `s → 0`, which of the following statements accurately describe the causal mechanisms that lead to monopoly pricing (`E[p] → v`) in this limit? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 59, "Question": "### Background\n\n**Research Question.** This problem explores the conceptual role of knowing the true Data Generating Process (DGP) in labor economics, specifically how it allows a researcher to distinguish between genuine discrimination and econometric specification error.\n\n**Setting / Institutional Environment.** The setting is a school district where teacher salaries are determined by a rigid, publicly known, two-dimensional grid. A teacher's salary is a deterministic, non-linear function of their contractually-defined experience units ($x^*$) and education units ($s^*$). Demographic characteristics like race and gender play no formal role in the salary formula.\n\n---\n\n### Data / Model Specification\n\nThe true Data Generating Process (DGP) for salary is the known contractual grid:\n\n  \n\\text{Salary}_i = g(x_i^*, s_i^*) \\quad \\text{(Eq. (1))}\n \n\nThis is a deterministic function. In contrast, an econometrician using survey data estimates a statistical model that includes demographics ($D_i$) and proxies for human capital ($H_i$, representing survey-based experience and education):\n\n  \n\\text{Salary}_i = f(H_i, D_i) + \\varepsilon_i \\quad \\text{(Eq. (2))}\n \n\n**Table 1: Stylized San Francisco Salary Schedule ($)**\n| Experience ($x^*$) | Education ($s^*=1$) | Education ($s^*=3$) |\n| :--- | :--- | :--- |\n| 1 | 20,265 | 20,265 |\n| 5 | 20,265 | 24,055 |\n| 10 | 24,055 | 29,730 |\n| 15 | | 33,135 |\n\n---\n\n### Question\n\nIn the institutional context described, an econometrician estimates Eq. (2) and finds a statistically significant, negative coefficient on a `Black` dummy variable. According to the paper's central argument, which of the following statements are valid interpretations of this finding? Select all that apply.", "Options": {"A": "The finding provides strong evidence of wage discrimination, suggesting the school district systematically underpays Black teachers relative to their contractual entitlement.", "B": "The non-linear salary structure of the true contract (Table 1) is the primary reason for the significant coefficient, regardless of how human capital is measured.", "C": "The result implies that the survey-based human capital measures ($H_i$) are imperfect proxies for the true contractual measures ($H_i^*$), and this imperfection is systematically correlated with race.", "D": "The finding is direct evidence of specification error, as the true data generating process (Eq. (1)) is known to exclude demographic factors."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: Tests understanding of the paper's core conceptual argument—that knowing the true DGP reframes the interpretation of demographic coefficients from discrimination to specification error.\nStrategy: Premise/assumption packaging. The question asks for all valid interpretations of a key finding.\nDistractor Logic: Option C is the 'Conceptual Opposite,' representing the standard interpretation that the paper explicitly refutes. Option D is a 'True but Irrelevant' distractor; while the DGP is non-linear, the key driver of the spurious coefficient is the correlation between proxy error and demographics, not just the functional form itself.", "qid": "59", "question": "### Background\n\n**Research Question.** This problem explores the conceptual role of knowing the true Data Generating Process (DGP) in labor economics, specifically how it allows a researcher to distinguish between genuine discrimination and econometric specification error.\n\n**Setting / Institutional Environment.** The setting is a school district where teacher salaries are determined by a rigid, publicly known, two-dimensional grid. A teacher's salary is a deterministic, non-linear function of their contractually-defined experience units ($x^*$) and education units ($s^*$). Demographic characteristics like race and gender play no formal role in the salary formula.\n\n---\n\n### Data / Model Specification\n\nThe true Data Generating Process (DGP) for salary is the known contractual grid:\n\n  \n\\text{Salary}_i = g(x_i^*, s_i^*) \\quad \\text{(Eq. (1))}\n \n\nThis is a deterministic function. In contrast, an econometrician using survey data estimates a statistical model that includes demographics ($D_i$) and proxies for human capital ($H_i$, representing survey-based experience and education):\n\n  \n\\text{Salary}_i = f(H_i, D_i) + \\varepsilon_i \\quad \\text{(Eq. (2))}\n \n\n**Table 1: Stylized San Francisco Salary Schedule ($)**\n| Experience ($x^*$) | Education ($s^*=1$) | Education ($s^*=3$) |\n| :--- | :--- | :--- |\n| 1 | 20,265 | 20,265 |\n| 5 | 20,265 | 24,055 |\n| 10 | 24,055 | 29,730 |\n| 15 | | 33,135 |\n\n---\n\n### Question\n\nIn the institutional context described, an econometrician estimates Eq. (2) and finds a statistically significant, negative coefficient on a `Black` dummy variable. According to the paper's central argument, which of the following statements are valid interpretations of this finding? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"B,C,D\"", "model_answer": ["B", "C", "D"], "error": null}}
{"ID": 67, "Question": "### Background\n\n**Research Question.** This problem characterizes the optimal dynamic contract in an influencer-follower relationship, focusing on the \"reap and sow\" dynamics that emerge from the underlying incentive problem.\n\n**Setting / Institutional Environment.** In a continuous-time principal-agent model, the state of the relationship is its expected discounted future duration, `d`. The follower (principal) designs a contract to maximize her own value, `V(d)`, subject to providing the influencer (agent) with value `W(d)`.\n\n### Data / Model Specification\n\nThe total surplus of the relationship is `TS(d) = s + (λ-s)d`. The follower's value is `V(d)` and the influencer's is `W(d) = TS(d) - V(d)`. To incentivize good advice (`a=0`), the follower must promise a future state `d^+` such that the influencer's gain in continuation value satisfies the incentive compatibility (IC) constraint:\n\n  \nW(d^+) - W(d) \\geq 1 \n \n\nThe solution (Proposition 1) is a threshold policy where `a(d)=0` for `d ≤ d̂` (\"Sow Phase\") and `a(d)=1` for `d > d̂` (\"Reap Phase\"). Correspondingly, the follower's value function `V(d)` is strictly concave for `d ≤ d̂` and linear for `d > d̂`.\n\n### Question\n\nSelect all statements that correctly describe the properties and economic intuition of the optimal contract.", "Options": {"A": "The influencer's value function `W(d)` is convex. This implies that as `d` increases, a larger jump in duration (`d^+ - d`) is required to deliver the fixed jump in value (`W(d^+) - W(d) = 1`) needed to satisfy the IC constraint.", "B": "In the 'reap' phase (`d > d̂`), it is optimal for the follower to allow monetization (`a=1`) because the influencer has built up so much reputation that they are easy to incentivize.", "C": "The follower's value function `V(d)` is strictly concave in the 'sow' phase because this is where she is actively managing incentives under uncertainty, making her value sensitive to the timing of rewards.", "D": "The total surplus `TS(d)` is a concave function of `d`, reflecting diminishing returns to extending the relationship's duration."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: This item assesses understanding of the paper's central theoretical result: the 'reap and sow' structure of the optimal contract and its connection to the mathematical properties (concavity/convexity) of the players' value functions.\n\nStrategy: The question uses 'Atomic Decomposition' to present four statements about the model's core mechanics. Two are correct characterizations of the value functions and their implications, while the distractors present plausible but incorrect alternatives.\n\nDistractor Logic:\n- C (Conceptual Opposite): This reverses the core logic. In the 'reap' phase, the influencer is *hard* to incentivize because their value `W(d)` is already high and its slope is steep, making it prohibitively costly for the follower to offer a sufficiently large reward. Monetization is the reward itself, not a phase where incentives are easy.\n- D (Formula Misuse): This directly contradicts the model specification. The total surplus function `TS(d) = s + (λ-s)d` is explicitly linear in `d`, not concave. This tests careful reading of the provided model setup.", "qid": "67", "question": "### Background\n\n**Research Question.** This problem characterizes the optimal dynamic contract in an influencer-follower relationship, focusing on the \"reap and sow\" dynamics that emerge from the underlying incentive problem.\n\n**Setting / Institutional Environment.** In a continuous-time principal-agent model, the state of the relationship is its expected discounted future duration, `d`. The follower (principal) designs a contract to maximize her own value, `V(d)`, subject to providing the influencer (agent) with value `W(d)`.\n\n### Data / Model Specification\n\nThe total surplus of the relationship is `TS(d) = s + (λ-s)d`. The follower's value is `V(d)` and the influencer's is `W(d) = TS(d) - V(d)`. To incentivize good advice (`a=0`), the follower must promise a future state `d^+` such that the influencer's gain in continuation value satisfies the incentive compatibility (IC) constraint:\n\n  \nW(d^+) - W(d) \\geq 1 \n \n\nThe solution (Proposition 1) is a threshold policy where `a(d)=0` for `d ≤ d̂` (\"Sow Phase\") and `a(d)=1` for `d > d̂` (\"Reap Phase\"). Correspondingly, the follower's value function `V(d)` is strictly concave for `d ≤ d̂` and linear for `d > d̂`.\n\n### Question\n\nSelect all statements that correctly describe the properties and economic intuition of the optimal contract.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 62, "Question": "### Background\n\n**Research Question.** This problem examines the core identification strategy of a model designed to estimate the prevalence of three unobserved wage-setting regimes—fully flexible, downwardly real rigid, and downwardly nominal rigid—using only the aggregate distribution of observed wage changes.\n\n**Setting and Sample.** The analysis uses a large panel of individual wage changes for job stayers in West Germany. The observed distribution of wage changes is not normal; it exhibits distinctive features, including a prominent spike at exactly zero and a visible asymmetry around the mode (fewer observations just below the mode than above it).\n\n### Data / Model Specification\n\nThe model assumes that the observed distribution of wage changes is a mixture of three components, all derived from a single underlying, unobserved 'notional' wage change distribution, which is assumed to be normal conditional on worker characteristics.\n1.  **Fully Flexible Regime:** The observed wage change equals the notional wage change.\n2.  **Nominal Rigidity Regime:** The observed wage change is censored from below at zero. If the notional change is negative, the observed change is zero.\n3.  **Real Rigidity Regime:** The observed wage change is censored from below at a positive threshold `r`. If the notional change is less than `r`, the observed change is `r`.\n\nThe key identification challenge is to estimate the population shares of these three unobserved regimes and the parameters of the notional distribution from the shape of the observed distribution.\n\n### Question\n\nBased on the paper's discussion of its methodology and potential limitations, select all statements that are correct.", "Options": {"A": "The model's key assumption is that the *observed* wage change distribution for workers in the fully flexible regime is normal.", "B": "The authors find that omitting the real rigidity regime primarily increases the estimated measurement error, leaving the estimate of nominal rigidity largely unbiased.", "C": "A restricted model that omits the real rigidity regime would likely misattribute the asymmetry around the mode to an inflated estimate of nominal rigidity.", "D": "The model's identification relies on the assumption that the underlying 'notional' wage change distribution is the same for workers in both flexible and rigid regimes, conditional on observables."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: Tests the ability to reason about model misspecification and understand the model's core identifying assumption.\nStrategy: Premise/Assumption Packaging. The question asks to select all correct statements regarding the model's structure, results under misspecification, and underlying assumptions.\nDistractor Logic: (C) is a 'Conceptual Opposite'; the paper explicitly states that omitting the real rigidity regime leads to a *substantially biased* estimate of nominal rigidity (overstated by a factor of 2-4). (D) is an 'Almost Right' error; the assumption is that the unobserved *notional* distribution is normal, not the observed distribution for any subset of workers.", "qid": "62", "question": "### Background\n\n**Research Question.** This problem examines the core identification strategy of a model designed to estimate the prevalence of three unobserved wage-setting regimes—fully flexible, downwardly real rigid, and downwardly nominal rigid—using only the aggregate distribution of observed wage changes.\n\n**Setting and Sample.** The analysis uses a large panel of individual wage changes for job stayers in West Germany. The observed distribution of wage changes is not normal; it exhibits distinctive features, including a prominent spike at exactly zero and a visible asymmetry around the mode (fewer observations just below the mode than above it).\n\n### Data / Model Specification\n\nThe model assumes that the observed distribution of wage changes is a mixture of three components, all derived from a single underlying, unobserved 'notional' wage change distribution, which is assumed to be normal conditional on worker characteristics.\n1.  **Fully Flexible Regime:** The observed wage change equals the notional wage change.\n2.  **Nominal Rigidity Regime:** The observed wage change is censored from below at zero. If the notional change is negative, the observed change is zero.\n3.  **Real Rigidity Regime:** The observed wage change is censored from below at a positive threshold `r`. If the notional change is less than `r`, the observed change is `r`.\n\nThe key identification challenge is to estimate the population shares of these three unobserved regimes and the parameters of the notional distribution from the shape of the observed distribution.\n\n### Question\n\nBased on the paper's discussion of its methodology and potential limitations, select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 60, "Question": "### Background\n\n**Research Question.** This problem explores how non-random measurement and proxy errors can create the appearance of wage discrimination.\n\n**Setting / Institutional Environment.** In a school district, teacher salaries are determined by a contractual grid based on true experience ($x^*$) and education ($s^*$). An econometrician estimates the following model using survey data:\n\n  \n\\text{Salary}_i = \\beta_0 + \\beta_1 H_i + \\gamma_M \\text{Male}_i + \\gamma_B \\text{Black}_i + \\varepsilon_i\n \n\nwhere $H_i$ represents survey-based measures of human capital (experience $x$ and education $s$).\n\n**Key Empirical Findings.** Subsequent analysis in the paper reveals two key patterns of reporting error:\n1.  **Experience Reporting:** Female teachers are significantly more likely than male teachers to have a reported experience level ($x$) that is greater than their true contractual experience level ($x^*$).\n2.  **Education Proxy:** For a given reported education level ($s$), Black teachers are significantly less likely than white teachers to be in the highest contractually-rewarded education category ($s^*$).\n\n---\n\n### Question\n\nGiven the key empirical findings on reporting errors, and assuming the true return to human capital is positive (β₁ > 0), which of the following statements correctly describe the econometric bias in the estimated coefficients for `Male` (γ_M) and `Black` (γ_B)? Select all that apply.", "Options": {"A": "The coefficient on `Male` (γ_M) is biased downwards because the model fails to account for women's more frequent career interruptions.", "B": "The coefficient on `Male` (γ_M) is biased upwards because being male is negatively correlated with the measurement error in experience.", "C": "The coefficient on `Black` (γ_B) is biased downwards because the unobserved component of true education ($s^*$) is negatively correlated with the `Black` dummy, conditional on the observed proxy ($s$).", "D": "The coefficient on `Black` (γ_B) is biased downwards because the model omits a variable, 'propensity to get a master's degree,' that is positively correlated with being Black."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: Tests the ability to apply the theory of omitted variable/proxy error bias to the specific empirical findings of the paper.\nStrategy: Atomic decomposition and Computational Judgment. The question breaks down the overall puzzle into the specific bias mechanisms for the `Male` and `Black` coefficients.\nDistractor Logic: Option D offers a plausible narrative ('career interruptions') that is not the direct econometric mechanism at play (reporting error). Option B mischaracterizes the source of the proxy error; while degree propensity is part of the story, the direct cause of bias is the conditional correlation between the `Black` dummy and the unobserved true education level, as stated in C.", "qid": "60", "question": "### Background\n\n**Research Question.** This problem explores how non-random measurement and proxy errors can create the appearance of wage discrimination.\n\n**Setting / Institutional Environment.** In a school district, teacher salaries are determined by a contractual grid based on true experience ($x^*$) and education ($s^*$). An econometrician estimates the following model using survey data:\n\n  \n\\text{Salary}_i = \\beta_0 + \\beta_1 H_i + \\gamma_M \\text{Male}_i + \\gamma_B \\text{Black}_i + \\varepsilon_i\n \n\nwhere $H_i$ represents survey-based measures of human capital (experience $x$ and education $s$).\n\n**Key Empirical Findings.** Subsequent analysis in the paper reveals two key patterns of reporting error:\n1.  **Experience Reporting:** Female teachers are significantly more likely than male teachers to have a reported experience level ($x$) that is greater than their true contractual experience level ($x^*$).\n2.  **Education Proxy:** For a given reported education level ($s$), Black teachers are significantly less likely than white teachers to be in the highest contractually-rewarded education category ($s^*$).\n\n---\n\n### Question\n\nGiven the key empirical findings on reporting errors, and assuming the true return to human capital is positive (β₁ > 0), which of the following statements correctly describe the econometric bias in the estimated coefficients for `Male` (γ_M) and `Black` (γ_B)? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 71, "Question": "### Background\n\nThe paper's primary identification challenge is that the actual stock of remaining benefits, `$S_{its}$`, is endogenous because it depends on past welfare use, which is correlated with unobserved determinants of current use. The strategy is to instrument for `$S_{its}$` using a simulated stock, `$Z_{its}$`, constructed from arguably exogenous components.\n\n---\n\n### Data / Model Specification\n\nThe main estimating equation is a linear probability model for welfare participation `$p_{its}$`:\n\n  \np_{i t s}=X_{i t}{\\Lambda}+V_{t s}\\Phi+L\\left({\\frac{S_{i t s}}{H_{i t}}}\\right)\\pi+\\mu_{s}+\\psi_{s}f(t)+\\nu_{y}+\\varepsilon_{i t s} \\quad \\text{(Eq. (1))}\n \n\nTo address the endogeneity of `$L(S_{its}/H_{it})$`, the strategy uses instruments based on simulated remaining benefits, `$Z_{its}$`, defined as:\n\n  \nZ_{i t s}=N_{s}-k_{j}*E_{i t s} \\quad \\text{(Eq. (2))}\n \n\nwhere `$N_s$` is the state-specific initial benefit endowment, `$E_{its}$` is the individual-specific exposure to time limits, and `$k_j$` is the pre-reform average welfare use for sociodemographic group `j`.\n\n---\n\nAccording to the paper's methodology, which of the following are valid statements regarding the endogeneity problem and the instrumental variable (IV) strategy? Select all that apply.", "Options": {"A": "The IV strategy's validity relies on the exclusion restriction, which assumes the instrument (derived from `$Z_{its}$`) affects current welfare participation only through its effect on actual remaining benefits (`$S_{its}$`).", "B": "The instrument `$Z_{its}$` is constructed to be exogenous by replacing an individual's actual, endogenous welfare history with a prediction based on her membership in a broad sociodemographic group.", "C": "The instrument `$Z_{its}$` is valid because it is more strongly correlated with current welfare participation `$p_{its}$` than the endogenous variable `$S_{its}$` is.", "D": "A primary source of endogeneity is that unobserved, persistent characteristics like poor health can cause both higher past welfare use (lowering `$S_{its}$`) and higher current welfare use."}, "Answer": ["A", "B", "D"], "pi_justification": "This item assesses understanding of the paper's core identification strategy. It uses a Reverse-Reasoning approach, asking the user to identify correct statements about the methodology. Option A correctly identifies the source of endogeneity. Option B correctly explains the construction of the instrument. Option C correctly states the key assumption (exclusion restriction) for the IV strategy to be valid. Option D is a Conceptual Distractor that misstates the conditions for a valid instrument; the instrument must be strongly correlated with the *endogenous variable* (`$S_{its}$`), not necessarily more correlated with the outcome than the endogenous variable itself.", "qid": "71", "question": "### Background\n\nThe paper's primary identification challenge is that the actual stock of remaining benefits, `$S_{its}$`, is endogenous because it depends on past welfare use, which is correlated with unobserved determinants of current use. The strategy is to instrument for `$S_{its}$` using a simulated stock, `$Z_{its}$`, constructed from arguably exogenous components.\n\n---\n\n### Data / Model Specification\n\nThe main estimating equation is a linear probability model for welfare participation `$p_{its}$`:\n\n  \np_{i t s}=X_{i t}{\\Lambda}+V_{t s}\\Phi+L\\left({\\frac{S_{i t s}}{H_{i t}}}\\right)\\pi+\\mu_{s}+\\psi_{s}f(t)+\\nu_{y}+\\varepsilon_{i t s} \\quad \\text{(Eq. (1))}\n \n\nTo address the endogeneity of `$L(S_{its}/H_{it})$`, the strategy uses instruments based on simulated remaining benefits, `$Z_{its}$`, defined as:\n\n  \nZ_{i t s}=N_{s}-k_{j}*E_{i t s} \\quad \\text{(Eq. (2))}\n \n\nwhere `$N_s$` is the state-specific initial benefit endowment, `$E_{its}$` is the individual-specific exposure to time limits, and `$k_j$` is the pre-reform average welfare use for sociodemographic group `j`.\n\n---\n\nAccording to the paper's methodology, which of the following are valid statements regarding the endogeneity problem and the instrumental variable (IV) strategy? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 72, "Question": "### Background\n\nA linear probability model is used to estimate the welfare participation (`$p_{its}$`) of single mothers. The key explanatory variables are a set of indicators and continuous terms based on the ratio of a woman's remaining welfare eligibility (`$S_{its}$`) to her eligibility horizon (`$H_{it}$`).\n\n---\n\n### Data / Model Specification\n\nThe empirical specification for welfare participation is:\n\n  \np_{i t s}=X_{i t}\\lambda+V_{t s}\\phi+I(t\\geq\\bar{T}_{s})\\bigg\\{\\alpha I\\bigg(0<\\frac{S_{i t s}}{H_{i t}}<1\\bigg)+\\beta\\frac{S_{i t s}}{H_{i t}}I\\bigg(0<\\frac{S_{i t s}}{H_{i t}}<1\\bigg) +\\gamma I\\bigg(\\frac{S_{i t s}}{H_{i t}}\\geq1\\bigg)+\\delta I\\bigg(\\frac{S_{i t s}}{H_{i t}}\\leq0\\bigg)\\bigg\\}+\\varepsilon_{i t s} \\quad \\text{(Eq. (1))}\n \n\nThe baseline group consists of individuals in periods before time limits were implemented.\n\n---\n\nBased on the theoretical hypotheses outlined in the paper (Banking, Unconstrained, Enforcement), which of the following statements about the parameters in Eq. (1) are theoretically predicted to be true? Select all that apply.", "Options": {"A": "The parameter `β` should be positive, as the incentive to bank benefits weakens when the stock of remaining eligibility (`S`) increases relative to the horizon (`H`).", "B": "The parameter `γ` should be negative, as even unconstrained individuals (`S/H ≥ 1`) will reduce welfare use as a precautionary measure.", "C": "The parameter `α` should be negative, reflecting the incentive to \"bank\" benefits by reducing current welfare use.", "D": "The parameter `δ` should be negative, reflecting the drop in participation when benefits are exhausted and the time limit is enforced."}, "Answer": ["A", "C", "D"], "pi_justification": "This item assesses the ability to map the paper's theoretical hypotheses directly onto the parameters of the empirical model. It's a foundational check of understanding the research design. Options A, B, and C correctly state the predicted signs for the Banking and Enforcement hypotheses. Option D is a Conceptual Distractor. The Unconstrained Hypothesis explicitly predicts that for individuals with `S/H ≥ 1`, the time limit is a non-binding constraint, and thus their behavior should not differ from the no-limit baseline, meaning `γ` is predicted to be zero, not negative.", "qid": "72", "question": "### Background\n\nA linear probability model is used to estimate the welfare participation (`$p_{its}$`) of single mothers. The key explanatory variables are a set of indicators and continuous terms based on the ratio of a woman's remaining welfare eligibility (`$S_{its}$`) to her eligibility horizon (`$H_{it}$`).\n\n---\n\n### Data / Model Specification\n\nThe empirical specification for welfare participation is:\n\n  \np_{i t s}=X_{i t}\\lambda+V_{t s}\\phi+I(t\\geq\\bar{T}_{s})\\bigg\\{\\alpha I\\bigg(0<\\frac{S_{i t s}}{H_{i t}}<1\\bigg)+\\beta\\frac{S_{i t s}}{H_{i t}}I\\bigg(0<\\frac{S_{i t s}}{H_{i t}}<1\\bigg) +\\gamma I\\bigg(\\frac{S_{i t s}}{H_{i t}}\\geq1\\bigg)+\\delta I\\bigg(\\frac{S_{i t s}}{H_{i t}}\\leq0\\bigg)\\bigg\\}+\\varepsilon_{i t s} \\quad \\text{(Eq. (1))}\n \n\nThe baseline group consists of individuals in periods before time limits were implemented.\n\n---\n\nBased on the theoretical hypotheses outlined in the paper (Banking, Unconstrained, Enforcement), which of the following statements about the parameters in Eq. (1) are theoretically predicted to be true? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 69, "Question": "### Background\n\nAn analysis of welfare time limits compares Ordinary Least Squares (OLS) and Instrumental Variables (IV) estimates of the parameters governing the behavioral \"banking\" effect (`α`) and the mechanical \"enforcement\" effect (`δ`). The key identification challenge is endogeneity arising from unobserved individual characteristics (e.g., barriers to work) that are correlated with both past and present welfare use.\n\n**Variables & Parameters.**\n- `α`: The \"banking\" parameter, representing the average effect on welfare participation for individuals with a binding time limit (remaining eligibility `S` is less than their eligibility horizon `H`, but greater than zero).\n- `δ`: The \"enforcement\" parameter, representing the average effect on welfare participation for individuals who have exhausted their benefits (`S/H ≤ 0`).\n\n---\n\n### Data / Model Specification\n\nThe following table presents OLS and the paper's preferred IV estimates for the key parameters from a linear probability model of welfare participation.\n\n**Table 1: OLS and IV Estimates of Time-Limit Effects**\n\n| Variable | (1) OLS | (5) IV |\n| :--- | :--- | :--- |\n| `I(0 < S/H < 1)` (Banking, `α`) | 0.064*** | -0.040** |\n| `I(S/H <= 0)` (Enforcement, `δ`) | 0.385*** | -0.863** |\n\n*Notes: From Table 4 in the paper. Standard errors omitted. *** p<0.01, ** p<0.05.*\n\n---\n\nBased on the theoretical framework and empirical results presented, which of the following statements are valid interpretations or conclusions? Select all that apply.", "Options": {"A": "The OLS estimate for the enforcement effect (`δ_OLS = 0.385`) suggests that, contrary to theory, exhausting welfare benefits causes a large increase in the probability of welfare participation.", "B": "The IV estimate for the enforcement effect (`δ_IV = -0.863`) is smaller in magnitude than the OLS estimate, indicating that OLS overstates the true penalty of benefit exhaustion.", "C": "The IV estimate for the banking effect (`α_IV = -0.040`) is consistent with the theory that forward-looking individuals reduce current welfare use to preserve eligibility for the future.", "D": "The difference between the OLS and IV estimates for the banking effect (`α`) implies that unobserved factors which increase current welfare need are positively correlated with having a lower stock of remaining benefits."}, "Answer": ["A", "C", "D"], "pi_justification": "This item assesses the ability to interpret and contrast OLS and IV estimates in the context of endogeneity. It uses a Reverse-Reasoning strategy, asking the user to identify valid conclusions from a set of results. Option A is a correct, literal interpretation of the biased OLS result. Option B correctly links the IV result to the paper's theory. Option C requires a deeper understanding of the source and direction of endogeneity bias. Option D is a numerical distractor (Sign Error); the IV estimate is much larger in magnitude, not smaller, than the OLS estimate, as it corrects a large positive bias.", "qid": "69", "question": "### Background\n\nAn analysis of welfare time limits compares Ordinary Least Squares (OLS) and Instrumental Variables (IV) estimates of the parameters governing the behavioral \"banking\" effect (`α`) and the mechanical \"enforcement\" effect (`δ`). The key identification challenge is endogeneity arising from unobserved individual characteristics (e.g., barriers to work) that are correlated with both past and present welfare use.\n\n**Variables & Parameters.**\n- `α`: The \"banking\" parameter, representing the average effect on welfare participation for individuals with a binding time limit (remaining eligibility `S` is less than their eligibility horizon `H`, but greater than zero).\n- `δ`: The \"enforcement\" parameter, representing the average effect on welfare participation for individuals who have exhausted their benefits (`S/H ≤ 0`).\n\n---\n\n### Data / Model Specification\n\nThe following table presents OLS and the paper's preferred IV estimates for the key parameters from a linear probability model of welfare participation.\n\n**Table 1: OLS and IV Estimates of Time-Limit Effects**\n\n| Variable | (1) OLS | (5) IV |\n| :--- | :--- | :--- |\n| `I(0 < S/H < 1)` (Banking, `α`) | 0.064*** | -0.040** |\n| `I(S/H <= 0)` (Enforcement, `δ`) | 0.385*** | -0.863** |\n\n*Notes: From Table 4 in the paper. Standard errors omitted. *** p<0.01, ** p<0.05.*\n\n---\n\nBased on the theoretical framework and empirical results presented, which of the following statements are valid interpretations or conclusions? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 64, "Question": "### Background\n\n**Research Question.** This problem investigates methods to resolve the 'masquerading shocks' problem by imposing additional, theory-consistent restrictions on the SVAR identification.\n\n**Setting.** The economy is described by the same static, three-equation New Keynesian model as before. A researcher augments the initial sign restrictions on inflation and interest rates with a new restriction on the implied Taylor rule.\n\n### Data / Model Specification\n\nThe model's closed-form solution and the definition of the identified shock `e_t^m` remain the same. The paper provides the formula for the implied coefficient on output in the misidentified Taylor rule, `\tilde{φ}_y`:\n\n  \n\\tilde{φ}_y = \\frac{p_{mm}φ_y - p_{md} - p_{ms}κ}{p_{md} + p_{mm}} \\quad \\text{(Eq. (1))}\n \n\nAll model parameters (`κ, φ_y, φ_π, σ^d, σ^s, σ^m`) are positive, and `φ_π > 1`. The true Taylor rule has a non-negative coefficient on output, `φ_y ≥ 0`.\n\n### Question\n\nA researcher proposes a new identification scheme that augments the original sign restrictions with the single, theory-consistent restriction that the implied Taylor rule coefficient on output must be non-negative, `\tilde{φ}_y ≥ 0`. Which of the following statements about the properties and power of this new restriction are correct? Select all that apply.", "Options": {"A": "This restriction completely eliminates any 'pure masquerading shock' (where `p_{mm}=0`, `p_{md}>0`, `p_{ms}>0`) from the identified set.", "B": "For an identified shock contaminated only by a demand shock (`p_{ms}=0`), this restriction imposes the upper bound `p_{md} / p_{mm} ≤ φ_y`.", "C": "This restriction is powerful because in the region of the identified set dominated by masquerading demand and supply shocks, the implied `\tilde{φ}_y` is invariably negative, thus violating the restriction.", "D": "This restriction ensures that the estimated impact of a contractionary policy shock on output will be unbiased."}, "Answer": ["A", "B", "C"], "pi_justification": "Assessment Target: This item assesses the ability to analyze the diagnostic power of an advanced identification technique (Taylor rule restrictions) proposed in the paper. It requires both qualitative reasoning and quantitative derivation.\nDepth Strategy: Scenario Application. The student must apply the new restriction (`\tilde{φ}_y ≥ 0`) to different scenarios of shock contamination to evaluate its effectiveness.\nDistractor Logic:\n- A (Correct): If `p_{mm}=0`, Eq. (1) becomes `\tilde{φ}_y = (-p_{md} - p_{ms}κ) / p_{md}`. Since `p_{md}, p_{ms}, κ` are all positive, `\tilde{φ}_y` is strictly negative, violating the new restriction. Thus, pure masqueraders are eliminated.\n- B (Correct): If `p_{ms}=0`, the restriction `\tilde{φ}_y ≥ 0` on Eq. (1) becomes `(p_{mm}φ_y - p_{md}) / (p_{md} + p_{mm}) ≥ 0`. Since the denominator is positive, this simplifies to `p_{mm}φ_y - p_{md} ≥ 0`, which rearranges to the stated upper bound.\n- C (Distractor - Conceptual Opposite): The restriction in B allows for `p_{md} > 0`, meaning some contamination from the expansionary demand shock can remain. This contamination biases the estimated output response of a contractionary shock towards zero (i.e., makes it less negative), so it is not unbiased.\n- D (Correct): This is the core intuition provided in the paper for why the restriction works so well. The masquerading shocks, being combinations of IS and Phillips Curve residuals, produce an implied 'policy rule' that is a distorted mix of those equations, resulting in a negative output coefficient.", "qid": "64", "question": "### Background\n\n**Research Question.** This problem investigates methods to resolve the 'masquerading shocks' problem by imposing additional, theory-consistent restrictions on the SVAR identification.\n\n**Setting.** The economy is described by the same static, three-equation New Keynesian model as before. A researcher augments the initial sign restrictions on inflation and interest rates with a new restriction on the implied Taylor rule.\n\n### Data / Model Specification\n\nThe model's closed-form solution and the definition of the identified shock `e_t^m` remain the same. The paper provides the formula for the implied coefficient on output in the misidentified Taylor rule, `\tilde{φ}_y`:\n\n  \n\\tilde{φ}_y = \\frac{p_{mm}φ_y - p_{md} - p_{ms}κ}{p_{md} + p_{mm}} \\quad \\text{(Eq. (1))}\n \n\nAll model parameters (`κ, φ_y, φ_π, σ^d, σ^s, σ^m`) are positive, and `φ_π > 1`. The true Taylor rule has a non-negative coefficient on output, `φ_y ≥ 0`.\n\n### Question\n\nA researcher proposes a new identification scheme that augments the original sign restrictions with the single, theory-consistent restriction that the implied Taylor rule coefficient on output must be non-negative, `\tilde{φ}_y ≥ 0`. Which of the following statements about the properties and power of this new restriction are correct? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 73, "Question": "### Background\n\n**Research Question.** This problem addresses the central positive result of the Shapiro-Stiglitz model: the derivation of an aggregate labor market equilibrium characterized by involuntary unemployment. It requires linking the micro-foundations of a worker's effort choice to the macro-level determination of wages and employment.\n\n**Setting / Institutional Environment.** The model describes a continuous-time labor market in a steady-state equilibrium. In this steady state, the flow of workers from employment to unemployment must equal the flow from unemployment back to employment. This condition endogenously determines the job acquisition rate for an unemployed worker. Firms have a production technology and demand labor, but must pay a wage high enough to satisfy the No-Shirking Condition (NSC) which itself depends on aggregate labor market conditions.\n\n**Variables & Parameters.**\n- `w`: Wage (real value).\n- `L`: Aggregate employment (number of workers).\n- `N`: Total labor supply, a fixed number (number of workers).\n- `F(L)`: Aggregate production function, with `F'(L) > 0` and `F''(L) < 0`.\n- `a`: The job acquisition rate per unit time for an unemployed worker (dimensionless rate).\n- `b`: Exogenous job separation rate (dimensionless rate).\n- `e`: Disutility of effort (real value, `e>0`).\n- `\\overline{w}`: Unemployment benefits (real value).\n- `q`: Probability per unit time of detecting a shirker (dimensionless rate).\n- `r`: Worker's discount rate (dimensionless rate, `r>0`).\n\n---\n\n### Data / Model Specification\n\nThe aggregate No-Shirking Condition (NSC), which gives the minimum wage `\\hat{w}` required to prevent shirking at a given level of aggregate employment `L`, is:\n\n  \n\\hat{w}(L) = \\overline{w} + e + \\frac{e}{q} \\left( \\frac{bN}{N-L} + r \\right)\n\\quad \\text{(Eq. (1))}\n \n\nThe aggregate labor demand condition is given by:\n\n  \nw = F'(L) \n\\quad \\text{(Eq. (2))}\n \n\nEquilibrium `(L*, w*)` occurs where the labor demand curve intersects the aggregate NSC curve.\n\n---\n\n### Question\n\nBased on the model, select all of the following statements that are correct descriptions of the aggregate labor market equilibrium.", "Options": {"A": "The aggregate NSC is upward-sloping because firms with more employees must pay higher wages to compensate for the diminishing marginal productivity of labor.", "B": "In equilibrium, the wage `w*` is set where the marginal product of labor `F'(L)` is equal to the disutility of effort `e`, as this is the social cost of labor.", "C": "The aggregate No-Shirking Condition (NSC) curve, `\\hat{w}(L)`, is upward-sloping in employment `L` because a tighter labor market (higher `L`) reduces the expected duration of unemployment for a fired worker, thus weakening the penalty for shirking.", "D": "A no-shirking equilibrium is impossible at full employment (`L=N`) because the job acquisition rate `a` would be infinite, eliminating the cost associated with being fired."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: This item tests the understanding of the two foundational pillars of the paper's main positive result: the economic logic behind the upward-sloping aggregate NSC and the impossibility of a full-employment equilibrium.\n\nStrategy: Atomic Decomposition. The original multi-part QA is broken down into discrete, independently verifiable propositions about the equilibrium.\n\nDistractor Logic:\n- (C) is a 'True but Irrelevant' / 'Conceptual' error. It correctly states that `F'(L)` is downward sloping but incorrectly attributes this logic to the NSC curve, conflating the labor demand side with the incentive constraint side of the model.\n- (D) is a 'Step-Omission' error. It describes the wage setting in a classical model but omits the crucial incentive-compatibility premium (`e/q * (...)`) that is central to the efficiency wage theory.", "qid": "73", "question": "### Background\n\n**Research Question.** This problem addresses the central positive result of the Shapiro-Stiglitz model: the derivation of an aggregate labor market equilibrium characterized by involuntary unemployment. It requires linking the micro-foundations of a worker's effort choice to the macro-level determination of wages and employment.\n\n**Setting / Institutional Environment.** The model describes a continuous-time labor market in a steady-state equilibrium. In this steady state, the flow of workers from employment to unemployment must equal the flow from unemployment back to employment. This condition endogenously determines the job acquisition rate for an unemployed worker. Firms have a production technology and demand labor, but must pay a wage high enough to satisfy the No-Shirking Condition (NSC) which itself depends on aggregate labor market conditions.\n\n**Variables & Parameters.**\n- `w`: Wage (real value).\n- `L`: Aggregate employment (number of workers).\n- `N`: Total labor supply, a fixed number (number of workers).\n- `F(L)`: Aggregate production function, with `F'(L) > 0` and `F''(L) < 0`.\n- `a`: The job acquisition rate per unit time for an unemployed worker (dimensionless rate).\n- `b`: Exogenous job separation rate (dimensionless rate).\n- `e`: Disutility of effort (real value, `e>0`).\n- `\\overline{w}`: Unemployment benefits (real value).\n- `q`: Probability per unit time of detecting a shirker (dimensionless rate).\n- `r`: Worker's discount rate (dimensionless rate, `r>0`).\n\n---\n\n### Data / Model Specification\n\nThe aggregate No-Shirking Condition (NSC), which gives the minimum wage `\\hat{w}` required to prevent shirking at a given level of aggregate employment `L`, is:\n\n  \n\\hat{w}(L) = \\overline{w} + e + \\frac{e}{q} \\left( \\frac{bN}{N-L} + r \\right)\n\\quad \\text{(Eq. (1))}\n \n\nThe aggregate labor demand condition is given by:\n\n  \nw = F'(L) \n\\quad \\text{(Eq. (2))}\n \n\nEquilibrium `(L*, w*)` occurs where the labor demand curve intersects the aggregate NSC curve.\n\n---\n\n### Question\n\nBased on the model, select all of the following statements that are correct descriptions of the aggregate labor market equilibrium.", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 70, "Question": "### Background\n\nThe paper investigates whether the mechanical enforcement of welfare time limits varies according to the specific design of state-level policies. The analysis compares the effect of benefit exhaustion (`S ≤ 0`) in two groups of states: \"Termination\" limit states, which drop the entire family from the rolls, and \"Reduction\" limit states, which only terminate the adult's portion of the benefit while children continue to receive assistance.\n\n**Variables & Parameters.**\n- `δ`: The \"enforcement\" parameter, representing the effect on welfare participation of being in the `S/H ≤ 0` range.\n\n---\n\n### Data / Model Specification\n\nThe following table presents IV estimates of the enforcement effect (`δ`), estimated separately for states with different time-limit policies.\n\n**Table 1: IV Estimates of the Enforcement Effect by Policy Type**\n\n| Sub-sample | Coefficient on `I(S <= 0)` (`δ`) |\n| :--- | :--- |\n| (1) Termination Limits | -1.229** |\n| (2) Reduction Limits | -0.102 |\n\n*Notes: From Table 5 in the paper. Standard errors omitted. ** p<0.05. The coefficient for Reduction Limits is not statistically significant.*\n\n---\n\nBased on the institutional context and the results in Table 1, which of the following conclusions are supported by the evidence? Select all that apply.", "Options": {"A": "The small and statistically insignificant effect in reduction-limit states is consistent with a policy where families transition to child-only benefits rather than leaving the welfare rolls entirely.", "B": "The results suggest that time limits are strongly enforced in states with termination policies, leading to a large drop in welfare participation upon benefit exhaustion.", "C": "Switching from a termination to a reduction policy would likely weaken the incentive for families to \"bank\" their benefits before reaching the time limit.", "D": "The data show that termination limits are less effective at reducing welfare participation than reduction limits."}, "Answer": ["A", "B", "C"], "pi_justification": "This item assesses the ability to connect institutional policy design to heterogeneous treatment effects. It uses a Scenario Application strategy, asking for valid conclusions from a sub-sample analysis. Options A and B are direct interpretations of the results in Table 1, linking them to the policy definitions. Option C requires a second-order inference (Reverse-Reasoning) about how a change in the enforcement penalty would affect prior banking behavior. Option D is a Conceptual Opposite distractor, as the data clearly show termination limits have a much stronger effect.", "qid": "70", "question": "### Background\n\nThe paper investigates whether the mechanical enforcement of welfare time limits varies according to the specific design of state-level policies. The analysis compares the effect of benefit exhaustion (`S ≤ 0`) in two groups of states: \"Termination\" limit states, which drop the entire family from the rolls, and \"Reduction\" limit states, which only terminate the adult's portion of the benefit while children continue to receive assistance.\n\n**Variables & Parameters.**\n- `δ`: The \"enforcement\" parameter, representing the effect on welfare participation of being in the `S/H ≤ 0` range.\n\n---\n\n### Data / Model Specification\n\nThe following table presents IV estimates of the enforcement effect (`δ`), estimated separately for states with different time-limit policies.\n\n**Table 1: IV Estimates of the Enforcement Effect by Policy Type**\n\n| Sub-sample | Coefficient on `I(S <= 0)` (`δ`) |\n| :--- | :--- |\n| (1) Termination Limits | -1.229** |\n| (2) Reduction Limits | -0.102 |\n\n*Notes: From Table 5 in the paper. Standard errors omitted. ** p<0.05. The coefficient for Reduction Limits is not statistically significant.*\n\n---\n\nBased on the institutional context and the results in Table 1, which of the following conclusions are supported by the evidence? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B\"", "model_answer": ["A", "B"], "error": null}}
{"ID": 74, "Question": "### Background\n\n**Research Question.** This problem analyzes the comparative statics of the Shapiro-Stiglitz model, specifically how the labor market equilibrium responds to an aggregate productivity shock.\n\n**Setting / Institutional Environment.** The model describes a continuous-time labor market in a steady-state equilibrium. Firms must pay a wage high enough to satisfy the upward-sloping aggregate No-Shirking Condition (NSC), and they hire workers up to the point where the marginal product of labor equals this wage.\n\n**Variables & Parameters.**\n- `w`: Wage (real value).\n- `L`: Aggregate employment (number of workers).\n- `N`: Total labor supply, a fixed number.\n- `F(L)`: Aggregate production function, with `F'(L) > 0` and `F''(L) < 0`.\n- `\\theta`: A Hicks-neutral technology parameter, initially `\\theta=1`.\n- `\\hat{w}(L)`: The aggregate NSC wage, an upward-sloping function of `L`.\n\n---\n\n### Data / Model Specification\n\nThe market equilibrium `(L*, w*)` is determined by the simultaneous satisfaction of the aggregate NSC and the labor demand condition. Following a productivity shock, the new equilibrium condition is:\n\n  \n\\theta F'(L) = \\hat{w}(L)\n\\quad \\text{(Eq. (1))}\n \n\nwhere `\\hat{w}(L) = \\overline{w} + e + \\frac{e}{q} ( \\frac{bN}{N-L} + r )`.\n\n---\n\n### Question\n\nConsider a positive, Hicks-neutral productivity shock that changes the production function to `\\theta F(L)` (where `\\theta > 1`). Select all of the following statements that correctly describe the shock's effect on the equilibrium.", "Options": {"A": "The productivity shock increases employment `L*`, but the equilibrium wage `w*` must fall to clear the market and maintain the no-shirking incentive.", "B": "The productivity shock shifts the labor demand curve `\\theta F'(L)` outward, leading to an increase in both equilibrium employment `L*` and the equilibrium wage `w*`.", "C": "The employment response is larger than in a standard competitive model because the higher productivity allows firms to more easily afford the higher efficiency wages required at higher employment levels.", "D": "The employment response to the shock is smaller in this model than in a standard competitive model with a fixed wage, because the induced rise in employment tightens the labor market and forces the equilibrium wage to increase along the upward-sloping NSC curve."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item tests the ability to perform comparative statics on the model's equilibrium and understand the economic intuition for the results, particularly the wage sluggishness or 'dampening' effect that is a key implication of the theory.\n\nStrategy: Computational Judgment / Atomic Decomposition. The question requires reasoning through the graphical and algebraic effects of a shock. The answer is decomposed into two key parts: the direction of the change in `L*` and `w*`, and the magnitude of the change in `L*` relative to a simpler model.\n\nDistractor Logic:\n- (C) is a 'Conceptual Opposite' error. It incorrectly assumes wages must fall, which would be true if the labor supply curve were upward sloping, but here the wage is determined by the NSC, which is also upward sloping in `L`.\n- (D) is also a 'Conceptual Opposite' error. It correctly identifies that firms can 'afford' higher wages but draws the wrong conclusion about the magnitude of the employment response, missing the key insight that the rising wage itself acts as a brake on hiring.", "qid": "74", "question": "### Background\n\n**Research Question.** This problem analyzes the comparative statics of the Shapiro-Stiglitz model, specifically how the labor market equilibrium responds to an aggregate productivity shock.\n\n**Setting / Institutional Environment.** The model describes a continuous-time labor market in a steady-state equilibrium. Firms must pay a wage high enough to satisfy the upward-sloping aggregate No-Shirking Condition (NSC), and they hire workers up to the point where the marginal product of labor equals this wage.\n\n**Variables & Parameters.**\n- `w`: Wage (real value).\n- `L`: Aggregate employment (number of workers).\n- `N`: Total labor supply, a fixed number.\n- `F(L)`: Aggregate production function, with `F'(L) > 0` and `F''(L) < 0`.\n- `\\theta`: A Hicks-neutral technology parameter, initially `\\theta=1`.\n- `\\hat{w}(L)`: The aggregate NSC wage, an upward-sloping function of `L`.\n\n---\n\n### Data / Model Specification\n\nThe market equilibrium `(L*, w*)` is determined by the simultaneous satisfaction of the aggregate NSC and the labor demand condition. Following a productivity shock, the new equilibrium condition is:\n\n  \n\\theta F'(L) = \\hat{w}(L)\n\\quad \\text{(Eq. (1))}\n \n\nwhere `\\hat{w}(L) = \\overline{w} + e + \\frac{e}{q} ( \\frac{bN}{N-L} + r )`.\n\n---\n\n### Question\n\nConsider a positive, Hicks-neutral productivity shock that changes the production function to `\\theta F(L)` (where `\\theta > 1`). Select all of the following statements that correctly describe the shock's effect on the equilibrium.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 61, "Question": "### Background\n\n**Research Question.** This problem examines the core identification strategy of a model designed to estimate the prevalence of three unobserved wage-setting regimes—fully flexible, downwardly real rigid, and downwardly nominal rigid—using only the aggregate distribution of observed wage changes.\n\n**Setting and Sample.** The analysis uses a large panel of individual wage changes for job stayers in West Germany. The observed distribution of wage changes is not normal; it exhibits distinctive features, including a prominent spike at exactly zero and a visible asymmetry around the mode (fewer observations just below the mode than above it).\n\n### Data / Model Specification\n\nThe model assumes that the observed distribution of wage changes is a mixture of three components, all derived from a single underlying, unobserved 'notional' wage change distribution, which is assumed to be normal conditional on worker characteristics.\n1.  **Fully Flexible Regime:** The observed wage change equals the notional wage change.\n2.  **Nominal Rigidity Regime:** The observed wage change is censored from below at zero. If the notional change is negative, the observed change is zero.\n3.  **Real Rigidity Regime:** The observed wage change is censored from below at a positive threshold `r`. If the notional change is less than `r`, the observed change is `r`.\n\nThe key identification challenge is to estimate the population shares of these three unobserved regimes and the parameters of the notional distribution from the shape of the observed distribution.\n\n### Question\n\nAccording to the paper's identification strategy, which of the following statements correctly link features of the observed wage change distribution to the model's components? Select all that apply.", "Options": {"A": "The asymmetry and \"missing mass\" of wage changes just below the distribution's mode are primarily used to identify the share of workers subject to *real* wage rigidity.", "B": "The overall variance of the distribution, after accounting for spikes, is used to identify the threshold `r` for the real rigidity regime.", "C": "The spike at exactly zero is used to identify the sum of both nominal and real rigidity, as both prevent some form of wage cuts.", "D": "The prominent spike at exactly zero is primarily used to identify the share of workers subject to *nominal* wage rigidity."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: Tests understanding of the core identification strategy, specifically how distinct distributional features map to different types of rigidity.\nStrategy: Atomic Decomposition. The original QA question about the identification mechanism is broken into four distinct propositions, two correct and two incorrect, forcing a precise understanding of the model.\nDistractor Logic: (C) is an 'Almost Right' error, incorrectly linking the variance to the rigidity threshold `r` instead of the notional distribution's variance. (D) is a 'Conceptual' error that fails to distinguish between the unique statistical fingerprints of nominal (spike at zero) and real (asymmetry at `r` > 0) rigidity.", "qid": "61", "question": "### Background\n\n**Research Question.** This problem examines the core identification strategy of a model designed to estimate the prevalence of three unobserved wage-setting regimes—fully flexible, downwardly real rigid, and downwardly nominal rigid—using only the aggregate distribution of observed wage changes.\n\n**Setting and Sample.** The analysis uses a large panel of individual wage changes for job stayers in West Germany. The observed distribution of wage changes is not normal; it exhibits distinctive features, including a prominent spike at exactly zero and a visible asymmetry around the mode (fewer observations just below the mode than above it).\n\n### Data / Model Specification\n\nThe model assumes that the observed distribution of wage changes is a mixture of three components, all derived from a single underlying, unobserved 'notional' wage change distribution, which is assumed to be normal conditional on worker characteristics.\n1.  **Fully Flexible Regime:** The observed wage change equals the notional wage change.\n2.  **Nominal Rigidity Regime:** The observed wage change is censored from below at zero. If the notional change is negative, the observed change is zero.\n3.  **Real Rigidity Regime:** The observed wage change is censored from below at a positive threshold `r`. If the notional change is less than `r`, the observed change is `r`.\n\nThe key identification challenge is to estimate the population shares of these three unobserved regimes and the parameters of the notional distribution from the shape of the observed distribution.\n\n### Question\n\nAccording to the paper's identification strategy, which of the following statements correctly link features of the observed wage change distribution to the model's components? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 78, "Question": "### Background\n\n**Research Question.** This problem investigates the drivers of aggregate consumption patterns by comparing the performance of demand models that incorporate different forms of dynamic behavior.\n\n**Setting and Sample.** The analysis uses a broad dataset including all goods and services, aggregated into four categories: I. Food, etc., II. Housing, III. Clothing, IV. Other. The data are Swedish annual time series from 1950-1970. Model performance is evaluated on both in-sample fit and out-of-sample prediction for 1971-1972.\n\n### Data / Model Specification\n\nThe LESH-pq model captures dynamics through a backward-looking habit-formation mechanism:\n\n  \np_{i t}q_{i t}=\\alpha_{i}p_{i t}q_{i,t-1}+\\beta_{i}\\left(y_{t}-\\sum_{k}\\alpha_{k}p_{k t}q_{k,t-1}\\right)+\\varepsilon_{i t} \\quad \\text{(Eq. (1))}\n \n\nThe RDI-w*Dq model captures dynamics through an autonomous trend term, `κ_i`:\n\n  \nw_{i t}^{*}D q_{i t}=\\kappa_{i}+\\mu_{i}D q_{t}+\\sum_{j}\\pi_{i j}D p_{j t}+\\varepsilon_{i t} \\quad \\text{(Eq. (2))}\n \n\n**Table 1. Average Information Inaccuracies (All Goods, 4 Commodities)**\n\n| Model      | In-Sample Fit (Is50.70) | Predictive Performance (I71-72) |\n|------------|-------------------------|---------------------------------| \n| LESH-pq    | 179                     | 41                              |\n| RDI-w*Dq   | 153                     | 32                              |\n\n*Note: Lower values indicate better performance.* \n\n### Question\n\nSuppose a government is considering a large, permanent, revenue-neutral tax reform in 1973: a new tax on \"Other Goods and Services\" (IV) offset by a subsidy for \"Food, Beverages and Tobacco\" (I). Based on the models' structures, which of the following are valid considerations when choosing a model to forecast the **long-run** consumption shares after this policy shock? Select all that apply.", "Options": {"A": "The LESH model provides a more theoretically sound framework for this forecast because its dynamic mechanism, habit formation, is endogenous and will evolve as consumers form new habits in response to the permanent price changes.", "B": "The RDI model should be chosen because its superior historical predictive performance (32 vs. 41) guarantees it will also be more accurate in forecasting the effects of a structural policy change.", "C": "Both models are equally suitable, as their strong historical performance indicates they have both captured the true underlying structure of consumer preferences.", "D": "The RDI model is likely unreliable for this task because its dynamic component, the autonomous trend `κ_i`, is estimated from historical data and will not adapt to the new economic environment created by the tax reform."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item assesses the user's ability to critically evaluate model suitability for a policy counterfactual, moving beyond historical fit to consider theoretical soundness (an application of the Lucas critique). Depth Strategy: Scenario Application. The user must apply their understanding of the models' structures to a novel policy forecasting scenario. Distractor Logic: Option C is a common but incorrect inference; historical performance does not guarantee reliability under a structural break. Option D is also incorrect; the models have different structures and cannot both be the 'true' model, and their suitability for this specific task differs greatly.", "qid": "78", "question": "### Background\n\n**Research Question.** This problem investigates the drivers of aggregate consumption patterns by comparing the performance of demand models that incorporate different forms of dynamic behavior.\n\n**Setting and Sample.** The analysis uses a broad dataset including all goods and services, aggregated into four categories: I. Food, etc., II. Housing, III. Clothing, IV. Other. The data are Swedish annual time series from 1950-1970. Model performance is evaluated on both in-sample fit and out-of-sample prediction for 1971-1972.\n\n### Data / Model Specification\n\nThe LESH-pq model captures dynamics through a backward-looking habit-formation mechanism:\n\n  \np_{i t}q_{i t}=\\alpha_{i}p_{i t}q_{i,t-1}+\\beta_{i}\\left(y_{t}-\\sum_{k}\\alpha_{k}p_{k t}q_{k,t-1}\\right)+\\varepsilon_{i t} \\quad \\text{(Eq. (1))}\n \n\nThe RDI-w*Dq model captures dynamics through an autonomous trend term, `κ_i`:\n\n  \nw_{i t}^{*}D q_{i t}=\\kappa_{i}+\\mu_{i}D q_{t}+\\sum_{j}\\pi_{i j}D p_{j t}+\\varepsilon_{i t} \\quad \\text{(Eq. (2))}\n \n\n**Table 1. Average Information Inaccuracies (All Goods, 4 Commodities)**\n\n| Model      | In-Sample Fit (Is50.70) | Predictive Performance (I71-72) |\n|------------|-------------------------|---------------------------------| \n| LESH-pq    | 179                     | 41                              |\n| RDI-w*Dq   | 153                     | 32                              |\n\n*Note: Lower values indicate better performance.* \n\n### Question\n\nSuppose a government is considering a large, permanent, revenue-neutral tax reform in 1973: a new tax on \"Other Goods and Services\" (IV) offset by a subsidy for \"Food, Beverages and Tobacco\" (I). Based on the models' structures, which of the following are valid considerations when choosing a model to forecast the **long-run** consumption shares after this policy shock? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 68, "Question": "### Background\n\n**Research Question.** This problem deconstructs the fundamental building blocks of the dynamic principal-agent model, focusing on the incentive constraint that defines the core economic trade-off for the influencer.\n\n**Setting / Institutional Environment.** An influencer privately chooses an ad intensity `a ∈ [0, 1]`. The choice creates a trade-off between an immediate flow payoff from advertising and an expected future reward from providing good advice. The future reward comes from an increase in the influencer's continuation value, `W(d)`, promised by the follower.\n\n### Data / Model Specification\n\nIn the baseline model, the influencer's objective is to choose `a` to maximize their total expected payoff, which is the sum of the flow payoff from ads and the expected change in continuation value:\n\n  \n\\lambda a + (1-a)\\lambda(W(d^+) - W(d)) \n \n\nwhere `λ` is a scaling parameter, `a` is ad intensity, and `W(d^+) - W(d)` is the promised increase in value if good advice is provided. This leads to the baseline incentive compatibility (IC) constraint to induce `a=0`: `W(d^+) - W(d) ≥ 1`.\n\nNow, consider a modification to the model: providing good advice is costly for the influencer, imposing a direct flow cost of `c(a) = k(1-a)` where `k > 0`. The flow payoff from ads remains `λa`.\n\n### Question\n\nUnder this new assumption of costly effort, select all of the following statements that are correct.", "Options": {"A": "The cost of effort `k` makes it easier for the follower to incentivize good advice, because the net benefit of advertising (`a=1`) over providing good advice (`a=0`) is reduced.", "B": "The new incentive compatibility (IC) constraint required to induce the influencer to choose `a=0` is `W(d^+) - W(d) ≥ 1 + k/λ`.", "C": "The new IC constraint required to induce `a=0` is `W(d^+) - W(d) ≥ 1 + k`.", "D": "The influencer's total objective function to be maximized by choosing `a` becomes `λa - k(1-a) + (1-a)λ(W(d^+) - W(d))`."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item tests the ability to perform a micro-derivation within the model's framework. It requires the student to modify the agent's objective function based on a new assumption and then correctly derive the resulting change in the incentive compatibility constraint.\n\nStrategy: This is a 'Scenario Application' and 'Computational Judgment' item. It presents a small, tractable extension to the baseline model and asks for both the setup (the new objective function) and the result (the new IC constraint) of the analysis.\n\nDistractor Logic:\n- C (Formula Misuse / Step-Omission Error): This is a common algebraic error. The derivation involves factoring out `a`, and a user might forget to divide the `k` term by `λ` when isolating the `W(d^+) - W(d)` term. The correct coefficient on `a` is `λ + k - λ(W(d^+) - W(d))`, and setting this to be non-positive yields the correct answer B, not C.\n- D (Conceptual Opposite): This reflects a fundamental misunderstanding of the trade-off. The cost `k` is incurred only when providing good advice (`a=0`), making that option *less* attractive. Therefore, it makes incentivizing good advice *harder*, not easier, as a larger reward is needed to compensate for both the foregone ad revenue and the direct cost of effort.", "qid": "68", "question": "### Background\n\n**Research Question.** This problem deconstructs the fundamental building blocks of the dynamic principal-agent model, focusing on the incentive constraint that defines the core economic trade-off for the influencer.\n\n**Setting / Institutional Environment.** An influencer privately chooses an ad intensity `a ∈ [0, 1]`. The choice creates a trade-off between an immediate flow payoff from advertising and an expected future reward from providing good advice. The future reward comes from an increase in the influencer's continuation value, `W(d)`, promised by the follower.\n\n### Data / Model Specification\n\nIn the baseline model, the influencer's objective is to choose `a` to maximize their total expected payoff, which is the sum of the flow payoff from ads and the expected change in continuation value:\n\n  \n\\lambda a + (1-a)\\lambda(W(d^+) - W(d)) \n \n\nwhere `λ` is a scaling parameter, `a` is ad intensity, and `W(d^+) - W(d)` is the promised increase in value if good advice is provided. This leads to the baseline incentive compatibility (IC) constraint to induce `a=0`: `W(d^+) - W(d) ≥ 1`.\n\nNow, consider a modification to the model: providing good advice is costly for the influencer, imposing a direct flow cost of `c(a) = k(1-a)` where `k > 0`. The flow payoff from ads remains `λa`.\n\n### Question\n\nUnder this new assumption of costly effort, select all of the following statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 79, "Question": "### Background\n\n**Research Question.** This problem analyzes the structure and theoretical underpinnings of the classic Linear Expenditure System (LES), focusing on the restrictive implications of its underlying utility function.\n\n### Data / Model Specification\n\nThe Linear Expenditure System (LES-w) is specified in share form as:\n\n  \nw_{i t}=c_{i}p_{i t}/y_{t}+\\beta_{i}\\left(1-\\sum_{k}c_{k}p_{k t}/y_{t}\\right)+\\varepsilon_{i t} \\quad \\text{(Eq. (1))}\n \n\nThe model imposes the adding-up constraint `\\sum_{i}\\beta_{i}=1`. The paper notes that the LES is derived from an additive utility function, which implies that \"there are no specific substitution effects and that the own-price elasticity is approximately proportional to the income elasticity, as shown in Deaton.\"\n\n### Question\n\nBased on the structure of the LES model in Eq. (1) and its theoretical underpinnings, which of the following statements are valid interpretations or implications? Select all that apply.", "Options": {"A": "The parameter `c_i` represents a subsistence or committed quantity of good `i`, which is purchased before any remaining 'supernumerary' income is allocated.", "B": "The underlying additive utility function implies that the marginal utility of consuming good `i` is independent of the quantity consumed of any other good `j`.", "C": "The parameter `β_i` represents the marginal budget share, indicating the fraction of each additional dollar of supernumerary income spent on good `i`.", "D": "The model implies that goods with high income elasticities (luxuries) must also have low own-price elasticities (be price inelastic)."}, "Answer": ["A", "B", "C"], "pi_justification": "Assessment Target: This item assesses the user's understanding of the parameter interpretation and theoretical implications of the Linear Expenditure System (LES), particularly the consequences of its additive utility function. Depth Strategy: Reverse-Reasoning. The user must connect the model's mathematical form and stated properties back to their underlying economic meaning. Distractor Logic: Option D is a Conceptual Opposite. The text explicitly states that the implication of additivity is that own-price elasticity is *proportional* to income elasticity, meaning luxuries (high income elasticity) would have high price elasticity, not low.", "qid": "79", "question": "### Background\n\n**Research Question.** This problem analyzes the structure and theoretical underpinnings of the classic Linear Expenditure System (LES), focusing on the restrictive implications of its underlying utility function.\n\n### Data / Model Specification\n\nThe Linear Expenditure System (LES-w) is specified in share form as:\n\n  \nw_{i t}=c_{i}p_{i t}/y_{t}+\\beta_{i}\\left(1-\\sum_{k}c_{k}p_{k t}/y_{t}\\right)+\\varepsilon_{i t} \\quad \\text{(Eq. (1))}\n \n\nThe model imposes the adding-up constraint `\\sum_{i}\\beta_{i}=1`. The paper notes that the LES is derived from an additive utility function, which implies that \"there are no specific substitution effects and that the own-price elasticity is approximately proportional to the income elasticity, as shown in Deaton.\"\n\n### Question\n\nBased on the structure of the LES model in Eq. (1) and its theoretical underpinnings, which of the following statements are valid interpretations or implications? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 76, "Question": "### Background\n\n**Research Question.** This problem requires analyzing the central behavioral constraint of the Shapiro-Stiglitz model: the No-Shirking Condition (NSC), which specifies the minimum wage `\\hat{w}` a firm must pay to induce a rational worker to exert effort.\n\n**Setting / Institutional Environment.** An employed worker chooses an effort level. If they shirk, they face a probability `q` of being caught and fired. The NSC defines the wage that makes a worker indifferent between shirking and not shirking.\n\n**Variables & Parameters.**\n- `\\hat{w}`: The minimum required wage (the NSC).\n- `V_u`: Expected lifetime utility of an unemployed individual.\n- `e`: Disutility of effort (`e>0`).\n- `r`: Worker's discount rate (`r>0`).\n- `b`: Exogenous separation rate.\n- `q`: Probability per unit time of detecting a shirker.\n\n---\n\n### Data / Model Specification\n\nThe No-Shirking Condition (NSC) can be expressed as a function of the model's parameters. The required wage `\\hat{w}` is given by:\n\n  \n\\hat{w} = rV_u + \\frac{e(r+b+q)}{q} = rV_u + e + \\frac{e(r+b)}{q}\n\\quad \\text{(Eq. (1))}\n \n\n---\n\n### Question\n\nA labor market has two types of firms paying efficiency wages to identical workers: high-tech firms with a high detection probability `q_H` and low-tech firms with a lower detection probability `q_L < q_H`. Based on the properties of the No-Shirking Condition (NSC) in Eq. (1), select all of the following statements that are correct.", "Options": {"A": "The wage-reducing effect of an increase in `q` is constant, meaning `\\hat{w}` is a linear function of `q`.", "B": "An increase in the exogenous quit rate `b` would decrease the required wage `\\hat{w}` because workers with shorter expected job tenures are less likely to risk being fired for shirking.", "C": "A government policy that improves monitoring technology for all firms (increasing both `q_L` and `q_H` by the same small amount) will cause the wage differential between low-tech and high-tech firms to compress.", "D": "The required wage `\\hat{w}` is a convex function of the detection probability `q`."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: This item tests for a sophisticated understanding of the NSC, moving beyond first-order comparative statics to analyze its second-order properties (convexity) and their economic implications for policy and wage dispersion.\n\nStrategy: Computational Judgment. The question requires the user to mentally (or physically) compute the second derivative of the NSC with respect to `q` to determine its curvature and then apply that mathematical property to a concrete economic scenario.\n\nDistractor Logic:\n- (C) is a 'Formula Misuse' error. It fails to recognize that the `1/q` term makes the function strictly non-linear and convex.\n- (D) is a 'Conceptual Opposite' error. It presents a plausible-sounding but incorrect intuition for the effect of `b`. A higher quit rate *reduces* the value of the job, making the threat of firing less potent and thus requiring a *higher* wage to maintain discipline.", "qid": "76", "question": "### Background\n\n**Research Question.** This problem requires analyzing the central behavioral constraint of the Shapiro-Stiglitz model: the No-Shirking Condition (NSC), which specifies the minimum wage `\\hat{w}` a firm must pay to induce a rational worker to exert effort.\n\n**Setting / Institutional Environment.** An employed worker chooses an effort level. If they shirk, they face a probability `q` of being caught and fired. The NSC defines the wage that makes a worker indifferent between shirking and not shirking.\n\n**Variables & Parameters.**\n- `\\hat{w}`: The minimum required wage (the NSC).\n- `V_u`: Expected lifetime utility of an unemployed individual.\n- `e`: Disutility of effort (`e>0`).\n- `r`: Worker's discount rate (`r>0`).\n- `b`: Exogenous separation rate.\n- `q`: Probability per unit time of detecting a shirker.\n\n---\n\n### Data / Model Specification\n\nThe No-Shirking Condition (NSC) can be expressed as a function of the model's parameters. The required wage `\\hat{w}` is given by:\n\n  \n\\hat{w} = rV_u + \\frac{e(r+b+q)}{q} = rV_u + e + \\frac{e(r+b)}{q}\n\\quad \\text{(Eq. (1))}\n \n\n---\n\n### Question\n\nA labor market has two types of firms paying efficiency wages to identical workers: high-tech firms with a high detection probability `q_H` and low-tech firms with a lower detection probability `q_L < q_H`. Based on the properties of the No-Shirking Condition (NSC) in Eq. (1), select all of the following statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 81, "Question": "### Background\n\n**Research Question.** This problem analyzes the logic of a one-period, static model of a unionized firm to understand why such a framework is insufficient to explain the involuntary unemployment of outsiders.\n\n**Setting / Institutional Environment.** A firm and a union of insiders bargain over the number of insiders to employ, `N`, and their wage, `w_I`. The firm can also hire non-union outsiders at a competitive reservation wage, `w_R`, to perform 'simple' jobs. Insiders have firm-specific skills for 'complicated' jobs but can also perform simple jobs. The outcome of the bargain is efficient, maximizing the total joint surplus of the coalition.\n\n### Data / Model Specification\n\n- **Key Employment Thresholds:**\n    - `N**(s)`: The level of insider employment where, if all insiders are in complicated jobs, their marginal product equals the outsider wage `w_R`.\n    - `N*(s)`: The level of insider employment where, if insiders fill *all* jobs (simple and complicated) and no outsiders are hired, their marginal product equals `w_R`. By construction, `N* > N**`.\n- **Outsider Demand:** The demand for outsiders is positive if `N ≤ N*(s)` and zero if `N > N*(s)`. Involuntary unemployment of outsiders occurs only if the firm operates with `N > N*(s)`.\n- **Marginal Value of Insiders (from Proposition 2):** The marginal value of an insider to the coalition, `V'(N) = ∂V/∂N`, behaves as follows:\n    1.  For `N < N**(s)`: `V'(N) > w_R`\n    2.  For `N**(s) ≤ N ≤ N*(s)`: `V'(N) = w_R`\n    3.  For `N > N*(s)`: `V'(N) < w_R`\n- **Bargaining Objective:** The firm and union choose `N` to maximize their total joint surplus, `S(N) = V(N) - w_R N`.\n\n### Question\n\nIn the one-period static model, the firm and union bargain to choose an insider employment level `N` that maximizes their joint surplus, `S(N)`. Based on the model's assumptions, select all statements that are **incorrect** descriptions of the bargaining outcome and its implications.", "Options": {"A": "For any employment level `N > N*(s)`, the marginal contribution of an insider to the joint surplus, `S'(N)`, is strictly negative.", "B": "The optimal level of insider employment `N` can be greater than `N*(s)`, which would cause involuntary unemployment of outsiders.", "C": "In the range `N**(s) ≤ N ≤ N*(s)`, adding one more insider has a marginal effect of exactly zero on the joint surplus `S(N)`.", "D": "The model can generate involuntary unemployment if the union has sufficient bargaining power to compel the firm to hire insiders beyond the point of static efficiency."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item tests the student's understanding of why the static model *fails* to generate the paper's main result (involuntary unemployment). It requires applying optimization logic to the specified surplus function.\nStrategy: Complement-set selection. The question asks for incorrect statements, forcing students to identify conclusions that are not supported by the model. This is an effective way to target and diagnose common misconceptions about the static case.\nDistractor Logic:\n- A & B (Correct Answers / Incorrect Statements): These options describe the very outcome (involuntary unemployment via `N > N*`) that the static model is designed to rule out. They represent the central conceptual error a student might make if they misunderstand the model's constraints.\n- C & D (Distractors / Correct Statements): These are true statements derived directly from the model's mechanics. `S'(N) = V'(N) - w_R`. For C, if `N > N*`, then `V'(N) < w_R`, so `S'(N) < 0`. For D, if `N` is in the specified range, `V'(N) = w_R`, so `S'(N) = 0`. These options serve as high-fidelity distractors that test careful application of the model's definitions.", "qid": "81", "question": "### Background\n\n**Research Question.** This problem analyzes the logic of a one-period, static model of a unionized firm to understand why such a framework is insufficient to explain the involuntary unemployment of outsiders.\n\n**Setting / Institutional Environment.** A firm and a union of insiders bargain over the number of insiders to employ, `N`, and their wage, `w_I`. The firm can also hire non-union outsiders at a competitive reservation wage, `w_R`, to perform 'simple' jobs. Insiders have firm-specific skills for 'complicated' jobs but can also perform simple jobs. The outcome of the bargain is efficient, maximizing the total joint surplus of the coalition.\n\n### Data / Model Specification\n\n- **Key Employment Thresholds:**\n    - `N**(s)`: The level of insider employment where, if all insiders are in complicated jobs, their marginal product equals the outsider wage `w_R`.\n    - `N*(s)`: The level of insider employment where, if insiders fill *all* jobs (simple and complicated) and no outsiders are hired, their marginal product equals `w_R`. By construction, `N* > N**`.\n- **Outsider Demand:** The demand for outsiders is positive if `N ≤ N*(s)` and zero if `N > N*(s)`. Involuntary unemployment of outsiders occurs only if the firm operates with `N > N*(s)`.\n- **Marginal Value of Insiders (from Proposition 2):** The marginal value of an insider to the coalition, `V'(N) = ∂V/∂N`, behaves as follows:\n    1.  For `N < N**(s)`: `V'(N) > w_R`\n    2.  For `N**(s) ≤ N ≤ N*(s)`: `V'(N) = w_R`\n    3.  For `N > N*(s)`: `V'(N) < w_R`\n- **Bargaining Objective:** The firm and union choose `N` to maximize their total joint surplus, `S(N) = V(N) - w_R N`.\n\n### Question\n\nIn the one-period static model, the firm and union bargain to choose an insider employment level `N` that maximizes their joint surplus, `S(N)`. Based on the model's assumptions, select all statements that are **incorrect** descriptions of the bargaining outcome and its implications.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 77, "Question": "### Background\n\n**Research Question.** This problem explores the trade-off between model complexity and forecasting performance by comparing a dynamic structural model with a simple static model in the context of food demand.\n\n**Setting and Sample.** The analysis uses Swedish annual time-series data for a 4-commodity grouping of food items from 1950-1970. Model performance is evaluated based on in-sample fit (1950-70) and out-of-sample predictive performance for 1971 and 1972, using information inaccuracy as the metric (lower is better).\n\n### Data / Model Specification\n\nThe Linear Expenditure System with Habit Formation (LESH-pq) incorporates dynamics via lagged consumption:\n\n  \np_{i t}q_{i t}=\\alpha_{i}p_{i t}q_{i,t-1}+\\beta_{i}\\left(y_{t}-\\sum_{k}\\alpha_{k}p_{k t}q_{k,t-1}\\right)+\\varepsilon_{i t} \\quad \\text{(Eq. (1))}\n \n\nThe simple Constant Elasticity of Demand System (CEDS-ln q) is a static model:\n\n  \n\\ln(q_{i t})=\\alpha_{i}+e_{i}\\ln(y_{t}/p_{t})+E_{i i}\\ln(p_{i t}/p_{t})+\\varepsilon_{i t} \\quad \\text{(Eq. (2))}\n \n\n**Table 1. Average Information Inaccuracies (4 Food Commodities)**\n\n| Model     | In-Sample Fit (I50-70) | Predictive Performance (I71-72) |\n|-----------|------------------------|---------------------------------| \n| LESH-pq   | 153                    | 389                             |\n| CEDS-ln q | 245                    | 217                             |\n\n*Note: Lower values indicate better performance.* \n\n### Question\n\nBased on the model specifications and the results in Table 1, which of the following statements are valid interpretations of the models' performance? Select all that apply.", "Options": {"A": "The reversal in performance, where the simpler CEDS-ln q model forecasts better out-of-sample, suggests that the LESH-pq model may have overfit the 1950-1970 data, capturing noise rather than a stable dynamic structure.", "B": "The LESH-pq model's poor out-of-sample performance can be attributed to its higher in-sample bias compared to the CEDS-ln q model.", "C": "The CEDS-ln q model's superior predictive performance (217 vs. 389) demonstrates that static models are fundamentally better for forecasting than dynamic models.", "D": "The LESH-pq model's superior in-sample fit (153 vs. 245) is likely due to its ability to capture the persistence and inertia inherent in food consumption habits via the `q_{i,t-1}` term."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item assesses the user's ability to interpret empirical results in the context of model specification, specifically by applying the concepts of habit formation and the bias-variance trade-off (overfitting). Depth Strategy: Reverse-Reasoning. The user is given the empirical results and must identify the plausible theoretical causes. Distractor Logic: Option C is a hasty generalization; the result is specific to this case and doesn't prove a general rule. Option D is a Conceptual Opposite; the more complex LESH model likely has lower in-sample bias but higher variance, which is the cause of its poor forecasting.", "qid": "77", "question": "### Background\n\n**Research Question.** This problem explores the trade-off between model complexity and forecasting performance by comparing a dynamic structural model with a simple static model in the context of food demand.\n\n**Setting and Sample.** The analysis uses Swedish annual time-series data for a 4-commodity grouping of food items from 1950-1970. Model performance is evaluated based on in-sample fit (1950-70) and out-of-sample predictive performance for 1971 and 1972, using information inaccuracy as the metric (lower is better).\n\n### Data / Model Specification\n\nThe Linear Expenditure System with Habit Formation (LESH-pq) incorporates dynamics via lagged consumption:\n\n  \np_{i t}q_{i t}=\\alpha_{i}p_{i t}q_{i,t-1}+\\beta_{i}\\left(y_{t}-\\sum_{k}\\alpha_{k}p_{k t}q_{k,t-1}\\right)+\\varepsilon_{i t} \\quad \\text{(Eq. (1))}\n \n\nThe simple Constant Elasticity of Demand System (CEDS-ln q) is a static model:\n\n  \n\\ln(q_{i t})=\\alpha_{i}+e_{i}\\ln(y_{t}/p_{t})+E_{i i}\\ln(p_{i t}/p_{t})+\\varepsilon_{i t} \\quad \\text{(Eq. (2))}\n \n\n**Table 1. Average Information Inaccuracies (4 Food Commodities)**\n\n| Model     | In-Sample Fit (I50-70) | Predictive Performance (I71-72) |\n|-----------|------------------------|---------------------------------| \n| LESH-pq   | 153                    | 389                             |\n| CEDS-ln q | 245                    | 217                             |\n\n*Note: Lower values indicate better performance.* \n\n### Question\n\nBased on the model specifications and the results in Table 1, which of the following statements are valid interpretations of the models' performance? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 80, "Question": "### Background\n\n**Research Question.** This problem analyzes how a firm's need to retain skilled labor for the future can lead it to employ an excessive number of skilled workers (insiders) in the present, causing involuntary unemployment among unskilled workers (outsiders).\n\n**Setting / Institutional Environment.** A firm and a union of insiders engage in a two-period Nash bargaining model. The key dynamic linkage is the stock of insiders. The number of insiders available in the second period (`N̄₂`) depends on the number employed in the first period (`N₁`), because unemployed insiders are more likely to quit the firm than employed insiders. The firm is assumed to be in a sufficiently bad state of the product market in period 1.\n\n### Data / Model Specification\n\n- **Workers and Jobs:** Insiders have firm-specific skills for 'complicated' jobs but can also do 'simple' jobs. Outsiders lack these skills and can only do simple jobs. Both are equally productive in simple jobs.\n- **Surplus Functions:** `V(N₁;s)` is the total surplus (revenue net of outsider wages) generated in period 1 with `N₁` insiders. `B(N̄₂)` is the expected total surplus in period 2, given `N̄₂` available insiders. It is increasing and concave in `N̄₂` (`B' > 0, B'' < 0`) for non-redundant levels of `N̄₂`.\n- **Static Optimum:** The statically optimal level of insider employment in period 1, denoted `N*(s)`, is where the marginal current-period surplus from an insider equals the outsider reservation wage `w_R`. For `N₁ > N*(s)`, `∂V(N₁;s)/∂N₁ < w_R`.\n- **Insider Retention:** The number of insiders available in period 2, `N̄₂`, follows the law of motion:\n\n  \n\\bar{N}_{2}=(1-P_{e})N_{1}+(1-P_{u})(\\bar{N}_{1}-N_{1})+n = h(N_1, n) \\quad \\text{(Eq. (1))}\n \n\nwhere `N̄₁` is the initial stock of insiders, `n` is the number of new trainees, and `P_e` and `P_u` are the probabilities that an employed and an unemployed insider, respectively, leave the firm. The crucial assumption is `P_u > P_e`.\n\n- **Optimization:** The firm-union pair chooses `N₁` to maximize the two-period total surplus. The first-order condition for an interior solution for `N₁` is:\n\n  \n\\frac{\\partial V(N_1;s)}{\\partial N_1} - w_R + \\frac{1}{1+r} B'(\\bar{N}_2) \\frac{\\partial h}{\\partial N_1} = 0 \\quad \\text{(Eq. (2))}\n \n\nwhere `r` is the interest rate.\n\n### Question\n\nBased on the two-period model, consider the firm-union's decision at the statically optimal employment level, `N₁ = N*(s)`. Select all statements that are correct descriptions of the economic trade-offs at this point.", "Options": {"A": "The firm-union pair will choose `N₁ = N*(s)` as the optimal employment level because the total marginal benefit of hiring an additional insider is zero at this point.", "B": "At `N₁ = N*(s)`, the marginal benefit from the current period's surplus (`∂V/∂N₁`) is exactly equal to the outsider reservation wage (`w_R`).", "C": "The forward-looking benefit of retaining an insider is positive only if the firm also plans to train new insiders (`n > 0`) in the second period.", "D": "At `N₁ = N*(s)`, the forward-looking marginal benefit of employing one more insider, which comes from increasing the future stock of insiders, is strictly positive."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item tests the student's ability to dissect the core first-order condition of the paper's dynamic model, distinguishing between the static and forward-looking components of the firm's decision.\nStrategy: Atomic Decomposition. The question breaks down the FOC into its constituent parts and asks the student to evaluate them at the critical threshold `N*(s)`. This requires understanding both the definition of the static optimum and the source of the dynamic incentive.\nDistractor Logic:\n- C (Conceptual Opposite): This distractor incorrectly equates the total marginal benefit with the static component, ignoring the positive future-looking term. It tempts students who fail to synthesize all parts of the FOC.\n- D (Formula Misuse/Conceptual Error): This distractor introduces a false causal link between retaining existing insiders and training new ones. It tests whether the student understands that the retention benefit (`∂h/∂N₁ = P_u - P_e`) is independent of the training decision (`n`).", "qid": "80", "question": "### Background\n\n**Research Question.** This problem analyzes how a firm's need to retain skilled labor for the future can lead it to employ an excessive number of skilled workers (insiders) in the present, causing involuntary unemployment among unskilled workers (outsiders).\n\n**Setting / Institutional Environment.** A firm and a union of insiders engage in a two-period Nash bargaining model. The key dynamic linkage is the stock of insiders. The number of insiders available in the second period (`N̄₂`) depends on the number employed in the first period (`N₁`), because unemployed insiders are more likely to quit the firm than employed insiders. The firm is assumed to be in a sufficiently bad state of the product market in period 1.\n\n### Data / Model Specification\n\n- **Workers and Jobs:** Insiders have firm-specific skills for 'complicated' jobs but can also do 'simple' jobs. Outsiders lack these skills and can only do simple jobs. Both are equally productive in simple jobs.\n- **Surplus Functions:** `V(N₁;s)` is the total surplus (revenue net of outsider wages) generated in period 1 with `N₁` insiders. `B(N̄₂)` is the expected total surplus in period 2, given `N̄₂` available insiders. It is increasing and concave in `N̄₂` (`B' > 0, B'' < 0`) for non-redundant levels of `N̄₂`.\n- **Static Optimum:** The statically optimal level of insider employment in period 1, denoted `N*(s)`, is where the marginal current-period surplus from an insider equals the outsider reservation wage `w_R`. For `N₁ > N*(s)`, `∂V(N₁;s)/∂N₁ < w_R`.\n- **Insider Retention:** The number of insiders available in period 2, `N̄₂`, follows the law of motion:\n\n  \n\\bar{N}_{2}=(1-P_{e})N_{1}+(1-P_{u})(\\bar{N}_{1}-N_{1})+n = h(N_1, n) \\quad \\text{(Eq. (1))}\n \n\nwhere `N̄₁` is the initial stock of insiders, `n` is the number of new trainees, and `P_e` and `P_u` are the probabilities that an employed and an unemployed insider, respectively, leave the firm. The crucial assumption is `P_u > P_e`.\n\n- **Optimization:** The firm-union pair chooses `N₁` to maximize the two-period total surplus. The first-order condition for an interior solution for `N₁` is:\n\n  \n\\frac{\\partial V(N_1;s)}{\\partial N_1} - w_R + \\frac{1}{1+r} B'(\\bar{N}_2) \\frac{\\partial h}{\\partial N_1} = 0 \\quad \\text{(Eq. (2))}\n \n\nwhere `r` is the interest rate.\n\n### Question\n\nBased on the two-period model, consider the firm-union's decision at the statically optimal employment level, `N₁ = N*(s)`. Select all statements that are correct descriptions of the economic trade-offs at this point.", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 84, "Question": "### Background\n\n**Research Question.** This problem examines the theoretical properties of the extreme-value distribution that make it a tractable choice for modeling asymmetric auctions and firm mergers.\n\n**Setting.** The model assumes each bidder `i`'s private value component, `Xᵢ`, is drawn independently from an extreme-value distribution. A key modeling step involves characterizing the distribution of the maximum of these values, which is relevant for determining winners and for modeling the value of a merged entity.\n\n---\n\n### Data / Model Specification\n\nThe cumulative distribution function (CDF) for a single bidder `i`'s value `Xᵢ` is given by:\n  \nFᵢ(t) = Pr(Xᵢ ≤ t) = exp[-exp(-μ(t - ηᵢ))] \n \nThe paper states that the maximum of a set of independent extreme-value variates is also an extreme-value variate. This property is known as 'closure under the maximum function'. In this model, the value of a merged firm is the maximum of the values of its constituent members.\n\n---\n\n### Question\n\nSelect all of the following statements that are correct regarding the model's properties and their interpretation.", "Options": {"A": "If two firms `i` and `j` merge, the location parameter `η_merged` of the new entity's value distribution is simply the sum of the individual location parameters, `ηᵢ + ηⱼ`.", "B": "The model assumes that after a merger, the individual firms' value distributions become perfectly correlated, meaning they always draw the same value.", "C": "The property of 'closure under the maximum function' is critical because it allows the post-merger entity's value to be modeled using the same family of distributions as the pre-merger firms, preserving analytical tractability.", "D": "In this model, the 'synergy' from a merger that increases the merged firm's expected value is a purely statistical effect of being able to bid the maximum of its members' independent value draws, not an assumed reduction in the members' underlying marginal costs."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: This item assesses the user's understanding of the key theoretical property ('closure under the maximum') that underpins the paper's modeling approach and their ability to distinguish between statistical effects and operational efficiencies within the model. Depth Strategy: Conceptual Judgment. The user must evaluate the correctness of statements about the model's core assumptions and implications. Distractor Logic: (C) is a formula misuse distractor. The correct formula for the new location parameter is `(1/μ)log[exp(μηᵢ) + exp(μηⱼ)]`, not a simple sum. (D) is a conceptual distractor (almost right). The merged firm acts as a single entity, but the model's value comes from the maximum of its members' *independent* value draws, not from their values becoming correlated.", "qid": "84", "question": "### Background\n\n**Research Question.** This problem examines the theoretical properties of the extreme-value distribution that make it a tractable choice for modeling asymmetric auctions and firm mergers.\n\n**Setting.** The model assumes each bidder `i`'s private value component, `Xᵢ`, is drawn independently from an extreme-value distribution. A key modeling step involves characterizing the distribution of the maximum of these values, which is relevant for determining winners and for modeling the value of a merged entity.\n\n---\n\n### Data / Model Specification\n\nThe cumulative distribution function (CDF) for a single bidder `i`'s value `Xᵢ` is given by:\n  \nFᵢ(t) = Pr(Xᵢ ≤ t) = exp[-exp(-μ(t - ηᵢ))] \n \nThe paper states that the maximum of a set of independent extreme-value variates is also an extreme-value variate. This property is known as 'closure under the maximum function'. In this model, the value of a merged firm is the maximum of the values of its constituent members.\n\n---\n\n### Question\n\nSelect all of the following statements that are correct regarding the model's properties and their interpretation.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 83, "Question": "### Background\n\n**Research Question.** This problem involves interpreting the results of a structural simulation of merger effects and evaluating the welfare standard used to assess merger efficiencies.\n\n**Setting.** Using an estimated structural model of a timber auction market, the price effects of the most anticompetitive two-firm merger are simulated for each of 51 auctions. The results, including the cost savings required to offset the price effect, are summarized.\n\n**Variables and Parameters.**\n- `%Δ Merged Firm's Winning Bid`: The percentage change in the price paid by the merged firm, conditional on it winning.\n- `%Δ Industry Price`: The expected percentage change in the overall auction price (seller revenue).\n- `Offsetting %Δ MC`: The percentage reduction in marginal cost (increase in value) required for the merged firm to leave the expected industry price unchanged.\n\n---\n\n### Data / Model Specification\n\n**Table 1: Simulated Mergers Among Two Best Bidders (Summary Statistics)**\n| Variable | Min | Max | Median | Mean |\n| :--- | :--- | :--- | :--- | :--- |\n| Sum of Merging Shares | 8.4 | 51.9 | 35.1 | 34.3 |\n| %Δ Merged Firm's Winning Bid | -0.4 | -5.4 | -2.7 | -2.6 |\n| %Δ Industry Price | -0.03 | -2.6 | -0.9 | -1.0 |\n| %Δ Merged Firm's Profits | 0.19 | 12.05 | 4.2 | 4.8 |\n| Offsetting %Δ MC | 0.6 | 9.7 | 3.8 | 4.1 |\n\nThe paper states that `%Δ Industry Price` is calculated as the change in the merged firm's winning bid multiplied by the merged firm's probability of winning.\n\n---\n\n### Question\n\nBased on the data in Table 1 and the principles of a second-price auction, select all of the following statements that are valid.", "Options": {"A": "The mean '%Δ Industry Price' (-1.0%) is smaller in magnitude than the mean '%Δ Merged Firm's Winning Bid' (-2.6%) because the price reduction only occurs in the fraction of auctions that the merged firm wins (mean share of 34.3%).", "B": "The data support a rule of thumb that for every 1% decrease in industry price, a marginal cost reduction of approximately 0.25% is required for offsetting.", "C": "The required 'Offsetting %Δ MC' is larger than the price effect it counteracts because merger efficiencies raise prices only when the merged firm loses, while the anticompetitive price reduction occurs when the merged firm wins.", "D": "If the antitrust authority used a total welfare standard (seller revenue + bidder profits) instead of a consumer welfare standard (price), the required 'Offsetting %Δ MC' to approve the merger would need to be larger than the 4.1% reported."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: This item tests the ability to interpret different measures of merger price effects, understand the economic intuition behind efficiency trade-offs in auctions, and reason about different welfare standards. Depth Strategy: Reverse-Reasoning. Given the summary statistics, the user must deduce the underlying causal mechanisms. Distractor Logic: (C) is a conceptual opposite. A total welfare standard is less strict because it accounts for the merging firms' profit gains, which a consumer (price) standard ignores. Therefore, a smaller, not larger, cost reduction would be required. (D) is a numerical distractor (formula misuse). It inverts the correct relationship; the mean data show a 4.1% MC reduction is needed to offset a 1.0% price change, a ratio of ~4:1, not 0.25:1.", "qid": "83", "question": "### Background\n\n**Research Question.** This problem involves interpreting the results of a structural simulation of merger effects and evaluating the welfare standard used to assess merger efficiencies.\n\n**Setting.** Using an estimated structural model of a timber auction market, the price effects of the most anticompetitive two-firm merger are simulated for each of 51 auctions. The results, including the cost savings required to offset the price effect, are summarized.\n\n**Variables and Parameters.**\n- `%Δ Merged Firm's Winning Bid`: The percentage change in the price paid by the merged firm, conditional on it winning.\n- `%Δ Industry Price`: The expected percentage change in the overall auction price (seller revenue).\n- `Offsetting %Δ MC`: The percentage reduction in marginal cost (increase in value) required for the merged firm to leave the expected industry price unchanged.\n\n---\n\n### Data / Model Specification\n\n**Table 1: Simulated Mergers Among Two Best Bidders (Summary Statistics)**\n| Variable | Min | Max | Median | Mean |\n| :--- | :--- | :--- | :--- | :--- |\n| Sum of Merging Shares | 8.4 | 51.9 | 35.1 | 34.3 |\n| %Δ Merged Firm's Winning Bid | -0.4 | -5.4 | -2.7 | -2.6 |\n| %Δ Industry Price | -0.03 | -2.6 | -0.9 | -1.0 |\n| %Δ Merged Firm's Profits | 0.19 | 12.05 | 4.2 | 4.8 |\n| Offsetting %Δ MC | 0.6 | 9.7 | 3.8 | 4.1 |\n\nThe paper states that `%Δ Industry Price` is calculated as the change in the merged firm's winning bid multiplied by the merged firm's probability of winning.\n\n---\n\n### Question\n\nBased on the data in Table 1 and the principles of a second-price auction, select all of the following statements that are valid.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 82, "Question": "### Background\n\n**Research Question.** This problem evaluates the use of a structural model to conduct a counterfactual policy simulation, specifically to estimate the economic cost of the Small Business Administration (SBA) set-aside program in timber auctions.\n\n**Setting.** The SBA set-aside program restricts participation in some auctions to small firms (those with fewer than 500 employees). The cost of this program is simulated by comparing actual auction outcomes to a counterfactual world where the program's effects are eliminated.\n\n**Variables and Parameters.**\n- `ηᵢ`: The observable portion of bidder `i`'s private value component (units: $/mbf).\n- `HAULᵢ`: Hauling distance for bidder `i` (units: miles).\n- `SBAᵢ`: An indicator variable equal to 1 if bidder `i` is a small firm, and 0 otherwise.\n- `β₂`: The estimated coefficient on the `SBAᵢ` dummy.\n\n---\n\n### Data / Model Specification\n\nThe observable component of a bidder's value, `ηᵢ`, is specified as:\n  \nηᵢ = β₁ ⋅ HAULᵢ + β₂ ⋅ SBAᵢ\n \n**Table 1: Estimated Value Distribution Parameters**\n| Variable | Coefficient |\n| :--- | :--- |\n| Hauling Miles (`β₁`) | -2.08 |\n| SBA Dummy (`β₂`) | -71.63 |\n| `1/μ` | 39.66 |\n\n**Table 2: Simulated Costs of the SBA Set-Aside Program**\n| Variable | Mean |\n| :--- | :--- |\n| Simulated Winning Bids ($/mbf) | 225.54 |\n| Current Winning Bids ($/mbf) | 200.64 |\n| %Δ Auction Revenue | 14.8% |\n\nThe simulation assumes that small, high-cost firms 'evolve into large, more efficient firms.'\n\n---\n\n### Question\n\nBased on the model, simulation description, and provided data, select all of the following statements that are correct interpretations or valid conclusions.", "Options": {"A": "The counterfactual simulation was implemented by setting the `SBAᵢ` dummy variable to 0 for all firms, effectively increasing the value component `ηᵢ` for all small firms by $71.63/mbf.", "B": "A more conservative simulation that only removes the participation restriction (i.e., allows large firms into the 10 set-aside auctions) but does not assume small firms become more efficient would result in a mean '%Δ Auction Revenue' greater than 14.8%.", "C": "Calculating the percentage change using the mean bids in Table 2 (`(225.54 - 200.64) / 200.64`) yields a result of approximately 12.4%, which is lower than the reported 14.8% because the paper reports the mean of the percentage changes from each of the 51 individual auctions.", "D": "The simulation's core assumption is that eliminating the SBA program causes small firms' hauling distances (`HAULᵢ`) to decrease, aligning them with the average distances of large firms."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: This item assesses the user's ability to interpret the mechanics of a counterfactual simulation, understand a common statistical nuance in reporting summary data (mean of ratios vs. ratio of means), and reason about alternative simulation designs. Depth Strategy: Scenario Application. The user must apply their understanding of the model to the specific simulation described. Distractor Logic: (C) is a conceptual opposite; a more conservative simulation that removes only one source of inefficiency (participation restriction) instead of two (restriction + firm inefficiency) must yield a smaller, not larger, effect. (D) is a formula misuse distractor; it misidentifies which parameter (`HAULᵢ` instead of `SBAᵢ`) is manipulated in the simulation, confusing the two sources of observed heterogeneity.", "qid": "82", "question": "### Background\n\n**Research Question.** This problem evaluates the use of a structural model to conduct a counterfactual policy simulation, specifically to estimate the economic cost of the Small Business Administration (SBA) set-aside program in timber auctions.\n\n**Setting.** The SBA set-aside program restricts participation in some auctions to small firms (those with fewer than 500 employees). The cost of this program is simulated by comparing actual auction outcomes to a counterfactual world where the program's effects are eliminated.\n\n**Variables and Parameters.**\n- `ηᵢ`: The observable portion of bidder `i`'s private value component (units: $/mbf).\n- `HAULᵢ`: Hauling distance for bidder `i` (units: miles).\n- `SBAᵢ`: An indicator variable equal to 1 if bidder `i` is a small firm, and 0 otherwise.\n- `β₂`: The estimated coefficient on the `SBAᵢ` dummy.\n\n---\n\n### Data / Model Specification\n\nThe observable component of a bidder's value, `ηᵢ`, is specified as:\n  \nηᵢ = β₁ ⋅ HAULᵢ + β₂ ⋅ SBAᵢ\n \n**Table 1: Estimated Value Distribution Parameters**\n| Variable | Coefficient |\n| :--- | :--- |\n| Hauling Miles (`β₁`) | -2.08 |\n| SBA Dummy (`β₂`) | -71.63 |\n| `1/μ` | 39.66 |\n\n**Table 2: Simulated Costs of the SBA Set-Aside Program**\n| Variable | Mean |\n| :--- | :--- |\n| Simulated Winning Bids ($/mbf) | 225.54 |\n| Current Winning Bids ($/mbf) | 200.64 |\n| %Δ Auction Revenue | 14.8% |\n\nThe simulation assumes that small, high-cost firms 'evolve into large, more efficient firms.'\n\n---\n\n### Question\n\nBased on the model, simulation description, and provided data, select all of the following statements that are correct interpretations or valid conclusions.", "model_evaluation_result": {"model_raw_response": "\"A,C\"", "model_answer": ["A", "C"], "error": null}}
{"ID": 75, "Question": "### Background\n\n**Research Question.** This problem investigates the normative properties of the efficiency wage equilibrium, comparing the decentralized market outcome to a social planner's solution to determine if the market generates a socially efficient level of unemployment.\n\n**Setting / Institutional Environment.** We compare the market equilibrium with the solution chosen by a social planner who maximizes total net national product. We consider a baseline model with exogenous monitoring and an extension where monitoring is endogenous and costly.\n\n**Variables & Parameters.**\n- `L*`, `w*`: The market equilibrium employment and wage.\n- `L**`, `w**`: The socially optimal employment and wage.\n- `F(L)`: Aggregate production function, assumed to be concave (`F'' < 0`).\n- `\\hat{w}(L, q)`: The aggregate no-shirking wage.\n\n---\n\n### Data / Model Specification\n\n- **Market Equilibrium:** Determined by `F'(L*) = \\hat{w}(L*, q)`.\n- **Social Planner's Optimum (Baseline):** Determined by `F(L**)/L** = \\hat{w}(L**, q)`. For a concave production function, `F(L)/L > F'(L)` for `L>0`.\n- **Extension:** In a case with endogenous monitoring and constant returns to scale (`F(L)=L`), the paper shows the welfare conclusion reverses.\n\n---\n\n### Question\n\nRegarding the normative properties of the market equilibrium, select all of the following statements that are correct according to the paper's analysis.", "Options": {"A": "The market equilibrium always generates too much unemployment, regardless of whether monitoring is exogenous or endogenous, because of the negative externality firms impose on each other by reducing the unemployment pool when they hire workers.", "B": "In the baseline model with exogenous monitoring and a concave production function, the market equilibrium generates too much unemployment (`L* < L**`) because firms' hiring decisions are based on the private cost of labor (`w`), which exceeds the social cost (`e`).", "C": "In the extension with endogenous monitoring and constant returns to scale, the market equilibrium generates too little unemployment (`L* > L**`) because individual firms overuse costly monitoring and fail to account for the social benefit of using a higher unemployment rate as a collective discipline device.", "D": "The market equilibrium is generally not Pareto optimal, but it would be if the government provided unemployment insurance, as this would align private and social incentives by compensating unemployed workers."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: This item assesses a deep understanding of the paper's nuanced welfare analysis, including the baseline result, the externalities at play, and the crucial reversal of the main conclusion in the model's extension.\n\nStrategy: Atomic Decomposition / Premise Packaging. The question packages the paper's key normative findings into distinct propositions, requiring the user to distinguish between the results of the baseline model and its extension.\n\nDistractor Logic:\n- (C) is a 'Conceptual Opposite' error. The paper explicitly argues that unemployment benefits *exacerbate* the problem by reducing the penalty of being fired, thus requiring higher wages and leading to more unemployment.\n- (D) is a 'Conceptual Opposite' / 'Overgeneralization' error. It correctly identifies one of the externalities but incorrectly claims the resulting underemployment is a universal feature of the model, failing to recognize the reversal shown in the endogenous monitoring extension.", "qid": "75", "question": "### Background\n\n**Research Question.** This problem investigates the normative properties of the efficiency wage equilibrium, comparing the decentralized market outcome to a social planner's solution to determine if the market generates a socially efficient level of unemployment.\n\n**Setting / Institutional Environment.** We compare the market equilibrium with the solution chosen by a social planner who maximizes total net national product. We consider a baseline model with exogenous monitoring and an extension where monitoring is endogenous and costly.\n\n**Variables & Parameters.**\n- `L*`, `w*`: The market equilibrium employment and wage.\n- `L**`, `w**`: The socially optimal employment and wage.\n- `F(L)`: Aggregate production function, assumed to be concave (`F'' < 0`).\n- `\\hat{w}(L, q)`: The aggregate no-shirking wage.\n\n---\n\n### Data / Model Specification\n\n- **Market Equilibrium:** Determined by `F'(L*) = \\hat{w}(L*, q)`.\n- **Social Planner's Optimum (Baseline):** Determined by `F(L**)/L** = \\hat{w}(L**, q)`. For a concave production function, `F(L)/L > F'(L)` for `L>0`.\n- **Extension:** In a case with endogenous monitoring and constant returns to scale (`F(L)=L`), the paper shows the welfare conclusion reverses.\n\n---\n\n### Question\n\nRegarding the normative properties of the market equilibrium, select all of the following statements that are correct according to the paper's analysis.", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 85, "Question": "### Background\n\n**Research Question.** This problem addresses the core identification strategy for estimating the parameters of a structural auction model in the presence of unobserved heterogeneity across auctions.\n\n**Setting.** The model specifies a bidder's value `Vᵢ` as the sum of an unobserved auction-specific common component `Y` and a bidder-specific private component `Xᵢ`. The institutional setting is a Forest Service oral auction where losing bids are publicly recorded.\n\n---\n\n### Data / Model Specification\n\nThe value structure is:\n  \nV_i = Y + X_i\n \nThe core identification assumption, based on the oral auction rules, is that losing bidders bid truthfully up to their values. This implies that the observed k-th highest bid from a losing bidder corresponds to the k-th highest value:\n  \nB_{(k)} = V_{(k)} = Y + X_{(k)} \\quad \\text{for } k \\ge 2 \\quad \\text{(Eq. 1)}\n \nThe estimation strategy relies on the difference between the second- and third-highest bids, `Δ = B₍₂₎ - B₍₃₎`.\n\n---\n\n### Question\n\nBased on the model and identification strategy, select all of the following statements that are correct.", "Options": {"A": "The common shock `Y` can be consistently estimated by taking the average of all losing bids within a single auction.", "B": "If informal collusion caused researchers to mistakenly observe the third- and sixth-highest bidders instead of the second- and third-highest, the resulting estimate of the private value variance (`Var(Xᵢ)`) would be biased downwards.", "C": "The strategy of differencing the second- and third-highest bids (`B₍₂₎ - B₍₃₎`) is used to eliminate the unobserved, auction-specific common shock `Y`.", "D": "This identification strategy critically relies on the institutional detail that in these oral auctions, it is a dominant strategy for losing bidders to bid up to their true values, making their final bids informative."}, "Answer": ["C", "D"], "pi_justification": "Assessment Target: This item tests the user's understanding of the paper's core identification strategy: why the common shock `Y` is a problem, how differencing solves it, and the institutional assumptions required. It also tests reasoning about sources of bias. Depth Strategy: Reverse-Reasoning. The user must identify the valid pre-conditions and consequences of the estimation strategy. Distractor Logic: (C) is a conceptual opposite. The gap between the 3rd and 6th values is expected to be larger than the gap between the 2nd and 3rd. Attributing this larger gap to the private value distribution would lead to an *upwardly* biased estimate of the variance. (D) is a conceptual distractor. The common shock `Y` is not identified; any average of bids would still be `Y` plus an average of `X` terms, so `Y` cannot be isolated.", "qid": "85", "question": "### Background\n\n**Research Question.** This problem addresses the core identification strategy for estimating the parameters of a structural auction model in the presence of unobserved heterogeneity across auctions.\n\n**Setting.** The model specifies a bidder's value `Vᵢ` as the sum of an unobserved auction-specific common component `Y` and a bidder-specific private component `Xᵢ`. The institutional setting is a Forest Service oral auction where losing bids are publicly recorded.\n\n---\n\n### Data / Model Specification\n\nThe value structure is:\n  \nV_i = Y + X_i\n \nThe core identification assumption, based on the oral auction rules, is that losing bidders bid truthfully up to their values. This implies that the observed k-th highest bid from a losing bidder corresponds to the k-th highest value:\n  \nB_{(k)} = V_{(k)} = Y + X_{(k)} \\quad \\text{for } k \\ge 2 \\quad \\text{(Eq. 1)}\n \nThe estimation strategy relies on the difference between the second- and third-highest bids, `Δ = B₍₂₎ - B₍₃₎`.\n\n---\n\n### Question\n\nBased on the model and identification strategy, select all of the following statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"B,C,D\"", "model_answer": ["B", "C", "D"], "error": null}}
{"ID": 87, "Question": "### Background\n\n**Research Question.** This problem explores the architecture of the hypothesis testing framework for comparing Absolute Concentration Curves (ACCs), from the fundamental definitions to the construction of specific, tailored test statistics.\n\n**Setting / Institutional Environment.** An econometrician wishes to formally test various hypotheses about the relationship between two ACCs, `A(t)` and `B(t)`. These hypotheses involve comparing the functions over their entire domain `t` in `[0,1]`.\n\n### Data / Model Specification\n\nThe Absolute Concentration Curve (ACC) for an asset with return `Y` with respect to a portfolio with value `X` (with CDF `F`) is defined as:\n\n  \nA(t) := \\operatorname{E}[Y \\cdot 1_{[X \\leq F^{-1}(t)]}] \\quad \\text{(Eq. 1)}\n \n\nTwo key hypotheses are converted into tests on scalar parameters:\n1.  **Equality (`H_{01}: A = B`):** Tested using the parameter `\\tau_1 := \\sup|A-B| = s(A-B) \\lor s(B-A)`, where `\\lor` is the maximum.\n2.  **Non-intersection (`H_{03}: A \\le B` or `A \\ge B`):** Tested against the alternative of intersection using the parameter `\\tau_3 := s(A-B) \\wedge s(B-A)`, where `\\wedge` is the minimum.\n\n### Question\n\nBased on the provided definitions, select all statements that are **correct** interpretations of the Absolute Concentration Curve (ACC) and the logic of the test parameters.", "Options": {"A": "The parameter `\\tau_3` uses the minimum (`\\wedge`) operator because an intersection requires `A-B` to be positive for some `t` AND `B-A` to be positive for some other `t`; `\\tau_3` is positive only if both conditions hold.", "B": "The value `A(t)` represents the expected return of asset Y, averaged over the scenarios where the portfolio's value `X` falls in the lowest `t`-quantile of its distribution.", "C": "The parameter `\\tau_1` uses the maximum (`\\lor`) operator to specifically test for intersection, as it captures the largest deviation in either direction.", "D": "The value `A(t)` is the regression coefficient of asset Y's return on an indicator for the portfolio's value `X` being less than or equal to its `t`-th quantile."}, "Answer": ["A", "B"], "pi_justification": "Assessment Target: This item tests the fundamental economic interpretation of the ACC and the statistical intuition behind the construction of the paper's key test statistics.\n\nStrategy: It uses an **Atomic Decomposition** strategy to create two correct options testing distinct core concepts. Option A assesses the economic interpretation of the ACC definition. Option B tests the statistical logic for using the `min` operator in the specialized test for intersection.\n\nDistractor Logic: The distractors target common points of confusion. Option C (Conceptual Opposite) incorrectly maps the `max` operator (used for testing equality) to the intersection hypothesis. Option D (Almost Right) presents a plausible but incorrect statistical interpretation of the ACC, confusing a conditional expectation with a regression coefficient.", "qid": "87", "question": "### Background\n\n**Research Question.** This problem explores the architecture of the hypothesis testing framework for comparing Absolute Concentration Curves (ACCs), from the fundamental definitions to the construction of specific, tailored test statistics.\n\n**Setting / Institutional Environment.** An econometrician wishes to formally test various hypotheses about the relationship between two ACCs, `A(t)` and `B(t)`. These hypotheses involve comparing the functions over their entire domain `t` in `[0,1]`.\n\n### Data / Model Specification\n\nThe Absolute Concentration Curve (ACC) for an asset with return `Y` with respect to a portfolio with value `X` (with CDF `F`) is defined as:\n\n  \nA(t) := \\operatorname{E}[Y \\cdot 1_{[X \\leq F^{-1}(t)]}] \\quad \\text{(Eq. 1)}\n \n\nTwo key hypotheses are converted into tests on scalar parameters:\n1.  **Equality (`H_{01}: A = B`):** Tested using the parameter `\\tau_1 := \\sup|A-B| = s(A-B) \\lor s(B-A)`, where `\\lor` is the maximum.\n2.  **Non-intersection (`H_{03}: A \\le B` or `A \\ge B`):** Tested against the alternative of intersection using the parameter `\\tau_3 := s(A-B) \\wedge s(B-A)`, where `\\wedge` is the minimum.\n\n### Question\n\nBased on the provided definitions, select all statements that are **correct** interpretations of the Absolute Concentration Curve (ACC) and the logic of the test parameters.", "model_evaluation_result": {"model_raw_response": "\"A,B\"", "model_answer": ["A", "B"], "error": null}}
{"ID": 89, "Question": "### Background\n\nThis problem deconstructs the core mechanism of the Samuelsonian surplus using the paper's simplest framework: a competitive economy with a minimum wage. It examines the laissez-faire equilibrium, the welfare effects of the minimum wage, and the necessary conditions for its existence.\n\n### Data / Model Specification\n\nConsider a discrete-time, overlapping-generations economy with the following features:\n- A population of `L` workers, each endowed with `\\alpha` units of capital.\n- A constant per-period probability of death, `d`.\n- Production is governed by a fixed-proportions function: `X = \\min(K_E, L_E)`, where `X` is output and `K_E, L_E` are employed capital and labor. Cost minimization implies `K_E = L_E`.\n- The economy has surplus labor, enforced by the assumption `\\alpha < 1`, which implies the aggregate capital stock `K = \\alpha L` is less than the labor force `L`.\n- The price of output is normalized to 1, and in a competitive market, this equals the cost of production: `1 = r + w`, where `r` is the return to capital and `w` is the wage.\n- `V_E` and `V_U` are the expected lifetime incomes for employed and unemployed workers, respectively. In this model, the solved expression for `V_U` is `V_U = (\\alpha r + \\alpha w) / d`.\n- Jobs are durable. A surviving worker keeps their job with probability `1-b`. The job survival rate is `h = (1-d)(1-b)`.\n\n### Question\n\nIn the context of the minimum wage model, select all of the following statements that are correct.", "Options": {"A": "In the laissez-faire equilibrium (with `w=0`), a positive social surplus exists because jobs are durable (`h>0`) and some workers are employed.", "B": "A binding minimum wage harms currently unemployed workers by reducing their expected lifetime income (`V_U`), because the lower return on their capital (`r = 1-w`) outweighs any potential future wage gains.", "C": "A binding minimum wage (`w > 0`) represents a weak Pareto improvement for the currently living generation, as it strictly increases the expected lifetime income of the employed (`V_E`) while leaving that of the unemployed (`V_U`) unchanged.", "D": "The social surplus created by the minimum wage would disappear if jobs were not durable (i.e., if the job separation rate `b=1`), because employment would no longer confer a special claim on future output."}, "Answer": ["C", "D"], "pi_justification": "This item tests the understanding of the core mechanism in the paper's simplest model (Section 2). The strategy is **Atomic Decomposition**, testing key results from different parts of the original question. **Option A** assesses the central policy conclusion about Pareto improvement. **Option B** tests a crucial boundary condition for the existence of the surplus (job durability), an example of **Applicability Domain Enumeration**. **Distractor C** is a high-fidelity **Conceptual: Almost Right** error, presenting a plausible but incomplete causal chain that leads to the wrong conclusion about `V_U`. **Distractor D** is a **Conceptual Opposite**, directly contradicting the model's baseline result that no surplus exists in the laissez-faire equilibrium.", "qid": "89", "question": "### Background\n\nThis problem deconstructs the core mechanism of the Samuelsonian surplus using the paper's simplest framework: a competitive economy with a minimum wage. It examines the laissez-faire equilibrium, the welfare effects of the minimum wage, and the necessary conditions for its existence.\n\n### Data / Model Specification\n\nConsider a discrete-time, overlapping-generations economy with the following features:\n- A population of `L` workers, each endowed with `\\alpha` units of capital.\n- A constant per-period probability of death, `d`.\n- Production is governed by a fixed-proportions function: `X = \\min(K_E, L_E)`, where `X` is output and `K_E, L_E` are employed capital and labor. Cost minimization implies `K_E = L_E`.\n- The economy has surplus labor, enforced by the assumption `\\alpha < 1`, which implies the aggregate capital stock `K = \\alpha L` is less than the labor force `L`.\n- The price of output is normalized to 1, and in a competitive market, this equals the cost of production: `1 = r + w`, where `r` is the return to capital and `w` is the wage.\n- `V_E` and `V_U` are the expected lifetime incomes for employed and unemployed workers, respectively. In this model, the solved expression for `V_U` is `V_U = (\\alpha r + \\alpha w) / d`.\n- Jobs are durable. A surviving worker keeps their job with probability `1-b`. The job survival rate is `h = (1-d)(1-b)`.\n\n### Question\n\nIn the context of the minimum wage model, select all of the following statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 88, "Question": "### Background\n\nThis problem explores the paper's central theoretical contribution: in a dynamic model of unemployment with search frictions, the existence of a “Samuelsonian surplus” creates a fundamental conflict of interest between the current generation and future generations, rendering the allocation that maximizes net output Pareto inefficient.\n\n### Data / Model Specification\n\nConsider a discrete-time, overlapping-generations search model with the following features:\n- There is a population of `L` agents who face a constant per-period probability of death, `d`.\n- Unemployed workers expend search effort `e` at a utility cost `c(e)` to find a productive partner.\n- `X` denotes the number of productive matches (jobs). Each match produces one unit of output.\n- The welfare of a newborn agent (representing all future generations) is their expected lifetime utility, `V_U`, which is proportional to the economy's steady-state net output, `Y(X)`.\n- The aggregate welfare of the current generation, `V`, is the sum of the total value of lifetime net output and a social surplus term, `S(X)`.\n\nThe relevant welfare functions are given by:\n  \nV_U(X) = \\frac{Y(X)}{Ld} \\quad \\text{(Eq. (1))}\n \n  \nV(X) = \\frac{Y(X)}{d} + S(X) \\quad \\text{(Eq. (2))}\n \nwhere:\n- Net output `Y(X)` is gross output `X` minus total search costs. It is assumed to be a concave function of `X`.\n- The social surplus `S(X)` arises from intergenerational transfers created by durable jobs. It is assumed to be strictly increasing in the level of employment `X` (i.e., `S'(X) > 0`).\n\nLet `X_F^*` be the employment level that maximizes the welfare of future generations (i.e., maximizes `Y(X)`), and `X_C^*` be the level that maximizes the welfare of the current generation (i.e., maximizes `V(X)`).\n\n### Question\n\nBased on the model, select all of the following statements that are correct.", "Options": {"A": "The allocation that maximizes net output (`X_F^*`) is Pareto inefficient because a marginal increase in employment from this point creates a first-order welfare gain for the current generation but only a second-order welfare loss for future generations.", "B": "The current generation's preferred level of employment (`X_C^*`) is strictly less than the level preferred by future generations (`X_F^*`) because the surplus `S(X)` represents a cost to the current generation.", "C": "The allocation that maximizes net output (`X_F^*`) is Pareto efficient because maximizing the total economic pie is the definition of efficiency in this framework.", "D": "The current generation's preferred level of employment (`X_C^*`) is strictly greater than the level preferred by future generations (`X_F^*`)."}, "Answer": ["A", "D"], "pi_justification": "This item assesses the ability to derive and interpret the paper's central theoretical result regarding the conflict of interest between generations. The conversion strategy is **Atomic Decomposition**, breaking the original multi-part proof into distinct, verifiable conclusions. **Option A** tests the final mathematical result (`X_C^* > X_F^*`). **Option B** tests the economic interpretation of Pareto inefficiency via first- and second-order effects. **Distractor C** is a classic **Conceptual: Almost Right** error, confusing output maximization with Pareto efficiency in a context with intergenerational transfers. **Distractor D** is a **Conceptual Opposite**, testing for sign errors or a fundamental misunderstanding of the surplus.", "qid": "88", "question": "### Background\n\nThis problem explores the paper's central theoretical contribution: in a dynamic model of unemployment with search frictions, the existence of a “Samuelsonian surplus” creates a fundamental conflict of interest between the current generation and future generations, rendering the allocation that maximizes net output Pareto inefficient.\n\n### Data / Model Specification\n\nConsider a discrete-time, overlapping-generations search model with the following features:\n- There is a population of `L` agents who face a constant per-period probability of death, `d`.\n- Unemployed workers expend search effort `e` at a utility cost `c(e)` to find a productive partner.\n- `X` denotes the number of productive matches (jobs). Each match produces one unit of output.\n- The welfare of a newborn agent (representing all future generations) is their expected lifetime utility, `V_U`, which is proportional to the economy's steady-state net output, `Y(X)`.\n- The aggregate welfare of the current generation, `V`, is the sum of the total value of lifetime net output and a social surplus term, `S(X)`.\n\nThe relevant welfare functions are given by:\n  \nV_U(X) = \\frac{Y(X)}{Ld} \\quad \\text{(Eq. (1))}\n \n  \nV(X) = \\frac{Y(X)}{d} + S(X) \\quad \\text{(Eq. (2))}\n \nwhere:\n- Net output `Y(X)` is gross output `X` minus total search costs. It is assumed to be a concave function of `X`.\n- The social surplus `S(X)` arises from intergenerational transfers created by durable jobs. It is assumed to be strictly increasing in the level of employment `X` (i.e., `S'(X) > 0`).\n\nLet `X_F^*` be the employment level that maximizes the welfare of future generations (i.e., maximizes `Y(X)`), and `X_C^*` be the level that maximizes the welfare of the current generation (i.e., maximizes `V(X)`).\n\n### Question\n\nBased on the model, select all of the following statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 91, "Question": "### Background\n\nThis problem analyzes a fundamental impossibility result from the paper: no proper subsolution of the No-Envy solution can simultaneously satisfy the desirable properties of Neutrality and Consistency. The proof is a cornerstone of the paper, demonstrating the centrality of the No-Envy solution concept.\n\n### Data / Model Specification\n\nConsider a solution `φ` that is a subsolution of the No-Envy solution `N`, meaning `φ(e) ⊆ N(e)` for all economies `e`. This solution must also satisfy Neutrality and Consistency.\n\n**Theorem 1:** If a subsolution of the no-envy solution (`φ ⊆ N`) satisfies Neutrality and Consistency, then it must coincide with the no-envy solution (`φ = N`).\n\nThe proof relies on **Lemma 1**, which states that for any economy `e` and any envy-free allocation `z ∈ N(e)`, one can construct an augmented economy `e' = (Q ∪ {i₀}, A ∪ {α₀}, M'; u')` and an extended allocation `z'` such that `z'` is envy-free in `e'` and essentially unique.\n\nThe utility functions in `e'` are constructed as follows, where `(α₀, M₀)` is the bundle for the new agent `i₀` in allocation `z'`:\n\n  \n\\forall i \\in Q, \\quad u'_{i}(\\alpha_{0}, M_{0}) = u_{i}(\\sigma(i), m_{\\sigma(i)}) \\quad \\text{(Eq. (1))}\n \n\n  \n\\forall \\alpha \\in A, \\quad u'_{i_0}(\\alpha_{0}, M_{0}) = u'_{i_0}(\\alpha, m_{\\alpha}) \\quad \\text{(Eq. (2))}\n \n\nIn the proof of Lemma 1, it is shown that for any other envy-free allocation `z''` in `e'`, the money vector must be identical (`m'' = m'`). A key step is proving that if one assumes `m''_{β} > m'_{β}` for some old object `β ∈ A`, a contradiction arises. Which of the following statements are valid steps in deriving this contradiction?\n", "Options": {"A": "The assumption `m''_{β} > m'_{β}` directly implies that the new agent `i₀` must be strictly better off under `z''` than under `z'`, i.e., `u'_{i₀}(z''_{i₀}) > u'_{i₀}(z'_{i₀})`.", "B": "The assumption `m''_{β} > m'_{β}` implies, via the ADG Lemma, that the new agent `i₀` must be weakly worse off under `z''` than under `z'`, i.e., `u'_{i₀}(z''_{i₀}) ≤ u'_{i₀}(z'_{i₀})`.", "C": "The fact that utility is strictly increasing in money means that `u'_{i₀}(β, m'_{β}) < u'_{i₀}(β, m''_{β})`.", "D": "The construction of `i₀`'s utility in Eq. (2) means `u'_{i₀}(z'_{i₀})` is equal to `u'_{i₀}(β, m'_{β})`."}, "Answer": ["B", "C", "D"], "pi_justification": "Assessment Target: This item assesses the student's ability to follow the detailed mathematical reasoning within the proof of Lemma 1, specifically the proof by contradiction in Claim 2. \nStrategy: Computational Judgment. The student must trace a multi-step logical derivation and identify which steps are valid. \nDistractor Logic:\n- D (Conceptual Opposite): This is the direct opposite of a correct step (A). The ADG Lemma, combined with the fact that the money for the new object `α₀` cannot increase, forces the new agent `i₀` to be weakly worse off, not better off. This is a common point of confusion in the proof. \nNote: The Single-Correct-Answer Inversion Protocol was considered but not needed. The question was framed to ask for all valid steps in the proof, which naturally yielded multiple correct options.", "qid": "91", "question": "### Background\n\nThis problem analyzes a fundamental impossibility result from the paper: no proper subsolution of the No-Envy solution can simultaneously satisfy the desirable properties of Neutrality and Consistency. The proof is a cornerstone of the paper, demonstrating the centrality of the No-Envy solution concept.\n\n### Data / Model Specification\n\nConsider a solution `φ` that is a subsolution of the No-Envy solution `N`, meaning `φ(e) ⊆ N(e)` for all economies `e`. This solution must also satisfy Neutrality and Consistency.\n\n**Theorem 1:** If a subsolution of the no-envy solution (`φ ⊆ N`) satisfies Neutrality and Consistency, then it must coincide with the no-envy solution (`φ = N`).\n\nThe proof relies on **Lemma 1**, which states that for any economy `e` and any envy-free allocation `z ∈ N(e)`, one can construct an augmented economy `e' = (Q ∪ {i₀}, A ∪ {α₀}, M'; u')` and an extended allocation `z'` such that `z'` is envy-free in `e'` and essentially unique.\n\nThe utility functions in `e'` are constructed as follows, where `(α₀, M₀)` is the bundle for the new agent `i₀` in allocation `z'`:\n\n  \n\\forall i \\in Q, \\quad u'_{i}(\\alpha_{0}, M_{0}) = u_{i}(\\sigma(i), m_{\\sigma(i)}) \\quad \\text{(Eq. (1))}\n \n\n  \n\\forall \\alpha \\in A, \\quad u'_{i_0}(\\alpha_{0}, M_{0}) = u'_{i_0}(\\alpha, m_{\\alpha}) \\quad \\text{(Eq. (2))}\n \n\nIn the proof of Lemma 1, it is shown that for any other envy-free allocation `z''` in `e'`, the money vector must be identical (`m'' = m'`). A key step is proving that if one assumes `m''_{β} > m'_{β}` for some old object `β ∈ A`, a contradiction arises. Which of the following statements are valid steps in deriving this contradiction?\n", "model_evaluation_result": {"model_raw_response": "\"C,D\"", "model_answer": ["C", "D"], "error": null}}
{"ID": 86, "Question": "### Background\n\n**Research Question.** This problem examines the foundational asymptotic theory that underpins the statistical tests for comparing Absolute Concentration Curves (ACCs) and the practical use of the bootstrap for inference.\n\n**Setting / Institutional Environment.** The analysis is theoretical, establishing the large-sample properties of the difference between empirical and true ACCs. This result is crucial for justifying the use of test statistics for hypothesis testing when their limiting distributions are not known in closed form.\n\n### Data / Model Specification\n\nLet `A(t)` and `B(t)` be the true, population ACCs for assets Y and Z with respect to a portfolio X. Let `A_n(t)` and `B_n(t)` be their empirical counterparts estimated from a sample of size `n`.\n\nThe entire inference strategy of the paper relies on the weak convergence of the normalized difference process `D_n(t)`:\n\n  \nD_{n}(t) = \\sqrt{n}((A_{n}(t)-B_{n}(t))-(A(t)-B(t))) \\Rightarrow \\Gamma(t) \\quad \\text{(Eq. 1)}\n \n\nwhere `\\Rightarrow` denotes weak convergence and `\\Gamma(t)` is a mean-zero Gaussian process. This result holds under certain regularity conditions, including an i.i.d. assumption on the data.\n\nTo perform inference in practice, an observable bootstrap process `D_n^*(t)` is constructed by drawing a bootstrap sample (size `n`, with replacement) and computing its ACCs `A_n^*(t)` and `B_n^*(t)`:\n\n  \nD_{n}^{*}(t) = \\sqrt{n}((A_{n}^{*}(t)-B_{n}^{*}(t))-(A_{n}(t)-B_{n}(t))) \\quad \\text{(Eq. 2)}\n \n\nIt can be shown that `D_n^*(t)` converges weakly to the same limiting process `\\Gamma(t)`.\n\n### Question\n\nBased on the provided asymptotic theory, select all statements that are **correct** descriptions of the paper's inferential framework and its underlying assumptions.", "Options": {"A": "If the underlying data `(Y_i, Z_i, X_i)` were not i.i.d. but instead clustered, the standard bootstrap procedure described would be invalid because it would fail to preserve the within-cluster correlation, leading to incorrect critical values.", "B": "The primary purpose of the weak convergence result is to establish a closed-form formula for the finite-sample distribution of the test statistics.", "C": "Under the null hypothesis `H_01: A=B`, the weak convergence of `D_n(t)` to `\\Gamma(t)` implies, by the Continuous Mapping Theorem, that the test statistic `\\sqrt{n}\\|A_n - B_n\\|_\\infty` converges in distribution to `\\|\\Gamma\\|_\\infty`.", "D": "The bootstrap process `D_n^*(t)` is used because it is a consistent estimator of the true, unobserved process `D_n(t)` for any given sample."}, "Answer": ["A", "C"], "pi_justification": "Assessment Target: This item assesses the student's understanding of the core inferential logic of the paper, from asymptotic theory to bootstrap application and assumption validity.\n\nStrategy: It uses an **Atomic Decomposition** strategy to break down the complex reasoning from the original QA into testable propositions. Option A tests the fundamental application of the Continuous Mapping Theorem. Option B tests the critical understanding of the i.i.d. assumption underlying the bootstrap.\n\nDistractor Logic: The distractors are designed to catch common misconceptions. Option C (Almost Right) confuses convergence to the same limit with convergence to each other, a subtle but critical distinction in bootstrap theory (`D_n^*` does not converge to `D_n`; they both converge to `\\Gamma`). Option D (Conceptual Opposite) misrepresents the entire purpose of asymptotic theory in this context; it is used precisely because finite-sample distributions are unknown and intractable.", "qid": "86", "question": "### Background\n\n**Research Question.** This problem examines the foundational asymptotic theory that underpins the statistical tests for comparing Absolute Concentration Curves (ACCs) and the practical use of the bootstrap for inference.\n\n**Setting / Institutional Environment.** The analysis is theoretical, establishing the large-sample properties of the difference between empirical and true ACCs. This result is crucial for justifying the use of test statistics for hypothesis testing when their limiting distributions are not known in closed form.\n\n### Data / Model Specification\n\nLet `A(t)` and `B(t)` be the true, population ACCs for assets Y and Z with respect to a portfolio X. Let `A_n(t)` and `B_n(t)` be their empirical counterparts estimated from a sample of size `n`.\n\nThe entire inference strategy of the paper relies on the weak convergence of the normalized difference process `D_n(t)`:\n\n  \nD_{n}(t) = \\sqrt{n}((A_{n}(t)-B_{n}(t))-(A(t)-B(t))) \\Rightarrow \\Gamma(t) \\quad \\text{(Eq. 1)}\n \n\nwhere `\\Rightarrow` denotes weak convergence and `\\Gamma(t)` is a mean-zero Gaussian process. This result holds under certain regularity conditions, including an i.i.d. assumption on the data.\n\nTo perform inference in practice, an observable bootstrap process `D_n^*(t)` is constructed by drawing a bootstrap sample (size `n`, with replacement) and computing its ACCs `A_n^*(t)` and `B_n^*(t)`:\n\n  \nD_{n}^{*}(t) = \\sqrt{n}((A_{n}^{*}(t)-B_{n}^{*}(t))-(A_{n}(t)-B_{n}(t))) \\quad \\text{(Eq. 2)}\n \n\nIt can be shown that `D_n^*(t)` converges weakly to the same limiting process `\\Gamma(t)`.\n\n### Question\n\nBased on the provided asymptotic theory, select all statements that are **correct** descriptions of the paper's inferential framework and its underlying assumptions.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 90, "Question": "### Background\n\nThis problem analyzes a fundamental impossibility result from the paper: no proper subsolution of the No-Envy solution can simultaneously satisfy the desirable properties of Neutrality and Consistency. The proof is a cornerstone of the paper, demonstrating the centrality of the No-Envy solution concept.\n\n### Data / Model Specification\n\nConsider a solution `φ` that is a subsolution of the No-Envy solution `N`, meaning `φ(e) ⊆ N(e)` for all economies `e`. This solution must also satisfy Neutrality (indifference to utility-preserving permutations of bundles) and Consistency (an allocation's restriction to a subgroup must be optimal for that subgroup's subeconomy).\n\n**Theorem 1:** If a subsolution of the no-envy solution (`φ ⊆ N`) satisfies Neutrality and Consistency, then it must coincide with the no-envy solution (`φ = N`).\n\nThe proof relies on **Lemma 1**, which states that for any economy `e` and any envy-free allocation `z ∈ N(e)`, one can construct an augmented economy `e' = (Q ∪ {i₀}, A ∪ {α₀}, M'; u')` and an extended allocation `z'` such that `z'` is envy-free in `e'` and essentially unique (any other `z'' ∈ N(e')` is an indifferent permutation of `z'`).\n\nThe utility functions in `e'` are constructed as follows, where `(α₀, M₀)` is the bundle for the new agent `i₀` in allocation `z'`:\n\n  \n\\forall i \\in Q, \\quad u'_{i}(\\alpha_{0}, M_{0}) = u_{i}(\\sigma(i), m_{\\sigma(i)}) \\quad \\text{(Eq. (1))}\n \n\n  \n\\forall \\alpha \\in A, \\quad u'_{i_0}(\\alpha_{0}, M_{0}) = u'_{i_0}(\\alpha, m_{\\alpha}) \\quad \\text{(Eq. (2))}\n \n\nBased on the logic of the proof for Theorem 1, which of the following statements are valid steps or direct consequences of the argument?\n", "Options": {"A": "The preference construction in Eq. (1) ensures that in the augmented economy `e'`, the original agents `i ∈ Q` strictly prefer their original bundle to the new bundle `(α₀, M₀)`.", "B": "The Neutrality axiom is invoked to establish that if some `z'' ∈ φ(e')` exists, and `z''` is an indifferent permutation of `z'`, then `z'` must also be in `φ(e')`.", "C": "The proof requires showing that for any `z ∈ N(e)`, there exists a larger economy `e'` where `z'` is the *only* element in `N(e')`, with no indifferent permutations possible.", "D": "The Consistency axiom is applied to the allocation `z' ∈ φ(e')` and the subgroup `Q`, which directly implies that the original allocation `z` must be in `φ(e)`."}, "Answer": ["B", "D"], "pi_justification": "Assessment Target: This item assesses the student's understanding of the logical structure of the proof of Theorem 1, specifically how the axioms of Neutrality and Consistency are deployed in sequence. \nStrategy: Reverse-Reasoning. The student is given the theorem and must identify the correct logical steps used to prove it. \nDistractor Logic:\n- C (Conceptual Opposite): This distractor incorrectly states that agents have a strict preference. The construction in Eq. (1) makes them exactly *indifferent*, which is a crucial detail for the proof's mechanics.\n- D (Almost Right): This distractor overstates the uniqueness condition from Lemma 1. The lemma only guarantees uniqueness *up to indifferent permutations*, not absolute uniqueness. This is a subtle but important distinction, as the Neutrality axiom would be irrelevant otherwise.", "qid": "90", "question": "### Background\n\nThis problem analyzes a fundamental impossibility result from the paper: no proper subsolution of the No-Envy solution can simultaneously satisfy the desirable properties of Neutrality and Consistency. The proof is a cornerstone of the paper, demonstrating the centrality of the No-Envy solution concept.\n\n### Data / Model Specification\n\nConsider a solution `φ` that is a subsolution of the No-Envy solution `N`, meaning `φ(e) ⊆ N(e)` for all economies `e`. This solution must also satisfy Neutrality (indifference to utility-preserving permutations of bundles) and Consistency (an allocation's restriction to a subgroup must be optimal for that subgroup's subeconomy).\n\n**Theorem 1:** If a subsolution of the no-envy solution (`φ ⊆ N`) satisfies Neutrality and Consistency, then it must coincide with the no-envy solution (`φ = N`).\n\nThe proof relies on **Lemma 1**, which states that for any economy `e` and any envy-free allocation `z ∈ N(e)`, one can construct an augmented economy `e' = (Q ∪ {i₀}, A ∪ {α₀}, M'; u')` and an extended allocation `z'` such that `z'` is envy-free in `e'` and essentially unique (any other `z'' ∈ N(e')` is an indifferent permutation of `z'`).\n\nThe utility functions in `e'` are constructed as follows, where `(α₀, M₀)` is the bundle for the new agent `i₀` in allocation `z'`:\n\n  \n\\forall i \\in Q, \\quad u'_{i}(\\alpha_{0}, M_{0}) = u_{i}(\\sigma(i), m_{\\sigma(i)}) \\quad \\text{(Eq. (1))}\n \n\n  \n\\forall \\alpha \\in A, \\quad u'_{i_0}(\\alpha_{0}, M_{0}) = u'_{i_0}(\\alpha, m_{\\alpha}) \\quad \\text{(Eq. (2))}\n \n\nBased on the logic of the proof for Theorem 1, which of the following statements are valid steps or direct consequences of the argument?\n", "model_evaluation_result": {"model_raw_response": "\"B,D\"", "model_answer": ["B", "D"], "error": null}}
{"ID": 94, "Question": "### Background\n\n**Research Question.** This question assesses understanding of the core informational assumption—strict signal affiliation—that underpins the paper's model of jump bidding as a strategic signalling game.\n\n**Setting.** A two-bidder, risk-neutral English auction. The value of the object to each bidder depends on their own private signal and their opponent's private signal. The auction is modeled as a two-stage \"metagame\": in Stage 1, bidders choose an opening bid of 0 or a fixed amount `K > 0`. In Stage 2, an open exit auction proceeds. If one bidder makes an unmatched jump bid, they become the \"aggressive\" bidder and their opponent becomes the \"weak\" bidder. Otherwise, standard symmetric bidding ensues.\n\n### Data / Model Specification\n\nThe valuation for bidder `i` is a function of their own signal `X_i` and their opponent's signal `X_j`:\n\n  \nV_i = v(X_i, X_j)\n \n\nwhere `v` is continuous and weakly increasing in both arguments. The signals `X_i` and `X_j` are drawn from a support `(0, \bar{X})` and are **strictly affiliated**. For univariate signals, this is defined by the strict Monotone Likelihood Ratio Property (MLRP). For any `x_j' > x_j` and `x_i' > x_i`, MLRP requires:\n\n  \n\\frac{g(x_{j}|x_{i})}{g(x_{j}|x_{i}^{\\prime})} > \\frac{g(x_{j}^{\\prime}|x_{i})}{g(x_{j}^{\\prime}|x_{i}^{\\prime})} \\quad \\text{(Eq. 1)}\n \n\nIn a symmetric signalling equilibrium, a bidder jumps if their signal `x` is above a certain cutoff `x*`. The expected gain from jump bidding for a bidder with signal `x` who wins is denoted `\\phi(x) = E[S^{*}(X_{j}) - P^{K}(X_{j}) | X_i=x, X_j < x]`, where `S*(x)` is the standard symmetric bid and `P^K(x)` is the price path after a jump.\n\n### Question\n\nAccording to the paper's model, which of the following statements correctly describe the role and implications of the strict signal affiliation (MLRP) assumption?", "Options": {"A": "It ensures that the expected gain from jump bidding, `\\phi(x)`, is a strictly increasing function of the bidder's own signal `x`.", "B": "It is the reason why the weak bidder's strategy `S_a(x)` must be higher than the symmetric equilibrium strategy `S*(x)`.", "C": "It guarantees that if signals were independent, the expected revenue from the jump-bidding game would be lower than from an open exit auction.", "D": "It implies that if the marginal bidder with signal `x*` is indifferent to jumping (i.e., `\\phi(x*) = 0`), all bidders with higher signals `x > x*` will strictly prefer to jump."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item tests the student's deep understanding of the paper's core informational assumption (strict affiliation) and its direct consequences for the existence and structure of the signalling equilibrium.\n\nChosen Strategy: Atomic Decomposition. The original QA problem's third part, which critiques the affiliation assumption, is broken down into independently verifiable propositions. This allows for a focused test on this crucial concept.\n\nDistractor Logic:\n- (C) Conceptual Opposite: The model explicitly requires the weak bidder's strategy `S_a(x)` to be *less than* the symmetric strategy `S*(x)` to create an incentive for the aggressive bidder.\n- (D) Conceptual Opposite / Formula Misuse: The paper explicitly states that with independent signals, the Revenue Equivalence Theorem applies, and the expected price (revenue) for the jump-bidding equilibrium would be *equivalent* to that of an open exit auction.", "qid": "94", "question": "### Background\n\n**Research Question.** This question assesses understanding of the core informational assumption—strict signal affiliation—that underpins the paper's model of jump bidding as a strategic signalling game.\n\n**Setting.** A two-bidder, risk-neutral English auction. The value of the object to each bidder depends on their own private signal and their opponent's private signal. The auction is modeled as a two-stage \"metagame\": in Stage 1, bidders choose an opening bid of 0 or a fixed amount `K > 0`. In Stage 2, an open exit auction proceeds. If one bidder makes an unmatched jump bid, they become the \"aggressive\" bidder and their opponent becomes the \"weak\" bidder. Otherwise, standard symmetric bidding ensues.\n\n### Data / Model Specification\n\nThe valuation for bidder `i` is a function of their own signal `X_i` and their opponent's signal `X_j`:\n\n  \nV_i = v(X_i, X_j)\n \n\nwhere `v` is continuous and weakly increasing in both arguments. The signals `X_i` and `X_j` are drawn from a support `(0, \bar{X})` and are **strictly affiliated**. For univariate signals, this is defined by the strict Monotone Likelihood Ratio Property (MLRP). For any `x_j' > x_j` and `x_i' > x_i`, MLRP requires:\n\n  \n\\frac{g(x_{j}|x_{i})}{g(x_{j}|x_{i}^{\\prime})} > \\frac{g(x_{j}^{\\prime}|x_{i})}{g(x_{j}^{\\prime}|x_{i}^{\\prime})} \\quad \\text{(Eq. 1)}\n \n\nIn a symmetric signalling equilibrium, a bidder jumps if their signal `x` is above a certain cutoff `x*`. The expected gain from jump bidding for a bidder with signal `x` who wins is denoted `\\phi(x) = E[S^{*}(X_{j}) - P^{K}(X_{j}) | X_i=x, X_j < x]`, where `S*(x)` is the standard symmetric bid and `P^K(x)` is the price path after a jump.\n\n### Question\n\nAccording to the paper's model, which of the following statements correctly describe the role and implications of the strict signal affiliation (MLRP) assumption?", "model_evaluation_result": {"model_raw_response": "\"A,D\"", "model_answer": ["A", "D"], "error": null}}
{"ID": 96, "Question": "### Background\n\n**Research Question.** This problem analyzes the long-run determinants of the skill premium in Chile, using a cointegration framework to test predictions from the Heckscher-Ohlin-Samuelson (HOS) model of trade.\n\n**Setting / Institutional Environment.** The study uses annual time series data for Chile from 1960-1996. After establishing that the key variables are non-stationary, a cointegrating regression is estimated to identify a stable long-run equilibrium relationship.\n\n**Variables & Parameters.**\n- `DCG-DEG`: The skill premium, defined as the difference between the log-wage regression coefficients for college graduates and elementary graduates (dependent variable).\n- `Open`: Openness to trade, measured as the volume of trade (exports + imports) as a percentage of GDP.\n- `Ptex`: A relative wholesale price index of textile products, serving as a proxy for the price of goods intensive in unskilled labor.\n- `Univer`: The proportion of the labor force with a college degree, serving as a proxy for the relative supply of skilled labor.\n\n---\n\n### Data / Model Specification\n\nThe estimated long-run cointegrating relationship is:\n\n  \n\\big(\\mathrm{DCG}-\\mathrm{DEG}\\big)_t = 1.908 + 0.0131\\big(\\mathrm{Open}\\big)_t - 0.357\\big(\\mathrm{Ptex}\\big)_t - 0.027\\big(\\mathrm{Univer}\\big)_t \n \n\n**Table 1: Cointegration Regression Results (Dependent Variable: DCG-DEG)**\n\n| Variable | Coefficient | (t-statistic) |\n| :--- | :--- | :--- |\n| Intercept | 1.908 | (8.81) |\n| Open | 0.0131 | (3.64) |\n| Ptex | -0.357 | (-2.09) |\n| Univer | -0.027 | (-2.61) |\n\n*Notes: Period 1960-1996 (N=37). The reported ADF test statistic on the residuals (-4.924) confirms that the null hypothesis of no cointegration is rejected at the 1% level.* \n\n---\n\nBased on the model and results in Table 1, which of the following statements are valid interpretations or conclusions? Select all that apply.", "Options": {"A": "The positive coefficient on `Open` suggests that, contrary to the experience of East Asian countries, greater trade integration for Chile was associated with a widening of the skill premium.", "B": "An increase in the relative supply of college-educated workers is associated with a decrease in the skill premium, consistent with standard labor supply effects.", "C": "A decrease in the relative price of textiles, which are intensive in unskilled labor, is predicted to widen the wage gap between college and elementary graduates.", "D": "The model predicts that a 10 percentage point increase in the proportion of the labor force with a college degree (`Univer`) would increase the college-elementary wage premium by approximately 27%."}, "Answer": ["A", "B", "C"], "pi_justification": "Assessment Target: This item assesses the candidate's ability to interpret the signs and implications of multiple regression coefficients from the paper's central empirical model. Depth Strategy: It requires translating statistical results into economic narratives consistent with the paper's theoretical framework (HOS model and labor supply/demand). Distractor Logic: Option D is a numerical distractor based on a sign error; the coefficient on `Univer` is -0.027, implying a decrease, not an increase, in the premium. It also misinterprets the magnitude. Options A, B, and C are all direct, correct interpretations of the coefficients for `Univer`, `Ptex`, and `Open` respectively, as discussed in the paper.", "qid": "96", "question": "### Background\n\n**Research Question.** This problem analyzes the long-run determinants of the skill premium in Chile, using a cointegration framework to test predictions from the Heckscher-Ohlin-Samuelson (HOS) model of trade.\n\n**Setting / Institutional Environment.** The study uses annual time series data for Chile from 1960-1996. After establishing that the key variables are non-stationary, a cointegrating regression is estimated to identify a stable long-run equilibrium relationship.\n\n**Variables & Parameters.**\n- `DCG-DEG`: The skill premium, defined as the difference between the log-wage regression coefficients for college graduates and elementary graduates (dependent variable).\n- `Open`: Openness to trade, measured as the volume of trade (exports + imports) as a percentage of GDP.\n- `Ptex`: A relative wholesale price index of textile products, serving as a proxy for the price of goods intensive in unskilled labor.\n- `Univer`: The proportion of the labor force with a college degree, serving as a proxy for the relative supply of skilled labor.\n\n---\n\n### Data / Model Specification\n\nThe estimated long-run cointegrating relationship is:\n\n  \n\\big(\\mathrm{DCG}-\\mathrm{DEG}\\big)_t = 1.908 + 0.0131\\big(\\mathrm{Open}\\big)_t - 0.357\\big(\\mathrm{Ptex}\\big)_t - 0.027\\big(\\mathrm{Univer}\\big)_t \n \n\n**Table 1: Cointegration Regression Results (Dependent Variable: DCG-DEG)**\n\n| Variable | Coefficient | (t-statistic) |\n| :--- | :--- | :--- |\n| Intercept | 1.908 | (8.81) |\n| Open | 0.0131 | (3.64) |\n| Ptex | -0.357 | (-2.09) |\n| Univer | -0.027 | (-2.61) |\n\n*Notes: Period 1960-1996 (N=37). The reported ADF test statistic on the residuals (-4.924) confirms that the null hypothesis of no cointegration is rejected at the 1% level.* \n\n---\n\nBased on the model and results in Table 1, which of the following statements are valid interpretations or conclusions? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 93, "Question": "### Background\n\nThis problem investigates the relationship between equity (no-envy) and efficiency (Pareto optimality) in the context of allocating indivisible objects and money.\n\n### Data / Model Specification\n\nAn allocation `z = (σ, m)` is **envy-free** if `uᵢ(zᵢ) ≥ uᵢ(zⱼ)` for all agents `i, j`. The set of such allocations is `N(e)`.\n\nAn allocation `z` is **Pareto efficient** if there is no other feasible allocation `z'` that makes at least one agent strictly better off without making any agent worse off. The set of such allocations is `P(e)`.\n\n**Proposition 1:** The no-envy solution is a subsolution of the Pareto solution (`N(e) ⊆ P(e)`).\n\nThe proof proceeds by contradiction. It assumes an allocation `z = (σ, m)` is envy-free (`z ∈ N(e)`) but is Pareto dominated by another feasible allocation `z' = (σ', m')`. Which of the following statements are valid steps in the derivation of the contradiction that proves Proposition 1?\n", "Options": {"A": "The proof requires that the object assignment must be the same in both allocations, i.e., `σ' = σ`.", "B": "The inequality `u_{jᵢ}(z'_{jᵢ}) ≥ u_{jᵢ}(zᵢ)` simplifies to `u_{jᵢ}(σ(i), m'_{σ(i)}) ≥ u_{jᵢ}(σ(i), m_{σ(i)})`, which implies `m'_{σ(i)} ≥ m_{σ(i)}` for all objects `σ(i)`.", "C": "For any agent `i`, let `jᵢ` be the agent who receives object `σ(i)` under the new assignment `σ'`. The chain of inequalities `u_{jᵢ}(z'_{jᵢ}) ≥ u_{jᵢ}(z_{jᵢ}) ≥ u_{jᵢ}(zᵢ)` must hold.", "D": "Since `z'` strictly dominates `z`, there must be at least one object `α` for which the monetary transfer is strictly greater, `m'_{α} > m_{α}`."}, "Answer": ["B", "C", "D"], "pi_justification": "Assessment Target: This item assesses the student's understanding of the proof of Proposition 1, which demonstrates that no-envy implies Pareto efficiency in this model. \nStrategy: Reverse-Reasoning. The student must identify the correct logical and mathematical steps within the provided proof structure. \nDistractor Logic:\n- D (Conceptual Opposite): This is a fatal flaw in reasoning. If `σ' = σ`, then for `z'` to Pareto dominate `z`, the money vector `m'` must Pareto dominate `m`. This would mean `Σm' > Σm`, which is a much simpler (but incorrect) proof that doesn't account for object reallocation. The proof's core logic handles the complex case where `σ' ≠ σ`.", "qid": "93", "question": "### Background\n\nThis problem investigates the relationship between equity (no-envy) and efficiency (Pareto optimality) in the context of allocating indivisible objects and money.\n\n### Data / Model Specification\n\nAn allocation `z = (σ, m)` is **envy-free** if `uᵢ(zᵢ) ≥ uᵢ(zⱼ)` for all agents `i, j`. The set of such allocations is `N(e)`.\n\nAn allocation `z` is **Pareto efficient** if there is no other feasible allocation `z'` that makes at least one agent strictly better off without making any agent worse off. The set of such allocations is `P(e)`.\n\n**Proposition 1:** The no-envy solution is a subsolution of the Pareto solution (`N(e) ⊆ P(e)`).\n\nThe proof proceeds by contradiction. It assumes an allocation `z = (σ, m)` is envy-free (`z ∈ N(e)`) but is Pareto dominated by another feasible allocation `z' = (σ', m')`. Which of the following statements are valid steps in the derivation of the contradiction that proves Proposition 1?\n", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 97, "Question": "### Background\n\n**Research Question.** This problem investigates the evolution of the skill premium in Chile by examining how the relative wages between different educational groups changed over a period of major economic reforms.\n\n**Setting / Institutional Environment.** The analysis uses survey data on average labor income for heads of households in Chile, categorized by education level, for selected years between 1960 and 1996.\n\n---\n\n### Data / Model Specification\n\n**Table 1: Average Labor Income Ratios by Education Level of Head of Household**\n\n| | 1960 | 1970 | 1980 | 1990 | 1996 |\n| :--- | :--- | :--- | :--- | :--- | :--- |\n| **University/secondary education** | | | | | |\n| **Total** | **2.2** | **2.3** | **2.4** | **3.6** | **3.3** |\n| **Secondary/primary education** | | | | | |\n| **Total** | **2.3** | **2.2** | **2.4** | **2.0** | **1.7** |\n\n---\n\nBased on the data in Table 1, which of the following statements accurately describe the trends in educational wage premiums in Chile? Select all that apply.", "Options": {"A": "In 1980, the wage premium for a university education over a secondary education was identical to the premium for a secondary education over a primary education.", "B": "The largest single-period increase in the university/secondary wage premium occurred between 1990 and 1996.", "C": "The wage premium for having a university education relative to a secondary education was higher in 1996 than it was in 1960.", "D": "The wage premium for having a secondary education relative to a primary education declined between 1960 and 1996."}, "Answer": ["A", "C", "D"], "pi_justification": "Assessment Target: This item tests the ability to accurately read and interpret trend data from a table, comparing values across time and between different series. Depth Strategy: It requires careful, comparative analysis of multiple data points to identify both long-term trends and specific period-to-period changes. Distractor Logic: Option D is an 'Almost Right' distractor. The largest increase occurred between 1980 and 1990 (2.4 to 3.6), not 1990-1996, which saw a decrease. Option A is correct, as the ratio fell from 2.3 to 1.7. Option B is correct, as the ratio rose from 2.2 to 3.3. Option C is correct, as both ratios were 2.4 in 1980.", "qid": "97", "question": "### Background\n\n**Research Question.** This problem investigates the evolution of the skill premium in Chile by examining how the relative wages between different educational groups changed over a period of major economic reforms.\n\n**Setting / Institutional Environment.** The analysis uses survey data on average labor income for heads of households in Chile, categorized by education level, for selected years between 1960 and 1996.\n\n---\n\n### Data / Model Specification\n\n**Table 1: Average Labor Income Ratios by Education Level of Head of Household**\n\n| | 1960 | 1970 | 1980 | 1990 | 1996 |\n| :--- | :--- | :--- | :--- | :--- | :--- |\n| **University/secondary education** | | | | | |\n| **Total** | **2.2** | **2.3** | **2.4** | **3.6** | **3.3** |\n| **Secondary/primary education** | | | | | |\n| **Total** | **2.3** | **2.2** | **2.4** | **2.0** | **1.7** |\n\n---\n\nBased on the data in Table 1, which of the following statements accurately describe the trends in educational wage premiums in Chile? Select all that apply.", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 92, "Question": "### Background\n\nThis problem investigates the axiomatic power of combining two individually weak consistency properties—Bilateral Consistency and Converse Consistency—to characterize the No-Envy solution `N`.\n\n### Data / Model Specification\n\nConsider a solution `φ` that is a subsolution of `N` (`φ ⊆ N`) and satisfies Neutrality.\n\n**Axioms:**\n- **Bilateral Consistency:** A 'top-down' property. For any `z ∈ φ(e)`, its restriction to any 2-agent subgroup `Q'` must be in the solution for that subeconomy: `z_{Q'} ∈ φ(t_{Q'}^z(e))`. \n- **Converse Consistency:** A 'bottom-up' property. For any feasible allocation `z`, if its restriction to *every* 2-agent subgroup `Q'` is in the solution for that subeconomy (`z_{Q'} ∈ φ(t_{Q'}^z(e))`), then the original allocation must be in the solution: `z ∈ φ(e)`.\n\n**Theorem 2:** If `φ ⊆ N` satisfies Neutrality, Bilateral Consistency, and Converse Consistency, then `φ = N`.\n\nThe proof proceeds by contradiction. It assumes there exists an economy `e` and an allocation `z` such that `z ∈ N(e)` but `z ∉ φ(e)`. Based on this assumption and the provided axioms, which of the following statements are logically necessary consequences?\n", "Options": {"A": "Because `z ∉ φ(e)`, the Bilateral Consistency axiom implies that there must exist at least one 2-agent subgroup `Q'` such that `z_{Q'} ∉ φ(t_{Q'}^z(e))`.", "B": "Because `φ` satisfies Bilateral Consistency, it must be true that for any 2-agent economy `e₂`, `φ(e₂) = N(e₂)`.", "C": "Because `z ∈ N(e)` and the No-Envy solution `N` satisfies Bilateral Consistency, it must be true that `z_{Q'} ∈ N(t_{Q'}^z(e))` for any 2-agent subgroup `Q'`.", "D": "Because `z ∉ φ(e)`, the Converse Consistency axiom implies that there must exist at least one 2-agent subgroup `Q'` such that `z_{Q'} ∉ φ(t_{Q'}^z(e))`."}, "Answer": ["B", "C", "D"], "pi_justification": "Assessment Target: This item assesses the student's ability to deconstruct the proof of Theorem 2 and understand the distinct roles played by each axiom. \nStrategy: Reverse-Reasoning. Given the setup for a proof by contradiction, the student must identify the correct logical deductions that follow from the premise. \nDistractor Logic:\n- D (Formula Misuse / Conceptual Distractor): This distractor incorrectly attributes the implication to the wrong axiom. The implication that a pairwise test must fail comes from negating the premise of *Converse* Consistency, not from applying Bilateral Consistency. Bilateral Consistency is a 'top-down' axiom that starts from an allocation *inside* `φ(e)`, which is not the case here.", "qid": "92", "question": "### Background\n\nThis problem investigates the axiomatic power of combining two individually weak consistency properties—Bilateral Consistency and Converse Consistency—to characterize the No-Envy solution `N`.\n\n### Data / Model Specification\n\nConsider a solution `φ` that is a subsolution of `N` (`φ ⊆ N`) and satisfies Neutrality.\n\n**Axioms:**\n- **Bilateral Consistency:** A 'top-down' property. For any `z ∈ φ(e)`, its restriction to any 2-agent subgroup `Q'` must be in the solution for that subeconomy: `z_{Q'} ∈ φ(t_{Q'}^z(e))`. \n- **Converse Consistency:** A 'bottom-up' property. For any feasible allocation `z`, if its restriction to *every* 2-agent subgroup `Q'` is in the solution for that subeconomy (`z_{Q'} ∈ φ(t_{Q'}^z(e))`), then the original allocation must be in the solution: `z ∈ φ(e)`.\n\n**Theorem 2:** If `φ ⊆ N` satisfies Neutrality, Bilateral Consistency, and Converse Consistency, then `φ = N`.\n\nThe proof proceeds by contradiction. It assumes there exists an economy `e` and an allocation `z` such that `z ∈ N(e)` but `z ∉ φ(e)`. Based on this assumption and the provided axioms, which of the following statements are logically necessary consequences?\n", "model_evaluation_result": {"model_raw_response": "\"A,C,D\"", "model_answer": ["A", "C", "D"], "error": null}}
{"ID": 105, "Question": "### Background\n\n**Research Question.** This problem explores how real-world complexities might affect the optimality of offering a menu of unemployment insurance (UI) contracts.\n\n**Setting.** The baseline model assumes workers know their type (e.g., their job-finding probability `f`) and that their choice of UI contract does not affect their employment prospects. The paper considers several extensions to this baseline.\n\n---\n\n### Scenario\n\nConsider a scenario where a planner has implemented an optimal separating menu of UI contracts based on the baseline model: Contract H (high insurance `b`, low lump-sum `a`) for low-efficiency workers and Contract L (low `b`, high `a`) for high-efficiency workers. Now, two real-world complications arise simultaneously:\n\n1.  **Signalling:** Employers can observe which UI contract a worker chose. They interpret a choice of Contract H as a signal of low job-finding ability, which negatively impacts their wage offers during bargaining.\n2.  **Recession:** A macroeconomic shock lowers the job offer arrival rate `f` for all workers, increasing the expected duration of unemployment for everyone.\n\n---\n\n### Question\n\nGiven these two new complications, which of the following outcomes are plausible consequences for the self-selection of workers into the pre-existing menu of contracts? (Select all that apply.)", "Options": {"A": "The recession increases the expected duration of unemployment for high-efficiency workers, raising their valuation of insurance (`MRS`) and making Contract H relatively more attractive to them.", "B": "The two effects work in opposite directions on the choices of high-efficiency workers: the recession pushes them toward Contract H, while the signalling effect pushes them toward Contract L.", "C": "The signalling effect makes it easier for the planner to separate types, as workers will be more inclined to choose the contract that accurately reflects their type.", "D": "The signalling effect creates an additional incentive for low-efficiency workers to deviate and choose Contract L, in order to appear as high-efficiency workers to potential employers."}, "Answer": ["A", "B", "D"], "pi_justification": "Assessment Target: This item assesses the ability to synthesize multiple theoretical extensions from the paper and apply them to a novel, complex scenario. It requires understanding the distinct mechanisms of signalling and macroeconomic shocks on worker incentives. Depth Strategy: Scenario Application. Distractor Logic: Option C is a conceptual opposite. The paper explicitly states that signalling `restricts the capacity of the planner to separate types` because it gives low-reservation-wage individuals an incentive to mimic high-reservation-wage individuals. This distractor targets users who misunderstand the strategic implications of signalling in this context.", "qid": "105", "question": "### Background\n\n**Research Question.** This problem explores how real-world complexities might affect the optimality of offering a menu of unemployment insurance (UI) contracts.\n\n**Setting.** The baseline model assumes workers know their type (e.g., their job-finding probability `f`) and that their choice of UI contract does not affect their employment prospects. The paper considers several extensions to this baseline.\n\n---\n\n### Scenario\n\nConsider a scenario where a planner has implemented an optimal separating menu of UI contracts based on the baseline model: Contract H (high insurance `b`, low lump-sum `a`) for low-efficiency workers and Contract L (low `b`, high `a`) for high-efficiency workers. Now, two real-world complications arise simultaneously:\n\n1.  **Signalling:** Employers can observe which UI contract a worker chose. They interpret a choice of Contract H as a signal of low job-finding ability, which negatively impacts their wage offers during bargaining.\n2.  **Recession:** A macroeconomic shock lowers the job offer arrival rate `f` for all workers, increasing the expected duration of unemployment for everyone.\n\n---\n\n### Question\n\nGiven these two new complications, which of the following outcomes are plausible consequences for the self-selection of workers into the pre-existing menu of contracts? (Select all that apply.)", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 95, "Question": "### Background\n\n**Research Question.** This question analyzes the strategic incentives and revenue implications of jump bidding using the paper's core motivating example. It compares outcomes from standard auction formats to a hybrid auction involving a potential jump bid.\n\n**Setting.** A two-bidder (Xenia and Yakov) auction for a single good with a common value component. Bidders receive affiliated private signals. We compare outcomes from standard auction formats to a hybrid auction involving a potential jump bid.\n\n### Data / Model Specification\n\nTwo bidders, Xenia and Yakov, receive private signals `X = A + B` and `Y = B + C`, where `A`, `B`, and `C` are independent U(0, 1) random variables. The true common value of the good is `V = (X + Y) / 2`.\n\nThe benchmark symmetric equilibrium bidding functions for standard auctions are:\n- Second-Price / Open Exit Auction: `B^{*}(x) = x`\n- First-Price Auction: `B^{*1}(x) = 2x/3`\n\nConsider a **hybrid auction game**:\n1.  In Stage 1, bidders simultaneously choose to bid 0 or a jump bid of `K = 2/3`.\n2.  If only one bidder jumps, the auction ends, and they win at price `K`.\n3.  If both or neither jump, the auction proceeds as a standard open exit auction (bidders use `B*(x) = x`).\n\nThe symmetric equilibrium for this game involves a cutoff `x* = 1`, where a bidder jumps to `K` if and only if their signal is 1 or greater. The paper shows that for `x* \\leq 1`, the cutoff is determined by the relation `K = 2x*/3`.\n\nThe expected revenues for the three mechanisms are:\n- `ER_2 = 30/36` (Second-Price)\n- `ER_1 = 28/36` (First-Price)\n- `ER_hybrid = 29/36` (Hybrid Jump-Bidding)\n\n### Question\n\nBased on the provided motivating example and its underlying model, which of the following statements are correct?", "Options": {"A": "The expected revenue in the standard second-price auction, `E[min(X,Y)]`, correctly calculates to 30/36 based on the signal structure `E[B] + E[min(A,C)]`.", "B": "If Xenia has a signal `X = 1.2` and Yakov has a signal `Y = 0.9`, the auction ends with Xenia winning at a final price of `0.9`.", "C": "The hybrid game's lower revenue relative to the second-price auction is primarily because jump bidding is an inefficient allocation mechanism, sometimes awarding the object to the bidder with the lower signal.", "D": "Lowering the jump bid `K` from 2/3 to 1/3 would cause the jump-bidding cutoff `x*` to decrease from 1 to 1/2, thereby increasing the frequency of the auction ending via a single jump bid."}, "Answer": ["A", "D"], "pi_justification": "Assessment Target: This item tests the ability to connect the abstract model to a concrete numerical example, requiring calculation, interpretation, and a comparative static analysis of the mechanism's parameters.\n\nChosen Strategy: Computational Judgment / Scenario Micro-variants. The item combines a verifiable factual derivation (Option A) with a scenario-based calculation that modifies a key parameter (`K`) to test understanding of the model's mechanics (Option B).\n\nDistractor Logic:\n- (C) Conceptual Opposite: A key result of the paper (Theorem 4.1) is that the signalling equilibrium is efficient; the allocation of the object is identical to the open exit auction. The revenue difference comes from the price paid, not from allocative inefficiency.\n- (D) Application Error / Step-Omission Error: This distractor tempts the user to incorrectly apply the second-price rule. Since Xenia's signal (1.2) is above the cutoff `x*=1` and Yakov's (0.9) is below, Xenia makes an unmatched jump bid and wins the auction at the price `K = 2/3`, not at Yakov's signal value.", "qid": "95", "question": "### Background\n\n**Research Question.** This question analyzes the strategic incentives and revenue implications of jump bidding using the paper's core motivating example. It compares outcomes from standard auction formats to a hybrid auction involving a potential jump bid.\n\n**Setting.** A two-bidder (Xenia and Yakov) auction for a single good with a common value component. Bidders receive affiliated private signals. We compare outcomes from standard auction formats to a hybrid auction involving a potential jump bid.\n\n### Data / Model Specification\n\nTwo bidders, Xenia and Yakov, receive private signals `X = A + B` and `Y = B + C`, where `A`, `B`, and `C` are independent U(0, 1) random variables. The true common value of the good is `V = (X + Y) / 2`.\n\nThe benchmark symmetric equilibrium bidding functions for standard auctions are:\n- Second-Price / Open Exit Auction: `B^{*}(x) = x`\n- First-Price Auction: `B^{*1}(x) = 2x/3`\n\nConsider a **hybrid auction game**:\n1.  In Stage 1, bidders simultaneously choose to bid 0 or a jump bid of `K = 2/3`.\n2.  If only one bidder jumps, the auction ends, and they win at price `K`.\n3.  If both or neither jump, the auction proceeds as a standard open exit auction (bidders use `B*(x) = x`).\n\nThe symmetric equilibrium for this game involves a cutoff `x* = 1`, where a bidder jumps to `K` if and only if their signal is 1 or greater. The paper shows that for `x* \\leq 1`, the cutoff is determined by the relation `K = 2x*/3`.\n\nThe expected revenues for the three mechanisms are:\n- `ER_2 = 30/36` (Second-Price)\n- `ER_1 = 28/36` (First-Price)\n- `ER_hybrid = 29/36` (Hybrid Jump-Bidding)\n\n### Question\n\nBased on the provided motivating example and its underlying model, which of the following statements are correct?", "model_evaluation_result": {"model_raw_response": "\"A,B,D\"", "model_answer": ["A", "B", "D"], "error": null}}
{"ID": 99, "Question": "### Background\n\n**Research Question.** This problem investigates the central result of the paper: under what conditions a principal in a dynamic moral hazard model with renegotiation prefers to induce an agent to randomize her action—thereby creating endogenous adverse selection—rather than implementing a high-effort action with certainty.\n\n**Setting / Institutional Environment.** A risk-neutral principal contracts with a risk-averse agent over two periods. The agent's action in period 1 is unobservable and has long-term effects on output. Crucially, the contract can be renegotiated at the start of period 2 after the period 1 output is realized. The agent's period 1 action (`a_1` for shirk, `a_2` for diligent) becomes her private information ('type') in the period 2 renegotiation subgame.\n\n### Data / Model Specification\n\nThe technology linking actions to outputs (`x_1 < x_2`) in each period is:\n\n| Action | Prob(x_1) | Prob(x_2) |\n| :--- | :--- | :--- |\n| `a_1` | 1 | 0 |\n| `a_2` | 1-`γ` | `γ` |\n\nLet `h(v)` be the principal's cost of providing `v` units of utility to the agent; `h` is strictly convex. Let `G_j` be the per-period utility cost of action `a_j`, with `G_1 < G_2`. The optimal one-period contract to induce `a_2` consists of utility payments `v_1^* = G_1` and `v_2^* = G_1 + (G_2 - G_1)/γ`.\n\nThe principal's utility from implementing `a_2` with certainty (`p=1`) via an optimal renegotiation-proof contract is `B(a_2)`. The net productivity gain from action `a_2` is parameterized by `K > 0` such that:\n  \n\\Pi(a_2) - \\Pi(a_1) = \\gamma[h(v_2^*) - h(v_1^*)] + K \\quad \\text{(Eq. (1))}\n \nwhere `Π(a_j)` is the expected revenue from action `a_j`.\n\nTo test if a mixed strategy is optimal, the paper constructs a feasible contract `C_tilde` that implements `a_2` with some probability `p_tilde < 1`:\n`C_tilde = {(v_1^*, v_2^*), M(x_1)=((v_1^*, v_1^*), (v_1^*, v_2^*)), M(x_2)=G_2}`.\nThis means period 1 payments are `(v_1^*, v_2^*)`. If `x_1` occurs, the agent can choose between a safe contract paying `v_1^*` or a risky one paying `(v_1^*, v_2^*)` in period 2. If `x_2` occurs, she gets a safe payment `G_2`.\n\nThe principal's net gain from using this mixed-strategy contract `C_tilde` over the optimal pure-strategy (`p=1`) contract is:\n  \n\\text{Gain} = B(\\tilde{p};\\tilde{C}) - B(a_2) = -2(1-\\tilde{p})\\gamma K + \\tilde{p}\\gamma [h(v_2^*) - h(G_2)] \\quad \\text{(Eq. (2))}\n \n\n### Question\n\nBased on the model and the provided contracts, select all statements that are correct.", "Options": {"A": "In the `Gain` formula (Eq. (2)), the term `h(v_2^*) - h(G_2)` is negative. This is because `G_2` represents the agent's total expected utility from the `a_2` contract, which must be greater than the utility from a single high-output outcome, `v_2^*`.", "B": "The mixed-strategy contract `C_tilde` is strictly preferred to the pure-strategy contract if the direct productivity gain from high effort, `K`, is sufficiently small.", "C": "The optimal renegotiation-proof contract that implements `a_2` with certainty (`p=1`) concentrates all incentive provision in period 1. Period 2 payments are constant (`v` after `x_1`, `w` after `x_2`) and are set equal to the corresponding period 1 payments (`v=u_1`, `w=u_2`).", "D": "Inducing randomization (`0 < p < 1`) is always optimal for any `K > 0` because spreading incentives across two periods is inherently more cost-effective for a risk-averse agent."}, "Answer": ["B", "C"], "pi_justification": "This item assesses understanding of the paper's central argument by decomposing it into two key atomic propositions. The correct options test the structure of the optimal pure-strategy contract (A) and the main welfare result on the optimality of randomization (B). Distractor (C) presents a common but incomplete intuition, ignoring the revenue trade-off. Distractor (D) targets a subtle mathematical error related to the properties of expected utility and convex cost functions, a frequent point of confusion.", "qid": "99", "question": "### Background\n\n**Research Question.** This problem investigates the central result of the paper: under what conditions a principal in a dynamic moral hazard model with renegotiation prefers to induce an agent to randomize her action—thereby creating endogenous adverse selection—rather than implementing a high-effort action with certainty.\n\n**Setting / Institutional Environment.** A risk-neutral principal contracts with a risk-averse agent over two periods. The agent's action in period 1 is unobservable and has long-term effects on output. Crucially, the contract can be renegotiated at the start of period 2 after the period 1 output is realized. The agent's period 1 action (`a_1` for shirk, `a_2` for diligent) becomes her private information ('type') in the period 2 renegotiation subgame.\n\n### Data / Model Specification\n\nThe technology linking actions to outputs (`x_1 < x_2`) in each period is:\n\n| Action | Prob(x_1) | Prob(x_2) |\n| :--- | :--- | :--- |\n| `a_1` | 1 | 0 |\n| `a_2` | 1-`γ` | `γ` |\n\nLet `h(v)` be the principal's cost of providing `v` units of utility to the agent; `h` is strictly convex. Let `G_j` be the per-period utility cost of action `a_j`, with `G_1 < G_2`. The optimal one-period contract to induce `a_2` consists of utility payments `v_1^* = G_1` and `v_2^* = G_1 + (G_2 - G_1)/γ`.\n\nThe principal's utility from implementing `a_2` with certainty (`p=1`) via an optimal renegotiation-proof contract is `B(a_2)`. The net productivity gain from action `a_2` is parameterized by `K > 0` such that:\n  \n\\Pi(a_2) - \\Pi(a_1) = \\gamma[h(v_2^*) - h(v_1^*)] + K \\quad \\text{(Eq. (1))}\n \nwhere `Π(a_j)` is the expected revenue from action `a_j`.\n\nTo test if a mixed strategy is optimal, the paper constructs a feasible contract `C_tilde` that implements `a_2` with some probability `p_tilde < 1`:\n`C_tilde = {(v_1^*, v_2^*), M(x_1)=((v_1^*, v_1^*), (v_1^*, v_2^*)), M(x_2)=G_2}`.\nThis means period 1 payments are `(v_1^*, v_2^*)`. If `x_1` occurs, the agent can choose between a safe contract paying `v_1^*` or a risky one paying `(v_1^*, v_2^*)` in period 2. If `x_2` occurs, she gets a safe payment `G_2`.\n\nThe principal's net gain from using this mixed-strategy contract `C_tilde` over the optimal pure-strategy (`p=1`) contract is:\n  \n\\text{Gain} = B(\\tilde{p};\\tilde{C}) - B(a_2) = -2(1-\\tilde{p})\\gamma K + \\tilde{p}\\gamma [h(v_2^*) - h(G_2)] \\quad \\text{(Eq. (2))}\n \n\n### Question\n\nBased on the model and the provided contracts, select all statements that are correct.", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 101, "Question": "### Background\n\n**Research Question.** This problem investigates the theoretical foundations of the Analytic Policy Function Iteration (APFI) framework, which is designed to solve a general class of linear rational expectations models with endogenous information frictions.\n\n**Setting / Institutional Environment.** The APFI method is an iterative algorithm that finds an equilibrium policy function. Its validity and computational feasibility rest on three key mathematical theorems that justify its core operational steps.\n\n---\n\n### Data / Model Specification\n\nThe APFI framework is designed to solve models cast in the canonical form:\n  \n\\sum_{k=0}^{l}A_{k}y_{t-k}+\\sum_{k=0}^{h}B_{k}\\mathbb{E}_{t}y_{t+k}=\\mathbf{0}\n \nThe **Baseline APFI Algorithm** involves three main steps in each iteration:\n1.  **Projection:** Approximate the current guess of the policy function using a finite-order VARMA process (i.e., a rational function).\n2.  **Evaluation:** Use the VARMA approximation to compute conditional expectations.\n3.  **Updating & Recursion:** Solve for an updated policy function and repeat until the function converges on a numerical grid.\n\nThis algorithm is justified by three foundational theorems from the paper:\n-   **Theorem 3.1 (Denseness of Rational Functions):** Any covariance-stationary equilibrium process, which resides in the Hardy space `H²`, can be approximated arbitrarily well by a VARMA process (a rational function).\n-   **Theorem 3.2 (Analytic Continuation & Convergence):** A solution found on the real unit interval `(-1, 1)` uniquely extends to the entire complex unit disk. Furthermore, pointwise convergence of a sequence of rational functions on this real interval implies convergence in the `H²` norm.\n-   **Theorem 3.3 (Annihilation):** The crucial \"annihilation\" step in computing expectations can be performed efficiently and accurately using the Inverse Discrete Fourier Transform (IDFT).\n\n---\n\n### The Questions\n\n**Theorem 3.2 (Analytic Continuation & Convergence)** is critical for the algorithm's validity. Which of the following are direct consequences of this theorem, as described in the paper? (Select all that apply)", "Options": {"A": "The equilibrium solution is guaranteed to be a rational function.", "B": "A valid stopping rule is to check for convergence of the policy function values on the grid, as this implies convergence in the correct `H²` norm.", "C": "The algorithm can be implemented on a simple grid of real numbers, `(-1, 1)`, instead of the full complex disk, without loss of generality.", "D": "The algorithm is guaranteed to converge to an equilibrium from any initial starting guess."}, "Answer": ["B", "C"], "pi_justification": "This item tests the two key implications of Theorem 3.2 for the algorithm's design (Conceptual Judgment). It uses a multiple-choice format to assess both the 'analytic continuation' (A) and 'convergence criterion' (B) aspects. The distractors represent common over-interpretations: a false guarantee of global convergence (C) and a conceptual error about the nature of the solution (D).", "qid": "101", "question": "### Background\n\n**Research Question.** This problem investigates the theoretical foundations of the Analytic Policy Function Iteration (APFI) framework, which is designed to solve a general class of linear rational expectations models with endogenous information frictions.\n\n**Setting / Institutional Environment.** The APFI method is an iterative algorithm that finds an equilibrium policy function. Its validity and computational feasibility rest on three key mathematical theorems that justify its core operational steps.\n\n---\n\n### Data / Model Specification\n\nThe APFI framework is designed to solve models cast in the canonical form:\n  \n\\sum_{k=0}^{l}A_{k}y_{t-k}+\\sum_{k=0}^{h}B_{k}\\mathbb{E}_{t}y_{t+k}=\\mathbf{0}\n \nThe **Baseline APFI Algorithm** involves three main steps in each iteration:\n1.  **Projection:** Approximate the current guess of the policy function using a finite-order VARMA process (i.e., a rational function).\n2.  **Evaluation:** Use the VARMA approximation to compute conditional expectations.\n3.  **Updating & Recursion:** Solve for an updated policy function and repeat until the function converges on a numerical grid.\n\nThis algorithm is justified by three foundational theorems from the paper:\n-   **Theorem 3.1 (Denseness of Rational Functions):** Any covariance-stationary equilibrium process, which resides in the Hardy space `H²`, can be approximated arbitrarily well by a VARMA process (a rational function).\n-   **Theorem 3.2 (Analytic Continuation & Convergence):** A solution found on the real unit interval `(-1, 1)` uniquely extends to the entire complex unit disk. Furthermore, pointwise convergence of a sequence of rational functions on this real interval implies convergence in the `H²` norm.\n-   **Theorem 3.3 (Annihilation):** The crucial \"annihilation\" step in computing expectations can be performed efficiently and accurately using the Inverse Discrete Fourier Transform (IDFT).\n\n---\n\n### The Questions\n\n**Theorem 3.2 (Analytic Continuation & Convergence)** is critical for the algorithm's validity. Which of the following are direct consequences of this theorem, as described in the paper? (Select all that apply)", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
{"ID": 103, "Question": "### Background\n\n**Research Question.** This problem requires the interpretation of empirical results from a regression discontinuity design to test the theoretical condition for the optimality of offering a menu of UI contracts.\n\n**Setting.** Researchers use a discontinuity in UI generosity at age 25 in Switzerland to estimate the marginal costs (sensitivity of insurance payments) and marginal benefits (sensitivity of reservation wage) of more generous UI. They estimate these effects separately for two groups of workers, classified by their caseworker as having low search efficiency (type `h`) or high search efficiency (type `l`). The planner's decision to offer a menu of contracts depends on whether the single-crossing condition is met.\n\n**Variables & Parameters.**\n- `MC_i`: Marginal cost for type `i`, estimated as the treatment effect on log insurance payments.\n- `MB_i`: Marginal benefit for type `i`, estimated as the treatment effect on log reservation wage.\n- Type `h`: Job seekers with low search efficiency.\n- Type `l`: Job seekers with high search efficiency.\n\n---\n\n### Data / Model Specification\n\nThe theoretical condition for a separating menu to be optimal is:\n  \nMC_h - MB_h < 0 < MC_l - MB_l\n \nThis implies the planner wants to offer more insurance to type `h` and less to type `l` than the current pooling contract provides. The following table presents the Regression Discontinuity (RD) estimates for `MB` and `MC` for each type.\n\n**Table 1: RD Estimates of Marginal Benefit and Marginal Cost**\n\n| | Marginal Benefit (Reservation Wage) | Marginal Cost (Insurance Payments) |\n|:---|:---:|:---:|\n| **Panel A: Type-h (Low Efficiency)** | | |\n| Treatment Effect | 0.1102 | 0.0733 |\n| **Panel B: Type-l (High Efficiency)** | | |\n| Treatment Effect | 0.0715 | 0.1809 |\n\n---\n\n### Question\n\nBased on the point estimates in Table 1, which of the following statements are valid conclusions within the paper's framework? (Select all that apply.)", "Options": {"A": "The net marginal cost for type-`l` (high efficiency) workers is positive, suggesting the planner should offer them a contract with less generous insurance than the current one.", "B": "The net marginal cost for type-`h` (low efficiency) workers is negative, suggesting the planner should offer them a contract with more generous insurance than the current one.", "C": "The single-crossing condition is met, supporting the policy recommendation to offer a menu of separating contracts rather than a single pooling contract.", "D": "The moral hazard cost, as measured by the response of total insurance payments (`MC`), is greater for low-efficiency workers than for high-efficiency workers."}, "Answer": ["A", "B", "C"], "pi_justification": "Assessment Target: This item assesses the ability to perform a multi-step computational judgment. The user must first calculate the net marginal cost (`MC - MB`) for each worker type using the provided table, then interpret the sign of these results in the context of the paper's theoretical condition, and finally draw a policy conclusion. Depth Strategy: Computational Judgment. Distractor Logic: Option C is a conceptual distractor that misinterprets the table. A quick glance might suggest `MB_h > MB_l`, but the key moral hazard indicator is `MC`, where `MC_l (0.1809) > MC_h (0.0733)`. This distractor targets users who fail to correctly identify the variable representing moral hazard cost.", "qid": "103", "question": "### Background\n\n**Research Question.** This problem requires the interpretation of empirical results from a regression discontinuity design to test the theoretical condition for the optimality of offering a menu of UI contracts.\n\n**Setting.** Researchers use a discontinuity in UI generosity at age 25 in Switzerland to estimate the marginal costs (sensitivity of insurance payments) and marginal benefits (sensitivity of reservation wage) of more generous UI. They estimate these effects separately for two groups of workers, classified by their caseworker as having low search efficiency (type `h`) or high search efficiency (type `l`). The planner's decision to offer a menu of contracts depends on whether the single-crossing condition is met.\n\n**Variables & Parameters.**\n- `MC_i`: Marginal cost for type `i`, estimated as the treatment effect on log insurance payments.\n- `MB_i`: Marginal benefit for type `i`, estimated as the treatment effect on log reservation wage.\n- Type `h`: Job seekers with low search efficiency.\n- Type `l`: Job seekers with high search efficiency.\n\n---\n\n### Data / Model Specification\n\nThe theoretical condition for a separating menu to be optimal is:\n  \nMC_h - MB_h < 0 < MC_l - MB_l\n \nThis implies the planner wants to offer more insurance to type `h` and less to type `l` than the current pooling contract provides. The following table presents the Regression Discontinuity (RD) estimates for `MB` and `MC` for each type.\n\n**Table 1: RD Estimates of Marginal Benefit and Marginal Cost**\n\n| | Marginal Benefit (Reservation Wage) | Marginal Cost (Insurance Payments) |\n|:---|:---:|:---:|\n| **Panel A: Type-h (Low Efficiency)** | | |\n| Treatment Effect | 0.1102 | 0.0733 |\n| **Panel B: Type-l (High Efficiency)** | | |\n| Treatment Effect | 0.0715 | 0.1809 |\n\n---\n\n### Question\n\nBased on the point estimates in Table 1, which of the following statements are valid conclusions within the paper's framework? (Select all that apply.)", "model_evaluation_result": {"model_raw_response": "\"A,B,C\"", "model_answer": ["A", "B", "C"], "error": null}}
{"ID": 108, "Question": "### Background\n\nTo identify the effect of age on risk attitudes, the paper's main strategy is to use annual GDP growth as a proxy for period effects, allowing for simultaneous estimation of age and cohort effects. As a robustness check, the authors also consider an alternative approach: an individual fixed-effects (FE) model, which leverages the panel nature of the data differently.\n\n---\n\n### Question\n\nWhen comparing the paper's main GDP-proxy model to an alternative individual fixed-effects (FE) model for estimating the effect of age on risk attitudes, which of the following statements are correct?", "Options": {"A": "The FE model primarily identifies the age effect by comparing different individuals at the same point in time, while the GDP-proxy model uses within-person changes over time.", "B": "The FE model's primary advantage is its robustness to any time-invariant individual heterogeneity (e.g., stable personality traits or genetic predispositions) that might be correlated with risk attitudes.", "C": "A key limitation of the FE model is that it cannot estimate the cohort effect, as this effect is time-invariant for each individual and is absorbed by the fixed effect.", "D": "The GDP-proxy model is considered more robust than the FE model because it avoids strong statistical assumptions by using real-world economic data as a control."}, "Answer": ["B", "C"], "pi_justification": "Assessment Target: This item tests the ability to compare and contrast two advanced econometric strategies (proxy variables vs. fixed effects) in the context of the paper's research question. Strategy: Atomic decomposition. The question breaks down the comparison into distinct claims about the advantages, limitations, and underlying logic of each method. Distractor Logic: (C) directly reverses the identification logic of FE (which relies on within-person changes) and pooled OLS/proxy models (which also use between-person variation). (D) creates a false trade-off; using 'real data' as a proxy does not eliminate the need for strong assumptions, but rather introduces a different, and arguably very strong, identifying assumption about unobserved trends.", "qid": "108", "question": "### Background\n\nTo identify the effect of age on risk attitudes, the paper's main strategy is to use annual GDP growth as a proxy for period effects, allowing for simultaneous estimation of age and cohort effects. As a robustness check, the authors also consider an alternative approach: an individual fixed-effects (FE) model, which leverages the panel nature of the data differently.\n\n---\n\n### Question\n\nWhen comparing the paper's main GDP-proxy model to an alternative individual fixed-effects (FE) model for estimating the effect of age on risk attitudes, which of the following statements are correct?", "model_evaluation_result": {"model_raw_response": "\"B,C\"", "model_answer": ["B", "C"], "error": null}}
