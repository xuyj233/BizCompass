[
  {
    "ID": 1,
    "text": "## Framework Overview\n\nThe Combinatorial Purged Cross-Validation (CPCV) method is an advanced backtesting technique designed to address the primary drawback of traditional Walk-Forward (WF) and Cross-Validation (CV) methods: they only test a single performance path. By generating multiple backtest paths from a single dataset, CPCV provides a distribution of performance outcomes, allowing for a more robust assessment of a strategy's viability and reducing the risk of backtest overfitting.\n\n## Key Concepts\n\n- **[Definition] Combinatorial Purged Cross-Validation (CPCV)**: A backtesting method that generates a specified number of alternative performance paths by creating all possible combinations of training and testing sets from a partitioned dataset. It incorporates purging to prevent information leakage between sets.\n- **[Definition] Combinatorial Splits**: The process of partitioning a dataset of `T` observations into `N` contiguous groups and then forming all possible combinations where `N-k` groups are used for training and `k` groups are used for testing.\n- **[Definition] Purging**: A procedure to remove observations from the training set whose labels are determined by information that overlaps with the testing set's time period. This is critical for preventing look-ahead bias and information leakage, especially when the training set does not strictly predate the testing set.\n\n## Computational Steps\n\nThe CPCV algorithm is executed through a sequence of five steps:\n\n1.  **Partition Data**: Divide the total `T` observations into `N` contiguous groups without shuffling. The first `N-1` groups are of size `floor(T/N)`, and the final group contains the remainder.\n2.  **Generate Splits**: Compute all possible training/testing splits. For a testing set size of `k` groups, the number of unique splits is given by the combination formula:\n    $$ \\binom{N}{N-k}=\\frac{\\prod_{i=0}^{k-1}(N-i)}{k!} \\quad (Equation 1) $$ \n3.  **Purge Training Sets**: For each generated split, apply a purging mechanism. If a label in the training set is derived from a time period that overlaps with any label in the testing set, that training observation must be removed.\n4.  **Fit and Forecast**: Train a model on each of the purged training sets and generate forecasts for their corresponding testing sets.\n5.  **Construct Backtest Paths**: Aggregate the forecasts from the various splits to construct a total of `phi` distinct backtest paths. The number of paths, `phi`, that can be generated is determined by `N` and `k`:\n    $$ \\phi[N,k] = \\frac{k}{N}\\binom{N}{N - k} = \\frac{\\prod_{i = 1}^{k - 1}(N - i)}{(k - 1)!} \\quad (Equation 2) $$ \n    From these paths, you can derive an empirical distribution of a performance metric like the Sharpe ratio, offering a much richer analysis than a single-point estimate.",
    "question": "Provide the pseudocode for a function that implements the core logic of the Combinatorial Purged Cross-Validation (CPCV) algorithm, focusing on generating the training/testing splits and calculating the number of resulting backtest paths.",
    "answer": "```\n// --- BEGIN PSEUODCODE ---\n//\n// FUNCTION Generate_CPCV_Splits(T, N, k)\n// INPUTS:\n//   - T: Total number of observations in the dataset.\n//   - N: The number of groups to partition the data into.\n//   - k: The number of groups to be used for the testing set in each split.\n// OUTPUTS:\n//   - A structure containing:\n//     - all_splits: A list of tuples, where each tuple contains (train_indices, test_indices).\n//     - phi: The total number of backtest paths that can be generated.\n//\n// BEGIN\n//   // Step 1: Partition Data (Implicitly by creating group indices)\n//   CREATE an array 'group_indices' of length N.\n//   FOR i from 0 to N-1:\n//     group_indices[i] = i\n//   ENDFOR\n//\n//   // Step 2: Generate all training/testing splits\n//   // A training set is a combination of N-k groups.\n//   // The test set is the complement.\n//   CREATE an empty list 'all_splits'.\n//   training_group_combinations = Combinations(group_indices, N-k)\n//\n//   FOR each 'train_group_combo' in training_group_combinations:\n//     // Identify test groups as the complement of training groups\n//     test_group_combo = group_indices EXCLUDING train_group_combo\n//\n//     // NOTE: This pseudocode assumes indices are group numbers.\n//     // A full implementation would map these group numbers back to the actual\n//     // observation indices from the original T observations.\n//     // For simplicity, we store the group numbers.\n//     APPEND (train_group_combo, test_group_combo) to 'all_splits'.\n//   ENDFOR\n//\n//   // Step 5: Calculate the number of backtest paths (phi)\n//   // Using Equation 2 from the text.\n//   IF k = 1 THEN\n//     phi = 1\n//   ELSE\n//     numerator = 1\n//     FOR i from 1 to k-1:\n//       numerator = numerator * (N - i)\n//     ENDFOR\n//\n//     denominator = Factorial(k - 1)\n//     phi = numerator / denominator\n//   ENDIF\n//\n//   CREATE a result structure containing 'all_splits' and 'phi'.\n//   RETURN result.\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 2,
    "text": "## Framework Overview\n\nCalibrating trading rules using historical simulations often leads to backtest overfitting, where parameters are tuned to specific past events and fail out-of-sample. An alternative approach is to characterize the underlying stochastic process of returns and then numerically derive the optimal trading rule parameters (profit-taking and stop-loss levels) through simulation. This avoids fitting to a single historical path and instead optimizes for the statistical properties of the process itself.\n\n## Key Concepts\n\n- **[Definition] Trading Rule**: A set of parameters, `R = {stop_loss, profit_take}`, that define the exit conditions for a position based on its mark-to-market profit or loss.\n- **[Definition] Backtest Overfitting**: A situation where a trading rule or strategy performs exceptionally well on in-sample historical data but is expected to underperform out-of-sample because it has been fitted to random noise rather than a persistent market inefficiency.\n- **[Definition] Ornstein-Uhlenbeck (O-U) Process**: A stochastic process that describes the velocity of a particle under friction. In finance, it is used to model mean-reverting price series. A discrete form is given by:\n    $$ P_{t} = (1 - \\phi)E[P] + \\phi P_{t - 1} + \\sigma \\epsilon_{t} \\quad (Equation 1) $$ \n    Where `P_t` is the price at time `t`, `E[P]` is the long-term mean price, `phi` is the rate of reversion, `sigma` is the volatility, and `epsilon_t` is a random shock.\n\n## The Algorithm\n\nThe numerical determination of an optimal trading rule (OTR) follows five sequential steps:\n\n1.  **Estimate Process Parameters**: Using historical price series data, estimate the parameters `phi` and `sigma` of the underlying O-U process. This is typically done via Ordinary Least Squares (OLS) on a linearized version of the process equation.\n2.  **Construct Rule Mesh**: Create a grid of candidate trading rules. For example, a Cartesian product of potential stop-loss values and profit-taking values, forming a mesh of `(stop_loss, profit_take)` pairs.\n3.  **Generate Synthetic Paths**: For a given set of initial conditions (e.g., entry price, forecasted price), generate a large number of synthetic price paths using the estimated O-U parameters (`phi`, `sigma`). A maximum holding period (vertical barrier) is imposed to ensure positions are eventually closed.\n4.  **Evaluate Rules on Paths**: For each trading rule in the mesh, apply its logic to every synthetic path generated in Step 3. This yields a distribution of final profit/loss outcomes for that specific rule. From this distribution, calculate a performance metric, typically the Sharpe Ratio:\n    $$ SR_{R} = \\frac{E[\\pi|R]}{\\sigma[\\pi|R]} \\quad (Equation 2) $$ \n    Where `E[pi|R]` and `sigma[pi|R]` are the mean and standard deviation of profits/losses for rule `R`.\n5.  **Determine Optimal Rule**: Identify the trading rule from the mesh that produced the highest Sharpe Ratio. This rule is considered the OTR for the given stochastic process parameters and can be used for future trades without direct historical backtesting.",
    "question": "Provide the pseudocode for a function that implements Step 3 and Step 4 of the described algorithm. This function should take the estimated process parameters and a single trading rule (a profit-take/stop-loss pair) as input, run a specified number of path simulations, and return the calculated Sharpe ratio for that rule.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION SimulateAndGetSharpe(process_params, trading_rule, n_paths, max_holding_period)\n// INPUTS:\n//   - process_params: A structure containing:\n//     - phi: The mean-reversion parameter of the O-U process.\n//     - sigma: The volatility parameter of the O-U process.\n//     - forecast_price: The long-term mean price E[P].\n//     - start_price: The initial price P_0 for each path.\n//   - trading_rule: A structure containing:\n//     - profit_take_level: The positive profit threshold to exit a trade.\n//     - stop_loss_level: The negative profit threshold (as a positive number) to exit a trade.\n//   - n_paths: The number of synthetic paths to generate (e.g., 100,000).\n//   - max_holding_period: The maximum number of steps before a trade is forced to exit (vertical barrier).\n// OUTPUTS:\n//   - The Sharpe Ratio for the given trading rule under the specified process.\n//\n// BEGIN\n//   CREATE an empty list 'final_profits'.\n//\n//   // Step 3: Generate Synthetic Paths and apply rule logic\n//   FOR i from 1 to n_paths:\n//     current_price = process_params.start_price\n//     holding_period = 0\n//\n//     LOOP indefinitely:\n//       // Generate next price using the discrete O-U formula (Equation 1)\n//       random_shock = StandardNormalRandom()\n//       next_price = (1 - process_params.phi) * process_params.forecast_price + \\\n//                    process_params.phi * current_price + \\\n//                    process_params.sigma * random_shock\n//\n//       current_price = next_price\n//       holding_period = holding_period + 1\n//\n//       // Calculate current profit/loss (assuming a long position of 1 unit)\n//       current_profit = current_price - process_params.start_price\n//\n//       // Check for barrier touches\n//       IF current_profit >= trading_rule.profit_take_level OR \\\n//          current_profit <= -trading_rule.stop_loss_level OR \\\n//          holding_period >= max_holding_period THEN\n//\n//         APPEND current_profit to 'final_profits'.\n//         BREAK LOOP // Exit the path simulation\n//       ENDIF\n//     ENDLOOP\n//   ENDFOR\n//\n//   // Step 4: Compute the Sharpe Ratio from the resulting distribution of profits\n//   mean_profit = Mean(final_profits)\n//   std_dev_profit = StandardDeviation(final_profits)\n//\n//   IF std_dev_profit is 0 THEN\n//     RETURN 0 // Avoid division by zero\n//   ELSE\n//     sharpe_ratio = mean_profit / std_dev_profit\n//     RETURN sharpe_ratio\n//   ENDIF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 3,
    "text": "## Framework Overview\n\nTo accurately measure a strategy's performance characteristics, such as the frequency of bets, it is essential to first identify the discrete betting periods. A continuous series of trades on the same side (e.g., multiple buys to build a long position) is considered part of a single bet. A bet is defined as the period of holding a non-zero position.\n\n## Key Concepts\n\n- **[Definition] Bet**: A sequence of positions held on the same side (long or short). A bet concludes when the position is either fully closed (flattened) or reversed to the opposite side (flipped).\n- **[Definition] Flattening**: A trade that reduces a position to zero. For example, selling all shares of a long position.\n- **[Definition] Flipping**: A trade that changes a position from long to short, or vice-versa. For example, holding +100 shares and then selling 200 shares to establish a -100 share position.\n\n## Computational Steps\n\nThe timestamps that mark the end of each bet can be derived from a time series of target positions, `tPos`. The logic involves identifying two types of events:\n\n1.  **Flattening Events**: A bet ends when a position that was non-zero in the previous period becomes zero in the current period.\n2.  **Flipping Events**: A bet ends at the moment a position's sign changes from positive to negative, or negative to positive, relative to the previous period.\n\nThis logic is captured in the following algorithm:\n\n**Algorithm 1: Deriving Bet Timestamps**\n\n```\n# Let tPos be a time-indexed series of target positions\n\n# 1. Identify timestamps where the position is currently zero\nzero_positions = timestamps where tPos is 0\n\n# 2. Identify timestamps where the prior position was non-zero\nshifted_tPos = tPos shifted forward by one period\nprior_nonzero = timestamps where shifted_tPos is not 0\n\n# 3. Flattening events are the intersection of the two sets\nflattening_bets = intersection of zero_positions and prior_nonzero\n\n# 4. Identify flipping events by checking for a sign change\n# This is true when the product of the current and prior position is negative\nposition_product = tPos[1:] * tPos[0:-1]\nflipping_bets = timestamps where position_product is negative\n\n# 5. Combine both sets of timestamps\nbet_timestamps = union of flattening_bets and flipping_bets\n\n# 6. Ensure the final observation is included if the position is not flat\nif the last timestamp in tPos is not in bet_timestamps:\n  append the last timestamp to bet_timestamps\n```",
    "question": "Provide the pseudocode for a function that implements the logic described in Algorithm 1 to derive the timestamps corresponding to the end of each bet.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GetBetTimestamps(tPos)\n// INPUTS:\n//   - tPos: A time-indexed series of numerical target positions.\n// OUTPUTS:\n//   - A sorted list of timestamps where bets are considered to have ended.\n//\n// BEGIN\n//   // Step 1 & 2: Identify flattening events\n//   // A bet is flattened if the current position is zero and the prior was not.\n//   tPos_is_zero = (tPos == 0)\n//   tPos_prior_is_nonzero = (Shift(tPos, 1) != 0)\n//   flattening_indices = Indices where (tPos_is_zero AND tPos_prior_is_nonzero)\n//\n//   // Step 3: Identify flipping events\n//   // A bet flips if the sign of the position changes.\n//   sign_product = tPos[1 to end] * tPos[0 to end-1]\n//   flipping_indices = Indices where (sign_product < 0)\n//\n//   // Step 4: Combine the indices\n//   // The union of both sets gives the majority of bet endpoints.\n//   bets = Union(flattening_indices, flipping_indices)\n//   bets = Sort(bets)\n//\n//   // Step 5: Handle the final position\n//   // If the last position in the series is non-zero, it marks the end of the final bet.\n//   last_timestamp = GetLastIndex(tPos)\n//   IF last_timestamp is NOT IN bets AND GetValueAtIndex(tPos, last_timestamp) != 0 THEN\n//     Append last_timestamp to bets\n//   END IF\n//\n//   RETURN bets\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 4,
    "text": "## Framework Overview\n\nThe Time-Weighted Rate of Return (TWRR) is a standard method for calculating investment performance that removes the distorting effects of cash inflows and outflows. It measures the compound growth rate of a portfolio. The calculation involves three main stages: calculating returns for each sub-period defined by cash flows, geometrically linking these returns, and finally annualizing the total return.\n\n## Key Concepts\n\n- **[Definition] Time-Weighted Rate of Return (TWRR)**: A measure of the compound rate of growth in a portfolio. Since it eliminates the impact of the timing of cash flows, it is the standard for comparing the performance of investment managers.\n- **[Definition] Sub-period**: A time interval between two consecutive external cash flows.\n\n## Computational Formulation\n\nThe TWRR calculation can be broken down into the following steps:\n\n**Step 1: Calculate Sub-Period Return (`r_i,t`)**\n\nThe return for portfolio `i` during sub-period `t` is calculated as the ratio of profit and loss to the capital employed.\n\n**Equation 1:**\n`r_i,t = 锜篲i,t / K_i,t`\n\nWhere the components are:\n\n**Equation 2: Profit and Loss (`锜篲i,t`)**\n`锜篲i,t = 鍗?[ (铻朠_j,t + A_j,t) * 鑳僟i,j,t-1 + 铻栬儍_i,j,t * (P_j,t - P铏卂j,t-1) ]`\n\n**Equation 3: Capital Employed (`K_i,t`)**\n`K_i,t = 鍗?[ P铏刜j,t-1 * 鑳僟i,j,t-1 ] + max(0, 鍗?[ P铏勮檯_j,t * 铻栬儍_i,j,t ])`\n\n*Variable Definitions:*\n- `锜篲i,t`: Mark-to-market profit or loss for portfolio `i` at time `t`.\n- `K_i,t`: Market value of assets under management for portfolio `i` through sub-period `t`.\n- `A_j,t`: Interest or dividend paid by one unit of instrument `j` at time `t`.\n- `P_j,t`: Clean price of security `j` at time `t`.\n- `P铏刜j,t`: Dirty price (clean price + accrued interest) of security `j` at time `t`.\n- `鑳僟i,j,t`: Holdings of portfolio `i` on security `j` at time `t`.\n- `铻朠_j,t`: Change in clean price for security `j` over sub-period `t`.\n- `铻栬儍_i,j,t`: Change in holdings for portfolio `i` on security `j` over sub-period `t`.\n- `P铏卂j,t-1`: Average transacted clean price for security `j` over the prior sub-period.\n- `P铏勮檯_j,t`: Average transacted dirty price for security `j` over sub-period `t`.\n- `鍗盽 denotes summation over all securities `j=1` to `J`.\n\n**Step 2: Geometrically Link Sub-Period Returns**\nThe total return over `T` periods is found by linking the sub-period returns.\n\n**Equation 4:**\n`锠乢i,T = 铻?(1 + r_i,t)` for `t=1` to `T`\n\n- `锠乢i,T`: The performance of one dollar invested in portfolio `i` over its entire life.\n\n**Step 3: Annualize the Total Return**\nThe total return is converted to an annualized figure.\n\n**Equation 5:**\n`R_i = (锠乢i,T)^(1/y_i) - 1`\n\n- `R_i`: The annualized rate of return of portfolio `i`.\n- `y_i`: The number of years elapsed between the first and last sub-period.",
    "question": "Provide the pseudocode for a function that implements the complete, three-step Time-Weighted Rate of Return (TWRR) calculation.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateAnnualizedTWRR(sub_period_data, total_years)\n// INPUTS:\n//   - sub_period_data: A list of records, where each record 't' contains all necessary\n//     data for that sub-period (holdings, prices, cashflows, etc.).\n//   - total_years: The total duration of the investment period in years.\n// OUTPUTS:\n//   - The annualized Time-Weighted Rate of Return (TWRR).\n//\n// BEGIN\n//   // Step 1: Calculate sub-period returns and store them\n//   sub_period_returns = New List()\n//\n//   FOR each period 't' in sub_period_data:\n//     // Calculate Profit and Loss (pi_i,t) for the period\n//     total_pnl = 0\n//     FOR each security 'j' in the portfolio:\n//       pnl_j = (delta_P_j_t + A_j_t) * theta_i_j_t_minus_1\n//       pnl_j += delta_theta_i_j_t * (P_j_t - avg_P_j_t_minus_1)\n//       total_pnl += pnl_j\n//     END FOR\n//\n//     // Calculate Capital Employed (K_i,t) for the period\n//     initial_market_value = 0\n//     new_purchases_value = 0\n//     FOR each security 'j' in the portfolio:\n//       initial_market_value += dirty_P_j_t_minus_1 * theta_i_j_t_minus_1\n//       new_purchases_value += avg_dirty_P_j_t * delta_theta_i_j_t\n//     END FOR\n//     capital_employed = initial_market_value + Max(0, new_purchases_value)\n//\n//     // Calculate sub-period return and add to list\n//     IF capital_employed != 0 THEN\n//       r_i_t = total_pnl / capital_employed\n//       Add (1 + r_i_t) to sub_period_returns\n//     ELSE\n//       Add 1.0 to sub_period_returns // No change in value\n//     END IF\n//   END FOR\n//\n//   // Step 2: Geometrically link the returns\n//   total_return_factor = 1.0\n//   FOR each factor in sub_period_returns:\n//     total_return_factor = total_return_factor * factor\n//   END FOR\n//\n//   // Step 3: Annualize the total return\n//   IF total_years > 0 THEN\n//     annualized_twrr = (total_return_factor ^ (1.0 / total_years)) - 1\n//   ELSE\n//     annualized_twrr = total_return_factor - 1\n//   END IF\n//\n//   RETURN annualized_twrr\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 5,
    "text": "## Framework Overview\n\nStrategy returns are rarely independent and identically distributed (IID), often exhibiting periods of consecutive losses known as runs. To quantify the impact of these runs, we analyze drawdowns and the time it takes to recover from them. This analysis is crucial for understanding a strategy's downside risk profile.\n\n## Key Concepts\n\n- **[Definition] High-Watermark (HWM)**: The highest peak in value that a portfolio has reached up to a certain point in time. It is the running maximum of the portfolio's value series.\n- **[Definition] Drawdown (DD)**: The maximum loss suffered by an investment from a peak (a high-watermark) to a subsequent trough. It measures the percentage or dollar decline from a HWM.\n- **[Definition] Time under Water (TuW)**: The time elapsed between a high-watermark and the moment the portfolio's value exceeds that previous HWM, marking a full recovery.\n\n## Computational Steps\n\nThe algorithm to compute the series of drawdowns and their associated time under water from a portfolio value series is as follows:\n\n**Algorithm 1: Deriving Drawdown and Time under Water**\n\n1.  **Calculate High-Watermarks**: For a given time series of portfolio values, create a new series representing the expanding maximum value up to each point in time. This is the HWM series.\n2.  **Identify Drawdown Periods**: Group the original value series by the HWM series. For each HWM, find the minimum portfolio value (trough) that occurred before a new HWM was established.\n3.  **Filter for Actual Drawdowns**: Keep only the groups where the HWM is greater than the subsequent minimum value. This ensures we are only measuring periods where a loss occurred.\n4.  **Calculate Drawdown (DD)**: For each identified drawdown period, calculate the magnitude of the loss. This can be the absolute dollar difference (`HWM - min_value`) or a percentage (`(HWM - min_value) / HWM`).\n5.  **Calculate Time under Water (TuW)**: For each drawdown, calculate the time duration from the date of the HWM to the date when the portfolio value first surpasses that HWM. This is typically measured in years or days.",
    "question": "Provide the pseudocode for a function that implements the logic described in Algorithm 1 to compute the series of drawdowns and the time under water associated with them.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ComputeDrawdownAndTimeUnderWater(value_series, in_dollars)\n// INPUTS:\n//   - value_series: A time-indexed series of portfolio values (or returns).\n//   - in_dollars: A boolean, TRUE to calculate DD in dollars, FALSE for percentage.\n// OUTPUTS:\n//   - A tuple containing two series: (drawdowns, time_under_water).\n//     'drawdowns' is indexed by the trough date, 'time_under_water' by the recovery date.\n//\n// BEGIN\n//   // Create a data structure with columns for value and high-watermark (hwm)\n//   df = CreateDataFrame(value_series, columns=['pnl'])\n//\n//   // Step 1: Calculate the expanding maximum for the HWM\n//   df['hwm'] = ExpandingMax(df['pnl'])\n//\n//   // Step 2 & 3: Identify HWMs followed by a trough\n//   // Group by HWM and find the minimum value within each group\n//   hwm_groups = GroupBy(df, 'hwm')\n//   troughs = FindMin(hwm_groups['pnl'])\n//\n//   // Associate each trough with the timestamp of its preceding HWM\n//   hwm_timestamps = GetFirstIndexForEachGroup(hwm_groups)\n//   troughs.SetIndex(hwm_timestamps)\n//\n//   // Filter out periods without a drawdown (where hwm == min)\n//   drawdown_periods = Filter(troughs, where troughs['hwm'] > troughs['min'])\n//\n//   // Step 4: Calculate Drawdown magnitude\n//   IF in_dollars THEN\n//     dd = drawdown_periods['hwm'] - drawdown_periods['min']\n//   ELSE\n//     dd = (drawdown_periods['hwm'] - drawdown_periods['min']) / drawdown_periods['hwm']\n//   END IF\n//\n//   // Step 5: Calculate Time under Water\n//   // Find the recovery time for each HWM\n//   tuw_series = New Series()\n//   hwm_list = GetIndex(drawdown_periods)\n//   FOR i from 0 to Length(hwm_list) - 1:\n//     hwm_level = GetValueAtIndex(drawdown_periods['hwm'], i)\n//     hwm_time = hwm_list[i]\n//\n//     // Find the first time the portfolio value exceeds the HWM level after the HWM time\n//     recovery_time = FindFirstIndex in value_series AFTER hwm_time\n//                       where value > hwm_level\n//\n//     IF recovery_time exists THEN\n//       duration = (recovery_time - hwm_time) in years\n//       tuw_series[recovery_time] = duration\n//     END IF\n//   END FOR\n//\n//   RETURN (dd, tuw_series)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 6,
    "text": "## Framework Overview\n\nThe standard Sharpe Ratio (SR) is a widely used metric for risk-adjusted returns, but it implicitly assumes that returns are independent and identically distributed (IID) Gaussian. This assumption is often violated in financial markets, where returns can be skewed and exhibit fat tails (high kurtosis). The Probabilistic Sharpe Ratio (PSR) addresses this shortcoming by providing a more robust estimate of skill.\n\n## Key Concepts\n\n- **[Definition] Sharpe Ratio (SR)**: A measure of excess return (over the risk-free rate) per unit of deviation (risk). It is defined as `SR = 娓?/ 锜絗, where `娓璥 is the mean of excess returns and `锜絗 is their standard deviation.\n- **[Definition] Probabilistic Sharpe Ratio (PSR)**: The probability that the true Sharpe Ratio of a strategy is greater than a certain benchmark Sharpe Ratio (`SR*`). It corrects the raw SR estimate for the inflationary effects of short track records or non-Normal returns (skewness and kurtosis).\n\n## Computational Formulation\n\nThe Probabilistic Sharpe Ratio is estimated using the statistical properties of the observed returns series. Given an observed Sharpe Ratio (`SR铏僠) and a benchmark Sharpe Ratio (`SR*`), the PSR is calculated as follows:\n\n**Equation 1: Probabilistic Sharpe Ratio (`PSR铏僠)**\n`PSR铏僛SR*] = Z[ ( (SR铏?- SR*) * sqrt(T - 1) ) / sqrt(1 - 绾檭_3*SR铏?+ ( (绾檭_4 - 1)/4 )*SR铏僞2 ) ]`\n\n*Variable Definitions:*\n- `Z[.]`: The Cumulative Distribution Function (CDF) of the Standard Normal distribution.\n- `SR铏僠: The observed Sharpe Ratio calculated from the returns series. This value should be in its original sampling frequency (e.g., daily), not annualized.\n- `SR*`: The benchmark Sharpe Ratio to test against (e.g., 1.0 / sqrt(252) for an annualized target of 1.0).\n- `T`: The number of observed returns in the series.\n- `绾檭_3`: The skewness of the observed returns series.\n- `绾檭_4`: The kurtosis of the observed returns series. For a perfect Normal distribution, kurtosis is 3.",
    "question": "Provide the pseudocode for a function that implements the Probabilistic Sharpe Ratio (PSR) calculation as described in Equation 1.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculatePSR(returns, benchmark_sr)\n// INPUTS:\n//   - returns: A series of numerical excess returns.\n//   - benchmark_sr: The benchmark Sharpe Ratio (at the same frequency as returns).\n// OUTPUTS:\n//   - The Probabilistic Sharpe Ratio (a value between 0 and 1).\n//\n// ASSUMES:\n//   - Helper functions exist for: Mean, StdDev, Skewness, Kurtosis, Sqrt, and CDF_Normal.\n//\n// BEGIN\n//   // Step 1: Calculate the required statistics from the returns series.\n//   T = Count(returns)\n//   IF T < 2 THEN\n//     RETURN NaN // Not enough data\n//   END IF\n//\n//   observed_mean = Mean(returns)\n//   observed_std = StdDev(returns)\n//   IF observed_std == 0 THEN\n//     RETURN NaN // Cannot compute SR\n//   END IF\n//\n//   // The observed SR must be at the native frequency of the returns.\n//   observed_sr = observed_mean / observed_std\n//\n//   skew = Skewness(returns)\n//   // Note: Financial kurtosis is often reported as 'excess kurtosis' (kurtosis - 3).\n//   // The formula uses standard kurtosis, where Normal distribution has kurtosis = 3.\n//   kurtosis = Kurtosis(returns)\n//\n//   // Step 2: Calculate the numerator of the Z-score argument.\n//   numerator = (observed_sr - benchmark_sr) * Sqrt(T - 1)\n//\n//   // Step 3: Calculate the denominator of the Z-score argument.\n//   denominator_term1 = 1\n//   denominator_term2 = skew * observed_sr\n//   denominator_term3 = ((kurtosis - 1) / 4) * (observed_sr ^ 2)\n//\n//   denominator_inner = denominator_term1 - denominator_term2 + denominator_term3\n//\n//   // The term inside the square root must be non-negative.\n//   IF denominator_inner < 0 THEN\n//     RETURN NaN\n//   END IF\n//   denominator = Sqrt(denominator_inner)\n//\n//   // Step 4: Calculate the Z-score and apply the Normal CDF.\n//   IF denominator == 0 THEN\n//      // Handle division by zero; outcome is either 0, 1, or undefined\n//      IF numerator > 0 THEN RETURN 1.0\n//      IF numerator < 0 THEN RETURN 0.0\n//      RETURN 0.5 // Undefined case, numerator is also 0\n//   END IF\n//\n//   z_score = numerator / denominator\n//   psr = CDF_Normal(z_score)\n//\n//   RETURN psr\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 7,
    "text": "### Framework Overview\nA common way to model a trading strategy is as a series of independent, identically distributed (IID) bets. In the simplest case, the payouts are symmetric: a profit of `锜篳 or a loss of `-锜篳. The performance of such a strategy is not dependent on the magnitude of `锜篳, but rather on the interplay between the strategy's precision (`p`) and its betting frequency (`n`).\n\n### Key Concepts\n- **[Definition] Symmetric Payout Strategy**: A strategy where each bet results in one of two outcomes: a fixed profit `锜?> 0` or an equivalent loss `-锜篳.\n- **[Definition] IID Bets**: Independent and Identically Distributed bets, meaning the outcome of one bet does not influence another, and the probability distribution for all bets is the same.\n- **[Definition] Precision (p)**: The probability that a bet results in a profit. `P[Outcome = 锜篯 = p`. The probability of a loss is `1 - p`.\n- **[Definition] Annualized Sharpe Ratio (鑳?**: A measure of risk-adjusted return. For this model, it is a function of precision `p` and the number of bets per year `n`.\n\n### Mathematical Derivation\nFor a strategy with `n` IID bets per year and symmetric payouts, the annualized Sharpe ratio `鑳僠 is given by:\n\n**Equation 1: Annualized Sharpe Ratio for Symmetric Payouts**\n```\n鑳?p, n) = [ (2p - 1) / (2 * sqrt(p * (1 - p))) ] * sqrt(n)\n```\nWhere:\n- `p`: The precision of the strategy.\n- `n`: The number of bets per year.\n\nTo determine the viability of a strategy, we can solve Equation 1 for the precision `p` required to achieve a target annualized Sharpe ratio `鑳僠. This yields the implied precision formula:\n\n**Equation 2: Implied Precision for Symmetric Payouts**\n```\np = 0.5 * (1 + sqrt(1 - n / (鑳僞2 + n)))\n```\nThis equation highlights the trade-off between precision and frequency. For a fixed target Sharpe ratio, a strategy with lower frequency (`n`) requires higher precision (`p`), and vice versa.",
    "question": "1.  **`[Symmetric Implied Precision Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the required precision `p` for a symmetric payout strategy, given the number of annual bets `n` and a target annualized Sharpe ratio `鑳僠.",
    "answer": "```\n// --- BEGIN PSEUODCODE ---\n//\n// FUNCTION calculateSymmetricImpliedPrecision(n, theta)\n// INPUTS:\n//   - n: An integer representing the number of bets per year.\n//   - theta: A float representing the target annualized Sharpe ratio.\n// OUTPUTS:\n//   - A float representing the required precision 'p', or an error/null value if no real solution exists.\n//\n// BEGIN\n//   // Calculate the term inside the square root from Equation 2.\n//   term = 1 - (n / (theta^2 + n))\n//\n//   // Check the constraint: if the term is negative, no real precision value exists.\n//   IF term < 0 THEN\n//     RETURN NULL // Or raise an error indicating an impossible target.\n//   END IF\n//\n//   // Apply Equation 2 to calculate the implied precision.\n//   precision = 0.5 * (1 + SQRT(term))\n//\n//   RETURN precision\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 8,
    "text": "### Framework Overview\nReal-world trading strategies often have asymmetric outcomes, where the magnitude of the average profit differs from the magnitude of the average loss. This model extends the binomial framework to account for such scenarios, where a bet results in a profit `锜?` with probability `p`, or a loss `锜?` with probability `1-p`.\n\n### Key Concepts\n- **[Definition] Asymmetric Payout Strategy**: A strategy where the typical profit from a winning bet is not equal in magnitude to the typical loss from a losing bet.\n- **[Definition] Profit Payout (锜?)**: The expected outcome of a profitable bet.\n- **[Definition] Loss Payout (锜?)**: The expected outcome of a losing bet (a negative value).\n- **[Definition] Precision (p)**: The probability that a bet results in a profit, `P[Outcome = 锜?] = p`.\n\n### Mathematical Derivation\nFor a strategy with `n` IID bets per year and asymmetric payouts, the annualized Sharpe ratio `鑳僠 is:\n\n**Equation 1: Annualized Sharpe Ratio for Asymmetric Payouts**\n```\n鑳?p, n, 锜?, 锜?) = [ ( (锜? - 锜?)p + 锜? ) / ( (锜? - 锜?) * sqrt(p(1-p)) ) ] * sqrt(n)\n```\nTo find the precision `p` required to achieve a target Sharpe ratio `鑳僠, we can rearrange Equation 1 into a quadratic equation and solve for `p`. The solution is given by the quadratic formula:\n\n**Equation 2: Implied Precision Formula**\n```\np = (-b + sqrt(b^2 - 4ac)) / 2a\n```\n\n**Equation 3: Coefficients for the Quadratic Formula**\n```\na = (n + 鑳僞2) * (锜? - 锜?)^2\nb = [2n锜? - 鑳僞2(锜? - 锜?)] * (锜? - 锜?)\nc = n * 锜?^2\n```\nWhere:\n- `p`: The required precision of the strategy.\n- `n`: The number of bets per year.\n- `鑳僠: The target annualized Sharpe ratio.\n- `锜?`: The profit payout (e.g., from a profit-taking limit).\n- `锜?`: The loss payout (e.g., from a stop-loss limit).",
    "question": "1.  **`[Asymmetric Implied Precision Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the minimum required precision `p` for an asymmetric payout strategy, given the profit payout `锜?`, loss payout `锜?`, number of annual bets `n`, and a target annualized Sharpe ratio `鑳僠.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION calculateAsymmetricImpliedPrecision(pi_plus, pi_minus, n, theta)\n// INPUTS:\n//   - pi_plus: A positive float for the profit payout (profit-taking).\n//   - pi_minus: A negative float for the loss payout (stop-loss).\n//   - n: An integer for the number of bets per year.\n//   - theta: A float for the target annualized Sharpe ratio.\n// OUTPUTS:\n//   - A float representing the required precision 'p', or an error/null value.\n//\n// BEGIN\n//   // Define payout difference for clarity.\n//   payout_diff = pi_plus - pi_minus\n//\n//   // Calculate coefficient 'a' based on Equation 3.\n//   a = (n + theta^2) * (payout_diff^2)\n//\n//   // Calculate coefficient 'b' based on Equation 3.\n//   b = (2 * n * pi_minus - theta^2 * payout_diff) * payout_diff\n//\n//   // Calculate coefficient 'c' based on Equation 3.\n//   c = n * pi_minus^2\n//\n//   // Calculate the discriminant of the quadratic equation.\n//   discriminant = b^2 - 4 * a * c\n//\n//   // If discriminant is negative, no real solution for precision exists.\n//   IF discriminant < 0 THEN\n//     RETURN NULL // Or raise an error.\n//   END IF\n//\n//   // Apply the quadratic formula (Equation 2) to find the precision.\n//   // We use the positive root as it corresponds to the meaningful solution for p.\n//   precision = (-b + SQRT(discriminant)) / (2 * a)\n//\n//   RETURN precision\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 9,
    "text": "## Framework Overview\n\nHierarchical Risk Parity (HRP) is a modern portfolio construction method that utilizes graph theory and machine learning to build stable and diversified portfolios. Unlike traditional quadratic optimizers, HRP does not require inverting the covariance matrix, making it robust against numerical instability and applicable even to singular covariance matrices. The algorithm operates in three distinct stages.\n\n### Key Concepts\n- **[Definition] Hierarchical Risk Parity (HRP)**: An asset allocation method that first structures assets into a hierarchy based on their correlations and then allocates capital in a top-down manner, distributing risk across different levels of the hierarchy.\n- **[Definition] Linkage Matrix**: An `(N-1)x4` matrix generated by a clustering algorithm that encodes the hierarchical tree structure. Each row represents a merge of two components (items or sub-clusters) into a new, larger cluster.\n- **[Definition] Quasi-Diagonalization**: A process of reordering the rows and columns of a covariance matrix to group similar assets together. This places the largest covariance values along the diagonal, revealing the underlying cluster structure without changing the basis of the matrix.\n- **[Definition] Recursive Bisection**: A top-down allocation algorithm that iteratively splits a portfolio into two sub-portfolios (bisections) and distributes weight between them in inverse proportion to their aggregate risk. This process is repeated until weights are assigned to individual assets.\n\n### Stage 1: Tree Clustering\n\nThis stage builds the hierarchical structure of the assets based on their correlation.\n\n1.  **Compute Correlation Matrix**: Given a `T x N` matrix of asset returns `X`, compute the `N x N` correlation matrix `锜籤.\n2.  **Compute Distance Matrix**: Convert the correlation matrix `锜籤 into a distance matrix `D` where each entry `d_ij` measures the 'distance' between assets `i` and `j`. A common metric is given by Equation 1:\n    *   `d_ij = sqrt(0.5 * (1 - 锜籣ij))` (Equation 1)\n3.  **Perform Hierarchical Clustering**: Apply a clustering algorithm to the distance matrix `D` to group assets. This step generates a **Linkage Matrix** that describes the nested cluster structure, detailing which assets are merged at each step and at what distance.\n\n### Stage 2: Quasi-Diagonalization\n\nThis stage reorders the covariance matrix according to the hierarchy developed in Stage 1.\n\n1.  **Traverse the Hierarchy**: Using the linkage matrix from Stage 1, traverse the cluster hierarchy from the top (the root cluster containing all assets) down to the individual assets.\n2.  **Generate Sorted Index**: The traversal produces a new, sorted ordering of the asset indices. This ordering ensures that assets belonging to the same cluster are placed next to each other.\n3.  **Reorder Covariance Matrix**: The original covariance matrix is re-indexed according to this new sorted order. The result is a quasi-diagonalized matrix where correlated asset blocks are visible along the main diagonal.\n\n### Stage 3: Recursive Bisection\n\nThis final stage allocates weights in a top-down manner across the hierarchical structure.\n\n1.  **Initialization**: Start with a single cluster containing all assets and an initial weight of 1.0 for each.\n2.  **Iteration**: While there are clusters with more than one asset:\n    a.  **Bisect Cluster**: Split the current cluster into two sub-clusters based on the sorted index from Stage 2.\n    b.  **Calculate Cluster Variance**: For each sub-cluster, calculate its aggregate variance. This is done by first computing an inverse-variance portfolio within the sub-cluster and then calculating the variance of that portfolio. The weight `w铏刞 for assets within a sub-cluster `j` with covariance matrix `V^(j)` is given by Equation 2:\n        *   `w铏刕(j) = (1 / diag(V^(j))) / trace(1 / diag(V^(j)))` (Equation 2)\n        The cluster variance `V铏刕(j)` is then `w铏刕(j)' * V^(j) * w铏刕(j)`.\n    c.  **Compute Split Factor**: Determine the allocation split `浼猔 between the two sub-clusters (`1` and `2`) based on their inverse variances, as shown in Equation 3:\n        *   `浼?= 1 - V铏刕(1) / (V铏刕(1) + V铏刕(2))` (Equation 3)\n    d.  **Assign Weights**: Allocate weight to the sub-clusters. The weights of assets in sub-cluster `1` are multiplied by `浼猔, and the weights of assets in sub-cluster `2` are multiplied by `(1 - 浼?`.\n3.  **Termination**: The process stops when all clusters have been broken down into individual assets, resulting in the final portfolio weights.",
    "question": "Provide the pseudocode for a main function that orchestrates the three stages of the Hierarchical Risk Parity algorithm (Tree Clustering, Quasi-Diagonalization, and Recursive Bisection) to compute portfolio weights from a given covariance matrix.",
    "answer": "```\n// --- BEGIN PSEUODCODE ---\n//\n// FUNCTION HierarchicalRiskParity(covariance_matrix, correlation_matrix)\n// INPUTS:\n//   - covariance_matrix: An N x N matrix of asset covariances.\n//   - correlation_matrix: An N x N matrix of asset correlations.\n// OUTPUTS:\n//   - weights: A list or series of final portfolio weights for N assets.\n//\n// BEGIN\n//   // --- Stage 1: Tree Clustering ---\n//   // Convert correlation matrix to a distance matrix as per Equation 1.\n//   distance_matrix = ConvertCorrelationToDistance(correlation_matrix)\n//\n//   // Perform hierarchical clustering to get the linkage matrix.\n//   linkage_matrix = TreeClustering(distance_matrix)\n//\n//   // --- Stage 2: Quasi-Diagonalization ---\n//   // Traverse the linkage matrix to get the sorted asset order.\n//   sorted_indices = QuasiDiagonalization(linkage_matrix)\n//\n//   // --- Stage 3: Recursive Bisection ---\n//   // Initialize weights to 1.0 for all assets, in the new sorted order.\n//   weights = Series(1.0, index=sorted_indices)\n//   // Initialize the list of clusters to contain a single cluster with all assets.\n//   clusters = [sorted_indices]\n//\n//   WHILE length(clusters) > 0:\n//     // Bisect each cluster in the current list into two halves.\n//     new_clusters = []\n//     FOR cluster IN clusters:\n//       IF length(cluster) > 1:\n//         midpoint = floor(length(cluster) / 2)\n//         sub_cluster_1 = cluster[0:midpoint]\n//         sub_cluster_2 = cluster[midpoint:end]\n//         new_clusters.append(sub_cluster_1)\n//         new_clusters.append(sub_cluster_2)\n//     clusters = new_clusters\n//\n//     // Process the bisections in pairs to allocate weights.\n//     FOR i from 0 to length(clusters) - 1, step 2:\n//       cluster_1 = clusters[i]\n//       cluster_2 = clusters[i+1]\n//\n//       // Calculate variance for each sub-cluster.\n//       variance_1 = GetClusterVariance(covariance_matrix, cluster_1)\n//       variance_2 = GetClusterVariance(covariance_matrix, cluster_2)\n//\n//       // Calculate the split factor alpha as per Equation 3.\n//       split_factor = 1 - variance_1 / (variance_1 + variance_2)\n//\n//       // Rescale weights in each cluster.\n//       weights[cluster_1] = weights[cluster_1] * split_factor\n//       weights[cluster_2] = weights[cluster_2] * (1 - split_factor)\n//\n//   RETURN weights\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 10,
    "text": "### Core Concept\nThe Chu-Stinchcombe-White (CSW) CUSUM test is a simplified method for detecting structural breaks directly on a time series of levels, such as log-prices. It operates under the null hypothesis of no change (i.e., the expected change in the series is zero). The test statistic measures the standardized departure of the current value from a past reference value. A large statistic suggests that the series has deviated significantly from its past behavior.\n\n- **[Definition] CUSUM Test on Levels**: A structural break test that works directly on a series `y_t` (e.g., log-prices) without requiring a set of predictive features `x_t`. It tests the null hypothesis that the series follows a random walk with zero drift.\n\n### Computational Formulae\nThe test involves calculating a standardized departure statistic, `S_{n,t}`, for a given time `t` relative to a starting time `n`.\n\n1.  **Standardized Departure (`S_{n,t}`)**: This statistic measures how far the current log-price `y_t` has moved from a past log-price `y_n`, scaled by the volatility and the time elapsed.\n\n    (Equation 1)\n    $$ S_{n,t} = (y_{t} - y_{n})\\big(\\hat{\\sigma}_{t}\\sqrt{t - n}\\big)^{-1} $$\n\n    The term `锜借檭_t` is the estimated volatility of the series' changes, calculated up to time `t`:\n\n    (Equation 2)\n    $$ \\hat{\\sigma}_{t}^{2} = (t - 1)^{-1}\\sum_{i = 2}^{t}(\\Delta y_{i})^{2} $$\n\n    - `y_t`: The log-price at the current time `t`.\n    - `y_n`: The log-price at a past reference time `n`, where `n < t`.\n    - `铻杫_i`: The change in log-price, `y_i - y_{i-1}`.\n\n2.  **Time-Dependent Critical Value**: The significance of the `S_{n,t}` statistic is assessed against a critical value that depends on the length of the window `t-n`.\n\n    (Equation 3)\n    $$ c_{\\alpha}[n,t] = \\sqrt{b_{\\alpha} + \\log[t - n]} $$\n\n    - `b_浼猔: A constant derived from Monte Carlo simulations (e.g., `b_0.05 = 4.6`).\n\n### Robustness Enhancement\nA key drawback is that the choice of the reference point `y_n` is arbitrary. To overcome this, a more robust statistic, `S_t`, is computed by taking the supremum (the maximum value) of `S_{n,t}` over all possible starting points `n` from `1` to `t-1`.\n\n(Equation 4)\n$$ S_{t} = \\sup_{n\\in [1,t-1]}\\{S_{n,t}\\} $$",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Robust CSW CUSUM Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the robust Chu-Stinchcombe-White CUSUM test. The function should take a series of log-prices up to time `T` and compute the robust statistic `S_T`.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateRobustCswCusum(log_price_series)\n// INPUTS:\n//   - log_price_series: A time series of log-prices of length T.\n// OUTPUTS:\n//   - S_T: The robust CSW CUSUM statistic at time T.\n//\n// BEGIN\n//   SET T = length of log_price_series\n//   IF T < 2 THEN RETURN 0 // Not enough data to compute\n//\n//   // Step 1: Calculate the volatility estimate sigma_hat_T (Equation 2)\n//   SET sum_sq_diff = 0\n//   FOR i FROM 2 TO T:\n//     SET delta_y = log_price_series[i] - log_price_series[i-1]\n//     sum_sq_diff = sum_sq_diff + delta_y^2\n//   ENDFOR\n//   SET sigma_sq_T = sum_sq_diff / (T - 1)\n//   SET sigma_T = sqrt(sigma_sq_T)\n//\n//   IF sigma_T is 0 THEN RETURN 0 // Avoid division by zero if series is flat\n//\n//   // Step 2: Find the supremum of S_n,T over all possible start points n (Equation 4)\n//   SET max_S_statistic = -INFINITY\n//   SET y_T = log_price_series[T]\n//\n//   FOR n FROM 1 TO T-1:\n//     SET y_n = log_price_series[n]\n//     SET t_minus_n = T - n\n//\n//     // Calculate S_n,T for the current start point n (Equation 1)\n//     SET numerator = y_T - y_n\n//     SET denominator = sigma_T * sqrt(t_minus_n)\n//\n//     IF denominator > 0 THEN\n//       SET current_S_statistic = numerator / denominator\n//       IF current_S_statistic > max_S_statistic THEN\n//         max_S_statistic = current_S_statistic\n//       ENDIF\n//     ENDIF\n//   ENDFOR\n//\n//   SET S_T = max_S_statistic\n//   RETURN S_T\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 11,
    "text": "### Model Overview\nThe Chow-Type Dickey-Fuller test is designed to detect a specific type of structural break: a shift from a random walk process to an explosive (bubble) process. It assumes that this change occurs at a single, discrete point in time.\n\n- **[Definition] Explosive Process**: A time series process where the current value is expected to be a multiple greater than 1 of its previous value, leading to exponential growth. This is characteristic of a financial bubble.\n- **[Definition] SDFC Test**: The Supremum Dickey-Fuller Chow test. It extends the basic Chow-type test by searching across all plausible break dates and selecting the one that produces the most significant evidence of a bubble, making the test robust to an unknown break date.\n\n### Hypothesis Testing Framework\nThe test evaluates two competing hypotheses for a time series `y_t`:\n- **Null Hypothesis (`H_0`)**: The series follows a random walk for all `t`. (`锜?= 1`).\n- **Alternative Hypothesis (`H_1`)**: The series is a random walk up to a break date `锜?T` and then becomes an explosive process (`锜?> 1`) afterwards.\n\nTo test this, the following regression model is fitted:\n\n(Equation 1)\n$$ \\Delta y_{t} = \\delta y_{t - 1}D_{t}[\\tau^{*}] + \\epsilon_{t} $$\n\n- `铻杫_t`: The change in the series, `y_t - y_{t-1}`.\n- `y_{t-1}`: The lagged value of the series.\n- `鏈猔: The coefficient of interest. `鏈?= 锜?- 1`, so `H_0: 鏈?= 0` and `H_1: 鏈?> 0`.\n- `D_t[锜?]`: A dummy variable that is 0 if `t < 锜?T` and 1 if `t 閳?锜?T`.\n- `锜?`: The fraction of the sample at which the break occurs (`锜?` is between 0 and 1).\n- `T`: The total sample size.\n\nFor a *known* break date `锜?`, the test statistic is a standard t-statistic for the coefficient `鏈猔:\n\n(Equation 2)\n$$ DFC_{\\tau^{*}} = \\frac{\\hat{\\delta}}{\\hat{\\sigma}_{\\hat{\\delta}}} $$\n\n### Implementation for Unknown Break Date\nSince the break date `锜?` is almost always unknown, the SDFC test computes the `DFC` statistic for all possible break dates within a given range and takes the maximum (supremum) value.\n\n(Equation 3)\n$$ SDFC = \\sup_{\\tau^{*}\\in [\\tau_{0},1 - \\tau_{0}]}{DFC_{\\tau^{*}}} $$\n\n- `锜縚0`: A trimming parameter (e.g., 0.15) that defines the search interval for `锜?`. This ensures that both the pre-break and post-break regimes have a sufficient number of observations for a reliable regression estimate.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[SDFC Test Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the Supremum Dickey-Fuller Chow (SDFC) test. The function should take a time series `y` and a trimming parameter `锜縚0` as input and return the SDFC statistic.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateSDFC(y_series, tau_0)\n// INPUTS:\n//   - y_series: A time series of T values.\n//   - tau_0: The trimming parameter for the search interval (e.g., 0.15).\n// OUTPUTS:\n//   - sdfc_statistic: The Supremum Dickey-Fuller Chow statistic.\n//\n// BEGIN\n//   SET T = length of y_series\n//\n//   // Define the search range for the break date index\n//   SET start_index = floor(T * tau_0)\n//   SET end_index = floor(T * (1 - tau_0))\n//\n//   // Prepare the dependent and independent variables for the regression\n//   SET delta_y = differences of y_series (from t=2 to T)\n//   SET lagged_y = y_series shifted by 1 (from t=1 to T-1)\n//\n//   SET max_dfc_statistic = -INFINITY\n//\n//   // Loop through all possible break dates in the specified range\n//   FOR break_point_T_star FROM start_index TO end_index:\n//     // Construct the independent variable for this specific break point\n//     // X_t = y_{t-1} * D_t[tau*]\n//     INITIALIZE X_variable as a vector of zeros of length (T-1)\n//     FOR t FROM break_point_T_star TO T-1:\n//       X_variable[t] = lagged_y[t]\n//     ENDFOR\n//\n//     // Perform a simple linear regression without an intercept:\n//     // delta_y_t = delta * X_t + epsilon_t\n//     // This can be solved via OLS.\n//     SET regression_result = OLS(dependent=delta_y, independent=X_variable)\n//\n//     // Extract the t-statistic for the coefficient delta\n//     SET delta_hat = regression_result.coefficient\n//     SET sigma_hat_delta = regression_result.coefficient_standard_error\n//\n//     IF sigma_hat_delta > 0 THEN\n//       SET dfc_tau_star = delta_hat / sigma_hat_delta\n//       // Update the maximum statistic found so far\n//       IF dfc_tau_star > max_dfc_statistic THEN\n//         max_dfc_statistic = dfc_tau_star\n//       ENDIF\n//     ENDIF\n//   ENDFOR\n//\n//   SET sdfc_statistic = max_dfc_statistic\n//   RETURN sdfc_statistic\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 12,
    "text": "### Core Motivation\nStandard unit root tests are often ineffective at detecting financial bubbles because a cycle of bubble-and-bust can appear stationary overall. The Supremum Augmented Dickey-Fuller (SADF) test is specifically designed to overcome this by identifying periodically collapsing explosive behavior.\n\n- **[Definition] Supremum Augmented Dickey-Fuller (SADF)**: A recursive testing procedure that detects bubbles by repeatedly running an Augmented Dickey-Fuller (ADF) test on a series of backward-expanding sample windows. It does not assume a fixed number of breaks, making it suitable for detecting multiple bubble episodes.\n\n### ADF Regression Specification\nThe core of the SADF test is the standard ADF regression model, which is fitted to each data sample.\n\n(Equation 1)\n$$ \\Delta y_{t} = \\alpha +\\beta y_{t - 1} + \\sum_{l = 1}^{L}\\gamma_{l}\\Delta y_{t - l} + \\epsilon_{t} $$\n\n- `y_t`: The time series, typically log-prices for better statistical properties.\n- `铻杫_t`: The first difference of the series, `y_t - y_{t-1}`.\n- `浼猔: The intercept or drift term.\n- `灏綻: The key coefficient of interest. A significantly positive `灏綻 indicates explosive behavior.\n- `L`: The number of lagged difference terms included to remove serial correlation in the residuals `钄歘t`.\n\n### SADF Statistic Calculation\nUnlike tests that check for a single break, SADF computes a series of statistics over time. For each endpoint `t` in the dataset (starting from a minimum sample size `锜縛), the SADF statistic is the supremum (maximum) of all ADF test statistics calculated on samples that end at `t` but have varying start points `t_0`.\n\n(Equation 2)\n$$ SADF_{t} = \\sup_{t_{0}\\in [1,t - \\tau ]}\\left\\{\\frac{\\hat{\\beta}_{t_{0},t}}{\\hat{\\sigma}_{\\hat{\\beta}_{t_{0},t}}}\\right\\} $$\n\n- `SADF_t`: The SADF statistic for the fixed endpoint `t`.\n- `t_0`: The start point of the regression sample, which expands backward from `t-锜縛 down to `1`.\n- `锜縛: The minimum sample length required to run a reliable ADF regression.\n- `灏捐檭_{t_0,t}`: The estimated `灏綻 coefficient from the ADF regression on the sample from `t_0` to `t`.\n- `锜借檭_{灏捐檭_{t_0,t}}`: The standard error of the estimated `灏綻 coefficient for that same sample.\n\nThe fraction in the equation is the standard ADF t-statistic for the coefficient `灏綻 on the sample `[t_0, t]`.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[SADF Inner Loop Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the 'inner loop' of the SADF algorithm. This function should compute the `SADF_t` statistic for a single, specified endpoint `t`, given a full history of log-prices up to that point.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateSADF_For_Endpoint_t(log_price_series, t, min_sample_length, num_lags)\n// INPUTS:\n//   - log_price_series: A time series of log-prices up to at least time t.\n//   - t: The fixed endpoint for which to calculate the SADF statistic.\n//   - min_sample_length: The minimum sample size, tau (锜?.\n//   - num_lags: The number of lags, L, for the ADF regression.\n// OUTPUTS:\n//   - sadf_t: The SADF statistic for the endpoint t.\n//\n// BEGIN\n//   SET max_adf_statistic = -INFINITY\n//\n//   // Define the range for the backward-expanding window's start point\n//   // The last possible start point is t - min_sample_length + 1\n//   SET last_start_point = t - min_sample_length + 1\n//\n//   // Loop through all possible start points t_0 for the fixed endpoint t\n//   FOR t_0 FROM 1 TO last_start_point:\n//     // 1. Slice the data for the current window [t_0, t]\n//     SET current_window_series = log_price_series from index t_0 to t\n//\n//     // 2. Prepare the variables for the ADF regression (Equation 1)\n//     //    This involves creating the dependent variable (delta_y) and\n//     //    the independent variables (lagged_y, and lagged delta_y's).\n//     //    Note: The effective number of observations for regression will be\n//     //    (t - t_0 + 1) - num_lags - 1.\n//     LET (y_reg, X_reg) = PrepareADFData(current_window_series, num_lags)\n//\n//     // 3. Fit the ADF regression model: y_reg = alpha + beta*X_reg_col1 + ...\n//     IF y_reg has enough observations THEN\n//       SET regression_result = OLS(dependent=y_reg, independent=X_reg)\n//\n//       // 4. Get the t-statistic for the beta coefficient (the first independent var)\n//       SET beta_hat = regression_result.coefficients[1] // Coeff for lagged_y\n//       SET beta_std_err = regression_result.standard_errors[1]\n//\n//       IF beta_std_err > 0 THEN\n//         SET adf_statistic = beta_hat / beta_std_err\n//\n//         // 5. Update the supremum (maximum) ADF statistic\n//         IF adf_statistic > max_adf_statistic THEN\n//           max_adf_statistic = adf_statistic\n//         ENDIF\n//       ENDIF\n//     ENDIF\n//   ENDFOR\n//\n//   SET sadf_t = max_adf_statistic\n//   RETURN sadf_t\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 13,
    "text": "### Motivation for Robustness\nThe standard Supremum ADF (SADF) test uses the single maximum ADF value from all tested windows. This makes it highly sensitive to outliers, which can be caused by sampling frequency or specific timestamps, potentially leading to unstable estimates. The Quantile ADF (QADF) method provides a more robust alternative by summarizing the upper tail of the ADF statistics' distribution.\n\n### QADF Framework\nInstead of focusing only on the supremum, QADF uses quantiles to measure the characteristics of high ADF values. The process begins with the series of ADF statistics generated by the SADF inner loop for a fixed endpoint `t`.\n\n1.  **Generate ADF Series (`s_t`)**: For a fixed endpoint `t`, run the ADF test on all backward-expanding windows `[t_0, t]` to get a collection of ADF t-statistics.\n\n    (Equation 1)\n    $$ s_t = \\{ADF_{t_0,t}\\}_{t_0\\in [1,t - \\tau ]} $$\n\n2.  **Calculate QADF Metrics**: From the series `s_t`, two key metrics are derived:\n\n    - **[Definition] Centrality (`Q_{t,q}`):** This is the `q`-th quantile of the `s_t` distribution. It represents a typical high value, making it less sensitive to a single extreme outlier than the supremum. For example, `q=0.95` would give the 95th percentile of the ADF statistics.\n\n      (Equation 2)\n      $$ Q_{t,q} = \\text{Quantile}[s_t, q] $$\n\n    - **[Definition] Dispersion (`Q铏坃{t,q,璋搣`):** This measures the spread or range of the high ADF values. It is calculated as the difference between two quantiles symmetrically surrounding the main quantile `q`.\n\n      (Equation 3)\n      $$ \\dot{Q}_{t,q,\\nu} = Q_{t,q + \\nu} - Q_{t,q - \\nu} $$\n\n      - `q`: The primary quantile of interest (e.g., 0.95).\n      - `璋揱: A small value defining the width of the dispersion interval (e.g., 0.025), subject to `0 < 璋?閳?min(q, 1-q)`.\n\nNote that the standard SADF is a special case of QADF where `q=1`, as `Q_{t,1}` is the supremum of `s_t`.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[QADF Metrics Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the QADF centrality and dispersion metrics. The function should take a pre-computed series of ADF statistics `s_t`, a quantile `q`, and a dispersion range `璋揱 as inputs.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateQADF(adf_series, q, nu)\n// INPUTS:\n//   - adf_series: A list or array of ADF t-statistics (s_t).\n//   - q: The primary quantile for the centrality measure (e.g., 0.95).\n//   - nu: The dispersion range parameter (e.g., 0.025).\n// OUTPUTS:\n//   - A pair of values: (centrality, dispersion).\n//\n// BEGIN\n//   // Basic input validation\n//   IF length of adf_series is 0 THEN\n//     RETURN (NULL, NULL)\n//   ENDIF\n//   IF NOT (0 < nu AND nu <= q AND nu <= (1-q)) THEN\n//     THROW error \"Invalid nu value. Must satisfy 0 < nu <= min(q, 1-q).\"\n//   ENDIF\n//\n//   // For accurate quantile calculation, the series should be sorted.\n//   SORT adf_series in ascending order.\n//\n//   // Step 1: Calculate Centrality (Q_t,q) (Equation 2)\n//   // The Quantile function finds the value at a given percentile.\n//   // For example, for a list of 100 items, the 0.95 quantile is the 95th item.\n//   SET centrality = Quantile(adf_series, q)\n//\n//   // Step 2: Calculate the upper and lower bounds for the dispersion measure\n//   SET upper_quantile_level = q + nu\n//   SET lower_quantile_level = q - nu\n//\n//   SET upper_quantile_value = Quantile(adf_series, upper_quantile_level)\n//   SET lower_quantile_value = Quantile(adf_series, lower_quantile_level)\n//\n//   // Step 3: Calculate Dispersion (dot(Q)_t,q,nu) (Equation 3)\n//   SET dispersion = upper_quantile_value - lower_quantile_value\n//\n//   RETURN (centrality, dispersion)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 14,
    "text": "### Alternative Robustness Approach\nAs an alternative to using quantiles (QADF), the Conditional ADF (CADF) method enhances robustness by computing the conditional moments (mean and standard deviation) of the ADF statistics that exceed a certain threshold. This approach directly measures the properties of the right tail of the distribution, which corresponds to the most explosive signals.\n\n### CADF Framework\nThe process starts with the same series of ADF statistics, `s_t`, generated for a fixed endpoint `t`.\n\n1.  **Generate ADF Series (`s_t`)**: For a fixed endpoint `t`, run the ADF test on all backward-expanding windows `[t_0, t]` to get a collection of ADF t-statistics.\n\n    (Equation 1)\n    $$ s_t = \\{ADF_{t_0,t}\\}_{t_0\\in [1,t - \\tau ]} $$\n\n2.  **Define the Tail of the Distribution**: First, a threshold is determined using a quantile `q` (e.g., `q=0.95`). This value, `Q_{t,q}`, separates the top `(1-q)*100%` of ADF statistics from the rest.\n\n3.  **Calculate CADF Metrics**: The metrics are the mean and standard deviation of only those ADF statistics in `s_t` that are greater than the threshold `Q_{t,q}`.\n\n    - **[Definition] Conditional Centrality (`C_{t,q}`):** This is the conditional expectation (the mean) of all ADF statistics in the tail of the distribution. It represents the average strength of the strong bubble signals.\n\n      (Equation 2)\n      $$ C_{t,q} = E[x \\mid x > Q_{t,q}], \\quad \\text{where } x \\in s_t $$\n\n    - **[Definition] Conditional Dispersion (`C铏坃{t,q}`):** This is the conditional standard deviation of the ADF statistics in the tail. It measures the volatility or consistency of the strong bubble signals.\n\n      (Equation 3)\n      $$ \\dot{C}_{t,q} = \\sqrt{E[(x - C_{t,q})^2 \\mid x > Q_{t,q}]}, \\quad \\text{where } x \\in s_t $$",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[CADF Metrics Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes the Conditional ADF (CADF) centrality and dispersion metrics. The function should take a pre-computed series of ADF statistics `s_t` and a quantile `q` as inputs.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateCADF(adf_series, q)\n// INPUTS:\n//   - adf_series: A list or array of ADF t-statistics (s_t).\n//   - q: The quantile used to define the tail of the distribution (e.g., 0.95).\n// OUTPUTS:\n//   - A pair of values: (conditional_centrality, conditional_dispersion).\n//\n// BEGIN\n//   // Basic input validation\n//   IF length of adf_series is 0 THEN\n//     RETURN (NULL, NULL)\n//   ENDIF\n//   IF NOT (0 < q < 1) THEN\n//     THROW error \"Invalid q value. Must be between 0 and 1.\"\n//   ENDIF\n//\n//   // Step 1: Determine the threshold value, Q_t,q\n//   SET threshold = Quantile(adf_series, q)\n//\n//   // Step 2: Filter the series to get only the values in the tail\n//   INITIALIZE empty list tail_series\n//   FOR value IN adf_series:\n//     IF value > threshold THEN\n//       APPEND value to tail_series\n//     ENDIF\n//   ENDFOR\n//\n//   // Check if the tail is empty\n//   IF length of tail_series is 0 THEN\n//     RETURN (NULL, NULL)\n//   ENDIF\n//\n//   // Step 3: Calculate Conditional Centrality (C_t,q) (Equation 2)\n//   // This is the mean of the values in the tail.\n//   SET conditional_centrality = Mean(tail_series)\n//\n//   // Step 4: Calculate Conditional Dispersion (dot(C)_t,q) (Equation 3)\n//   // This is the standard deviation of the values in the tail.\n//   SET conditional_dispersion = StandardDeviation(tail_series)\n//\n//   RETURN (conditional_centrality, conditional_dispersion)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 15,
    "text": "### Motivation\nWhile the ADF specification is standard for unit-root tests, financial bubbles may follow other functional forms of explosive growth. The Sub- and Super-Martingale Test (SMT) framework provides a way to test for explosiveness using alternative trend specifications, making it more flexible than ADF-based methods.\n\n### Alternative Trend Specifications\nThe SMT framework tests for an explosive time trend (`灏?閳?0`) by fitting one of several possible regression models. We are interested in both explosive growth (`灏?> 0`) and collapse (`灏?< 0`).\n\n1.  **Polynomial Trend 1 (SM-Poly1)**: `y_t = 浼?+ 绾瑃 + 灏総铏?+ 钄歘t`\n2.  **Polynomial Trend 2 (SM-Poly2)**: `log(y_t) = 浼?+ 绾瑃 + 灏総铏?+ 钄歘t`\n3.  **Exponential Trend (SM-Exp)**: `log(y_t) = log(浼? + 灏総 + 灏塤t`\n4.  **Power Trend (SM-Power)**: `log(y_t) = log(浼? + 灏緇og(t) + 灏塤t`\n\nIn each model, the coefficient `灏綻 captures the non-linear, explosive component of the trend.\n\n### Penalized SMT Statistic\nSimilar to SADF, the SMT statistic is computed by fitting the chosen model on backward-expanding windows and taking the supremum of the resulting t-statistics for the `灏綻 coefficient.\n\n- **[Definition] SMT Statistic**: The supremum of the absolute t-statistics for the `灏綻 coefficient across all tested sample windows. The absolute value is used because both explosive growth and collapse are of interest.\n\n(Equation 1)\n$$ SMT_{t} = \\sup_{t_{0}\\in [1,t - \\tau ]}\\left\\{\\frac{|\\hat{\\beta}_{t_{0},t}|}{\\hat{\\sigma}_{\\hat{\\beta}_{t_{0},t}}}\\right\\} $$\n\nHowever, this basic form is biased towards long-run bubbles, as the standard error of `灏綻 (`锜借檭_灏綻) naturally decreases with longer sample sizes. To counteract this, a penalization factor is introduced.\n\n- **[Definition] Penalization Factor (`锠乣)**: A coefficient between 0 and 1 that adjusts the test statistic to control its sensitivity to bubble duration. A `锠乣 near 0 favors long-run bubbles, while a `锠乣 near 1 gives more weight to short-run bubbles.\n\n(Equation 2)\n$$ SMT_{t} = \\sup_{t_{0}\\in [1,t - \\tau ]}\\left\\{\\frac{|\\hat{\\beta}_{t_{0},t}|}{\\hat{\\sigma}_{\\hat{\\beta}_{t_{0},t}}(t - t_{0})^{\\phi}}\\right\\} $$\n\n- `(t - t_0)`: The length of the current sample window.\n- `锠乣: The penalization factor. A common choice is `锠?0.5` to directly counteract the `sqrt(N)` effect on standard error.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Penalized SMT Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the penalized Sub- and Super-Martingale Test (SMT). The function should compute the `SMT_t` statistic for a single endpoint `t`, given a price series, a chosen model type, and a penalization factor `锠乣.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculatePenalizedSMT(series, t, min_sample_length, phi, model_type)\n// INPUTS:\n//   - series: A time series of prices or log-prices up to time t.\n//   - t: The fixed endpoint for which to calculate the SMT statistic.\n//   - min_sample_length: The minimum sample size, tau (锜?.\n//   - phi: The sample-length penalization factor (锠?, between 0 and 1.\n//   - model_type: A string indicating the model to use ('Poly1', 'Poly2', 'Exp', 'Power').\n// OUTPUTS:\n//   - smt_t: The penalized SMT statistic for the endpoint t.\n//\n// BEGIN\n//   SET max_penalized_stat = -INFINITY\n//\n//   // Define the range for the backward-expanding window's start point\n//   SET last_start_point = t - min_sample_length + 1\n//\n//   // Loop through all possible start points t_0\n//   FOR t_0 FROM 1 TO last_start_point:\n//     // 1. Slice the data for the current window [t_0, t]\n//     SET current_window = series from index t_0 to t\n//     SET sample_length = t - t_0 + 1\n//\n//     // 2. Prepare the dependent (y_reg) and independent (X_reg) variables\n//     //    based on the specified model_type.\n//     //    For example, for 'Power' model on a price series:\n//     //      y_reg would be log(current_window)\n//     //      X_reg would be a matrix with a column of ones (for log(alpha))\n//     //      and a column of log(time indices from t_0 to t) (for beta).\n//     LET (y_reg, X_reg) = PrepareRegressionData(current_window, model_type)\n//\n//     // 3. Fit the specified linear regression model\n//     SET regression_result = OLS(dependent=y_reg, independent=X_reg)\n//\n//     // 4. Extract the estimate and standard error for the beta coefficient.\n//     //    Beta is the coefficient for the highest-order term (t^2, t, or log(t)).\n//     SET beta_hat = regression_result.coefficients['beta_term']\n//     SET beta_std_err = regression_result.standard_errors['beta_term']\n//\n//     IF beta_std_err > 0 THEN\n//       // 5. Calculate the penalized statistic for this window (Equation 2)\n//       SET numerator = absolute_value(beta_hat)\n//       SET denominator = beta_std_err * (sample_length ^ phi)\n//\n//       IF denominator > 0 THEN\n//         SET penalized_stat = numerator / denominator\n//\n//         // 6. Update the supremum (maximum) statistic\n//         IF penalized_stat > max_penalized_stat THEN\n//           max_penalized_stat = penalized_stat\n//         ENDIF\n//       ENDIF\n//     ENDIF\n//   ENDFOR\n//\n//   SET smt_t = max_penalized_stat\n//   RETURN smt_t\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 16,
    "text": "### Framework Overview\nIn a double auction market, every trade has an initiator, or aggressor. The Tick Rule is a simple yet effective algorithm for inferring the aggressor's side (buy or sell) by observing the sequence of trade prices. It is a foundational technique in market microstructure analysis.\n\n### Key Concepts\n- **[Definition] Double Auction Book**: A market structure where potential buyers submit bids (prices they are willing to pay) and potential sellers submit offers (prices they are willing to accept). A trade occurs when a bid and offer are matched.\n- **[Definition] Trade Aggressor**: The party in a trade who initiates the transaction by accepting a standing quote. A buyer who accepts an offer is a buy-aggressor; a seller who accepts a bid is a sell-aggressor.\n\n### Computational Steps\nThe aggressor side for a trade at time `t`, denoted `b_t`, is determined by the change in price from the previous trade. A buy-initiated trade is labeled `1`, and a sell-initiated trade is labeled `-1`.\n\nThe logic is defined by Equation 1:\n\n**Equation 1: The Tick Rule**\n```\nb_{t} = \n  CASE\n    WHEN 铻杙_{t} > 0 THEN 1\n    WHEN 铻杙_{t} < 0 THEN -1\n    WHEN 铻杙_{t} = 0 THEN b_{t-1}\n  END\n```\n\nWhere:\n- `b_t`: The aggressor side for the trade at time `t`.\n- `p_t`: The price of the trade at time `t`.\n- `铻杙_t`: The change in price, calculated as `p_t - p_{t-1}`.\n- `b_{t-1}`: The aggressor side of the previous trade. The initial value, `b_0`, is typically set to `1`.",
    "question": "Provide the pseudocode for a function that implements the Tick Rule algorithm to classify a sequence of trade prices.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ClassifyTradesByTickRule(prices)\n// INPUTS:\n//   - prices: A list or array of trade prices in chronological order.\n// OUTPUTS:\n//   - A list or array of aggressor side classifications (1 for buy, -1 for sell).\n//\n// BEGIN\n//   IF prices is empty or has fewer than 2 elements THEN\n//     RETURN an empty list\n//   END IF\n//\n//   // Initialize the list of aggressor sides and set the initial value b_0 = 1.\n//   aggressor_sides = []\n//   previous_b = 1\n//\n//   // The first trade has no preceding price, so we cannot classify it based on a change.\n//   // Depending on convention, one might skip it or assign a default.\n//   // For this implementation, we start classifying from the second trade.\n//\n//   FOR t FROM 1 TO length(prices) - 1\n//     price_change = prices[t] - prices[t-1]\n//\n//     // Apply the Tick Rule logic from Equation 1.\n//     IF price_change > 0 THEN\n//       current_b = 1\n//     ELSE IF price_change < 0 THEN\n//       current_b = -1\n//     ELSE // price_change is 0\n//       current_b = previous_b\n//     END IF\n//\n//     // Store the result and update the previous aggressor side for the next iteration.\n//     ADD current_b TO aggressor_sides\n//     previous_b = current_b\n//   END FOR\n//\n//   RETURN aggressor_sides\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 17,
    "text": "### Framework Overview\nThe Roll Model provides a method for estimating a security's effective bid-ask spread using only the time series of transaction prices. It is particularly useful for illiquid assets where reliable quote data is unavailable. The model is based on the insight that trades bouncing between the bid and ask induce negative serial correlation in price changes.\n\n### Key Concepts\n- **[Definition] Effective Bid-Ask Spread**: The actual spread paid by a trader, which accounts for the fact that trades can occur inside the quoted spread. The Roll Model estimates this effective spread.\n- **[Definition] Serial Covariance**: A measure of the relationship between a variable and a lagged version of itself. In this model, the lag-1 autocovariance of price changes is key.\n\n### Model and Assumptions\nThe model assumes an unobserved mid-price, `m_t`, follows a random walk. The observed transaction price, `p_t`, is the mid-price plus or minus half the spread, `c`, depending on the trade's aggressor side, `b_t`.\n\n**Equation 1: Observed Price**\n```\np_t = m_t + b_t * c\n```\nWhere:\n- `p_t`: The observed price of the trade at time `t`.\n- `m_t`: The unobserved mid-price at time `t`.\n- `b_t`: The aggressor side (`1` for a buy, `-1` for a sell).\n- `c`: Half the effective bid-ask spread.\n\nUnder assumptions of equally likely and independent buys/sells, the model derives the relationship between the spread and the covariance of price changes.\n\n### Estimation Formulas\nThe covariance of consecutive price changes, `铻杙_t`, is related to the half-spread `c` as follows:\n\n**Equation 2: Covariance of Price Changes**\n```\n锜絒铻杙_t, 铻杙_{t-1}] = -c铏廫n```\n\nFrom this, we can solve for `c` to estimate the half-spread:\n\n**Equation 3: Half-Spread Estimation**\n```\nc = sqrt(max(0, -锜絒铻杙_t, 铻杙_{t-1}]))\n```\n\nWhere:\n- `锜絒铻杙_t, 铻杙_{t-1}]`: The sample covariance between the series of price changes (`p_t - p_{t-1}`) and its one-period lag.\n\nThe full effective spread is `2 * c`.",
    "question": "Provide the pseudocode for a function that implements the Roll Model to estimate the full effective bid-ask spread from a series of transaction prices.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION EstimateRollSpread(prices)\n// INPUTS:\n//   - prices: A list or array of trade prices in chronological order.\n// OUTPUTS:\n//   - The estimated full effective bid-ask spread. Returns 0 if calculation is not possible.\n//\n// BEGIN\n//   IF prices is empty or has fewer than 3 elements THEN\n//     // Need at least 3 prices to get 2 price changes for covariance.\n//     RETURN 0.0\n//   END IF\n//\n//   // Step 1: Calculate the series of price changes.\n//   price_changes = []\n//   FOR t FROM 1 TO length(prices) - 1\n//     ADD (prices[t] - prices[t-1]) TO price_changes\n//   END FOR\n//\n//   // Step 2: Calculate the lag-1 autocovariance of the price changes.\n//   // This is Cov(price_changes[1:], price_changes[:-1])\n//   series1 = slice(price_changes, 1, end)\n//   series2 = slice(price_changes, 0, end-1)\n//   \n//   // Standard covariance calculation\n//   mean1 = calculate_mean(series1)\n//   mean2 = calculate_mean(series2)\n//   covariance_sum = 0\n//   FOR i FROM 0 TO length(series1) - 1\n//     covariance_sum = covariance_sum + (series1[i] - mean1) * (series2[i] - mean2)\n//   END FOR\n//   autocovariance = covariance_sum / (length(series1) - 1)\n//\n//   // Step 3: Apply Equation 3 to estimate the half-spread 'c'.\n//   // The max(0, ...) handles cases where autocovariance is positive, which violates model assumptions.\n//   half_spread_squared = max(0, -autocovariance)\n//   half_spread = sqrt(half_spread_squared)\n//\n//   // Step 4: The full spread is 2 * c.\n//   full_spread = 2 * half_spread\n//\n//   RETURN full_spread\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 18,
    "text": "### Framework Overview\nStandard volatility estimators often use closing prices, which can be inefficient as they ignore price movements within a trading bar. The Parkinson High-Low Volatility Estimator, derived from the work of Parkinson (1980), provides a more accurate estimate by incorporating the high and low prices of each bar, assuming prices follow a geometric Brownian motion.\n\n### Key Concepts\n- **[Definition] High-Low Volatility Estimator**: A method for calculating the statistical volatility of a financial instrument using the highest and lowest prices recorded during a period (bar).\n- **[Definition] Geometric Brownian Motion**: A stochastic process often used to model asset prices, where the logarithm of the price follows a Brownian motion with drift.\n\n### Estimation Formulas\nFor a series of `T` price bars, Parkinson derived two relationships. We will focus on the second for this problem.\n\n**Equation 1: Estimator from Squared Log Ratio**\n```\nE[ (1/T) * 鍗?log(H_t / L_t))铏?] = k閳?* 锜借檹_HL\n```\n\n**Equation 2: Estimator from Log Ratio**\n```\nE[ (1/T) * 鍗?log(H_t / L_t)) ] = k閳?* 锜絖HL\n```\n\nWhere:\n- `H_t`: The high price for bar `t`.\n- `L_t`: The low price for bar `t`.\n- `T`: The total number of bars in the sample.\n- `锜絖HL`: The high-low volatility feature to be estimated.\n- `k閳т梗: A constant equal to `4 * log(2)`.\n- `k閳т繖: A constant equal to `sqrt(8 / 锜?`.\n\nBy rearranging Equation 2, we can solve for `锜絖HL` using the sample mean of the log high-low ratio.",
    "question": "Provide the pseudocode for a function that implements the Parkinson volatility estimator using the relationship described in Equation 2.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION EstimateParkinsonVolatility(high_prices, low_prices)\n// INPUTS:\n//   - high_prices: A list or array of high prices for each bar.\n//   - low_prices: A list or array of low prices for each bar.\n// OUTPUTS:\n//   - The estimated Parkinson high-low volatility (锜絖HL).\n//\n// BEGIN\n//   IF length(high_prices) != length(low_prices) OR length(high_prices) == 0 THEN\n//     RETURN 0.0 // Or raise an error for invalid input\n//   END IF\n//\n//   // Define the constant k閳?from Equation 2.\n//   CONSTANT PI = 3.1415926535\n//   CONSTANT k2 = sqrt(8 / PI)\n//\n//   // Step 1: Calculate the log of the high-to-low ratio for each bar.\n//   log_ratios = []\n//   FOR t FROM 0 TO length(high_prices) - 1\n//     IF low_prices[t] <= 0 THEN\n//       // Skip bars with invalid low prices to avoid division by zero or log of non-positive number.\n//       CONTINUE\n//     END IF\n//     ratio = high_prices[t] / low_prices[t]\n//     ADD log(ratio) TO log_ratios\n//   END FOR\n//\n//   IF length(log_ratios) == 0 THEN\n//     RETURN 0.0\n//   END IF\n//\n//   // Step 2: Calculate the sample mean of the log ratios.\n//   // This corresponds to the term E[...] in Equation 2.\n//   mean_log_ratio = calculate_mean(log_ratios)\n//\n//   // Step 3: Rearrange Equation 2 to solve for 锜絖HL.\n//   // 锜絖HL = E[...] / k閳т繐n//   volatility_estimate = mean_log_ratio / k2\n//\n//   RETURN volatility_estimate\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 19,
    "text": "### Framework Overview\nThe Corwin and Schultz (2012) model provides an estimate of the bid-ask spread using only daily high and low prices. It is built on two principles: 1) The high-low price ratio reflects both fundamental volatility and the bid-ask spread, and 2) The volatility component of this ratio grows with the length of the observation period.\n\n### Key Concepts\n- **[Definition] Corwin-Schultz Spread Estimator**: A model that disentangles the bid-ask spread from volatility in high-low price data by comparing single-day price ranges to two-day price ranges.\n\n### Computational Steps\nThe algorithm estimates the spread, `S_t`, as a percentage of price, through a series of intermediate calculations.\n\n**Step 1: Calculate Beta (`灏綺t`)**\nBeta captures the sum of squared log high-low ratios over two consecutive periods (e.g., days `t` and `t-1`).\n\n**Equation 1: Beta Component**\n```\n灏綺t = [log(H_t / L_t)]铏?+ [log(H_{t-1} / L_{t-1})]铏廫n```\n\n**Step 2: Calculate Gamma (`绾琠t`)**\nGamma captures the squared log ratio of the high and low over the combined two-period interval.\n\n**Equation 2: Gamma Component**\n```\n绾琠t = [log(H_{t-1,t} / L_{t-1,t})]铏廫n```\n\n**Step 3: Calculate Alpha (`浼猒t`)**\nAlpha combines Beta and Gamma to isolate the spread component.\n\n**Equation 3: Alpha Component**\n```\n浼猒t = (sqrt(2*灏綺t) - sqrt(灏綺t)) / (3 - 2*sqrt(2))  -  sqrt(绾琠t / (3 - 2*sqrt(2)))\n```\n*Note*: If `浼猒t` is calculated to be negative, it should be set to 0, as a negative spread is nonsensical.\n\n**Step 4: Calculate the Spread (`S_t`)**\nFinally, the spread is derived from alpha.\n\n**Equation 4: Spread Estimation**\n```\nS_t = (2 * (e^浼猒t - 1)) / (1 + e^浼猒t)\n```\n\nWhere:\n- `H_t`, `L_t`: High and low prices for period `t`.\n- `H_{t-1,t}`: The highest price over periods `t-1` and `t`.\n- `L_{t-1,t}`: The lowest price over periods `t-1` and `t`.",
    "question": "Provide the pseudocode for a function that implements the complete Corwin-Schultz spread estimator for a given time `t`, using the high and low prices from periods `t` and `t-1`.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION EstimateCorwinSchultzSpread(high_t, low_t, high_t_minus_1, low_t_minus_1)\n// INPUTS:\n//   - high_t: High price for the current period t.\n//   - low_t: Low price for the current period t.\n//   - high_t_minus_1: High price for the previous period t-1.\n//   - low_t_minus_1: Low price for the previous period t-1.\n// OUTPUTS:\n//   - The estimated spread (S_t) as a percentage.\n//\n// BEGIN\n//   // Step 1: Calculate Beta (灏綺t) as per Equation 1.\n//   log_ratio_t = log(high_t / low_t)\n//   log_ratio_t_minus_1 = log(high_t_minus_1 / low_t_minus_1)\n//   beta = (log_ratio_t)^2 + (log_ratio_t_minus_1)^2\n//\n//   // Step 2: Calculate Gamma (绾琠t) as per Equation 2.\n//   two_period_high = max(high_t, high_t_minus_1)\n//   two_period_low = min(low_t, low_t_minus_1)\n//   gamma = (log(two_period_high / two_period_low))^2\n//\n//   // Step 3: Calculate Alpha (浼猒t) as per Equation 3.\n//   denominator = 3 - 2 * sqrt(2)\n//   term1 = (sqrt(2 * beta) - sqrt(beta)) / denominator\n//   term2 = sqrt(gamma / denominator)\n//   alpha = term1 - term2\n//\n//   // As per the model's specification, set negative alphas to 0.\n//   IF alpha < 0 THEN\n//     alpha = 0\n//   END IF\n//\n//   // Step 4: Calculate the final spread (S_t) as per Equation 4.\n//   spread = (2 * (exp(alpha) - 1)) / (1 + exp(alpha))\n//\n//   RETURN spread\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 20,
    "text": "### Framework Overview\nHasbrouck's (2009) model extends the ideas of Kyle and Amihud to estimate a price impact coefficient from trade-and-quote (TAQ) data. It refines the relationship between price changes and order flow by using the square root of dollar volume, which often provides a better fit for the non-linear nature of market impact.\n\n### Key Concepts\n- **[Definition] Hasbrouck's Lambda (浣?**: A measure of price impact, estimated by regressing log price changes against the sum of signed square-root dollar volumes within a bar.\n- **[Definition] Signed Square-Root Dollar Volume**: For a single trade, this is the trade's aggressor flag (`+1` for buy, `-1` for sell) multiplied by the square root of its dollar volume (`price * volume`).\n\n### Estimation Model\nThe model is specified as a regression of log price changes on the aggregated signed square-root dollar volume for each bar.\n\n**Equation 1: Hasbrouck's Lambda Regression**\n```\nlog(p铏刜{i,锜縸) - log(p铏刜{i,锜?1}) = 浣峗i * (鍗盻{t閳湐_{i,锜縸} b_{i,t} * sqrt(p_{i,t} * V_{i,t})) + 钄歘{i,锜縸\n```\n\nWhere:\n- `i`: The security index.\n- `锜縛: The bar index.\n- `p铏刜{i,锜縸`: The closing price of bar `锜縛 for security `i`.\n- `浣峗i`: Hasbrouck's Lambda for security `i`.\n- `B_{i,锜縸`: The set of all trades in bar `锜縛 for security `i`.\n- `b_{i,t}`: The aggressor flag (`+1` or `-1`) for trade `t`.\n- `p_{i,t} * V_{i,t}`: The dollar volume of trade `t`.\n- The term `鍗?...)` is the independent variable: the sum of signed square-root dollar volumes for all trades within bar `锜縛.",
    "question": "Provide the pseudocode for a function that takes a list of bars (where each bar contains a list of its constituent trades) and computes the two series needed for the Hasbrouck's Lambda regression: the inter-bar log returns, and the aggregated signed square-root dollar volume for each bar.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PrepareHasbrouckRegressionData(bars)\n// INPUTS:\n//   - bars: A list of bar objects. Each bar object should contain:\n//     - 'close_price': The closing price of the bar.\n//     - 'trades': A list of trade objects, where each trade has 'price', 'volume', and 'aggressor_flag'.\n// OUTPUTS:\n//   - A pair of lists: (dependent_variable, independent_variable).\n//     - dependent_variable: List of log price changes between bars.\n//     - independent_variable: List of aggregated signed sqrt dollar volumes for each bar.\n//\n// BEGIN\n//   log_returns = []\n//   signed_sqrt_dollar_volumes = []\n//\n//   // We need the previous bar's close price to calculate the return, so we start from the second bar.\n//   FOR tau FROM 1 TO length(bars) - 1\n//     // Calculate the dependent variable: log price change.\n//     previous_close = bars[tau-1].close_price\n//     current_close = bars[tau].close_price\n//     IF previous_close > 0 AND current_close > 0 THEN\n//       current_log_return = log(current_close) - log(previous_close)\n//       ADD current_log_return TO log_returns\n//     ELSE\n//       // Skip if prices are invalid.\n//       CONTINUE\n//     END IF\n//\n//     // Calculate the independent variable for the current bar (tau).\n//     current_bar_trades = bars[tau].trades\n//     aggregated_value = 0\n//     FOR each trade IN current_bar_trades\n//       dollar_volume = trade.price * trade.volume\n//       IF dollar_volume >= 0 THEN\n//         signed_sqrt_dv = trade.aggressor_flag * sqrt(dollar_volume)\n//         aggregated_value = aggregated_value + signed_sqrt_dv\n//       END IF\n//     END FOR\n//     ADD aggregated_value TO signed_sqrt_dollar_volumes\n//   END FOR\n//\n//   // Ensure both lists are of the same length before returning.\n//   // The loop structure naturally produces lists of length(bars)-1.\n//\n//   RETURN (log_returns, signed_sqrt_dollar_volumes)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 21,
    "text": "### Framework Overview\nThe Volume-Synchronized Probability of Informed Trading (VPIN) is a high-frequency estimator of the Probability of Information-based Trading (PIN). It is designed to detect order flow toxicity in real-time by measuring the degree of order imbalance. The key innovation is its use of a volume clock, where data is sampled every time a fixed amount of volume `V` is traded, making the analysis robust to fluctuations in trading activity.\n\n### Key Concepts\n- **[Definition] VPIN**: An indicator that estimates the probability of informed trading by calculating the ratio of absolute order imbalance to total volume over a series of volume bars.\n- **[Definition] Volume Clock**: A method of sampling data based on cumulative volume rather than time. A new \"bar\" is formed whenever a predefined quantum of volume has been traded.\n- **[Definition] Order Imbalance**: The absolute difference between buy-initiated volume and sell-initiated volume within a bar, `|V_B - V_S|`.\n\n### Estimation Formula\nVPIN is calculated over a rolling window of `n` volume bars. Since each bar is constructed to have the same total volume `V`, the total volume over the window is simply `n * V`.\n\n**Equation 1: VPIN Calculation**\n```\nVPIN_锜?= (鍗盻{i=1 to n} |V_{锜?i+1}^B - V_{锜?i+1}^S|) / (n * V)\n```\n\nWhere:\n- `VPIN_锜縛: The VPIN value calculated at the end of bar `锜縛.\n- `n`: The number of volume bars in the rolling window.\n- `V_{锜?i+1}^B`: The sum of volumes from buy-initiated trades within bar `锜?i+1`.\n- `V_{锜?i+1}^S`: The sum of volumes from sell-initiated trades within bar `锜?i+1`.\n- `V`: The fixed total volume of each bar (i.e., `V = V^B + V^S` for any bar).",
    "question": "Provide the pseudocode for a function that calculates a single VPIN value given a window of `n` volume bars.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateVPIN(volume_bar_window)\n// INPUTS:\n//   - volume_bar_window: A list or array of the most recent 'n' volume bars.\n//     Each bar is an object with 'buy_volume' and 'sell_volume' properties.\n// OUTPUTS:\n//   - The calculated VPIN value as a float. Returns 0 if input is invalid.\n//\n// BEGIN\n//   // Step 1: Validate input.\n//   IF volume_bar_window is empty THEN\n//     RETURN 0.0\n//   END IF\n//\n//   // Step 2: Calculate the numerator of the VPIN formula.\n//   // This is the sum of absolute order imbalances over the window.\n//   total_imbalance = 0\n//   FOR each bar IN volume_bar_window\n//     imbalance = abs(bar.buy_volume - bar.sell_volume)\n//     total_imbalance = total_imbalance + imbalance\n//   END FOR\n//\n//   // Step 3: Calculate the denominator of the VPIN formula.\n//   // Get the fixed volume 'V' from the first bar in the window.\n//   // Get the window size 'n'.\n//   fixed_bar_volume_V = volume_bar_window[0].buy_volume + volume_bar_window[0].sell_volume\n//   window_size_n = length(volume_bar_window)\n//\n//   IF fixed_bar_volume_V <= 0 THEN\n//     // Avoid division by zero if volume is zero.\n//     RETURN 0.0\n//   END IF\n//\n//   total_window_volume = window_size_n * fixed_bar_volume_V\n//\n//   // Step 4: Compute the final VPIN value.\n//   vpin_value = total_imbalance / total_window_volume\n//\n//   RETURN vpin_value\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 22,
    "text": "### Framework Overview\nMarket microstructure theory suggests that the persistence of order flow imbalance can indicate the presence of informed traders. When informed traders split large orders into smaller pieces to avoid detection, they create a sequence of trades with the same aggressor side (all buys or all sells). This behavior results in positive autocorrelation in the signed order flow series.\n\n### Key Concepts\n- **[Definition] Signed Order Flow**: A time series representing the direction and size of aggressive trades. It is typically calculated as `b_t * V_t`, where `b_t` is the aggressor flag (`+1` for buy, `-1` for sell) and `V_t` is the volume for a given bar or trade `t`.\n- **[Definition] Serial Correlation (Autocorrelation)**: The correlation of a time series with a lagged version of itself. A positive lag-1 autocorrelation means that a positive value is likely to be followed by another positive value, and a negative value by another negative value, indicating persistence.\n\n### Feature Application\nBy calculating the lag-1 autocorrelation of signed order flow over a rolling window, we can create a dynamic feature that measures the current degree of order flow persistence. A high positive value suggests that informed traders may be active, potentially foreshadowing a price move in the direction of the imbalance.",
    "question": "Provide the pseudocode for a function that computes the rolling lag-1 autocorrelation of a signed volume series.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION RollingLag1Autocorrelation(series, window_size)\n// INPUTS:\n//   - series: A list or array of signed order flow values.\n//   - window_size: The number of observations to include in each rolling window.\n// OUTPUTS:\n//   - A list of rolling lag-1 autocorrelation values.\n//\n// BEGIN\n//   autocorrelation_results = []\n//\n//   // The loop starts at window_size because we need a full window of data to compute the first value.\n//   FOR i FROM window_size TO length(series)\n//     // Extract the current window of data.\n//     current_window = slice(series, i - window_size, i)\n//\n//     // Create the two series for correlation: the series and its lag-1 version.\n//     // Y_t: The series from the second element to the end of the window.\n//     // Y_t_minus_1: The series from the first element to the second-to-last.\n//     Y_t = slice(current_window, 1, end)\n//     Y_t_minus_1 = slice(current_window, 0, end - 1)\n//\n//     // Calculate the Pearson correlation between Y_t and Y_t_minus_1.\n//     // This is a standard statistical function.\n//     correlation_value = calculate_pearson_correlation(Y_t, Y_t_minus_1)\n//\n//     ADD correlation_value TO autocorrelation_results\n//   END FOR\n//\n//   RETURN autocorrelation_results\n// END\n//\n// --- HELPER FUNCTION --- \n// FUNCTION calculate_pearson_correlation(X, Y)\n//   // Standard implementation of Pearson correlation coefficient:\n//   // Cov(X, Y) / (StdDev(X) * StdDev(Y))\n//   // ... implementation details omitted for brevity ...\n//   RETURN correlation\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 23,
    "text": "### Framework Overview\nTraditional microstructure literature often treats 'information' as an abstract concept. This framework proposes a rigorous, quantitative definition: microstructural information is the complexity faced by a market maker's predictive model. It is measured by how surprised the model is by a new market outcome, where surprise is quantified by cross-entropy loss. High loss (high surprise) indicates the presence of asymmetric information that the model cannot explain.\n\n### Key Concepts\n- **[Definition] Cross-Entropy Loss**: A metric from information theory that measures the performance of a classification model whose output is a probability value. It quantifies the 'surprise' or difference between the predicted probability and the actual outcome.\n- **[Definition] Kernel Density Estimator (KDE)**: A non-parametric way to estimate the probability density function (PDF) of a random variable, allowing for the creation of a smooth curve from a set of data points.\n- **[Definition] Cumulative Distribution Function (CDF)**: A function that gives the probability that a random variable will take a value less than or equal to a specific value.\n\n### The Six-Step Process\nThe full process to calculate the information metric `锠乣 is as follows:\n1.  **Labeling**: Create labels (`y`) indicating profitable (1) or unprofitable (0) market-making outcomes.\n2.  **Classifier Fitting**: Train a classifier (e.g., logistic regression) on features (`X`) to predict these labels.\n3.  **Prediction**: Use the trained classifier on new, out-of-sample data to get probability predictions (`娆).\n4.  **Loss Calculation**: For each prediction, calculate the cross-entropy loss, `L`.\n5.  **KDE Fitting**: Fit a KDE on a historical array of *negative* cross-entropy losses (`{-L_t}`). This estimates the distribution of model performance.\n6.  **Information Estimation**: The microstructural information `锠乣 for a new observation with loss `L_锜縛 is calculated as `锠乢锜?= F(-L_锜?`, where `F` is the CDF derived from the KDE fit in the previous step. A value of `锠乣 near 1 indicates a very high-loss (surprising) event, signaling significant microstructural information.",
    "question": "Provide the pseudocode for a function that implements Step 5 and Step 6 of the process. The function should take a history of negative cross-entropy losses and a new negative loss value, and return the final microstructural information metric `锠乣.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateMicrostructuralInfo(historical_neg_losses, new_neg_loss)\n// INPUTS:\n//   - historical_neg_losses: A list or array of historical negative cross-entropy loss values.\n//   - new_neg_loss: The new negative cross-entropy loss value to be evaluated.\n// OUTPUTS:\n//   - The microstructural information metric 'phi' (a value between 0 and 1).\n//\n// BEGIN\n//   // Step 5: Fit a Kernel Density Estimator (KDE) on the historical data.\n//   // This step creates an object 'kde' that represents the estimated probability density function (PDF).\n//   // The specific implementation details (e.g., bandwidth selection) depend on the library used.\n//   kde_model = fit_kde(historical_neg_losses)\n//\n//   // Step 6: Use the fitted KDE to compute the Cumulative Distribution Function (CDF) value for the new loss.\n//   // The CDF, F(x), is the integral of the PDF from negative infinity to x.\n//   // Most statistical libraries provide a method to compute the CDF from a fitted KDE.\n//   // This value represents the probability that a random loss from this distribution\n//   // is less than or equal to the new_neg_loss.\n//   phi = kde_model.cdf(new_neg_loss)\n//\n//   // The result 'phi' is the microstructural information metric.\n//   RETURN phi\n// END\n//\n// --- PSEUDO-LIBRARY FUNCTIONS ---\n// FUNCTION fit_kde(data)\n//   // Represents a library function that takes numerical data and returns a fitted KDE object.\n//   // The returned object has methods like .pdf(x) and .cdf(x).\n//   RETURN a_kde_object\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 24,
    "text": "In high-performance computing, many tasks involve two nested loops, such as computing a covariance matrix or evaluating multiple financial barriers. When the inner loop's iteration count depends on the outer loop's index (e.g., `for i in 1..N: for j in 1..i:`), the workload is not uniform. The first few iterations of the outer loop generate few tasks, while later iterations generate many. A simple linear partition of tasks would lead to severe load imbalance, with some processors finishing quickly while others are still working on the heavier tasks. The Two-Nested Loops Partitioning algorithm solves this by creating partitions (molecules) with an approximately equal number of atomic tasks, ensuring all processors remain busy for a similar duration.\n\nKey Concepts\n- [Definition] Atomic Tasks: The most granular, indivisible units of computation. In a nested loop structure `for i in 1..N: for j in 1..i:`, each `(i, j)` pair represents one atomic task.\n- [Definition] Molecules: A group of atomic tasks assigned to a single processor for sequential execution. The goal of partitioning is to create molecules of roughly equal computational weight.\n\nComputational Steps\nConsider a set of atomic tasks structured as a lower-triangular matrix from two nested loops, where the outer loop iterates `i = 1, ..., N`. The total number of operations is `(1/2) * N * (N + 1)`.\n\nTo partition these tasks among `M` processors, we must find the row indices `r_1, r_2, ..., r_M` that define the boundaries of each molecule. Each molecule should contain approximately `(1 / (2M)) * N * (N + 1)` tasks.\n\nThe algorithm iteratively determines these boundaries.\n\n1.  **First Partition Boundary (r_1)**: The first molecule consists of rows `1` to `r_1`. The number of tasks is `(1/2) * r_1 * (r_1 + 1)`. Setting this equal to the target task count per processor and solving for `r_1` yields the positive root:\n\n    ```\n    Equation 1: r_1 = (-1 + sqrt(1 + 4 * N * (N + 1) / M)) / 2\n    ```\n\n2.  **General Partition Boundary (r_m)**: For any subsequent molecule `m` (from `m=2` to `M`), which contains rows from `r_{m-1} + 1` to `r_m`, the number of tasks is `(1/2) * (r_m + r_{m-1} + 1) * (r_m - r_{m-1})`. Setting this equal to the target task count gives the recursive formula for the boundary `r_m`:\n\n    ```\n    Equation 2: r_m = (-1 + sqrt(1 + 4 * (r_{m-1}^2 + r_{m-1} + N * (N + 1) / M))) / 2\n    ```\n\n    Note that Equation 2 simplifies to Equation 1 when `m=1` by setting `r_0 = 0`. Since row indices must be integers, the calculated `r_m` values are rounded to the nearest whole number.",
    "question": "Implement the Two-Nested Loops Partitioning algorithm in pseudocode. The function should accept the total number of outer loop iterations (`N`) and the number of processors (`M`) as input. It must return a list of integer indices that define the partition boundaries, ensuring a balanced workload for a lower-triangular task structure.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION nestedParts(numAtoms, numProcessors)\n// INPUTS:\n//   - numAtoms (N): The total number of iterations in the outer loop (e.g., rows).\n//   - numProcessors (M): The number of parallel processors to distribute the work across.\n// OUTPUTS:\n//   - An array of integer indices representing the partition boundaries. The array will have\n//     length numProcessors + 1, starting with 0.\n//\n// BEGIN\n//   // Initialize the list of partition boundaries, starting with the 0-th row.\n//   partitions = [0]\n//\n//   // Calculate the total number of atomic tasks in the lower-triangular structure.\n//   total_tasks = numAtoms * (numAtoms + 1)\n//\n//   // Loop through each processor to determine its corresponding partition boundary.\n//   FOR m FROM 1 TO numProcessors:\n//     // Get the boundary of the previous partition, r_{m-1}.\n//     prev_boundary = partitions[m-1]\n//\n//     // Calculate the term inside the square root from Equation 2.\n//     // This term represents the cumulative task count up to the previous boundary\n//     // plus the target task count for the current processor.\n//     term_inside_sqrt = 1 + 4 * (prev_boundary^2 + prev_boundary + total_tasks / (2 * numProcessors))\n//\n//     // Calculate the next boundary, r_m, using the recursive formula.\n//     next_boundary = (-1 + SQRT(term_inside_sqrt)) / 2\n//\n//     // Round the result to the nearest integer as row indices must be whole numbers.\n//     rounded_boundary = ROUND(next_boundary)\n//\n//     // Append the calculated boundary to the list.\n//     APPEND rounded_boundary TO partitions\n//   ENDFOR\n//\n//   // Ensure the final boundary is exactly the total number of atoms.\n//   partitions[numProcessors] = numAtoms\n//\n//   RETURN partitions\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 25,
    "text": "### Framework Overview\nThis problem addresses the challenge of finding a globally optimal trading trajectory over multiple time horizons, which is often intractable for standard convex optimizers due to non-linear transaction costs and time-varying return distributions. The proposed solution is a brute-force approach that discretizes the problem, making it solvable via an exhaustive combinatorial search.\n\n### Key Concepts\n- **[Definition] Trading Trajectory**: An N x H matrix, denoted as `蠅`, where `N` is the number of assets and `H` is the number of time horizons. Each element `蠅(n, h)` represents the capital allocation to asset `n` at horizon `h`.\n- **[Definition] Combinatorial Optimization**: A class of optimization problems where the set of feasible solutions is discrete or can be reduced to a discrete set. The goal is to find an optimal solution from a finite number of combinations.\n- **[Definition] Pigeonhole Partitioning**: An algorithm to determine all possible ways to allocate `K` discrete units of capital among `N` assets. It generates all non-negative integer solutions to the equation `p鈧?+ p鈧?+ ... + p鈧?= K`.\n\n### Objective Function\nThe goal is to maximize the Sharpe Ratio (SR) of the entire trading trajectory. Given a trajectory `蠅`, the total expected return and risk are calculated across all `H` horizons.\n\nThe Sharpe Ratio is defined as:\n\n**Equation 1**: `SR[蠅] = (危[h=1 to H] (渭'鈧?* 蠅鈧?- 蟿鈧橻蠅])) / sqrt(危[h=1 to H] (蠅'鈧?* V鈧?* 蠅鈧?)`\n\nWhere:\n- `蠅鈧檂: The vector of asset weights at horizon `h`.\n- `渭鈧檂: The vector of forecasted mean returns at horizon `h`.\n- `V鈧檂: The forecasted covariance matrix of returns at horizon `h`.\n- `蟿鈧橻蠅]`: The transaction cost function at horizon `h`, which depends on the change in allocations from `h-1` to `h`.\n\n### Algorithmic Steps\nThe optimization process involves three main stages:\n\n1.  **Generate Feasible Static Solutions (`惟`)**: First, discretize the allocation space for a single period. Using Pigeonhole Partitioning, generate all possible ways to allocate `K` units of capital across `N` assets. For each partition, convert the integer units into fractional weights (e.g., `p岬?/ K`) and generate all possible signed versions (long/short) to create the complete set `惟` of all possible single-period weight vectors.\n\n2.  **Generate All Possible Trajectories (`桅`)**: Create the set of all possible H-step trajectories, `桅`, by taking the Cartesian product of the static solution set `惟` with itself `H` times. Each element of `桅` is a unique N x H trading trajectory matrix.\n\n3.  **Evaluate Trajectories and Select Optimum**: Iterate through every trajectory in `桅`. For each one, calculate its total transaction costs and its overall Sharpe Ratio using Equation 1. The trajectory that yields the highest Sharpe Ratio is selected as the globally optimal solution.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Dynamic Trajectory Optimization]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the complete dynamic portfolio optimization algorithm. This function should take a set of market parameters (mean forecasts, covariance matrices, and transaction cost factors for each horizon) and a discretization level `K` as input, and return the optimal trading trajectory.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DynamicPortfolioOptimization(parameters, K, N)\n// INPUTS:\n//   - parameters: A list of H dictionaries, where each dictionary contains 'mean', 'cov', and 'c' (cost factors) for a given horizon.\n//   - K: The number of discrete capital units for partitioning.\n//   - N: The number of assets.\n// OUTPUTS:\n//   - optimal_trajectory: An N x H matrix representing the best trading path found.\n//\n// BEGIN\n//   // Stage 1: Generate all feasible static weight vectors (Omega)\n//   FUNCTION GenerateAllWeights(K, N)\n//     partitions = PigeonholePartitions(K, N) // Generates integer allocations\n//     all_weights = empty_set\n//     FOR each partition IN partitions\n//       absolute_weights = partition / K\n//       sign_combinations = CartesianProduct({-1, 1}, N)\n//       FOR each sign_combo IN sign_combinations\n//         signed_weights = absolute_weights * sign_combo\n//         ADD signed_weights TO all_weights\n//       ENDFOR\n//     ENDFOR\n//     RETURN all_weights\n//   ENDFUNCTION\n//\n//   H = length(parameters)\n//   Omega = GenerateAllWeights(K, N)\n//\n//   // Stage 2: Generate all possible trajectories (Phi)\n//   Phi = CartesianProduct(Omega, H) // All combinations of weight vectors over H periods\n//\n//   // Stage 3: Evaluate all trajectories\n//   best_sr = -INFINITY\n//   optimal_trajectory = NULL\n//\n//   FOR each trajectory IN Phi\n//     // Calculate total mean return, total variance, and transaction costs\n//     total_mean_return = 0\n//     total_variance = 0\n//     previous_weights = vector of zeros of size N\n//\n//     FOR h FROM 0 TO H-1\n//       current_weights = trajectory column at h\n//       params_h = parameters[h]\n//\n//       // Calculate transaction cost for the current step\n//       weight_change = AbsoluteValue(current_weights - previous_weights)\n//       t_cost = Sum(params_h['c'] * SquareRoot(weight_change))\n//\n//       // Accumulate mean and variance\n//       total_mean_return += DotProduct(current_weights, params_h['mean']) - t_cost\n//       total_variance += DotProduct(current_weights, MatrixMultiply(params_h['cov'], current_weights))\n//\n//       previous_weights = current_weights\n//     ENDFOR\n//\n//     // Calculate Sharpe Ratio for the trajectory\n//     current_sr = total_mean_return / SquareRoot(total_variance)\n//\n//     // Update the best trajectory found so far\n//     IF current_sr > best_sr THEN\n//       best_sr = current_sr\n//       optimal_trajectory = trajectory\n//     ENDIF\n//   ENDFOR\n//\n//   RETURN optimal_trajectory\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 26,
    "text": "### Motivation\nIn quantitative finance, it is often necessary to generate synthetic data that mimics the correlation structure of real-world financial instruments. A common requirement for Monte Carlo simulations is to create a random data matrix with a specific, known rank, which controls the degree of linear dependence among its columns (e.g., asset returns).\n\n### Key Concepts\n- **[Definition] Matrix Rank**: The maximum number of linearly independent column (or row) vectors in a matrix. A low-rank matrix implies strong correlations or co-movements among its variables.\n- **[Definition] Singular Value Decomposition (SVD)**: A factorization of a matrix into three matrices, `M = U危V*`, where `U` and `V*` are unitary matrices and `危` is a rectangular diagonal matrix of singular values. SVD is useful for identifying the principal components and rank of a matrix.\n- **[Definition] Homoscedastic Noise**: Random noise where the variance is constant across all observations.\n- **[Definition] Heteroscedastic Noise**: Random noise where the variance is not constant and differs for different observations.\n\n### Core Methodology\nThe algorithm constructs a random `nSamples x nCols` matrix `X` with a specified `rank` using the following steps:\n\n1.  **Generate a Basis**: Create an initial random square matrix of size `nCols x nCols`. Apply SVD to this matrix to obtain the orthogonal matrix `U`, whose columns form a basis for the space.\n2.  **Construct the Rank-Constrained Matrix**: Generate a random matrix of size `nSamples x rank`. By multiplying this matrix with the first `rank` columns of the basis `U` (transposed), we project the random data onto a `rank`-dimensional subspace, resulting in a matrix `X` that has the desired rank.\n    - `X = random(nSamples, rank) @ U[:, :rank].T`\n3.  **Optional Noise Addition**: To make the synthetic data more realistic, random noise can be added to the matrix `X`.\n    - **Homoscedastic**: Add noise drawn from a Gaussian distribution with a constant standard deviation `蟽` to every element of `X`.\n    - **Heteroscedastic**: Add noise where the standard deviation is different for each column, controlled by `蟽` and a random scaling factor.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Rank-Constrained Random Matrix Generation]`**:\n    *   **Task**: Provide the pseudocode for a function that generates a random matrix of a specified size and rank, with optional support for adding homoscedastic or heteroscedastic noise.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateRandomMatrixWithRank(num_samples, num_cols, rank, sigma, is_homoscedastic)\n// INPUTS:\n//   - num_samples: The number of rows for the output matrix.\n//   - num_cols: The number of columns for the output matrix.\n//   - rank: The desired rank of the output matrix.\n//   - sigma: The standard deviation of the noise to be added.\n//   - is_homoscedastic: A boolean flag; TRUE for homoscedastic, FALSE for heteroscedastic noise.\n// OUTPUTS:\n//   - X: The generated num_samples x num_cols random matrix with the specified rank.\n//\n// BEGIN\n//   // Step 1: Generate an orthogonal basis using SVD\n//   random_square_matrix = GenerateRandomGaussian(num_cols, num_cols)\n//   U, S, V = SVD(random_square_matrix)\n//\n//   // Step 2: Construct the rank-constrained matrix\n//   random_core_matrix = GenerateRandomGaussian(num_samples, rank)\n//   basis_vectors = U[:, 0:rank] // Get the first 'rank' columns of U\n//   X = MatrixMultiply(random_core_matrix, Transpose(basis_vectors))\n//\n//   // Step 3: Add optional noise if sigma is greater than 0\n//   IF sigma > 0 THEN\n//     IF is_homoscedastic THEN\n//       // Add noise with constant variance across all elements\n//       homoscedastic_noise = sigma * GenerateRandomGaussian(num_samples, num_cols)\n//       X = X + homoscedastic_noise\n//     ELSE\n//       // Add noise with different variance for each column\n//       column_sigmas = sigma * (GenerateRandomUniform(num_cols) + 0.5)\n//       heteroscedastic_noise = GenerateRandomGaussian(num_samples, num_cols) * column_sigmas // Element-wise multiplication broadcasted by row\n//       X = X + heteroscedastic_noise\n//     ENDIF\n//   ENDIF\n//\n//   RETURN X\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 27,
    "text": "### Objective\nThe goal is to compute the optimal portfolio weights for a single investment period based on the principles of Mean-Variance Optimization (MVO). This approach seeks to find the portfolio that offers the highest expected return for a defined level of risk (variance).\n\n### Key Concepts\n- **[Definition] Mean-Variance Optimization (MVO)**: A portfolio construction method developed by Harry Markowitz that derives an efficient frontier of optimal portfolios. The unconstrained solution provides a set of weights proportional to the inverse of the covariance matrix multiplied by the expected returns vector.\n- **[Definition] Full-Investment Constraint**: A condition requiring that the sum of the absolute values of all portfolio weights equals one (`危|w岬 = 1`). This ensures the portfolio is fully invested, accounting for both long and short positions, without leverage beyond the allocated capital.\n\n### Mathematical Formulation\nFor a universe of assets with a forecasted mean returns vector `渭` and a covariance matrix `V`, the unconstrained MVO solution for the weight vector `w` is given by:\n\n**Equation 1**: `w_raw 鈭?V鈦宦?* 渭`\n\nThis provides the relative allocation proportions. To meet specific portfolio constraints, these raw weights must be rescaled.\n\n### Computational Steps\nThe implementation follows a two-step process:\n\n1.  **Calculate Raw Optimal Weights**: First, compute the inverse of the asset covariance matrix, `V鈦宦筦. Then, multiply this inverse matrix by the vector of mean expected returns, `渭`, to get the unscaled raw weights (`w_raw`).\n\n2.  **Rescale for Full Investment**: To enforce the full-investment constraint, calculate the sum of the absolute values of all elements in the `w_raw` vector. Divide each element of `w_raw` by this sum to produce the final, rescaled weight vector `w`.\n    - `w = w_raw / 危|w_raw|`",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Static MVO with Full Investment]`**:\n    *   **Task**: Provide the pseudocode for a function that computes the static optimal mean-variance portfolio and rescales the weights to ensure the portfolio is fully invested (i.e., the sum of the absolute values of the weights is 1).",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION StaticOptimalPortfolio(covariance_matrix, mean_vector)\n// INPUTS:\n//   - covariance_matrix: An N x N asset covariance matrix (V).\n//   - mean_vector: A vector of N asset mean returns (渭).\n// OUTPUTS:\n//   - rescaled_weights: A vector of N portfolio weights that sum to 1 in absolute value.\n//\n// BEGIN\n//   // Step 1: Calculate the raw optimal weights using the MVO formula\n//   // Ensure the covariance matrix is invertible before proceeding\n//   IF IsInvertible(covariance_matrix) == FALSE THEN\n//     RETURN ERROR \"Covariance matrix is singular.\"\n//   ENDIF\n//\n//   inverse_covariance = Invert(covariance_matrix)\n//   raw_weights = MatrixMultiply(inverse_covariance, mean_vector)\n//\n//   // Step 2: Rescale the weights to enforce the full-investment constraint\n//   sum_of_absolute_weights = Sum(AbsoluteValue(raw_weights))\n//\n//   // Avoid division by zero if all raw weights are zero\n//   IF sum_of_absolute_weights == 0 THEN\n//     RETURN raw_weights // Or handle as an error/edge case\n//   ENDIF\n//\n//   rescaled_weights = raw_weights / sum_of_absolute_weights\n//\n//   RETURN rescaled_weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 28,
    "text": "### Framework Overview\nInformation-driven bars sample data more frequently when new information arrives in the market, which is often proxied by imbalances in trade flow. Tick Imbalance Bars (TIBs) are designed to sample whenever the imbalance between buy and sell-initiated ticks exceeds a dynamically updated expectation, allowing the sampling frequency to adapt to periods of informed trading.\n\n### Key Concepts\n- **[Definition] Tick Imbalance Bars (TIBs)**: A bar construction method where a new bar is formed as soon as the cumulative tick imbalance surpasses a dynamic threshold. This synchronizes data sampling with the arrival of asymmetric information.\n- **[Definition] Tick Rule**: A method to classify each trade (tick) as a 'buy' or 'sell'. A common implementation is to compare the current trade price `p_t` with the previous trade price `p_{t-1}`. The signed tick, `b_t`, is determined as follows:\n\n    *Equation 1*: \n    $$ b_{t} = \\begin{cases} b_{t-1} & \\text{if } \\Delta p_{t} = 0 \\\\ \\frac{|\\Delta p_{t}|}{\\Delta p_{t}} & \\text{if } \\Delta p_{t} \\neq 0 \\end{cases} $$\n    where `b_t` is either +1 (buy) or -1 (sell), and `b_0` is initialized from the previous bar's last `b_t` value.\n\n### Computational Steps\nThe algorithm to form a TIB involves three steps:\n\n1.  **Compute Tick Imbalance**: For a sequence of `T` ticks within a potential bar, the cumulative tick imbalance, `鑳僟T`, is the sum of the signed ticks:\n\n    *Equation 2*: \n    $$ \\theta_{T} = \\sum_{t=1}^{T} b_{t} $$\n\n2.  **Estimate Expected Imbalance**: At the start of a new bar, we must estimate the threshold that `|鑳僟T|` must exceed. This threshold is the product of the expected number of ticks in a bar, `E_0[T]`, and the expected imbalance per tick, `|E_0[b_t]|`.\n\n    The expected imbalance is calculated as:\n    *Equation 3*: \n    $$ E_0[\\theta_T] = E_0[T] \\times (P[b_t=1] - P[b_t=-1]) = E_0[T] \\times (2P[b_t=1] - 1) $$\n\n    In practice, `E_0[T]` is estimated using an exponentially weighted moving average (EWMA) of the number of ticks from prior bars. The term `(2P[b_t=1] - 1)` is estimated using an EWMA of the `b_t` values from prior ticks.\n\n3.  **Form the Bar**: A new bar is formed and sampled at tick `T*`, which is the first tick `T` where the absolute cumulative imbalance `|鑳僟T|` meets or exceeds the absolute expected imbalance.\n\n    *Equation 4*: \n    $$ T^{*} = \\arg \\min_{T} \\left\\{ |\\theta_{T}| \\ge E_{0}[T] \\times |2P[b_{t}=1] - 1| \\right\\} $$",
    "question": "Provide the pseudocode for a function that processes a stream of raw ticks (price, volume) and generates Tick Imbalance Bars. The function should maintain and use running estimates for the expected bar length and expected tick sign.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateTickImbalanceBars(ticks_stream)\n// INPUTS:\n//   - ticks_stream: An iterator yielding tuples of (price, volume) for each tick.\n// OUTPUTS:\n//   - Yields a bar (list of ticks) each time the TIB condition is met.\n//\n// BEGIN\n//   // Initialization of EWMA estimators and state variables\n//   SET expected_T = initial_expected_ticks_per_bar // e.g., 1000\n//   SET expected_b = 0.0 // Initial estimate for (2P[b_t=1] - 1)\n//   SET current_bar_ticks = []\n//   SET cumulative_theta = 0\n//   SET prev_price = get_first_tick(ticks_stream).price\n//   SET prev_b = 1 // Initial boundary condition for b_0\n//\n//   // Main loop to process incoming ticks\n//   FOR each new_tick in ticks_stream:\n//     // Step 1: Apply the Tick Rule (Equation 1)\n//     price_change = new_tick.price - prev_price\n//     IF price_change != 0 THEN\n//       b = sign(price_change)\n//     ELSE\n//       b = prev_b\n//     END IF\n//\n//     // Step 2: Update cumulative tick imbalance (Equation 2)\n//     cumulative_theta = cumulative_theta + b\n//     add new_tick to current_bar_ticks\n//\n//     // Step 3: Check the bar formation condition (Equation 4)\n//     threshold = expected_T * absolute(expected_b)\n//     IF absolute(cumulative_theta) >= threshold THEN\n//       // A bar is formed\n//       YIELD current_bar_ticks\n//\n//       // Update EWMA estimators for the next bar\n//       current_T = length(current_bar_ticks)\n//       average_b_in_bar = cumulative_theta / current_T\n//       expected_T = EWMA(expected_T, current_T) // Update with new T\n//       expected_b = EWMA(expected_b, average_b_in_bar) // Update with new imbalance\n//\n//       // Reset state for the next bar\n//       current_bar_ticks = []\n//       cumulative_theta = 0\n//     END IF\n//\n//     // Update state for the next tick\n//     prev_price = new_tick.price\n//     prev_b = b\n//   END FOR\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 29,
    "text": "### Framework Overview\nTrading complex instruments like futures spreads introduces several modeling challenges, including changing weights, negative series values, and the need to account for rebalancing. The ETF Trick is a method to convert such a series into a single, continuous, positive-valued time series that represents the value of a $1 initial investment, simplifying modeling and backtesting.\n\n### Key Concepts\n- **[Definition] The ETF Trick**: A procedure to construct a total return index for a multi-leg portfolio (e.g., a spread) that dynamically rebalances. It produces a single time series `K_t` representing the mark-to-market value of an initial $1 investment, with profits and losses reinvested at rebalancing points.\n\n### Input Data\nFor a set of `I` instruments over `T` bars, the following data is required for each instrument `i` at bar `t`:\n- `o_{i,t}`: Open price\n- `p_{i,t}`: Close price\n- `锠乢{i,t}`: USD value of one price point (e.g., contract multiplier)\n- `d_{i,t}`: Dividend or carry paid\n- `锠卂{i,t}`: Target allocation weight for the upcoming period\n- `B`: A set of bars `t` on which rebalancing occurs.\n\n### Computational Steps\nThe value of the virtual ETF, `K_t`, is derived iteratively. We start with `K_0 = 1`.\n\n1.  **Calculate Holdings (`h_{i,t}`):** The number of contracts/shares of instrument `i` held at time `t` is determined. Holdings only change on rebalancing bars.\n\n    *Equation 1*:\n    $$ h_{i,t} = \\begin{cases} \\frac{\\omega_{i,t} K_t}{\\phi_{i,t} p_{i,t} \\sum_{j=1}^{I} |\\omega_{j,t}|} & \\text{if } t \\in B \\\\ h_{i,t-1} & \\text{otherwise} \\end{cases} $$\n    *Note*: The original text uses `锠卂{i,t+1}` and `o_{i,t+1}` in the denominator, implying forward-looking information. For a practical backtest implementation, we use information available at time `t`, such as `p_{i,t}`.\n\n2.  **Calculate Price Change (`鏈猒{i,t}`):** The change in market value for instrument `i` from `t-1` to `t` depends on whether a rebalance occurred at `t-1`.\n\n    *Equation 2*:\n    $$ \\delta_{i,t} = \\begin{cases} p_{i,t} - o_{i,t} & \\text{if } (t-1) \\in B \\\\ p_{i,t} - p_{i,t-1} & \\text{otherwise} \\end{cases} $$\n\n3.  **Update Investment Value (`K_t`):** The portfolio value is updated based on the prior holdings and the current period's price changes and dividends.\n\n    *Equation 3*:\n    $$ K_{t} = K_{t-1} + \\sum_{i=1}^{I} h_{i,t-1} \\phi_{i,t} (\\delta_{i,t} + d_{i,t}) $$",
    "question": "Provide the pseudocode for a function that computes the total return series `K_t` for a multi-instrument portfolio using the ETF Trick. The function should process a history of bars and a rebalancing schedule.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ComputeEtfTrickSeries(bars_data, weights_data, rebalance_dates)\n// INPUTS:\n//   - bars_data: A structure containing time series for o, p, phi, d for all instruments.\n//   - weights_data: A structure containing the target weights omega for all instruments.\n//   - rebalance_dates: A set of timestamps when rebalancing occurs.\n// OUTPUTS:\n//   - A time series of the portfolio value K_t.\n//\n// BEGIN\n//   // Initialization\n//   SET K_series = empty time series\n//   SET K_previous = 1.0\n//   SET h_previous = array of zeros (size = number of instruments)\n//   Append (initial_date, K_previous) to K_series\n//\n//   // Iterate through each time step t from 1 to T\n//   FOR t in bars_data.timestamps:\n//     SET total_pnl_at_t = 0\n//\n//     // Calculate PnL for the current bar\n//     FOR each instrument i:\n//       // Step 2: Calculate price change delta_i,t\n//       IF (t-1) is in rebalance_dates THEN\n//         delta_i_t = bars_data.p[i,t] - bars_data.o[i,t]\n//       ELSE\n//         delta_i_t = bars_data.p[i,t] - bars_data.p[i,t-1]\n//       END IF\n//\n//       // Accumulate PnL from all instruments\n//       instrument_pnl = h_previous[i] * bars_data.phi[i,t] * (delta_i_t + bars_data.d[i,t])\n//       total_pnl_at_t = total_pnl_at_t + instrument_pnl\n//     END FOR\n//\n//     // Step 3: Update investment value K_t\n//     K_current = K_previous + total_pnl_at_t\n//     Append (t, K_current) to K_series\n//\n//     // Step 1: Calculate new holdings h_i,t if it's a rebalance day\n//     SET h_current = h_previous\n//     IF t is in rebalance_dates THEN\n//       SET sum_abs_weights = 0\n//       FOR each instrument j:\n//         sum_abs_weights = sum_abs_weights + absolute(weights_data.omega[j,t])\n//       END FOR\n//\n//       IF sum_abs_weights > 0 THEN\n//         FOR each instrument i:\n//           denominator = bars_data.phi[i,t] * bars_data.p[i,t] * sum_abs_weights\n//           h_current[i] = (weights_data.omega[i,t] * K_current) / denominator\n//         END FOR\n//       END IF\n//     END IF\n//\n//     // Update state for next iteration\n//     K_previous = K_current\n//     h_previous = h_current\n//   END FOR\n//\n//   RETURN K_series\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 30,
    "text": "### Framework Overview\nPrincipal Component Analysis (PCA) can be used to decompose portfolio risk into uncorrelated sources. By performing a spectral decomposition of an asset covariance matrix, we can construct a portfolio where the risk is explicitly allocated across these orthogonal principal components. This allows for precise control over the portfolio's risk profile.\n\n### Key Concepts\n- **[Definition] Spectral Decomposition**: The process of decomposing a covariance matrix `V` into its eigenvalues `铻瀈 and eigenvectors `W`, such that `VW = W铻瀈. The eigenvectors represent the uncorrelated principal components (directions of variance), and the eigenvalues represent the magnitude of variance along those components.\n- **[Definition] Principal Component Risk Contribution**: The proportion of the total portfolio variance that can be attributed to each individual principal component.\n\n### Computational Steps\nGiven a covariance matrix `V` for `N` assets, the goal is to find the allocation vector `锠卄 that results in a desired risk distribution `R` across the `N` principal components.\n\n1.  **Perform Spectral Decomposition**: Decompose the covariance matrix `V` to get the diagonal matrix of eigenvalues `铻瀈 and the matrix of corresponding eigenvectors `W`.\n    `V = W铻濿'`\n    The columns of `W` and diagonal elements of `铻瀈 should be sorted in descending order of eigenvalue magnitude.\n\n2.  **Define Portfolio Risk in PC Space**: The total portfolio variance `锜借檹` can be expressed in terms of `锠卄 and `V`. This can be transformed into the basis of principal components:\n    *Equation 1*: `锜借檹 = 锠?V锠?= 锠?W铻濿'锠?= 灏?铻炲熬`\n    where `灏?= W'锠卄 is the vector of portfolio weights projected onto the principal components (the 'loadings').\n\n3.  **Calculate Risk Contribution**: Since `铻瀈 is diagonal, the total variance is the sum of the variance from each component:\n    *Equation 2*: `锜借檹 = 鍗?灏綺n铏?* 铻瀇{n,n})`\n    The risk contribution `R_n` from the n-th component is:\n    *Equation 3*: `R_n = (灏綺n铏?* 铻瀇{n,n}) / 锜借檹`\n\n4.  **Derive PC Allocations from Target Risk**: To achieve a target risk distribution `R`, we can invert Equation 3 to solve for the required loadings `灏綻. For a target total portfolio risk `锜絗, the loading for the n-th component is:\n    *Equation 4*: `灏綺n = 锜?* sqrt(R_n / 铻瀇{n,n})`\n\n5.  **Transform PC Allocations to Asset Weights**: Finally, transform the loadings `灏綻 from the principal component basis back to the original asset basis to get the final allocation vector `锠卄:\n    *Equation 5*: `锠?= W灏綻",
    "question": "Provide the pseudocode for a function that computes portfolio weights based on a target risk distribution across principal components. The function should handle a default case where all risk is allocated to the single principal component with the smallest variance (eigenvalue).",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PcaWeights(covariance_matrix, risk_distribution, target_risk)\n// INPUTS:\n//   - covariance_matrix: An N x N asset covariance matrix (V).\n//   - risk_distribution: An array of size N specifying the target risk contribution (R_n) from each principal component. Can be None.\n//   - target_risk: The desired total standard deviation of the portfolio (sigma).\n// OUTPUTS:\n//   - An array of size N containing the asset weights (omega).\n//\n// BEGIN\n//   // Step 1: Perform Spectral Decomposition\n//   eigenvalues, eigenvectors = Eigendecomposition(covariance_matrix)\n//\n//   // Sort eigenvalues and eigenvectors in descending order\n//   sorted_indices = SortIndices(eigenvalues, order='descending')\n//   sorted_eigenvalues = eigenvalues[sorted_indices]\n//   sorted_eigenvectors = eigenvectors[:, sorted_indices]\n//\n//   // Handle default risk distribution case\n//   IF risk_distribution is None THEN\n//     // Allocate 100% of risk to the component with the smallest eigenvalue\n//     risk_distribution = array of zeros of size N\n//     risk_distribution[N-1] = 1.0\n//   END IF\n//\n//   // Step 4: Derive PC Allocations (loadings) from Target Risk\n//   // Note: variance = eigenvalue, so we use sorted_eigenvalues for Lambda_n,n\n//   // R_n / Lambda_n,n gives variance of loadings, sqrt gives std dev of loadings\n//   loadings_variance = risk_distribution / sorted_eigenvalues\n//   loadings_std_dev = Sqrt(loadings_variance)\n//   loadings = target_risk * loadings_std_dev // This is the vector beta\n//\n//   // Step 5: Transform PC Allocations to Asset Weights\n//   // Reshape 'loadings' to be a column vector for matrix multiplication\n//   loadings_col_vector = Reshape(loadings, (N, 1))\n//   weights = MatrixMultiply(sorted_eigenvectors, loadings_col_vector)\n//\n//   RETURN weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 31,
    "text": "### Framework Overview\nFutures contracts have expiration dates, forcing traders to 'roll' from an expiring contract to a new one. This roll creates price gaps in a continuous series, as the expiring and new contracts trade at different prices. A naive price series concatenating different contracts is not representative of a continuous investment strategy. Proper adjustment is required to create a series suitable for backtesting and PnL simulation.\n\n### Key Concepts\n- **[Definition] Roll Gap**: The price difference between the new contract's open price and the old contract's close price at the time of a roll. This gap does not represent a profit or loss for a continuously held position and must be adjusted for.\n\n### Computational Steps for a Non-Negative Rolled Series\nA robust method to create a continuous, non-negative price series that reflects the performance of a $1 investment is as follows:\n\n1.  **Compute Cumulative Roll Gaps**: \n    - Identify all roll dates, which are the first dates a new contract ticker appears in the data.\n    - For each roll date (starting from the second contract), calculate the gap: `gap = new_contract_open_price - old_contract_close_price_on_previous_day`.\n    - Create a cumulative sum of these gaps over time. This results in a `gaps` series, which represents the total adjustment needed at any point in time.\n\n2.  **Create an Adjusted Price Series**:\n    - Create a new price series (`rolled_prices`) by subtracting the `gaps` series from the original raw price series.\n    - `rolled_prices[t] = raw_prices[t] - gaps[t]`\n    - This series represents a price history adjusted for all historical roll gaps. Note that this series can become negative.\n\n3.  **Generate a Return-Based Investment Series**:\n    - To ensure the final series is non-negative and represents investment growth, calculate returns based on the adjusted prices but scaled by the true (raw) price level.\n    - `returns[t] = (rolled_prices['Close'][t] - rolled_prices['Close'][t-1]) / raw_prices['Close'][t-1]`\n    - Create the final price series (`investment_series`) by taking the cumulative product of `(1 + returns)`, starting from an initial value of 1.\n    - `investment_series[t] = (1 + returns).cumprod()`\n    - This final series accurately reflects the performance of a $1 investment in the futures contract, with gains and losses compounded over time.",
    "question": "Provide the pseudocode for a function that takes a raw futures price series (containing timestamps, prices, and contract tickers) and generates a non-negative, continuous price series representing a $1 investment, following the three-step process described.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateNonNegativeRolledSeries(raw_series)\n// INPUTS:\n//   - raw_series: A data structure with columns for 'Timestamp', 'Ticker', 'Open', 'Close'.\n// OUTPUTS:\n//   - A new series representing the cumulative performance of a $1 investment.\n//\n// BEGIN\n//   // --- Step 1: Compute Cumulative Roll Gaps ---\n//   SET roll_dates = Find first timestamp for each unique 'Ticker' in raw_series.\n//   SET gaps = create a new series with the same index as raw_series, initialized to 0.\n//\n//   // Iterate through roll dates, starting from the second contract\n//   FOR i from 1 to length(roll_dates) - 1:\n//     current_roll_date = roll_dates[i]\n//     previous_day_index = index of raw_series just before current_roll_date\n//\n//     // Get prices for gap calculation\n//     new_contract_open = raw_series['Open'] at current_roll_date\n//     old_contract_close = raw_series['Close'] at previous_day_index\n//\n//     // Calculate the gap at this roll\n//     gap_value = new_contract_open - old_contract_close\n//     gaps at current_roll_date = gap_value\n//   END FOR\n//\n//   // Create the cumulative gaps series\n//   SET cumulative_gaps = CumulativeSum(gaps)\n//\n//   // --- Step 2: Create an Adjusted Price Series ---\n//   SET rolled_series = copy of raw_series\n//   rolled_series['Close'] = raw_series['Close'] - cumulative_gaps\n//   rolled_series['Open'] = raw_series['Open'] - cumulative_gaps\n//\n//   // --- Step 3: Generate a Return-Based Investment Series ---\n//   // Calculate the price change of the adjusted series\n//   SET adjusted_price_diff = Difference(rolled_series['Close'])\n//\n//   // Get the previous day's raw close price for scaling returns\n//   SET prev_raw_close = Shift(raw_series['Close'], 1)\n//\n//   // Calculate the return series\n//   SET returns = adjusted_price_diff / prev_raw_close\n//   // Set the first return to 0 as it's undefined\n//   returns[0] = 0\n//\n//   // Calculate the final investment series\n//   SET investment_series = CumulativeProduct(1 + returns)\n//\n//   RETURN investment_series\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 32,
    "text": "### Framework Overview\nInstead of analyzing every data point, event-based sampling focuses on periods of significant change. This reduces the dataset size and concentrates the analysis on moments that are more likely to be informative. The CUSUM (Cumulative Sum) filter is a technique designed to detect deviations in a series mean. A symmetric version can be used to sample events corresponding to both significant upward and downward trends.\n\n### Key Concepts\n- **[Definition] Symmetric CUSUM Filter**: An event-sampling method that triggers an event when the cumulative sum of deviations from a mean value exceeds a predefined threshold `h`, in either a positive or negative direction. After an event is triggered, the corresponding cumulative sum is reset.\n\n### Computational Steps\nGiven a time series of observations `y_t` (e.g., prices) and a threshold `h`, the symmetric CUSUM filter identifies event timestamps.\n\n1.  **Initialize Cumulative Sums**: Two cumulative sum variables are maintained: one for positive deviations (`S_t^+`) and one for negative deviations (`S_t^-`). Both are initialized to zero.\n    `S_0^+ = 0`\n    `S_0^- = 0`\n\n2.  **Iterate and Update Sums**: For each observation `y_t` from `t=1` to `T`, calculate the deviation from the previous value, `铻杫_t = y_t - y_{t-1}`. Update the cumulative sums according to the following rules:\n\n    *Equation 1 (Positive Sum)*:\n    $$ S_{t}^{+} = \\max \\{ 0, S_{t-1}^{+} + \\Delta y_t \\} $$\n\n    *Equation 2 (Negative Sum)*:\n    $$ S_{t}^{-} = \\min \\{ 0, S_{t-1}^{-} + \\Delta y_t \\} $$\n\n    The `max{0, ...}` and `min{0, ...}` operations act as resets. If the positive sum `S^+` would become negative, it is reset to 0. Similarly, if the negative sum `S^-` would become positive, it is reset to 0. This ensures the filter only accumulates consecutive runs of positive or negative deviations.\n\n3.  **Trigger and Reset**: After updating the sums at step `t`, check if either has crossed the threshold `h`.\n    - If `S_t^+ >= h`, an upward event is triggered. Record the timestamp `t` and reset `S_t^+` to 0.\n    - If `S_t^- <= -h`, a downward event is triggered. Record the timestamp `t` and reset `S_t^-` to 0.\n\nThis process generates a sparse set of event timestamps corresponding to significant, sustained movements in the underlying series.",
    "question": "Provide the pseudocode for a function that implements the Symmetric CUSUM filter. The function should take a price series and a threshold `h` as input and return a list of timestamps where events were triggered.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GetCusumEvents(price_series, threshold_h)\n// INPUTS:\n//   - price_series: A time-indexed series of prices.\n//   - threshold_h: A positive numeric value for the event threshold.\n// OUTPUTS:\n//   - A list of timestamps where CUSUM events occurred.\n//\n// BEGIN\n//   // Initialization\n//   SET event_timestamps = []\n//   SET s_positive = 0.0\n//   SET s_negative = 0.0\n//   SET previous_price = price_series[0]\n//\n//   // Iterate through the price series starting from the second element\n//   FOR t from 1 to length(price_series) - 1:\n//     current_price = price_series[t]\n//     current_timestamp = timestamp of price_series[t]\n//     price_diff = current_price - previous_price\n//\n//     // Step 2: Update positive and negative cumulative sums\n//     s_positive = max(0, s_positive + price_diff)\n//     s_negative = min(0, s_negative + price_diff)\n//\n//     // Step 3: Check for event triggers\n//     IF s_positive >= threshold_h THEN\n//       // Upward event triggered\n//       add current_timestamp to event_timestamps\n//       s_positive = 0 // Reset positive sum\n//\n//     ELSE IF s_negative <= -threshold_h THEN\n//       // Downward event triggered\n//       add current_timestamp to event_timestamps\n//       s_negative = 0 // Reset negative sum\n//     END IF\n//\n//     // Update state for next iteration\n//     previous_price = current_price\n//   END FOR\n//\n//   RETURN event_timestamps\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 33,
    "text": "The Triple-Barrier Method is a superior labeling technique that accounts for the path-dependent nature of trading. It labels an observation based on which of three barriers is touched first: an upper barrier (profit-take), a lower barrier (stop-loss), or a vertical barrier (time expiration). This approach is more realistic as it mirrors how trades are managed with explicit risk limits.\n\n**Key Concepts**\n\n- **[Definition] Triple-Barrier Method**: A path-dependent labeling method where an event is defined by three boundaries. The label is determined by the first boundary the price path intersects.\n- **[Definition] Horizontal Barriers**: These represent price targets. The upper barrier is a profit-take (PT) level, and the lower barrier is a stop-loss (SL) level. They are often set dynamically as a function of volatility.\n- **[Definition] Vertical Barrier**: This represents the maximum holding period for the position. If neither horizontal barrier is touched within this time limit, the position is closed.\n\n**Computational Logic**\n\nThe core of the method is a function that, for a given trade entry, determines the touch time for each barrier. The final event time `t閳т梗 is the minimum of the three touch times.\n\nThe logic for finding the horizontal barrier touch times is central. For each trade event starting at `loc` and with a maximum duration ending at `t1_vertical`, the process is as follows:\n\n1.  **Isolate Price Path**: Extract the series of prices from the trade's start time (`loc`) to the vertical barrier time (`t1_vertical`).\n2.  **Calculate Path Returns**: Normalize the price path to calculate the cumulative return at each point in time relative to the entry price. If the trade has a predefined `side` (e.g., long=1, short=-1), the returns should be multiplied by the side to correctly orient the PT and SL levels.\n3.  **Set Barrier Levels**: Define the upper profit-take (`pt`) and lower stop-loss (`sl`) return thresholds.\n4.  **Find First Touch**: Determine the earliest timestamp where the path returns exceed the `pt` level and the earliest timestamp where path returns fall below the `sl` level.",
    "question": "Based on the provided text, provide the pseudocode for a function that implements the logic to find the first touch times for the profit-take and stop-loss barriers for a single trade event.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FindHorizontalBarrierTouches(close_prices, event_start_time, event_end_time, side, pt_level, sl_level)\n// INPUTS:\n//   - close_prices: A time-series of asset prices.\n//   - event_start_time: The timestamp when the trade is initiated.\n//   - event_end_time: The timestamp of the vertical barrier (max holding period).\n//   - side: The side of the trade (1 for long, -1 for short).\n//   - pt_level: The positive return threshold for the profit-take barrier.\n//   - sl_level: The negative return threshold for the stop-loss barrier.\n// OUTPUTS:\n//   - A tuple containing (profit_take_touch_time, stop_loss_touch_time). Values are null if not touched.\n//\n// BEGIN\n//   // 1. Isolate the relevant price path for the event.\n//   path_prices = prices from close_prices between event_start_time and event_end_time.\n//   entry_price = price from close_prices at event_start_time.\n//\n//   // 2. Calculate path returns, adjusted for trade side.\n//   path_returns = (path_prices / entry_price - 1) * side.\n//\n//   // 3. Find the first time the profit-take barrier is touched.\n//   profit_take_touches = timestamps from path_returns where return > pt_level.\n//   IF profit_take_touches is not empty THEN\n//     profit_take_touch_time = minimum(profit_take_touches).\n//   ELSE\n//     profit_take_touch_time = NULL.\n//   END IF\n//\n//   // 4. Find the first time the stop-loss barrier is touched.\n//   stop_loss_touches = timestamps from path_returns where return < sl_level.\n//   IF stop_loss_touches is not empty THEN\n//     stop_loss_touch_time = minimum(stop_loss_touches).\n//   ELSE\n//     stop_loss_touch_time = NULL.\n//   END IF\n//\n//   RETURN (profit_take_touch_time, stop_loss_touch_time).\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 34,
    "text": "In classification tasks, severe class imbalance閳ユ敋here one class is significantly more frequent than others閳ユ攦an degrade model performance. Classifiers may become biased towards the majority class, leading to poor predictive power for rare but important events. A practical approach to mitigate this is to prune the dataset by removing observations belonging to extremely rare classes.\n\n**Key Concepts**\n\n- **[Definition] Class Imbalance**: A scenario in classification datasets where the number of observations per class is not equally distributed. For example, in a set of {-1, 0, 1} labels, the '0' class might represent 95% of the data, while '-1' and '1' each represent only 2.5%.\n\n**Algorithm Logic**\n\nThe proposed algorithm recursively drops the least populated class until a stable class distribution is achieved. The procedure is as follows:\n\n1.  **Start Loop**: Begin an iterative process.\n2.  **Calculate Frequencies**: For the current dataset, compute the relative frequency of each unique label (class). For example, `{'1': 0.5, '-1': 0.45, '0': 0.05}`.\n3.  **Identify Rarest Class**: Find the class with the minimum frequency. In the example above, this is class '0'.\n4.  **Check Termination Conditions**: The loop terminates if either of the following conditions is met:\n    *   The minimum class frequency is greater than or equal to a specified `min_percentage` threshold.\n    *   The number of unique classes remaining is less than 3 (i.e., only two classes are left).\n5.  **Drop and Recurse**: If neither termination condition is met, filter the dataset to remove all observations belonging to the rarest class. The loop then repeats from Step 2 with the reduced dataset.\n6.  **Return Data**: Once the loop terminates, return the final, pruned dataset.",
    "question": "Based on the provided text, provide the pseudocode for a function that implements the recursive label dropping logic to address class imbalance.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DropRareLabels(events, min_percentage)\n// INPUTS:\n//   - events: A list of data records, where each record has a 'label' attribute.\n//   - min_percentage: The minimum frequency a class must have to be retained.\n// OUTPUTS:\n//   - A new list of data records with rare classes removed.\n//\n// BEGIN\n//   // Create a copy to avoid modifying the original data.\n//   filtered_events = copy(events)\n//\n//   WHILE TRUE DO\n//     // 2. Calculate the frequency of each label.\n//     label_counts = count occurrences of each unique label in filtered_events.\n//     total_count = number of records in filtered_events.\n//     label_frequencies = label_counts / total_count.\n//\n//     // Find the minimum frequency and the number of unique classes.\n//     min_freq = minimum value in label_frequencies.\n//     num_classes = number of unique labels.\n//\n//     // 3. Check termination conditions.\n//     IF min_freq >= min_percentage OR num_classes < 3 THEN\n//       BREAK LOOP.\n//     END IF\n//\n//     // 4. Identify the rarest class and drop it.\n//     rarest_label = the label corresponding to min_freq.\n//     // Create a new list containing only the events that do not have the rarest label.\n//     filtered_events = all records in filtered_events where record.label is not rarest_label.\n//   END WHILE\n//\n//   RETURN filtered_events.\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 35,
    "text": "### Framework Overview\nIn financial machine learning, observations are often not Independent and Identically Distributed (IID) due to overlapping time intervals used for labeling. For instance, the label for an observation at time `i` might depend on prices from `t_i,0` to `t_i,1`, while the label for observation `j > i` depends on prices from `t_j,0` to `t_j,1`. If these intervals overlap, the labels are not independent. To address this, we can quantify the uniqueness of each label.\n\n### Key Concepts\n1.  **[Definition] Concurrency**: The number of labels that are simultaneously active at a specific point in time `t`. A label `i` is considered active at time `t` if its evaluation period `[t_i,0, t_i,1]` includes time `t`.\n2.  **[Definition] Label Uniqueness**: At a given time `t`, the uniqueness of a label `i` is the inverse of the concurrency at that time. If a label is the only active one, its uniqueness is 1; if it is one of three active labels, its uniqueness is 1/3.\n3.  **[Definition] Average Uniqueness**: The average uniqueness of a label `i` is its mean uniqueness calculated over its entire lifespan `[t_i,0, t_i,1]`.\n\n### Computational Steps\nLet's formalize the calculation for a set of `I` labels over a total of `T` time steps.\n\n1.  **Calculate Concurrency**: First, we compute the number of labels concurrent at each time `t`, denoted as `c_t`. This is achieved by summing an indicator variable `1_{t,i}` which is 1 if label `i`'s lifespan includes time `t`, and 0 otherwise.\n    *   **Equation 1: Concurrency at time t**\n        `c_t = sum_{i=1 to I} 1_{t,i}`\n        *   `c_t`: The number of concurrent labels at time `t`.\n        *   `I`: The total number of labels.\n        *   `1_{t,i}`: An indicator that is 1 if label `i` is active at time `t`, and 0 otherwise.\n\n2.  **Calculate Average Uniqueness**: The average uniqueness for a specific label `i`, denoted `\\bar{u}_i`, is the average of the reciprocal of concurrency over the label's lifespan.\n    *   **Equation 2: Average Uniqueness of Label i**\n        `\\bar{u}_i = (sum_{t=t_{i,0} to t_{i,1}} (1 / c_t)) / (t_{i,1} - t_{i,0})`\n        *   `\\bar{u}_i`: The average uniqueness of label `i`.\n        *   `[t_{i,0}, t_{i,1}]`: The start and end times for the evaluation period of label `i`.\n        *   `c_t`: The concurrency at time `t`, as calculated in Equation 1.",
    "question": "1.  **`[Average Uniqueness Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the average uniqueness for a set of events. This function takes as input the event lifespans and a pre-computed time series of concurrency values.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateAverageUniqueness(event_lifespans, concurrency_series)\n// INPUTS:\n//   - event_lifespans: A data structure (e.g., a Series or DataFrame) where each entry `i` contains the start time `t_in` and end time `t_out` for that event's label.\n//   - concurrency_series: A time series where the index is time `t` and the value is the concurrency `c_t`.\n// OUTPUTS:\n//   - A Series where the index corresponds to the event index and the value is the calculated average uniqueness `\\bar{u}_i`.\n//\n// BEGIN\n//   INITIALIZE an empty Series `avg_uniqueness` with the same index as `event_lifespans`.\n//\n//   // Iterate over each event to calculate its average uniqueness.\n//   FOR each event `i` with start time `t_in` and end time `t_out` in `event_lifespans`:\n//     // Select the concurrency values that fall within the event's lifespan.\n//     LET `relevant_concurrency` be the slice of `concurrency_series` from `t_in` to `t_out`.\n//\n//     // Calculate the uniqueness at each time point (1/c_t).\n//     // Note: Handle cases where concurrency might be zero to avoid division errors, though theoretically it should be at least 1.\n//     LET `uniqueness_over_time` be 1.0 divided by each value in `relevant_concurrency`.\n//\n//     // Compute the mean of these uniqueness values.\n//     LET `mean_uniqueness` be the average of `uniqueness_over_time`.\n//\n//     // Store the result for event `i`.\n//     SET `avg_uniqueness[i]` to `mean_uniqueness`.\n//   ENDFOR\n//\n//   RETURN `avg_uniqueness`.\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 36,
    "text": "### Motivation\nStandard bootstrapping (sampling with replacement) assumes observations are IID. In finance, overlapping labels violate this assumption, leading to inefficient sampling where redundant observations are over-represented. The Sequential Bootstrap is a superior method that addresses this by making draws according to a changing probability that actively controls for redundancy.\n\n### Core Concepts\n1.  **[Definition] Indicator Matrix**: A binary matrix `indM` where rows correspond to time bars and columns correspond to observations. `indM[t, i] = 1` if the label for observation `i` is a function of the return at time `t`, and 0 otherwise.\n2.  **[Definition] Average Uniqueness**: A measure of how much an observation's label overlaps with other labels. It is calculated based on the indicator matrix.\n3.  **[Definition] Sequential Bootstrap**: An iterative sampling process where the probability of drawing an observation is inversely related to its overlap with observations already selected for the sample.\n\n### Algorithmic Steps\nThe algorithm proceeds iteratively to build a sample of a desired length (e.g., size `I`).\n\n1.  **Initialization**: Start with an empty list of selected indices, `phi`, and a uniform probability distribution for the first draw, `delta_j = 1/I` for all observations `j`.\n\n2.  **Iterative Drawing**: For each draw until the sample is full:\n    a.  **Draw a Sample**: Select one observation index based on the current probability distribution and add it to `phi`.\n    b.  **Update Probabilities**: Recalculate the drawing probabilities for all observations for the *next* draw. For each observation `j`, its new un-normalized probability is its average uniqueness *given the observations already in `phi`*. The average uniqueness of a potential draw `j` is computed by considering a temporary sample that includes `phi` and `j`.\n    c.  **Normalize**: The new probabilities `delta_j` are calculated by normalizing the average uniqueness scores so they sum to 1.\n        *   **Equation 1: Draw Probability for sample j**\n            `delta_j = \\bar{u}_j / (sum_{k=1 to I} \\bar{u}_k)`\n            *   `delta_j`: The probability of drawing observation `j` in the next step.\n            *   `\\bar{u}_j`: The average uniqueness of observation `j`, calculated relative to the set of observations already drawn into the bootstrap sample.\n            *   `I`: The total number of observations.\n\n3.  **Termination**: The process repeats until `phi` contains the desired number of samples. This procedure ensures that as the sample is built, observations that heavily overlap with already-selected ones become less likely to be chosen, leading to a more diverse and IID-like sample.",
    "question": "1.  **`[Sequential Bootstrap Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the Sequential Bootstrap algorithm. The function should take an indicator matrix as input and return a list of sampled observation indices.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION SequentialBootstrap(indicator_matrix, sample_length)\n// INPUTS:\n//   - indicator_matrix: A binary matrix where rows are time bars and columns are observations.\n//   - sample_length: The desired number of samples to draw.\n// OUTPUTS:\n//   - A list of observation indices representing the bootstrapped sample.\n//\n// HELPER FUNCTION GetAverageUniqueness(sub_matrix)\n//   // This helper calculates the average uniqueness for each observation in a given matrix.\n//   LET concurrency = sum of each row in sub_matrix.\n//   LET uniqueness_matrix = sub_matrix element-wise divided by concurrency (broadcasted by row).\n//   LET avg_uniqueness = mean of each column in uniqueness_matrix (ignoring zero values).\n//   RETURN avg_uniqueness.\n// END HELPER\n//\n// BEGIN\n//   INITIALIZE an empty list `phi` to store the sampled indices.\n//   LET `all_indices` be the column indices of `indicator_matrix`.\n//\n//   // Loop until the desired sample size is reached.\n//   WHILE length of `phi` < `sample_length`:\n//     INITIALIZE an empty Series `avg_uniqueness_candidates`.\n//\n//     // Calculate the marginal uniqueness for each potential next draw.\n//     FOR each index `i` in `all_indices`:\n//       // Create a temporary indicator matrix for the current sample plus the candidate `i`.\n//       LET `temp_indices` be the concatenation of `phi` and `[i]`.\n//       LET `temp_matrix` be the columns of `indicator_matrix` corresponding to `temp_indices`.\n//\n//       // Calculate the average uniqueness of the candidate `i` within this temporary context.\n//       // The last element of the result corresponds to the candidate `i`.\n//       LET `candidate_uniqueness` = GetAverageUniqueness(`temp_matrix`).last_element.\n//       STORE `candidate_uniqueness` for index `i` in `avg_uniqueness_candidates`.\n//     ENDFOR\n//\n//     // Convert uniqueness scores to a probability distribution.\n//     LET `probabilities` = `avg_uniqueness_candidates` / sum of `avg_uniqueness_candidates`.\n//\n//     // Draw one sample according to the new probabilities.\n//     LET `drawn_index` = a random choice from `all_indices` using `probabilities`.\n//\n//     // Add the drawn sample to our list.\n//     APPEND `drawn_index` to `phi`.\n//   ENDWHILE\n//\n//   RETURN `phi`.\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 37,
    "text": "### Rationale\nWhen training a machine learning model, not all observations are equally important. Two key factors determine an observation's importance: its uniqueness and the magnitude of its outcome. Observations with highly overlapping labels contain redundant information and should be down-weighted. Conversely, labels associated with large market movements (high absolute returns) are more informative and should be up-weighted. The return attribution method combines these two ideas.\n\n### Key Concepts\n1.  **[Definition] Return Attribution**: A method to assign a weight to a sample based on the sum of returns that can be uniquely attributed to it. For each time step `t` within a label's lifespan, the return `r_{t-1,t}` is divided by the number of concurrent events `c_t`. This fraction represents the portion of the return attributed to that specific label.\n\n### Computational Formulae\nThe process involves two main steps: calculating the raw, un-normalized weight and then scaling all weights.\n\n1.  **Calculate Raw Weight**: The raw weight for an observation `i`, denoted `\\tilde{w}_i`, is the absolute value of the sum of its attributed returns over its entire lifespan `[t_{i,0}, t_{i,1}]`.\n    *   **Equation 1: Raw Sample Weight**\n        `\\tilde{w}_i = |sum_{t = t_{i,0}}^{t_{i,1}} (r_{t - 1,t} / c_t)|`\n        *   `\\tilde{w}_i`: The un-normalized weight for observation `i`.\n        *   `[t_{i,0}, t_{i,1}]`: The start and end times for the evaluation period of label `i`.\n        *   `r_{t-1,t}`: The log-return at time `t`.\n        *   `c_t`: The number of concurrent labels active at time `t`.\n\n2.  **Normalize Weights**: The final weights `w_i` are scaled so that their sum equals the total number of observations `I`. This is a common convention in ML libraries like scikit-learn, which often assume a default weight of 1 for each sample.\n    *   **Equation 2: Normalized Sample Weight**\n        `w_i = \\tilde{w}_i * I / (sum_{j=1 to I} \\tilde{w}_j)`\n        *   `w_i`: The final, normalized weight for observation `i`.\n        *   `I`: The total number of observations.",
    "question": "1.  **`[Return Attribution Weighting Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes sample weights based on return attribution. The function will take event lifespans, a concurrency series, and a price series as input.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateReturnAttributionWeights(event_lifespans, concurrency_series, close_prices)\n// INPUTS:\n//   - event_lifespans: A data structure where each entry `i` contains the start time `t_in` and end time `t_out`.\n//   - concurrency_series: A time series of concurrency values `c_t`.\n//   - close_prices: A time series of closing prices.\n// OUTPUTS:\n//   - A Series of final, normalized sample weights `w_i`.\n//\n// BEGIN\n//   // Step 1: Calculate log returns.\n//   LET `log_returns` be the differenced log of `close_prices`.\n//\n//   INITIALIZE an empty Series `raw_weights` with the same index as `event_lifespans`.\n//\n//   // Step 2: Calculate raw weight for each event.\n//   FOR each event `i` with start time `t_in` and end time `t_out` in `event_lifespans`:\n//     // Select the returns and concurrency for the event's lifespan.\n//     LET `relevant_returns` be the slice of `log_returns` from `t_in` to `t_out`.\n//     LET `relevant_concurrency` be the slice of `concurrency_series` from `t_in` to `t_out`.\n//\n//     // Calculate attributed returns.\n//     LET `attributed_returns` be `relevant_returns` element-wise divided by `relevant_concurrency`.\n//\n//     // Sum the attributed returns and take the absolute value.\n//     LET `total_attributed_return` = absolute value of the sum of `attributed_returns`.\n//\n//     // Store the raw weight.\n//     SET `raw_weights[i]` to `total_attributed_return`.\n//   ENDFOR\n//\n//   // Step 3: Normalize the weights.\n//   LET `total_samples` = number of entries in `event_lifespans`.\n//   LET `sum_of_raw_weights` = sum of all values in `raw_weights`.\n//\n//   IF `sum_of_raw_weights` > 0 THEN\n//     LET `normalization_factor` = `total_samples` / `sum_of_raw_weights`.\n//     LET `final_weights` = `raw_weights` * `normalization_factor`.\n//   ELSE\n//     // Handle edge case where all weights are zero.\n//     LET `final_weights` = a Series of ones with the same index as `raw_weights`.\n//   ENDIF\n//\n//   RETURN `final_weights`.\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 38,
    "text": "### Framework Overview\nFractional differentiation is a technique that generalizes standard integer differentiation (like calculating returns) to non-integer orders. This allows a time series to be made stationary while preserving as much of its original memory as possible, which is crucial for predictive modeling.\n\nThe method is derived from the binomial series expansion of the backshift operator.\n\n### Key Concepts\n- **[Definition] Backshift Operator (B)**: An operator applied to a time series `{X_t}` such that `B^k * X_t = X_{t-k}`. For example, `(1 - B) * X_t = X_t - X_{t-1}`.\n- **[Definition] Fractional Differentiation**: The application of the operator `(1 - B)^d` to a time series, where `d` is a real number. This transforms the series `{X_t}` into a new series `{\\tilde{X}_t}`.\n- **[Definition] Long Memory**: A property of a time series where observations in the distant past have a persistent correlation with current observations. Fractional differentiation with a non-integer `d` preserves this property, whereas integer differentiation (e.g., `d=1`) destroys it.\n\n### Mathematical Derivation\nThe fractional differentiation operator `(1 - B)^d` can be expressed using a formal binomial series expansion:\n\n**Equation 1: Binomial Series Expansion**\n```\n(1 - B)^d = \\sum_{k=0}^{\\infty} \\binom{d}{k} (-B)^k = 1 - d B + \\frac{d(d-1)}{2!}B^2 - \\frac{d(d-1)(d-2)}{3!}B^3 + \\cdots\n```\n\nApplying this operator to a time series `{X_t}` results in a fractionally differentiated series `{\\tilde{X}_t}`, where each point is a weighted sum of past values:\n\n**Equation 2: Differentiated Series Calculation**\n```\n\\tilde{X}_{t} = \\sum_{k = 0}^{\\infty} \\omega_{k} X_{t - k}\n```\n\nThe weights `\\omega_k` are derived directly from the coefficients of the binomial expansion in Equation 1:\n\n**Equation 3: Weight Series Definition**\n```\n\\omega = \\left\\{ \\omega_0, \\omega_1, \\omega_2, \\ldots \\right\\} = \\left\\{1, -d, \\frac{d(d-1)}{2!}, \\ldots, (-1)^k \\prod_{i=0}^{k-1} \\frac{d-i}{k!}, \\ldots \\right\\}\n```\n\n### Iterative Estimation\nCalculating each weight `\\omega_k` using the product form in Equation 3 is computationally inefficient. A more practical approach is to generate the weights iteratively. Observing the relationship between consecutive weights, we can derive a simple recursive formula, starting with `\\omega_0 = 1`:\n\n**Equation 4: Iterative Weight Formula**\n```\n\\omega_{k} = -\\omega_{k - 1} \\frac{d - k + 1}{k}\n```\n\n- **Where**:\n  - `\\omega_k` is the weight at lag `k`.\n  - `\\omega_{k-1}` is the weight at the previous lag `k-1`.\n  - `d` is the order of differentiation.\n  - `k` is the current lag index (`k >= 1`).",
    "question": "Provide the pseudocode for a function that generates a specified number of weights for a given fractional differentiation order `d` using the iterative estimation formula.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateWeights(d, size)\n// INPUTS:\n//   - d: A real number representing the order of differentiation.\n//   - size: An integer specifying the total number of weights to generate.\n// OUTPUTS:\n//   - A list or array of floating-point numbers representing the weights [w_0, w_1, ..., w_{size-1}].\n//\n// BEGIN\n//   // Initialize a list to store the weights.\n//   // The first weight, w_0, is always 1.0, as per the definition.\n//   LET weights = [1.0]\n//\n//   // Iteratively compute the remaining weights from k=1 to size-1.\n//   FOR k FROM 1 TO size - 1:\n//     // Get the previous weight, w_{k-1}.\n//     LET prev_weight = weights[k - 1]\n//\n//     // Apply the iterative formula from Equation 4.\n//     LET next_weight = -prev_weight * (d - k + 1) / k\n//\n//     // Append the newly computed weight to the list.\n//     APPEND next_weight TO weights\n//   END FOR\n//\n//   RETURN weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 39,
    "text": "### Implementation Overview\nWhen applying fractional differentiation to a finite time series, two primary methods exist: the standard expanding window method and the superior fixed-width window method. The choice of method significantly impacts the statistical properties of the resulting series.\n\n### Method 1: Expanding Window (Standard Fracdiff)\nThis method computes each differentiated point `\\tilde{X}_t` using all available past data up to that point. For `\\tilde{X}_t`, it uses `t` observations and `t` weights. For `\\tilde{X}_{t+1}`, it uses `t+1` observations and `t+1` weights.\n\n- **[Definition] Expanding Window Fracdiff**: An implementation where the number of historical data points (and corresponding weights) used to calculate a differentiated value increases for each subsequent point in the time series.\n- **Drawback**: This approach introduces a non-stationarity, often seen as a negative drift in the output series. This happens because as the window expands, new, small, negative weights are continuously added to the calculation, systematically pulling down the values over time. This artifact can corrupt subsequent analysis.\n\n### Method 2: Fixed-Width Window Fracdiff (FFD)\nThis improved method avoids the drift problem by using a constant number of weights for every calculation. The window size is determined by finding the point at which the weights become insignificantly small.\n\n- **[Definition] Fixed-Width Window Fracdiff (FFD)**: An implementation where the series of weights is truncated once the absolute value of a weight falls below a specified threshold `\\tau`. The same truncated vector of weights is then applied across the entire time series.\n\n#### FFD Computational Steps\n1.  **Determine Window Size**: Generate the series of weights `\\omega_k` for a given differentiation order `d` using the iterative formula (starting with `\\omega_0 = 1`): `\\omega_{k} = -\\omega_{k - 1} \\frac{d - k + 1}{k}`. Continue generating weights until the absolute value of the most recent weight, `|\\omega_k|`, falls below a user-defined threshold `\\tau` (e.g., 1e-5). The set of all generated weights forms the fixed-width window.\n\n2.  **Truncate Weights**: Create a new, fixed-size weight vector `\\tilde{\\omega}` containing only the generated weights.\n\n    **Equation 1: Truncated Weights**\n    ```\n    \\tilde{\\omega}_{k} = \\begin{cases} \\omega_{k} & \\text{if } |\\omega_k| \\ge \\tau \\\\ 0 & \\text{otherwise} \\end{cases}\n    ```\n\n3.  **Apply Fixed Window**: Slide this fixed-width window across the time series. For each time `t` where a full window of past data is available, calculate the differentiated value `\\tilde{X}_t` as the dot product of the truncated weight vector and the corresponding slice of the input series.\n\n    **Equation 2: FFD Calculation**\n    ```\n    \\tilde{X}_{t} = \\sum_{k = 0}^{l^{*}} \\tilde{\\omega}_{k} X_{t - k}\n    ```\n    (where `l*` is the last index `k` for which `|\\omega_k| \\ge \\tau`)\n\nThis ensures that every point in the output series is computed with the same amount of memory, eliminating the artificial drift and producing a stationary series suitable for modeling.",
    "question": "Provide the pseudocode for a function that applies the Fixed-Width Window Fractional Differentiation (FFD) method to a time series. This function should internally determine the required window size based on a weight threshold.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FracDiff_FFD(series, d, threshold)\n// INPUTS:\n//   - series: A time series of numerical values.\n//   - d: A real number for the order of differentiation.\n//   - threshold: A small positive float (e.g., 1e-5) to determine the weight cutoff.\n// OUTPUTS:\n//   - A new time series containing the fractionally differentiated values.\n//\n// BEGIN\n//   // --- Step 1: Determine Window Size & Truncate Weights ---\n//   LET weights = []\n//   LET w = 1.0\n//   APPEND w TO weights\n//\n//   LET k = 1\n//   LOOP WHILE ABS(w) > threshold:\n//     // Use the iterative formula to get the next weight.\n//     w = -weights[k - 1] * (d - k + 1) / k\n//     APPEND w TO weights\n//     INCREMENT k\n//   END LOOP\n//\n//   LET window_size = LENGTH(weights)\n//   LET output_series = NEW_SERIES()\n//\n//   // --- Step 2: Apply Fixed Window ---\n//   // Iterate through the input series, starting from the first point\n//   // where a full window of past data is available.\n//   FOR i FROM (window_size - 1) TO (LENGTH(series) - 1):\n//     // Get the slice of the input series corresponding to the current window.\n//     LET data_slice = GET_SLICE(series, FROM (i - window_size + 1) TO i)\n//\n//     // Calculate the dot product of the weights and the data slice.\n//     // Note: The weights are generated for lags 0, 1, 2... so they should be\n//     // multiplied by data at t, t-1, t-2... which requires reversing one of them.\n//     LET differentiated_value = DOT_PRODUCT(REVERSE(weights), data_slice)\n//\n//     // Store the result in the output series, preserving the original timestamp.\n//     LET timestamp = GET_TIMESTAMP(series, AT i)\n//     SET_VALUE(output_series, AT timestamp, TO differentiated_value)\n//   END FOR\n//\n//   RETURN output_series\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 40,
    "text": "## Framework Overview\nStandard k-fold cross-validation fails in finance because financial data is not IID (Independent and Identically Distributed). Specifically, labels for observations often span overlapping time periods, causing information from the test set to leak into the training set. Purged K-Fold Cross-Validation is a specialized generator designed to create train/test splits that prevent this leakage.\n\n## Key Concepts\n\n1.  **Label Timing Data (`t1` series)**: A critical input is a data series (e.g., a pandas Series) where the index represents the start time of an observation (`t_0`) and the value represents the end time of its corresponding label (`t_1`). This structure is essential for identifying overlaps.\n\n2.  **Purging**:\n    *   **[Definition] Purging**: The process of removing observations from the training set if their labels' time spans overlap with the time spans of any labels in the test set. This is the primary mechanism for preventing leakage.\n\n3.  **Embargoing**:\n    *   **[Definition] Embargoing**: The process of removing observations from the training set that occur immediately *after* the test set ends. This creates a small time gap and helps mitigate leakage from serially correlated features where information might persist beyond the label's formal end time.\n\n## Computational Logic\n\nThe core of the algorithm involves generating k-fold splits and then systematically cleaning the training indices for each split.\n\n**1. Identifying Label Overlap**\nFor a training label `i` spanning `[t_{i,0}, t_{i,1}]` and a test label `j` spanning `[t_{j,0}, t_{j,1}]`, an overlap occurs if any of the following conditions are met:\n\n*   Equation 1: `t_{j,0} <= t_{i,0} <= t_{j,1}` (Training start is inside test interval)\n*   Equation 2: `t_{j,0} <= t_{i,1} <= t_{j,1}` (Training end is inside test interval)\n*   Equation 3: `t_{i,0} <= t_{j,0} <= t_{j,1} <= t_{i,1}` (Training interval envelops test interval)\n\nAny training observation `i` satisfying these conditions relative to any test observation `j` must be purged.\n\n**2. The Purged K-Fold Process**\nThe overall process for the generator is as follows:\n\n1.  Divide the dataset indices into `k` contiguous splits. These will form the initial test sets.\n2.  For each test set split:\n    a.  Identify all training indices that come *before* the test set begins.\n    b.  Identify the latest end time (`t_1`) among all labels in the current test set.\n    c.  Apply the embargo by finding the first potential training index that starts *after* the latest test label end time plus the embargo period.\n    d.  Combine the early training indices (from step 2a) with the post-embargo training indices (from step 2c) to form the final, purged training set.\n    e.  Yield the pair of (final training indices, test indices).",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Purged K-Fold Generator Implementation]`**:\n    *   **Task**: Provide the pseudocode for a generator function that implements the complete Purged K-Fold Cross-Validation logic, including both purging and embargoing. The generator should yield pairs of training and testing indices for each fold.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PurgedKFoldGenerator(X_indices, t1_series, n_splits, embargo_pct)\n// INPUTS:\n//   - X_indices: An array of integer indices for the entire dataset X.\n//   - t1_series: A Series where index is observation start time and value is label end time.\n//   - n_splits: The number of folds (k).\n//   - embargo_pct: The percentage of the dataset size to use as an embargo period.\n// OUTPUTS:\n//   - Yields a tuple of (train_indices, test_indices) for each fold.\n//\n// BEGIN\n//   // 1. Split the main indices into k folds for testing.\n//   test_splits = split_array_into_k_parts(X_indices, n_splits)\n//\n//   // Calculate the size of the embargo in terms of number of observations.\n//   embargo_size = integer(length(X_indices) * embargo_pct)\n//\n//   // 2. Iterate through each fold to generate train/test splits.\n//   FOR each test_indices in test_splits:\n//     // Get the start time of the first observation in the test set.\n//     test_start_time = t1_series.index[test_indices[0]]\n//\n//     // --- PURGING LOGIC (Implicit) ---\n//     // Find all indices for training data that occurred *before* the test set started.\n//     // This implicitly purges any training data that overlaps with or is inside the test set.\n//     train_indices_before = indices in X_indices where t1_series.values < test_start_time\n//\n//     // Find the latest end time of any label within the current test set.\n//     latest_test_label_end_time = max(t1_series.values[test_indices])\n//\n//     // --- EMBARGO LOGIC ---\n//     // Find all indices for training data that start *after* the embargo period.\n//     // First, find all observations that start after the test set's latest label end time.\n//     potential_indices_after = indices in X_indices where t1_series.index > latest_test_label_end_time\n//     // Then, apply the embargo by skipping the first 'embargo_size' of these observations.\n//     train_indices_after = potential_indices_after[embargo_size:]\n//\n//     // Combine the two parts to form the final training set.\n//     final_train_indices = concatenate(train_indices_before, train_indices_after)\n//\n//     // Yield the result for this fold.\n//     YIELD (final_train_indices, test_indices)\n//   ENDFOR\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 41,
    "text": "## Problem Context\nStandard machine learning libraries, such as scikit-learn, are powerful but not infallible, especially when applied to the nuances of financial data. Their default cross-validation scoring functions (e.g., `cross_val_score`) can produce misleading results due to subtle bugs. Two documented issues are:\n\n1.  **Inconsistent Sample Weighting**: The function may pass sample weights to the model's `fit` method but fail to pass them to the scoring metric (e.g., `log_loss`), leading to a mismatch in how performance is evaluated.\n2.  **Missing Class Labels**: Scoring functions may not have access to the classifier's learned attributes (like `classes_`), causing errors when the metric requires them, particularly in classification tasks.\n\nTo ensure reliable model evaluation, a custom scoring function is required that bypasses these issues.\n\n## Key Requirements\n\n*   **[Definition] Purged K-Fold Integration**: The scoring function must not use a standard k-fold splitter. Instead, it must instantiate and use a `PurgedKFold` generator to create train/test splits, which correctly handles information leakage from overlapping financial labels.\n\n*   **[Definition] Correct Sample Weighting**: The implementation must ensure that the same set of sample weights is applied consistently. This means passing the relevant subset of weights to the model's `fit` method for training and to the final scoring metric for evaluation.\n\n*   **[Definition] Explicit Class Label Handling**: For classification metrics like `log_loss`, the function must explicitly pass the fitted classifier's `classes_` attribute to the scoring function. This avoids errors that occur when the scoring function cannot infer the full set of possible labels from the test set alone.\n\n## Procedural Steps\nThe custom scoring function should follow this logic:\n\n1.  Initialize a `PurgedKFold` generator using the provided label timing data (`t1`) and embargo percentage.\n2.  Create an empty list to store the scores from each fold.\n3.  Iterate through the `(train_indices, test_indices)` pairs yielded by the `PurgedKFold` generator.\n4.  For each fold:\n    a.  Select the training data (`X_train`, `y_train`) and corresponding `sample_weight_train` using `train_indices`.\n    b.  Fit the classifier using this training data and sample weights.\n    c.  Select the test data (`X_test`, `y_test`) and corresponding `sample_weight_test` using `test_indices`.\n    d.  Generate predictions (probabilities or classes) on the test data.\n    e.  Calculate the score for the fold using the appropriate metric (e.g., `log_loss`, `accuracy_score`), explicitly passing `y_test`, the predictions, `sample_weight_test`, and (if needed) the fitted classifier's `classes_`.\n    f.  Append the calculated score to the list.\n5.  Return the list of scores as an array.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Bug-Resistant CV Scoring Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that correctly computes cross-validation scores for a given classifier. The function must use the Purged K-Fold methodology for splitting and explicitly handle the correct application of sample weights and class labels during scoring.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION cvScore(classifier, X, y, sample_weights, scoring_method, t1_series, num_cv_splits, embargo_pct)\n// INPUTS:\n//   - classifier: The machine learning model object with fit/predict methods.\n//   - X: The feature dataset.\n//   - y: The label dataset.\n//   - sample_weights: A series of weights for each observation.\n//   - scoring_method: String, e.g., 'neg_log_loss' or 'accuracy'.\n//   - t1_series: A Series for Purged K-Fold, mapping observation start to label end times.\n//   - num_cv_splits: The number of cross-validation folds.\n//   - embargo_pct: The embargo percentage for Purged K-Fold.\n// OUTPUTS:\n//   - An array of scores, one for each cross-validation fold.\n//\n// BEGIN\n//   // 1. Initialize the custom Purged K-Fold generator.\n//   cv_generator = PurgedKFoldGenerator(X.indices, t1_series, num_cv_splits, embargo_pct)\n//\n//   scores = empty_list()\n//\n//   // 2. Iterate through the purged and embargoed train/test splits.\n//   FOR train_indices, test_indices in cv_generator:\n//     // 3. Prepare data for the current fold.\n//     X_train = X.subset(train_indices)\n//     y_train = y.subset(train_indices)\n//     weights_train = sample_weights.subset(train_indices)\n//\n//     X_test = X.subset(test_indices)\n//     y_test = y.subset(test_indices)\n//     weights_test = sample_weights.subset(test_indices)\n//\n//     // 4. Fit the classifier on the training data with sample weights.\n//     fitted_model = classifier.fit(X_train, y_train, sample_weight=weights_train)\n//\n//     // 5. Calculate the score for the fold, handling specific methods.\n//     fold_score = 0\n//     IF scoring_method == 'neg_log_loss':\n//       // Generate probabilities for log_loss.\n//       probabilities = fitted_model.predict_proba(X_test)\n//       // Explicitly pass weights and the fitted model's classes to the metric.\n//       fold_score = -log_loss(y_true=y_test, y_pred=probabilities, sample_weight=weights_test, labels=fitted_model.classes_)\n//     ELSE IF scoring_method == 'accuracy':\n//       // Generate class predictions for accuracy.\n//       predictions = fitted_model.predict(X_test)\n//       // Explicitly pass weights to the metric.\n//       fold_score = accuracy_score(y_true=y_test, y_pred=predictions, sample_weight=weights_test)\n//     ENDIF\n//\n//     // 6. Store the result.\n//     scores.append(fold_score)\n//   ENDFOR\n//\n//   // 7. Return the collected scores.\n//   RETURN array(scores)\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 42,
    "text": "### Framework Overview\n\nMean Decrease Impurity (MDI) is a method used to evaluate the importance of features within tree-based ensemble models, such as Random Forests. It operates by measuring how much each feature contributes to reducing impurity (i.e., increasing node purity) across all decision trees in the ensemble. The final importance of a feature is the average of its impurity reduction contribution over all trees.\n\n### Key Concepts & Properties\n\n- [Definition] Mean Decrease Impurity (MDI): An in-sample (IS), model-specific feature importance technique for tree-based classifiers. It quantifies a feature's contribution by averaging its total impurity reduction at split nodes across all trees in a forest.\n- [Definition] Masking Effects: A phenomenon where a tree-based model systematically prefers one feature over another correlated or similar feature, potentially causing the second feature to appear unimportant. To mitigate this, models can be trained with `max_features=1`, forcing each split to consider only one randomly selected feature.\n- [Definition] Substitution Effects: When two or more features contain similar information (i.e., are correlated), MDI may dilute their importance by splitting it among them. For instance, two identical features would each receive half the importance they would have had alone.\n\n### Computational Steps & Considerations\n\nThe calculation of MDI involves several critical steps, especially when accounting for specific model configurations:\n\n1.  **Model Specificity**: MDI is only applicable to tree-based classifiers and cannot be generalized to other model types.\n2.  **In-Sample Nature**: Because MDI is calculated on the training data, every feature will likely be assigned some non-zero importance, even if it has no true predictive power on out-of-sample data.\n3.  **Handling Unused Features**: When a model is configured with `max_features=1`, many features will not be selected for splitting in any given tree. Their importance for that tree will be zero. These zero values should not be included when averaging, as they represent non-selection, not zero contribution. The standard practice is to replace these zeros with a null value (e.g., `NaN`) before calculating the mean.\n4.  **Normalization**: By construction, the feature importances for a single tree sum to 1. The final aggregated MDI scores are typically normalized so that the mean importances across all features also sum to 1.",
    "question": "Provide the pseudocode for a function that calculates Mean Decrease Impurity (MDI) feature importance from a fitted tree-based ensemble model (e.g., a Random Forest). The implementation must account for the masking effect by replacing zero-importance values with a null value (e.g., `NaN`) before aggregation, a necessary step when models are trained with `max_features=1`.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION MdiFeatureImportance(fitted_model, feature_names)\n// INPUTS:\n//   - fitted_model: A trained tree-based ensemble model (e.g., RandomForest) that exposes an 'estimators_' attribute.\n//   - feature_names: A list of strings corresponding to the column names of the training features.\n// OUTPUTS:\n//   - A table (e.g., DataFrame) with columns 'mean' and 'std', indexed by feature_names, containing the normalized mean importance and standard error.\n//\n// BEGIN\n//   // Step 1: Extract feature importances from each tree in the forest.\n//   LET importance_dict = an empty Dictionary\n//   FOR i from 0 to (number of trees in fitted_model.estimators_ - 1)\n//     LET tree = fitted_model.estimators_[i]\n//     importance_dict[i] = tree.feature_importances_ // This is an array of importances for this tree\n//   END FOR\n//\n//   // Step 2: Convert the dictionary to a table and assign feature names.\n//   LET importance_table = CreateTableFromDictionary(importance_dict, orientation='index')\n//   SET importance_table.columns = feature_names\n//\n//   // Step 3: Handle masking effects from 'max_features=1' setting.\n//   // Replace 0s with NaN so they are ignored in the mean calculation.\n//   REPLACE all 0 values in importance_table with NaN\n//\n//   // Step 4: Calculate the mean and standard error of importance for each feature.\n//   LET num_trees = number of rows in importance_table\n//   LET mean_importance = CalculateColumnMeans(importance_table) // Ignores NaN\n//   LET std_dev_importance = CalculateColumnStdDev(importance_table) // Ignores NaN\n//   LET std_error_importance = std_dev_importance / SquareRoot(num_trees)\n//\n//   // Step 5: Combine results and normalize the mean importance.\n//   LET result_table = CreateTable({'mean': mean_importance, 'std': std_error_importance})\n//   LET total_mean_importance = Sum(result_table['mean'])\n//   result_table['mean'] = result_table['mean'] / total_mean_importance\n//\n//   RETURN result_table\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 43,
    "text": "### Framework Overview\n\nMean Decrease Accuracy (MDA) is a powerful, model-agnostic technique for assessing feature importance. Unlike in-sample methods, MDA evaluates features based on their impact on a model's out-of-sample (OOS) predictive performance. The core idea is to measure the decrease in model performance when the information content of a single feature is destroyed through random permutation.\n\n### Key Concepts\n\n- [Definition] Mean Decrease Accuracy (MDA): An out-of-sample (OOS) feature importance method. It measures the importance of a feature by quantifying the drop in a model's predictive score (e.g., accuracy, log-loss) after that feature's values have been randomly shuffled in the test set.\n- [Definition] Permutation Importance: A more general name for MDA, as the scoring metric is not limited to accuracy. Any valid performance score can be used.\n- [Definition] Purged Cross-Validation: A financial machine learning-specific cross-validation technique that prevents information leakage. It works by creating a temporal gap (\"purging\") between the training and testing sets to ensure that labels from the training set do not overlap in time with observations in the test set.\n\n### Computational Steps\n\nThe MDA process is executed within a cross-validation loop:\n\n1.  **Establish Baseline**: For each fold in a cross-validation split, train a model and compute its performance score on the original, unmodified test set. This is the baseline score.\n2.  **Permute and Rescore**: For each feature, create a copy of the test set and randomly shuffle the values in that feature's column. Then, use the already-trained model to make predictions on this modified test set and calculate a new performance score. \n3.  **Calculate Importance**: The raw importance for that feature in that fold is the difference between the baseline score and the score from the permuted data.\n4.  **Aggregate**: Repeat this process for all features and all folds. The final importance for each feature is the average of its raw importance scores across all folds.\n\n### Key Considerations\n\n1.  **Model Agnostic**: MDA can be applied to any classifier or regression model, not just tree-based methods.\n2.  **Substitution Effects**: If two features are highly correlated (substitutes), permuting one may not significantly degrade performance because the other feature still provides the necessary information. This can cause MDA to incorrectly label both features as unimportant.\n3.  **Out-of-Sample Evaluation**: Because MDA is based on OOS performance, it is possible for it to conclude that all features are unimportant if the model has no predictive power.\n4.  **Financial Data**: For time-series financial data, it is critical to use a cross-validation method like Purged K-Fold to prevent look-ahead bias and ensure the OOS scores are valid.",
    "question": "Provide the pseudocode for a function that calculates Mean Decrease Accuracy (MDA) feature importance. The implementation must accept a purged cross-validation generator to compute robust out-of-sample scores for a given classifier and scoring function.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION MdaFeatureImportance(classifier, features_X, labels_y, cv_generator, scoring_function)\n// INPUTS:\n//   - classifier: The machine learning model to be evaluated.\n//   - features_X: A table of features for the entire dataset.\n//   - labels_y: A series of labels for the entire dataset.\n//   - cv_generator: A purged cross-validation object that yields (train_indices, test_indices).\n//   - scoring_function: A function that takes (true_labels, predictions) and returns a score.\n// OUTPUTS:\n//   - A table (e.g., DataFrame) with columns 'mean' and 'std', indexed by feature name, containing the final importance scores.\n//\n// BEGIN\n//   LET baseline_scores = an empty Series\n//   LET permuted_scores = an empty DataFrame with columns matching feature names in features_X\n//   LET fold_index = 0\n//\n//   // Step 1: Loop through each fold from the purged CV generator.\n//   FOR each (train_indices, test_indices) in cv_generator.split(features_X)\n//     LET X_train = features_X.iloc[train_indices]\n//     LET y_train = labels_y.iloc[train_indices]\n//     LET X_test = features_X.iloc[test_indices]\n//     LET y_test = labels_y.iloc[test_indices]\n//\n//     // Step 2: Fit the model and calculate the baseline score on the original test set.\n//     LET fitted_model = classifier.fit(X_train, y_train)\n//     LET predictions_baseline = fitted_model.predict(X_test)\n//     LET score_baseline = scoring_function(y_test, predictions_baseline)\n//     baseline_scores[fold_index] = score_baseline\n//\n//     // Step 3: Loop through each feature to calculate permuted scores.\n//     FOR each feature_name in features_X.columns\n//       LET X_test_permuted = X_test.copy()\n//       // Permute the single feature column.\n//       SHUFFLE X_test_permuted[feature_name].values\n//\n//       LET predictions_permuted = fitted_model.predict(X_test_permuted)\n//       LET score_permuted = scoring_function(y_test, predictions_permuted)\n//       permuted_scores.at[fold_index, feature_name] = score_permuted\n//     END FOR\n//\n//     INCREMENT fold_index\n//   END FOR\n//\n//   // Step 4: Calculate importance. For a score where higher is better (e.g., accuracy),\n//   // importance is the drop in performance: baseline_score - permuted_score.\n//   LET importance = an empty DataFrame\n//   FOR each feature_name in permuted_scores.columns\n//     importance[feature_name] = baseline_scores - permuted_scores[feature_name]\n//   END FOR\n//\n//   // Step 5: Aggregate results across all folds.\n//   LET mean_importance = CalculateColumnMeans(importance)\n//   LET std_dev_importance = CalculateColumnStdDev(importance)\n//   LET num_folds = number of rows in importance\n//   LET std_error_importance = std_dev_importance / SquareRoot(num_folds)\n//\n//   LET result_table = CreateTable({'mean': mean_importance, 'std': std_error_importance})\n//\n//   RETURN result_table\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 44,
    "text": "## Framework Overview\n\nHyper-parameter tuning is a critical step to prevent model overfitting. A standard approach is Grid Search Cross-Validation, which exhaustively searches a predefined set of parameter combinations to find the one that maximizes a chosen performance score. In financial applications, standard cross-validation (CV) is prone to data leakage. Therefore, it is essential to use a specialized CV scheme like Purged K-Fold, which prevents the model from being evaluated on information it would not have had in a live trading scenario.\n\nThis task involves creating a function that integrates Grid Search with Purged K-Fold CV, while also addressing practical implementation challenges like passing sample weights through Scikit-learn pipelines and enhancing model stability through bagging.\n\n## Key Components\n\n1.  **Cross-Validation Strategy**:\n    *   **[Definition] Purged K-Fold Cross-Validation**: A cross-validation technique designed for financial time series. It creates training and testing splits, then \"purges\" any training samples whose labels overlap in time with the labels of the test set. This prevents look-ahead bias, where the model inadvertently learns from future information.\n\n2.  **Hyper-Parameter Search**:\n    *   **[Definition] Grid Search Cross-Validation**: An algorithm that performs an exhaustive search over a specified grid of hyper-parameter values for an estimator. It evaluates every combination of parameters using cross-validation and returns the combination that yields the best performance.\n\n3.  **Model Enhancement**:\n    *   **[Definition] Bagging (Bootstrap Aggregating)**: An ensemble meta-algorithm that improves the stability and accuracy of machine learning models. It works by training multiple models on different random subsets of the training data and averaging their predictions.\n\n4.  **Performance Scoring**:\n    *   **[Definition] Meta-Labeling Scoring ('f1' score)**: For binary classification tasks with imbalanced classes (common in meta-labeling), the 'f1' score is preferred. It is the harmonic mean of precision and recall, providing a more realistic performance measure than accuracy when one class heavily outweighs the other.\n\n## Implementation Challenge: Sample Weights in Pipelines\n\nA common issue with standard Scikit-learn `Pipeline` objects is their inability to directly accept a `sample_weight` argument in their `.fit()` method. This is problematic in finance, where observations are often weighted by their market importance (e.g., by returns). A workaround is to create a custom pipeline class that correctly handles and passes the `sample_weight` argument to the final estimator in the pipeline.\n\n**Snippet 1: An Enhanced Pipeline Class**\n```python\nclass MyPipeline(Pipeline):\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        if sample_weight is not None:\n            fit_params[self.steps[-1][0] + '__sample_weight'] = sample_weight\n        return super(MyPipeline, self).fit(X, y, **fit_params)\n```",
    "question": "Provide the pseudocode for a function that performs hyper-parameter tuning using Grid Search with Purged K-Fold. The function should incorporate the `MyPipeline` workaround for sample weights and include logic to optionally apply bagging to the best-performing model.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION HyperParameterFit(features, labels, t1_series, classifier_pipeline, param_grid, cv_folds, bagging_params, fit_params)\n// INPUTS:\n//   - features: Dataframe of input features.\n//   - labels: Series of output labels.\n//   - t1_series: Series mapping observation start times to label end times (for purging).\n//   - classifier_pipeline: The machine learning pipeline to be tuned.\n//   - param_grid: Dictionary defining the grid of parameters to search.\n//   - cv_folds: Integer, the number of cross-validation folds.\n//   - bagging_params: List/Tuple containing [n_estimators, max_samples, max_features]. If max_samples is 0, bagging is skipped.\n//   - fit_params: Dictionary of additional parameters for the fit method, e.g., sample_weight.\n// OUTPUTS:\n//   - A fully trained and tuned classifier pipeline, possibly wrapped in a BaggingClassifier.\n//\n// BEGIN\n//   // Step 1: Determine the appropriate scoring metric based on the label type.\n//   IF the set of unique labels is {0, 1} THEN\n//     scoring_metric = 'f1' // Use F1 score for binary meta-labeling\n//   ELSE\n//     scoring_metric = 'neg_log_loss' // Use log loss for other cases\n//   END IF\n//\n//   // Step 2: Initialize the Purged K-Fold cross-validator.\n//   inner_cv = CREATE PurgedKFold(n_splits = cv_folds, t1 = t1_series)\n//\n//   // Step 3: Set up and run the Grid Search with the purged CV.\n//   grid_search = CREATE GridSearchCV(estimator = classifier_pipeline, param_grid = param_grid, scoring = scoring_metric, cv = inner_cv)\n//   best_estimator = grid_search.fit(features, labels, **fit_params).best_estimator_\n//\n//   // Step 4: Re-fit the best estimator on the entire dataset, potentially with bagging.\n//   // The custom MyPipeline is used here to handle sample weights correctly within the bagging process.\n//   IF bagging_params[1] > 0 THEN\n//     // Wrap the steps of the best pipeline into our custom MyPipeline\n//     base_model = CREATE MyPipeline(steps = best_estimator.steps)\n//     \n//     // Create a BaggingClassifier with the custom pipeline as the base estimator\n//     final_model = CREATE BaggingClassifier(base_estimator = base_model, \n//                                         n_estimators = bagging_params[0], \n//                                         max_samples = bagging_params[1], \n//                                         max_features = bagging_params[2])\n//\n//     // Extract sample_weight from fit_params for the final fit\n//     final_model.fit(features, labels, **fit_params) // MyPipeline handles the weight passing\n//   ELSE\n//     final_model = best_estimator // No bagging, use the best estimator directly\n//   END IF\n//\n//   // Step 5: Return the final, trained model.\n//   RETURN final_model\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 45,
    "text": "## Framework Overview\n\nFor machine learning models with a large number of hyper-parameters, an exhaustive Grid Search becomes computationally intractable. The number of combinations to evaluate grows exponentially with the number of parameters, making the process prohibitively slow. Randomized Search offers a more efficient alternative.\n\nInstead of trying every combination, Randomized Search samples a fixed number of parameter combinations from specified statistical distributions. This approach has two major benefits: it allows direct control over the computational budget, and it is more effective at finding good parameters when some parameters are more influential than others.\n\nThis task is to create a unified function that can perform hyper-parameter tuning using either Grid Search or Randomized Search, always in combination with Purged K-Fold cross-validation to prevent data leakage.\n\n## Key Concepts\n\n1.  **Search Strategy**:\n    *   **[Definition] Randomized Search Cross-Validation**: A hyper-parameter tuning technique that samples a fixed number of parameter settings (`n_iter`) from specified distributions. It is more efficient than Grid Search when the parameter space is large, as it is not guaranteed to explore all combinations but is likely to find a very good combination within a fixed budget.\n\n2.  **Efficiency**:\n    *   **[Definition] Computational Budget**: A limit on the computational resources (e.g., time or number of iterations) allocated to a task. In Randomized Search, the `n_iter` parameter directly sets the computational budget by defining how many parameter combinations will be tested, regardless of the size of the parameter space.\n\n## Integrated Implementation\n\nThe goal is to create a single, flexible function for hyper-parameter tuning. This function should default to the exhaustive Grid Search method but switch to the more efficient Randomized Search method if a specific number of iterations is provided. This is achieved by checking an input parameter (e.g., `rndSearchIter`). If this parameter is zero, `GridSearchCV` is used. If it is greater than zero, `RandomizedSearchCV` is used with the specified number of iterations.\n\nThis design provides a powerful tool that adapts to the complexity of the tuning problem: use Grid Search for simpler models with few parameters and Randomized Search for complex models with many parameters.",
    "question": "Provide the pseudocode for a single function that performs hyper-parameter tuning using Purged K-Fold. The function must be able to operate in either Grid Search mode or Randomized Search mode based on an input parameter that specifies the number of random search iterations.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FlexibleHyperParameterFit(features, labels, t1_series, classifier_pipeline, param_grid, cv_folds, bagging_params, rnd_search_iter, fit_params)\n// INPUTS:\n//   - features: Dataframe of input features.\n//   - labels: Series of output labels.\n//   - t1_series: Series mapping observation start times to label end times (for purging).\n//   - classifier_pipeline: The machine learning pipeline to be tuned.\n//   - param_grid: Dictionary defining parameter grid (for Grid Search) or distributions (for Randomized Search).\n//   - cv_folds: Integer, the number of cross-validation folds.\n//   - bagging_params: List/Tuple for bagging configuration.\n//   - rnd_search_iter: Integer. If 0, use Grid Search. If > 0, use Randomized Search with this many iterations.\n//   - fit_params: Dictionary of additional parameters for the fit method, e.g., sample_weight.\n// OUTPUTS:\n//   - A fully trained and tuned classifier pipeline.\n//\n// BEGIN\n//   // Step 1: Determine the appropriate scoring metric.\n//   IF the set of unique labels is {0, 1} THEN\n//     scoring_metric = 'f1'\n//   ELSE\n//     scoring_metric = 'neg_log_loss'\n//   END IF\n//\n//   // Step 2: Initialize the Purged K-Fold cross-validator.\n//   inner_cv = CREATE PurgedKFold(n_splits = cv_folds, t1 = t1_series)\n//\n//   // Step 3: Dynamically choose search method based on rnd_search_iter.\n//   IF rnd_search_iter == 0 THEN\n//     // Use Grid Search for an exhaustive search.\n//     searcher = CREATE GridSearchCV(estimator = classifier_pipeline, param_grid = param_grid, scoring = scoring_metric, cv = inner_cv)\n//   ELSE\n//     // Use Randomized Search for a budgeted search.\n//     searcher = CREATE RandomizedSearchCV(estimator = classifier_pipeline, param_distributions = param_grid, scoring = scoring_metric, cv = inner_cv, n_iter = rnd_search_iter)\n//   END IF\n//\n//   // Step 4: Execute the search and get the best estimator.\n//   best_estimator = searcher.fit(features, labels, **fit_params).best_estimator_\n//\n//   // Step 5: Optionally apply bagging to the best estimator (logic omitted for brevity, but would be identical to previous problem).\n//   // ... Bagging logic here ...\n//   final_model = best_estimator // Assuming no bagging for this pseudocode's focus.\n//\n//   // Step 6: Return the final, trained model.\n//   RETURN final_model\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 46,
    "text": "## Motivation for Log-Uniform Sampling\n\nWhen using Randomized Search for hyper-parameter tuning, we sample values from statistical distributions. For many non-negative parameters (like regularization strength `C` or kernel coefficient `gamma` in an SVM), a standard uniform distribution is inefficient. The model's performance may change dramatically for values between 0.01 and 1, but very little for values between 100 and 1000. Sampling uniformly from `[0.01, 1000]` would waste most samples on the high end where performance is flat.\n\nA more effective approach is to sample in a way that explores different orders of magnitude evenly. This is achieved by sampling from a distribution where the *logarithm* of the drawn values is uniformly distributed.\n\n## Mathematical Definition\n\n*   **[Definition] Log-Uniform Distribution**: A continuous probability distribution of a random variable `x` whose logarithm is uniformly distributed. If a random variable `x` follows a log-uniform distribution between `a` and `b` (where `0 < a < b`), then `log(x)` is uniformly distributed on the interval `[log(a), log(b)]`.\n\nThis distribution is defined by its Cumulative Distribution Function (CDF) and Probability Density Function (PDF).\n\n**Equation 1: Cumulative Distribution Function (CDF)**\n$$ F[x] = \\begin{cases} 0 & \\text{for } x < a \\\\ \\frac{\\log(x) - \\log(a)}{\\log(b) - \\log(a)} & \\text{for } a \\le x \\le b \\\\ 1 & \\text{for } x > b \\end{cases} $$\nWhere:\n*   `x`: The value of the random variable.\n*   `a`: The lower bound of the distribution's support (`a > 0`).\n*   `b`: The upper bound of the distribution's support (`b > a`).\n*   `F[x]`: The probability that the random variable takes a value less than or equal to `x`.\n\n**Equation 2: Probability Density Function (PDF)**\n$$ f[x] = \\begin{cases} 0 & \\text{for } x < a \\\\ \\frac{1}{x \\cdot \\log(b/a)} & \\text{for } a \\le x \\le b \\\\ 0 & \\text{for } x > b \\end{cases} $$ \n\n## Implementation Approach\n\nStatistical libraries like `scipy.stats` in Python provide base classes for creating custom distributions. To implement the Log-Uniform distribution, one can create a new class that inherits from the `rv_continuous` base class and override its `_cdf` method using the formula from **Equation 1**. The library can then use this core function to derive other properties like the PDF and generate random variates (samples).",
    "question": "Provide the pseudocode for a class that implements the Log-Uniform distribution. The class should be designed to be compatible with a statistical library by inheriting from a continuous random variable base class and implementing the core `_cdf` (Cumulative Distribution Function) method.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// CLASS LogUniformDistribution INHERITS FROM ContinuousRandomVariableBase\n// DESCRIPTION:\n//   Implements a log-uniform random variable between bounds 'a' and 'b'.\n//   The class is initialized with these bounds.\n//\n// CONSTRUCTOR(a, b, name='LogUniform')\n//   // The base class constructor handles storing a, b, and name.\n//   CALL SUPER.CONSTRUCTOR(a=a, b=b, name=name)\n// END CONSTRUCTOR\n//\n// METHOD _cdf(x)\n//   // This method implements the core logic from Equation 1.\n//   // The base class will handle the cases where x < a or x > b.\n//   // INPUTS:\n//   //   - x: A value at which to evaluate the CDF.\n//   // OUTPUTS:\n//   //   - The value of the CDF at x.\n//   //\n//   // BEGIN\n//   // Calculate the numerator: log(x) - log(a) = log(x/a)\n//   numerator = LOG(x / self.a)\n//\n//   // Calculate the denominator: log(b) - log(a) = log(b/a)\n//   denominator = LOG(self.b / self.a)\n//\n//   // Return the result of the division.\n//   RETURN numerator / denominator\n//   // END\n// END METHOD\n//\n// END CLASS\n//\n// FUNCTION CreateLogUniform(a, b)\n//   // Helper function to instantiate and return a LogUniformDistribution object.\n//   // INPUTS:\n//   //   - a: The lower bound.\n//   //   - b: The upper bound.\n//   // OUTPUTS:\n//   //   - An instance of the LogUniformDistribution class.\n//   //\n//   // BEGIN\n//   RETURN NEW LogUniformDistribution(a=a, b=b)\n//   // END\n// END FUNCTION\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 47,
    "text": "## 1. Framework Overview\nBootstrap Aggregation (bagging) is an ensemble method designed to reduce the variance of a model's forecasts, thereby mitigating overfitting. The process involves three main steps:\n1.  **Generate Samples**: Create N training datasets by random sampling with replacement from the original dataset.\n2.  **Train Estimators**: Fit N independent estimators, one on each of the N bootstrapped datasets. This step is highly parallelizable.\n3.  **Aggregate Forecasts**: The final ensemble forecast is the simple average of the individual forecasts (for regression) or the result of majority voting (for classification).\n\n## 2. Key Concepts\n- **[Definition] Bootstrap Aggregation (Bagging)**: An ensemble machine learning algorithm that aims to improve the stability and accuracy of models by training multiple instances on different random subsets of the training data and then aggregating their predictions.\n- **[Definition] Overfitting**: A modeling error that occurs when a function is too closely fit to a limited set of data points. An overfit model captures noise and random fluctuations in the training data rather than the underlying relationship, leading to poor performance on new, unseen data.\n- **[Definition] Observation Redundancy**: A common issue in financial time series where observations are not independent and identically distributed (IID). For example, labels based on overlapping time windows cause samples to be highly correlated. This redundancy can inflate the correlation between bagged estimators, reducing the effectiveness of bagging.\n\n## 3. Variance Reduction Formula\nThe primary benefit of bagging is its ability to reduce forecast variance. The variance of the bagged prediction is a function of the number of estimators (N), the average variance of a single estimator's prediction, and the average correlation among their forecasts. The relationship is captured by Equation 1.\n\n**Equation 1: Variance of a Bagged Prediction**\n```\nV[ (1/N) * 鍗?锠乢i[c]) ] = 锜借檯铏?* ( 锜昏檯 + (1 - 锜昏檯) / N )\n```\nWhere:\n- `V[...]` is the variance of the ensemble's average prediction.\n- `N` is the number of bagged estimators.\n- `锠乢i[c]` is the prediction of the i-th estimator for class c.\n- `锜借檯铏廯 is the average variance of a single estimator's prediction.\n- `锜昏檯` is the average correlation among the forecasts of the N estimators.\n\nThis equation demonstrates that bagging is only effective at reducing variance if the average correlation `锜昏檯` is less than 1. As `锜昏檯` approaches 1, the ensemble variance approaches the average variance of a single estimator (`锜借檯铏廯), and the benefit of bagging diminishes.",
    "question": "1.  **`[Bagged Variance Calculation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the standard deviation (the square root of variance) of a bagged prediction based on Equation 1. The function should accept the number of estimators, the average standard deviation of a single estimator, and the average correlation as inputs.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateBaggedStdDev(N, avg_estimator_std_dev, avg_correlation)\n// INPUTS:\n//   - N: An integer representing the number of estimators in the ensemble.\n//   - avg_estimator_std_dev: A float representing the average standard deviation (sqrt of 锜借檯铏? of a single estimator's prediction.\n//   - avg_correlation: A float representing the average correlation (锜昏檯) among estimator forecasts.\n// OUTPUTS:\n//   - A float representing the standard deviation of the bagged ensemble's prediction.\n//\n// BEGIN\n//   // Step 1: Calculate the average variance of a single estimator.\n//   avg_estimator_variance = avg_estimator_std_dev ^ 2\n//\n//   // Step 2: Apply Equation 1 to calculate the variance of the bagged prediction.\n//   // V = 锜借檯铏?* ( 锜昏檯 + (1 - 锜昏檯) / N )\n//   bagged_variance = avg_estimator_variance * (avg_correlation + (1 - avg_correlation) / N)\n//\n//   // Step 3: Calculate the standard deviation by taking the square root of the variance.\n//   bagged_std_dev = SQRT(bagged_variance)\n//\n//   // Step 4: Return the final result.\n//   RETURN bagged_std_dev\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 48,
    "text": "## 1. Framework Overview\nBoosting is an ensemble method that sequentially combines multiple simple models (weak learners) to produce a single strong predictive model. Unlike bagging, which trains estimators in parallel, boosting is an iterative process where each subsequent model attempts to correct the errors of its predecessor. This is achieved by adjusting the weights of the training samples at each step.\n\n## 2. Key Concepts\n- **[Definition] Boosting**: A family of machine learning algorithms that convert a collection of weak learners into a strong learner. The process works by sequentially training models, with each new model placing greater emphasis on the instances that previous models misclassified.\n- **[Definition] Weak Learner**: A classifier that performs only slightly better than random chance. Decision trees with a very limited depth (stumps) are a common choice for weak learners in boosting algorithms.\n- **[Definition] Sample Weights**: Values assigned to each training observation that determine its importance during the model fitting process. In boosting, misclassified samples have their weights increased, forcing the next learner to focus more on them.\n\n## 3. The Boosting Algorithm Steps\nThe general procedure for a boosting algorithm can be summarized in the following six steps:\n\n1.  **Initialize Weights**: Assign an equal weight to every observation in the training set.\n2.  **Fit Estimator**: Train a weak learner on the training set using the current sample weights.\n3.  **Evaluate Performance**: Assess the accuracy of the weak learner. If its performance is below a predefined acceptance threshold (e.g., 50% for a binary classifier), it is discarded, and the process may resample and retry or terminate.\n4.  **Update Sample Weights**: Increase the weights of the observations that were misclassified by the current learner and decrease the weights of those that were correctly classified.\n5.  **Iterate**: Repeat steps 2 through 4 until a predefined number of N estimators have been successfully produced and kept.\n6.  **Form Ensemble**: The final prediction is a weighted average of the forecasts from the N individual learners, where each learner's weight in the final vote is typically determined by its individual accuracy.",
    "question": "1.  **`[Boosting Logic Implementation]`**:\n    *   **Task**: Provide the pseudocode for a generic boosting algorithm that follows the six-step process described. The pseudocode should represent the main loop and the key operations within it, including sample weight updates and the formation of the final ensemble.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenericBoosting(training_data, N_estimators, accuracy_threshold)\n// INPUTS:\n//   - training_data: A dataset containing features and labels.\n//   - N_estimators: The target number of weak learners for the ensemble.\n//   - accuracy_threshold: The minimum accuracy a learner must achieve to be included.\n// OUTPUTS:\n//   - An ensemble model consisting of a list of learners and their corresponding weights.\n//\n// BEGIN\n//   // Step 1: Initialize sample weights uniformly.\n//   num_samples = GET_NUMBER_OF_ROWS(training_data)\n//   sample_weights = INITIALIZE_ARRAY(num_samples, 1.0 / num_samples)\n//\n//   // Initialize lists to store the final ensemble components.\n//   kept_learners = []\n//   learner_weights = []\n//   num_kept_learners = 0\n//\n//   // Step 5 (Loop): Repeat until N estimators are produced.\n//   WHILE num_kept_learners < N_estimators:\n//     // Step 2: Fit an estimator on a sample drawn according to current weights.\n//     current_sample = DRAW_SAMPLE(training_data, sample_weights)\n//     weak_learner = FIT_WEAK_LEARNER(current_sample)\n//\n//     // Make predictions on the full training data to evaluate.\n//     predictions = weak_learner.PREDICT(training_data.features)\n//     accuracy = CALCULATE_ACCURACY(predictions, training_data.labels)\n//\n//     // Step 3: Evaluate performance.\n//     IF accuracy > accuracy_threshold THEN\n//       // Calculate error and learner's weight for the final ensemble.\n//       error = 1 - accuracy\n//       alpha = 0.5 * LOG((1 - error) / error) // Example: AdaBoost weight calculation\n//\n//       // Step 4: Update sample weights.\n//       FOR i FROM 0 TO num_samples - 1:\n//         IF predictions[i] == training_data.labels[i] THEN\n//           sample_weights[i] = sample_weights[i] * EXP(-alpha) // Decrease weight\n//         ELSE\n//           sample_weights[i] = sample_weights[i] * EXP(alpha) // Increase weight\n//         END IF\n//       END FOR\n//       NORMALIZE(sample_weights) // Ensure weights sum to 1.\n//\n//       // Add the successful learner and its weight to the ensemble.\n//       APPEND(kept_learners, weak_learner)\n//       APPEND(learner_weights, alpha)\n//       num_kept_learners = num_kept_learners + 1\n//     END IF\n//   END WHILE\n//\n//   // Step 6: Return the final ensemble.\n//   ensemble_model = CREATE_ENSEMBLE(kept_learners, learner_weights)\n//   RETURN ensemble_model\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 49,
    "text": "A common method for determining bet size is to quantify the confidence of a model's prediction. This can be framed as a statistical test where the null hypothesis is that the model's prediction is no better than a random guess. The more confidently we can reject this null hypothesis, the larger the bet size.\n\n**Key Concepts**\n\n- **[Definition] Standard Normal CDF**: The Cumulative Distribution Function (CDF) of the standard Normal distribution, denoted as `Z[.]`, maps a value to the probability of observing a random variable that is less than or equal to that value. The output of `Z[.]` is always in the range `[0, 1]`.\n\n**Binary Classification Case (2 Classes)**\n\nFor a binary outcome (e.g., `{-1, 1}`), the null hypothesis is that the probability of a positive outcome is `p[x=1] = 0.5`.\n\n1.  **Compute Test Statistic (`z`)**: The `z` statistic measures how many standard deviations the observed probability `p[x=1]` is from the null hypothesis mean of 0.5.\n\n    **Equation 1: Binary Test Statistic**\n    `z = (p[x=1] - 0.5) / sqrt(p[x=1] * (1 - p[x=1]))`\n\n2.  **Compute Bet Size (`m`)**: The `z` statistic is passed through the standard Normal CDF `Z[.]` to map it to a `[0, 1]` range, which is then scaled to the `[-1, 1]` bet size range.\n\n    **Equation 2: Binary Bet Size**\n    `m = 2 * Z[z] - 1`\n\n**Multi-Class Classification Case (>2 Classes)**\n\nFor `N` possible outcomes, the method uses a one-vs-rest (OvR) approach. The null hypothesis is that the probability of the predicted class is `1/N` (a random guess).\n\n1.  **Identify Max Probability**: Let `p铏刞 be the probability of the predicted (most likely) class, `p铏?= max_i{p_i}`.\n2.  **Compute Test Statistic (`z`)**: The `z` statistic measures the significance of `p铏刞 relative to `1/N`.\n\n    **Equation 3: Multi-Class Test Statistic**\n    `z = (p铏?- 1/N) / sqrt(p铏?* (1 - p铏?)`\n\n3.  **Compute Bet Size (`m`)**: The size of the bet is calculated similarly to the binary case, but it is then multiplied by the predicted side/label `x` (e.g., `x` could be -1, 0, or 1).\n\n    **Equation 4: Multi-Class Bet Size**\n    `m = x * (2 * Z[z] - 1)`\n    - `x`: The predicted label (e.g., -1 for short, 1 for long).\n    - The term `(2 * Z[z] - 1)` represents the magnitude of the bet, which is always in `[0, 1]` since `z >= 0` in the multi-class case.",
    "question": "Based on the provided context, provide the pseudocode for a function that converts a predicted probability into a bet size magnitude (a value between 0 and 1). The function should take the probability of the predicted class and the total number of classes as input.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GetBetSizeMagnitude(predicted_prob, num_classes)\n// INPUTS:\n//   - predicted_prob: The probability of the most likely class (a float between 0 and 1).\n//   - num_classes: The total number of possible classes (an integer >= 2).\n// OUTPUTS:\n//   - The magnitude of the bet size (a float between 0 and 1).\n//\n// DEPENDENCIES:\n//   - StandardNormalCDF(value): A function that computes the CDF of the standard Normal distribution.\n//   - Sqrt(value): A function that computes the square root.\n//\n// BEGIN\n//   // Handle binary case as described in Equation 1 and 2.\n//   // Note: For binary, predicted_prob is for the positive class (e.g., label = 1).\n//   // The bet size 'm' from Equation 2 is already the final signed value.\n//   // To get magnitude, we take the absolute value.\n//   IF num_classes == 2 THEN\n//     // Avoid division by zero if probability is exactly 0 or 1.\n//     IF predicted_prob == 0.0 OR predicted_prob == 1.0 THEN\n//       RETURN 1.0\n//     END IF\n//\n//     // Calculate z-statistic for binary case.\n//     numerator = predicted_prob - 0.5\n//     denominator = Sqrt(predicted_prob * (1.0 - predicted_prob))\n//     z_stat = numerator / denominator\n//\n//     // Return the absolute value of the scaled CDF.\n//     RETURN Abs(2 * StandardNormalCDF(z_stat) - 1)\n//   END IF\n//\n//   // Handle multi-class case as described in Equation 3 and 4.\n//   IF num_classes > 2 THEN\n//     // Avoid division by zero if probability is exactly 0 or 1.\n//     IF predicted_prob == 0.0 OR predicted_prob == 1.0 THEN\n//       RETURN 1.0\n//     END IF\n//\n//     // Calculate z-statistic for multi-class case.\n//     null_hypothesis_prob = 1.0 / num_classes\n//     numerator = predicted_prob - null_hypothesis_prob\n//     denominator = Sqrt(predicted_prob * (1.0 - predicted_prob))\n//     z_stat = numerator / denominator\n//\n//     // Return the scaled CDF, which is the magnitude.\n//     RETURN 2 * StandardNormalCDF(z_stat) - 1\n//   END IF\n//\n//   // Return 0 if num_classes is invalid.\n//   RETURN 0.0\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 50,
    "text": "When a trading strategy generates signals, a new signal might arrive before a previous one has concluded. Simply overriding the old bet with the new one can lead to excessive turnover and transaction costs. A more robust approach is to average the bet sizes of all signals that are concurrently active at a given point in time. This smooths the final position and reduces unnecessary trades.\n\n**Framework Overview**\n\nThe core of the algorithm is to determine, for any given timestamp, which signals are currently 'active' and then compute their average value.\n\n- **[Definition] Active Signal**: A signal is considered active at a specific time `t` if two conditions are met:\n    1. The signal was issued at or before time `t`.\n    2. The signal's expiration time `t1` is after time `t`, OR the expiration time is unknown (e.g., null/NaN), implying it has not yet terminated.\n\n**Computational Steps**\n\n1.  **Identify Evaluation Points**: The set of active signals only changes when a new signal starts or an existing signal ends. Therefore, the algorithm should be evaluated at a set of discrete time points (`tPnts`) composed of all unique signal start times and end times (`t1`).\n2.  **Filter for Active Signals**: For each time point `t` in `tPnts`, filter the master list of all signals to find the subset that satisfies the 'Active Signal' definition.\n3.  **Compute Average**: Calculate the arithmetic mean of the 'signal' values for the filtered subset of active signals. If no signals are active at time `t`, the resulting average signal is 0.",
    "question": "Based on the provided context, provide the pseudocode for a function that, given a specific timestamp and a collection of all signals, calculates the average value of the signals that are active at that exact timestamp.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateAverageActiveSignal(all_signals, current_timestamp)\n// INPUTS:\n//   - all_signals: A collection (e.g., a list of records or a dataframe) of signal objects.\n//     Each signal object must have three properties:\n//       - start_time: The timestamp when the signal was generated.\n//       - end_time_t1: The timestamp when the signal expires. Can be NULL.\n//       - signal_value: The numeric bet size of the signal (e.g., between -1 and 1).\n//   - current_timestamp: The specific point in time for which to calculate the average active signal.\n// OUTPUTS:\n//   - A float representing the average signal_value of all active signals. Returns 0 if no signals are active.\n//\n// BEGIN\n//   // Create an empty list to store the values of active signals.\n//   active_signal_values = NewList()\n//\n//   // Iterate through each signal to check if it is active.\n//   FOR each signal IN all_signals:\n//     // Condition 1: Signal must have started at or before the current timestamp.\n//     has_started = (signal.start_time <= current_timestamp)\n//\n//     // Condition 2: Signal must not have ended yet.\n//     // This is true if the end time is after the current timestamp OR if the end time is NULL.\n//     has_not_ended = (signal.end_time_t1 > current_timestamp) OR (signal.end_time_t1 IS NULL)\n//\n//     // If both conditions are met, the signal is active.\n//     IF has_started AND has_not_ended THEN\n//       Add signal.signal_value to active_signal_values\n//     END IF\n//   END FOR\n//\n//   // Calculate the average of the collected active signal values.\n//   IF Count(active_signal_values) > 0 THEN\n//     RETURN Mean(active_signal_values)\n//   ELSE\n//     // If no signals were active, return 0.\n//     RETURN 0.0\n//   END IF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 51,
    "text": "After processing, such as averaging active signals, the resulting bet size is often a continuous value (e.g., 0.3751). Acting on every minor change in this value can lead to excessive trading, or 'jitter', which incurs unnecessary transaction costs. To mitigate this, bet sizes can be discretized to a predefined grid of values.\n\n**Key Concepts**\n\n- **[Definition] Discretization**: The process of mapping a continuous range of values to a smaller, finite set of discrete values. For example, mapping any value in `[0.2, 0.3)` to `0.25` if the step size is 0.05.\n\n**Discretization Algorithm**\n\nThe process involves three steps: scaling, rounding, and re-scaling, followed by clipping to ensure the final value remains within the valid `[-1, 1]` range.\n\n1.  **Rounding to Step Size**: The core logic is captured by the following formula:\n\n    **Equation 1: Discretization Formula**\n    `m_discrete = round(m_continuous / step_size) * step_size`\n\n    - `m_continuous`: The original, continuous bet size.\n    - `step_size`: The desired increment of discretization (e.g., 0.05).\n    - `m_discrete`: The resulting discretized bet size.\n\n2.  **Clipping (Capping and Flooring)**: After rounding, it's possible for the value to exceed the `[-1, 1]` bounds (e.g., if `m_continuous` is 0.99 and `step_size` is 0.05, the result is 1.0). Therefore, the value must be capped at `1.0` and floored at `-1.0` to maintain a valid bet size.",
    "question": "Based on the provided context, provide the pseudocode for a function that takes a continuous bet size (a single float) and a step size, and returns the discretized and clipped bet size.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DiscretizeSignal(continuous_signal, step_size)\n// INPUTS:\n//   - continuous_signal: A float representing the original bet size (e.g., from -1.0 to 1.0).\n//   - step_size: A positive float representing the desired discretization increment (e.g., 0.01).\n// OUTPUTS:\n//   - A float representing the discretized and clipped bet size.\n//\n// DEPENDENCIES:\n//   - Round(value): A function that rounds a float to the nearest integer.\n//   - Max(a, b): A function that returns the greater of two numbers.\n//   - Min(a, b): A function that returns the smaller of two numbers.\n//\n// BEGIN\n//   // Ensure step_size is a positive number to avoid division by zero.\n//   IF step_size <= 0 THEN\n//     // Or handle as an error.\n//     RETURN continuous_signal\n//   END IF\n//\n//   // Step 1: Scale, round, and re-scale the signal.\n//   scaled_signal = continuous_signal / step_size\n//   rounded_signal = Round(scaled_signal)\n//   discretized_signal = rounded_signal * step_size\n//\n//   // Step 2: Clip the result to the [-1, 1] interval.\n//   // First, apply the floor at -1.0.\n//   floored_signal = Max(-1.0, discretized_signal)\n//   // Second, apply the cap at 1.0.\n//   clipped_signal = Min(1.0, floored_signal)\n//\n//   RETURN clipped_signal\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 52,
    "text": "A sophisticated strategy can dynamically adjust its target position size as market conditions evolve. This approach uses a forecast price `f_i` and the current market price `p_t` to determine an ideal position. As the market price converges to the forecast (`p_t` -> `f_i`), the position size shrinks, allowing the strategy to realize profits.\n\n**Key Concepts**\n\n- **[Definition] Price Divergence (`x`)**: The difference between the forecasted price and the current market price, calculated as `x = f_i - p_t`.\n\n**Dynamic Sizing with a Sigmoid Function**\n\nThe relationship between price divergence and bet size can be modeled using a sigmoid function, which maps a large range of inputs to a bounded output (e.g., `(-1, 1)`).\n\n**Equation 1: Sigmoid Bet Size Function**\n`m[锠? x] = x / sqrt(锠?+ x^2)`\n- `m`: The resulting bet size, between -1 and 1.\n- `x`: The price divergence `f_i - p_t`.\n- `锠卄: A coefficient that regulates the width (i.e., the steepness) of the sigmoid function. A smaller `锠卄 leads to a steeper curve.\n\nOnce the bet size `m` is calculated, the target position `q铏僟i,t` can be determined.\n\n**Equation 2: Target Position Calculation**\n`q铏僟i,t = integer(m[锠? f_i - p_t] * Q)`\n- `Q`: The maximum absolute position size (e.g., 100 shares).\n- `integer()`: A function that truncates the decimal part.\n\n**Calibration of the Sigmoid Width (`锠卄)**\n\nTo be useful, the parameter `锠卄 must be calibrated. This is done by specifying a desired bet size `m*` for a given price divergence `x`. For example, a user might decide that a divergence of $10 should result in a bet size of 0.95.\n\n**Equation 3: Calibration of `锠卄**\n`锠?= x^2 * (1 / (m*^2) - 1)`\n- `x`: The user-defined target price divergence.\n- `m*`: The user-defined target bet size for that divergence.",
    "question": "Based on the provided context, provide the pseudocode for two functions. The first function, `CalibrateOmega`, should implement Equation 3 to find the `锠卄 parameter. The second function, `GetTargetPosition`, should use this `锠卄 to calculate the dynamic target position based on Equation 1 and Equation 2.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalibrateOmega(target_divergence, target_bet_size)\n// INPUTS:\n//   - target_divergence: The user-defined price divergence 'x' for calibration.\n//   - target_bet_size: The desired bet size 'm*' at the target divergence. Should be in (-1, 1).\n// OUTPUTS:\n//   - The calibrated omega '锠? parameter (a float).\n//\n// DEPENDENCIES:\n//   - Power(base, exponent): A function for exponentiation.\n//\n// BEGIN\n//   // Ensure target_bet_size is not 0 to avoid division by zero.\n//   IF target_bet_size == 0.0 THEN\n//     // Return a very large number or handle as an error.\n//     RETURN Infinity\n//   END IF\n//\n//   // Implementation of Equation 3.\n//   term1 = Power(target_divergence, 2)\n//   term2 = (1.0 / Power(target_bet_size, 2)) - 1.0\n//   omega = term1 * term2\n//\n//   RETURN omega\n// END\n\n// ------------------------------------------------------------------------\n\n// FUNCTION GetTargetPosition(omega, forecast_price, market_price, max_position)\n// INPUTS:\n//   - omega: The calibrated width parameter '锠? from CalibrateOmega.\n//   - forecast_price: The strategy's forecast price 'f_i'.\n//   - market_price: The current market price 'p_t'.\n//   - max_position: The maximum absolute position size 'Q'.\n// OUTPUTS:\n//   - The calculated integer target position 'q铏僟i,t'.\n//\n// DEPENDENCIES:\n//   - Sqrt(value): A function that computes the square root.\n//   - Integer(value): A function that truncates a float to an integer.\n//\n// BEGIN\n//   // Calculate price divergence 'x'.\n//   divergence_x = forecast_price - market_price\n//\n//   // Calculate bet size 'm' using the sigmoid function from Equation 1.\n//   denominator = Sqrt(omega + Power(divergence_x, 2))\n//   // Avoid division by zero, though unlikely with omega > 0.\n//   IF denominator == 0.0 THEN\n//     bet_size_m = 0.0\n//   ELSE\n//     bet_size_m = divergence_x / denominator\n//   END IF\n//\n//   // Calculate the target position using Equation 2.\n//   target_pos = Integer(bet_size_m * max_position)\n//\n//   RETURN target_pos\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 53,
    "text": "## Framework Overview\nTo combat data-snooping bias閳ユ敄he risk of fitting a model to random historical patterns閳ユ攰t is crucial to favor simpler, more robust models. Linear models, which have fewer free parameters and are less complex than non-linear alternatives, are an effective way to achieve this. Instead of predicting absolute returns, which is notoriously difficult, a simpler and often more effective approach is to rank assets based on a combination of predictive factors. This text outlines two linear methods for combining factors, with a focus on a rank-based aggregation technique.\n\n## Key Concepts\n- **[Definition] Data-Snooping Bias**: A statistical bias that occurs when a model is developed based on repeated testing of the same dataset. This can lead to a model that performs well on historical data but has poor predictive power because it has been overfitted to random noise rather than a true underlying pattern.\n- **[Definition] Linear Model**: A predictive model where the output is a linear combination of the input features. In trading, this often means the predicted return or the capital allocated is directly proportional to the value of one or more predictive factors.\n\n## Computational Models\n\nTwo primary linear methods for combining predictive factors (`f`) to predict future returns (`R`) are presented below.\n\n**1. Z-Score Based Combination**\nThis method first normalizes each factor into a Z-score and then combines them with equal weighting.\n\nFirst, calculate the Z-score for each factor `i`:\n$$ z(i) = \\frac{f(i) - \\text{mean}(f)}{\\text{std}(f)} \\quad (1) $$ \nWhere:\n- `z(i)`: The Z-score of the i-th factor.\n- `f(i)`: The value of the i-th factor.\n- `mean(f)`: The historical average of the factor values (in-sample).\n- `std(f)`: The historical standard deviation of the factor values (in-sample).\n\nNext, predict the return `R` using the combined Z-scores:\n$$ R = \\text{mean}(R) + \\text{std}(R) \\frac{\\sum_{i}^{n} \\text{sign}(i) z(i)}{n} \\quad (2) $$ \nWhere:\n- `R`: The predicted return.\n- `mean(R)` and `std(R)`: The historical average and standard deviation of returns.\n- `sign(i)`: The sign (+1 or -1) of the historical correlation between factor `f(i)` and the return `R`.\n- `n`: The total number of factors.\n\n**2. Rank-Based Combination**\nAn even simpler method, which avoids direct return prediction in favor of a robust ranking score, combines the ranks of each factor.\n\nFor a given stock `s`, its final rank is calculated as the sum of its signed ranks across all factors:\n$$ \\text{rank}_{s} = \\sum_{i}^{n} \\text{sign}(i) \\cdot \\text{rank}_{s}(i) \\quad (3) $$ \nWhere:\n- `rank_s`: The final combined rank score for stock `s`.\n- `n`: The total number of factors.\n- `sign(i)`: The sign (+1 or -1) of the historical correlation between factor `f(i)` and the expected return.\n- `rank_s(i)`: The rank of stock `s` based solely on factor `f(i)` (e.g., a lower number indicates a higher rank, such as 1st, 2nd, 3rd...).",
    "question": "Based on the `Instruction` and `Text` provided, provide the pseudocode for a function that calculates a final rank score for each stock in a given universe by combining multiple factor ranks according to the rank-based combination model (Equation 3).",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateCombinedRank(stock_universe, factor_data, factor_signs)\n// INPUTS:\n//   - stock_universe: A list of stock identifiers (e.g., ['AAPL', 'MSFT', 'GOOG']).\n//   - factor_data: A dictionary where keys are factor names (e.g., 'EarningsYield', 'Momentum')\n//                  and values are dictionaries mapping stock identifiers to their raw factor values.\n//                  Example: {'EarningsYield': {'AAPL': 0.05, 'MSFT': 0.04}, 'Momentum': {'AAPL': 1.2, 'MSFT': -0.5}}\n//   - factor_signs: A dictionary mapping factor names to the sign of their correlation with future returns (+1 or -1).\n//                   Example: {'EarningsYield': +1, 'Momentum': +1}\n// OUTPUTS:\n//   - A dictionary mapping stock identifiers to their final combined rank score.\n//\n// BEGIN\n//   Initialize a dictionary `combined_ranks` for all stocks in `stock_universe` with a score of 0.\n//   FOR each stock `s` in `stock_universe`:\n//     combined_ranks[s] = 0\n//   ENDFOR\n//\n//   // Iterate through each factor to calculate and aggregate signed ranks.\n//   FOR each `factor_name`, `stock_values` in `factor_data`:\n//     // Create a list of (stock, value) pairs to sort for ranking.\n//     let sortable_list = []\n//     FOR each `stock`, `value` in `stock_values`:\n//       add (stock, value) to sortable_list\n//     ENDFOR\n//\n//     // Sort the list by factor value in descending order to determine ranks.\n//     // A higher value gets a better (lower) rank number.\n//     sort sortable_list in descending order based on `value`.\n//\n//     // Get the correlation sign for the current factor.\n//     let sign = factor_signs[factor_name]\n//\n//     // Calculate and add the signed rank to the combined score for each stock.\n//     FOR `i` from 0 to length(sortable_list) - 1:\n//       let stock = sortable_list[i].stock\n//       let rank = i + 1 // Rank is 1-based index.\n//       let signed_rank = sign * rank\n//\n//       // Add the signed rank to the stock's total score.\n//       combined_ranks[stock] = combined_ranks[stock] + signed_rank\n//     ENDFOR\n//   ENDFOR\n//\n//   RETURN combined_ranks\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 54,
    "text": "## Framework Overview\nWhen backtesting trading strategies, it is crucial to use a historical price series that accurately reflects a stock's value over time. Corporate actions such as stock splits and dividends cause sudden, artificial drops in a stock's price that do not represent a change in the company's total market value. Failing to adjust for these events will lead to erroneous trading signals, as a strategy might interpret a price drop from a 2-for-1 split as a genuine market crash.\n\n## Key Concepts\n- **[Definition] Back-Adjustment**: The process of modifying historical price data prior to a corporate action to create a continuous series that is free of artificial price gaps. This ensures that historical percentage changes remain accurate.\n- **[Definition] Ex-Date (Ex-Dividend Date)**: The first day a stock trades without the value of the recently declared dividend or split. To be entitled to the corporate action, an investor must own the stock *before* the ex-date. Adjustments must be applied to all prices *before* this date.\n\n## Adjustment Logic\n\n**1. Stock Splits**\nIn an N-for-1 stock split, the number of shares increases by a factor of N, and the stock price is divided by N. To create a continuous price series, all historical prices *before* the split's ex-date must be divided by the split ratio N.\n- **Example**: For a 2-for-1 split (N=2), all historical prices before the ex-date are divided by 2.\n\n**2. Reverse Stock Splits**\nIn a 1-for-N reverse stock split, the number of shares is divided by N, and the stock price is multiplied by N. To adjust for this, all historical prices *before* the reverse split's ex-date must be multiplied by the split ratio N.\n- **Example**: For a 1-for-10 reverse split (N=10), all historical prices before the ex-date are multiplied by 10.\n\n**3. Cash Dividends**\nWhen a company pays a cash dividend of `d` dollars per share, the stock price typically drops by approximately `d` on the ex-date. To adjust for this, the dividend amount `d` must be subtracted from all historical prices *before* the dividend's ex-date.\n- **Example**: For a $0.50 dividend, $0.50 is subtracted from all historical prices before the ex-date.",
    "question": "Based on the `Instruction` and `Text` provided, provide the pseudocode for a function that takes a historical price series and a list of corporate actions (splits and dividends) and returns the fully adjusted price series.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION AdjustPricesForCorporateActions(price_series, corporate_actions)\n// INPUTS:\n//   - price_series: An array of objects, where each object has a 'date' and 'price'.\n//                   Example: [{'date': '2023-01-01', 'price': 100.0}, {'date': '2023-01-02', 'price': 102.0}, ...]\n//   - corporate_actions: An array of objects, where each object has an 'ex_date', 'type' ('SPLIT', 'REVERSE_SPLIT', 'DIVIDEND'), and 'value'.\n//                      For splits, 'value' is the ratio (e.g., 2 for a 2-for-1 split).\n//                      For dividends, 'value' is the cash amount.\n//                      Example: [{'ex_date': '2023-06-15', 'type': 'SPLIT', 'value': 2.0}, {'ex_date': '2023-03-10', 'type': 'DIVIDEND', 'value': 0.50}]\n// OUTPUTS:\n//   - An adjusted price series in the same format as the input.\n//\n// BEGIN\n//   // It is crucial to process actions from most recent to oldest to apply adjustments correctly.\n//   Sort `corporate_actions` in descending order by 'ex_date'.\n//\n//   // Create a mutable copy of the price series to modify.\n//   let adjusted_prices = copy(price_series)\n//\n//   // Iterate through each corporate action.\n//   FOR each `action` in `corporate_actions`:\n//     let ex_date = action.ex_date\n//     let action_type = action.type\n//     let action_value = action.value\n//\n//     // Iterate through the price series to apply the adjustment.\n//     FOR each `price_point` in `adjusted_prices`:\n//       // Apply adjustment to all prices strictly BEFORE the ex-date.\n//       IF price_point.date < ex_date THEN\n//         IF action_type == 'SPLIT' THEN\n//           // For an N-for-1 split, divide the price by N.\n//           price_point.price = price_point.price / action_value\n//         ELSEIF action_type == 'REVERSE_SPLIT' THEN\n//           // For a 1-for-N reverse split, multiply the price by N.\n//           price_point.price = price_point.price * action_value\n//         ELSEIF action_type == 'DIVIDEND' THEN\n//           // For a cash dividend, subtract the dividend amount.\n//           price_point.price = price_point.price - action_value\n//         ENDIF\n//       ENDIF\n//     ENDFOR\n//   ENDFOR\n//\n//   RETURN adjusted_prices\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 55,
    "text": "## Framework Overview\nFutures contracts have fixed expiration dates, forcing traders to periodically \"roll over\" their positions from an expiring contract to the next one. This process creates artificial price gaps in a naively concatenated historical price series, which can corrupt backtest calculations. To create a usable historical series, known as a continuous contract, these gaps must be eliminated through a process called back-adjustment.\n\n## Key Concepts\n- **[Definition] Continuous Contract**: A synthetic historical price series for a futures product, created by stitching together individual contracts over time and adjusting for price differences at rollover dates.\n- **[Definition] Rollover**: The process of closing a position in an expiring front-month contract and simultaneously opening a new position in the next-nearest contract (the back contract).\n- **[Definition] Front-Month Contract**: The futures contract with the nearest expiration date.\n- **[Definition] Back Contract**: The futures contract with the second-nearest expiration date.\n\n## The Rollover Problem\nConsider a rollover on date `T+1`. The key prices are:\n- `p(T)`: The closing price of the front contract on the day before rollover.\n- `p(T+1)`: The closing price of the front contract on the rollover day.\n- `q(T+1)`: The closing price of the new front contract (the back contract) on the rollover day.\n\nA trader's true P&L on day `T+1` is `p(T+1) - p(T)`. However, a simple concatenated series would show a price of `p(T)` on day `T` and `q(T+1)` on day `T+1`, leading to an incorrect P&L calculation of `q(T+1) - p(T)`. Back-adjustment corrects this.\n\n## Adjustment Methods\nThere are two primary methods for back-adjustment, each with a critical trade-off.\n\n**1. Price Back-Adjustment (Additive)**\nThis method preserves the correctness of P&L calculations. To eliminate the price gap at a rollover on date `T+1`, an adjustment factor is calculated and added to all historical prices on or before date `T`.\n- **Adjustment Factor**: `q(T+1) - p(T+1)`\n- **Logic**: For every price `p(t)` where `t <= T`, the new adjusted price becomes `p(t) + (q(T+1) - p(T+1))`. This ensures the adjusted price change from `T` to `T+1` correctly reflects the true P&L: `q(T+1) - [p(T) + (q(T+1) - p(T+1))] = p(T+1) - p(T)`.\n- **Use Case**: This method is essential for strategies based on price differences or spreads.\n\n**2. Return Back-Adjustment (Multiplicative)**\nThis method preserves the correctness of percentage return calculations but distorts P&L. It involves multiplying historical prices by a ratio.\n- **Adjustment Factor**: `q(T+1) / p(T+1)`\n- **Logic**: For every price `p(t)` where `t <= T`, the new adjusted price becomes `p(t) * (q(T+1) / p(T+1))`. \n- **Use Case**: This method is required for strategies based on price ratios.",
    "question": "Based on the `Instruction` and `Text` provided, provide the pseudocode for a function that constructs a continuous futures contract series using the price back-adjustment method. The function should take the price series of individual front-month contracts and a schedule of rollover dates.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CreateContinuousContract_PriceAdjusted(contract_data, rollover_schedule)\n// INPUTS:\n//   - contract_data: A dictionary where keys are contract symbols (e.g., 'ESM3', 'ESU3') and values are their historical price series (array of {'date', 'price'}).\n//   - rollover_schedule: An ordered list of rollover events, from oldest to newest. Each event is an object {'date', 'old_contract', 'new_contract'}.\n//                      Example: [{'date': '2023-03-15', 'old_contract': 'ESH3', 'new_contract': 'ESM3'}, ...]\n// OUTPUTS:\n//   - A single, continuous, back-adjusted price series.\n//\n// BEGIN\n//   // 1. Concatenate the individual contract series into one long, unadjusted series.\n//   let continuous_series = []\n//   let last_date = very_early_date\n//   FOR each `rollover` in `rollover_schedule`:\n//     let old_contract = rollover.old_contract\n//     let prices = contract_data[old_contract]\n//     FOR each `price_point` in `prices`:\n//       IF price_point.date > last_date AND price_point.date <= rollover.date THEN\n//         add price_point to continuous_series\n//       ENDIF\n//     ENDFOR\n//     last_date = rollover.date\n//   ENDFOR\n//   // Add the final contract's data after the last rollover.\n//   let final_contract_symbol = rollover_schedule[last_item].new_contract\n//   let final_prices = contract_data[final_contract_symbol]\n//   FOR each `price_point` in `final_prices`:\n//     IF price_point.date > last_date THEN\n//       add price_point to continuous_series\n//     ENDIF\n//   ENDFOR\n//\n//   // 2. Apply back-adjustments, iterating backward from the most recent rollover.\n//   let reversed_schedule = reverse(rollover_schedule)\n//   FOR each `rollover` in `reversed_schedule`:\n//     let rollover_date = rollover.date\n//     let old_contract = rollover.old_contract\n//     let new_contract = rollover.new_contract\n//\n//     // Find the prices on the rollover date for both contracts.\n//     let p_T_plus_1 = find_price_on_date(contract_data[old_contract], rollover_date)\n//     let q_T_plus_1 = find_price_on_date(contract_data[new_contract], rollover_date)\n//\n//     // Calculate the additive adjustment factor.\n//     let adjustment_factor = q_T_plus_1 - p_T_plus_1\n//\n//     // Apply the factor to all prices in the continuous series before the rollover date.\n//     FOR each `price_point` in `continuous_series`:\n//       IF price_point.date < rollover_date THEN\n//         price_point.price = price_point.price + adjustment_factor\n//       ENDIF\n//     ENDFOR\n//   ENDFOR\n//\n//   RETURN continuous_series\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 56,
    "text": "### 1. Conceptual Overview\n\n- **[Definition] Mean Reversion**: A property of a time series where its value tends to move towards its historical average or mean over time. If a price is above the mean, it is expected to fall, and if it is below the mean, it is expected to rise.\n\n- **[Definition] Augmented Dickey-Fuller (ADF) Test**: A statistical test for stationarity in a time series. It tests the null hypothesis that a unit root is present in a time series sample, which for financial series implies it follows a random walk and is not mean-reverting. Rejecting the null hypothesis suggests the series is mean-reverting.\n\n### 2. Mathematical Model\n\nThe ADF test is based on a linear regression model that describes price changes:\n\n$$ \n\\Delta y(t) = \\lambda y(t - 1) + \\mu +\\beta t + \\sum_{i=1}^{k} \\alpha_i \\Delta y(t - i) + \\epsilon_t \\tag{1}\n$$ \n\nWhere:\n- `铻杫(t)`: The change in price at time `t`, calculated as `y(t) - y(t-1)`.\n- `y(t-1)`: The price at the previous time step, `t-1`.\n- `浣峘 (lambda): The key coefficient. If `浣峘 is significantly negative, it indicates mean reversion. The ADF test's goal is to determine if we can reject the null hypothesis that `浣?= 0`.\n- `娓璥 (mu): An intercept term, representing a constant offset.\n- `灏綻 (beta): A coefficient for a time trend `t`.\n- `k`: The number of lagged price differences included to account for serial correlation in the residuals.\n- `浼猒i` (alpha_i): The coefficients for the lagged price differences.\n- `钄歘t` (epsilon_t): The error term at time `t`.\n\n### 3. Test Procedure\n\nThe core of the test is to perform an Ordinary Least Squares (OLS) regression using the model in Equation 1. The test statistic is then calculated as the estimated coefficient `浣峘 divided by its standard error:\n\n`Test Statistic = 浣?/ SE(浣?`\n\nThis statistic is compared against critical values from the Dickey-Fuller distribution. For mean reversion, we expect `浣峘 to be negative. A test statistic that is *more negative* than the critical value (e.g., -3.5 vs. a critical value of -2.9) allows us to reject the null hypothesis and conclude the series is likely mean-reverting.",
    "question": "1.  **`[ADF Test Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the core logic of the Augmented Dickey-Fuller test. The function should perform the necessary regression and compute the test statistic.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateADFStatistic(price_series, num_lags)\n// INPUTS:\n//   - price_series: A 1D array of historical prices.\n//   - num_lags: The number of lagged price differences (k) to include.\n// OUTPUTS:\n//   - The ADF test statistic (lambda / standard_error_of_lambda).\n//\n// BEGIN\n//   // 1. Prepare the data for regression\n//   price_changes = difference(price_series, 1) // Corresponds to 铻杫(t)\n//   lagged_prices = lag(price_series, 1)      // Corresponds to y(t-1)\n//\n//   // 2. Align data by removing initial NaN/null values\n//   // The first price_change and lagged_price will be null.\n//   // Additional rows must be removed to align with lagged differences.\n//   aligned_changes = price_changes from index (num_lags + 1) to end\n//   aligned_lagged_prices = lagged_prices from index (num_lags + 1) to end\n//   \n//   // 3. Construct the matrix of independent variables (regressors)\n//   // Start with the primary variable y(t-1) and an intercept term.\n//   X_matrix = matrix with columns [aligned_lagged_prices, vector_of_ones]\n//\n//   // Add lagged difference terms if num_lags > 0\n//   FOR i from 1 to num_lags\n//     lagged_changes = lag(price_changes, i)\n//     aligned_lagged_changes = lagged_changes from index (num_lags + 1) to end\n//     add aligned_lagged_changes as a new column to X_matrix\n//   END FOR\n//\n//   // 4. Define the dependent variable\n//   Y_vector = aligned_changes\n//\n//   // 5. Perform Ordinary Least Squares (OLS) regression\n//   // This is a standard library function.\n//   regression_results = OLS(Y_vector, X_matrix)\n//\n//   // 6. Extract the coefficient for y(t-1) and its standard error\n//   // The coefficient for y(t-1) is our lambda.\n//   lambda_coefficient = regression_results.coefficients[0]\n//   std_error_lambda = regression_results.standard_errors[0]\n//\n//   // 7. Calculate and return the ADF test statistic\n//   IF std_error_lambda is 0 THEN RETURN infinity // Avoid division by zero\n//   adf_statistic = lambda_coefficient / std_error_lambda\n//   RETURN adf_statistic\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 57,
    "text": "### 1. Core Concept\n\nThe Hurst Exponent is a measure of the long-term memory of a time series. It characterizes the series' tendency to regress to the mean, drift in one direction, or follow a random walk.\n\n- **[Definition] Stationarity**: In this context, a price series is considered stationary (or mean-reverting) if its variance increases more slowly than that of a geometric random walk.\n\n- **[Definition] Geometric Random Walk**: A process where future steps are independent of past ones. For log prices, the variance of price changes is expected to grow linearly with the time lag.\n\n- **[Definition] Hurst Exponent (H)**: A value between 0 and 1 that quantifies the nature of a time series:\n    - `H < 0.5`: The series is mean-reverting.\n    - `H = 0.5`: The series is a geometric random walk.\n    - `H > 0.5`: The series is trending (persistent).\n\n### 2. Mathematical Formulation\n\nThe speed of diffusion of a series is characterized by its variance over a given time lag `锜縛.\n\n$$ \n\\mathrm{Var}(\\tau) = \\langle |z(t + \\tau) - z(t)|^2\\rangle \\tag{1}\n$$ \n\nWhere:\n- `z`: The series of log prices, `z = log(y)`.\n- `锜縛 (tau): The time lag between two price measurements.\n- `<...>`: An average taken over all possible values of `t`.\n\nFor a general time series, this variance can be related to the time lag `锜縛 through the Hurst Exponent `H`:\n\n$$ \n\\langle |z(t + \\tau) - z(t)|^2\\rangle \\sim \\tau^{2H} \\tag{2}\n$$ \n\nTo compute `H`, we can take the logarithm of both sides of Equation 2:\n\n`log(Var(锜?) 閳?log(C) + 2H * log(锜?`\n\nThis shows that `log(Var(锜?)` is a linear function of `log(锜?` with a slope of `2H`. We can therefore estimate `H` by calculating the variance for several different lags `锜縛, performing a linear regression on the log-log data, and dividing the resulting slope by 2.",
    "question": "1.  **`[Hurst Exponent Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the Hurst Exponent for a given price series.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateHurstExponent(price_series)\n// INPUTS:\n//   - price_series: A 1D array of historical prices.\n// OUTPUTS:\n//   - The estimated Hurst Exponent (H).\n//\n// BEGIN\n//   // 1. Define a range of time lags to analyze.\n//   // A geometric spacing is often used, e.g., 2, 3, 4, ..., 100.\n//   lags = generate_lags(from=2, to=100)\n//   \n//   // 2. Convert prices to log prices for calculations.\n//   log_prices = log(price_series)\n//\n//   // 3. Calculate variance for each time lag.\n//   variances = empty_array()\n//   FOR EACH lag_tau IN lags\n//     // Calculate the differences between prices separated by lag_tau.\n//     price_differences = log_prices[lag_tau:] - log_prices[:-lag_tau]\n//     \n//     // Calculate the variance of these differences.\n//     current_variance = variance(price_differences)\n//     add current_variance to variances\n//   END FOR\n//\n//   // 4. Prepare data for linear regression.\n//   // We fit a line to the log-log plot of variance vs. lag.\n//   log_lags = log(lags)\n//   log_variances = log(variances)\n//\n//   // 5. Perform Ordinary Least Squares (OLS) regression.\n//   // We model log_variances as the dependent variable (Y)\n//   // and log_lags as the independent variable (X).\n//   regression_results = OLS(log_variances, [log_lags, vector_of_ones])\n//\n//   // 6. The slope of the regression line is equal to 2H.\n//   slope = regression_results.coefficients[0]\n//   \n//   // 7. Calculate and return the Hurst Exponent.\n//   hurst_exponent = slope / 2\n//   RETURN hurst_exponent\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 58,
    "text": "### 1. Conceptual Framework\n\nWhile statistical tests like ADF provide a binary (yes/no) answer on mean reversion, the Half-Life provides a practical, continuous measure of its speed. It is a crucial parameter for strategy design, as it defines a natural time scale for look-back periods and expected holding times.\n\n- **[Definition] Ornstein-Uhlenbeck Process**: A stochastic process that describes the velocity of a massive particle under friction. In finance, it is used to model a mean-reverting time series. Its continuous-time representation is:\n\n$$ \ndy(t) = (\\lambda y(t - 1) + \\mu)dt + d\\epsilon \\tag{1}\n$$ \n\n- **[Definition] Half-Life of Mean Reversion**: The expected time it will take for a price series to revert halfway back to its long-term mean after a deviation.\n\n### 2. Mathematical Derivation\n\nThe discrete version of the Ornstein-Uhlenbeck process can be simplified to a linear regression of price changes against lagged prices:\n\n`铻杫(t) 閳?浣?* y(t-1) + 娓璥\n\nBy running this regression, we can estimate the coefficient `浣峘.\n\nThe solution to the differential equation (Equation 1) shows that the expected value of the price `y(t)` decays exponentially towards its mean (`-娓?浣峘). The speed of this decay is governed by `浣峘.\n\nThe half-life of this exponential decay is given by the formula:\n\n$$ \n\\text{Half-Life} = \\frac{-\\log(2)}{\\lambda} \\tag{2}\n$$ \n\nWhere:\n- `log(2)`: The natural logarithm of 2 (approximately 0.693).\n- `浣峘 (lambda): The regression coefficient obtained from regressing `y(t) - y(t-1)` against `y(t-1)`. For a mean-reverting series, `浣峘 must be negative, resulting in a positive half-life.",
    "question": "1.  **`[Half-Life Calculation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes the half-life of mean reversion for a given price series.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateHalfLife(price_series)\n// INPUTS:\n//   - price_series: A 1D array of historical prices.\n// OUTPUTS:\n//   - The estimated half-life of mean reversion in units of time steps.\n//\n// BEGIN\n//   // 1. Create the lagged price series and the series of price changes.\n//   lagged_prices = lag(price_series, 1)\n//   price_changes = difference(price_series, 1)\n//\n//   // 2. Align the series by removing the first element, which will be NaN/null.\n//   lagged_prices = lagged_prices from index 1 to end\n//   price_changes = price_changes from index 1 to end\n//\n//   // 3. Prepare the data for regression.\n//   // The dependent variable (Y) is the price change.\n//   // The independent variable (X) is the lagged price.\n//   // We also include a constant term for the intercept (mu).\n//   Y_vector = price_changes\n//   X_matrix = matrix with columns [lagged_prices, vector_of_ones]\n//\n//   // 4. Perform Ordinary Least Squares (OLS) regression.\n//   regression_results = OLS(Y_vector, X_matrix)\n//\n//   // 5. Extract the regression coefficient for the lagged price.\n//   // This coefficient is our lambda.\n//   lambda = regression_results.coefficients[0]\n//\n//   // 6. Handle edge cases.\n//   // If lambda is non-negative, the series is not mean-reverting.\n//   IF lambda >= 0 THEN\n//     RETURN infinity // Or an indicator for non-mean-reverting\n//   END IF\n//\n//   // 7. Calculate and return the half-life using the formula.\n//   half_life = -log(2) / lambda\n//   RETURN half_life\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 59,
    "text": "### 1. Core Concept\n\nMost individual financial assets are not mean-reverting. However, it is often possible to create a synthetic portfolio of two or more assets whose market value *is* mean-reverting. This is the foundation of statistical arbitrage and pairs trading.\n\n- **[Definition] Cointegration**: A statistical property of two or more non-stationary time series where a linear combination of them is stationary. If two price series, X and Y, are cointegrated, there exists a hedge ratio `灏綻 such that the series `Y - 灏?X` is stationary.\n\n- **[Definition] Hedge Ratio**: The number of units of one asset that must be held to offset the price movements of another. In the context of cointegration, it is the coefficient that creates a stationary portfolio.\n\n- **[Definition] Cointegrated ADF (CADF) Test**: A two-step procedure to test for cointegration between a pair of time series. It formalizes the process of finding an optimal hedge ratio and then testing the resulting spread for stationarity.\n\n### 2. Procedural Steps\n\nThe CADF test involves the following sequence:\n\n1.  **Find the Optimal Hedge Ratio**: Perform an Ordinary Least Squares (OLS) regression of one price series (e.g., Y, the dependent variable) against the other (e.g., X, the independent variable) and an intercept. The regression model is `Y = 灏?X + c`. The resulting coefficient `灏綻 is the optimal hedge ratio.\n\n2.  **Form the Portfolio (Spread) Series**: Using the hedge ratio from Step 1, construct a new time series representing the market value of the spread: `Spread(t) = Y(t) - 灏?* X(t)`.\n\n3.  **Test the Spread for Stationarity**: Apply the standard Augmented Dickey-Fuller (ADF) test to the `Spread(t)` series. If the ADF test rejects the null hypothesis of a unit root, we can conclude that the original series Y and X are cointegrated.\n\n### 3. Important Consideration: Order Dependency\n\nThe CADF test is order-dependent. Regressing Y on X will produce a hedge ratio `灏綺1`, while regressing X on Y will produce a different hedge ratio `灏綺2` (where `灏綺2` is not necessarily `1/灏綺1`). It is possible for one combination to produce a stationary spread while the other does not. A robust implementation should ideally test both directions.",
    "question": "1.  **`[CADF Test Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that performs the Cointegrated Augmented Dickey-Fuller test on two price series.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PerformCADFTest(series_Y, series_X, num_lags_for_adf)\n// INPUTS:\n//   - series_Y: A 1D array of prices for the dependent asset.\n//   - series_X: A 1D array of prices for the independent asset.\n//   - num_lags_for_adf: The number of lags to use in the final ADF test.\n// OUTPUTS:\n//   - A structure containing the hedge_ratio and the adf_statistic.\n//\n// ASSUMES:\n//   - A function CalculateADFStatistic(price_series, num_lags) exists.\n//\n// BEGIN\n//   // STEP 1: Find the Optimal Hedge Ratio via OLS regression.\n//   // We model Y = beta * X + intercept.\n//   Y_vector = series_Y\n//   X_matrix = matrix with columns [series_X, vector_of_ones]\n//\n//   regression_results = OLS(Y_vector, X_matrix)\n//   hedge_ratio = regression_results.coefficients[0]\n//\n//   // STEP 2: Form the Portfolio (Spread) Series.\n//   spread_series = series_Y - hedge_ratio * series_X\n//\n//   // STEP 3: Test the Spread for Stationarity using the ADF test.\n//   adf_statistic = CalculateADFStatistic(spread_series, num_lags_for_adf)\n//   \n//   // 4. Return the results.\n//   result = new_structure()\n//   result.hedge_ratio = hedge_ratio\n//   result.adf_statistic = adf_statistic\n//   RETURN result\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 60,
    "text": "### 1. Framework Overview\n\nThe Johansen test is a powerful procedure for testing cointegration among several time series (more than two). Unlike the order-dependent CADF test, it can identify all possible independent stationary portfolios that can be formed from a given set of assets.\n\n- **[Definition] Johansen Test**: A statistical test that determines the number of cointegrating relationships within a group of time series. As a by-product, it provides the specific hedge ratios (eigenvectors) needed to construct these stationary portfolios.\n\n- **[Definition] Rank (of a matrix)**: In this context, the rank `r` of the coefficient matrix `铻瀈 in the model below corresponds to the number of independent cointegrating relationships (i.e., stationary portfolios) that exist among the `n` price series.\n\n- **[Definition] Eigenvector**: A vector that, when a linear transformation is applied to it, changes only by a scalar factor (the eigenvalue). In the Johansen test, the eigenvectors of the `铻瀈 matrix represent the hedge ratios for the cointegrating portfolios.\n\n### 2. Vector Error Correction Model (VECM)\n\nThe Johansen test is based on a generalization of the ADF model to multiple time series, known as the Vector Error Correction Model (VECM):\n\n$$ \n\\Delta Y(t) = \\Lambda Y(t - 1) + M + \\sum_{i=1}^{k} A_i \\Delta Y(t - i) + \\epsilon_t \\tag{1}\n$$ \n\nWhere:\n- `Y(t)`: A vector containing the prices of all `n` assets at time `t`.\n- `铻朰(t)`: The vector of price changes.\n- `铻瀈 (Lambda): The crucial `n x n` coefficient matrix. The test analyzes this matrix to find cointegrating relationships.\n- `M`, `A_i`, `钄歘t`: Vector/matrix equivalents of the intercept, lagged difference coefficients, and error term from the ADF model.\n\n### 3. Interpreting the Output\n\nThe test performs an eigenvalue decomposition on a matrix derived from `铻瀈. The key outputs are:\n\n- **Eigenvalues**: These are sorted in descending order. The magnitude of an eigenvalue indicates the \"strength\" or speed of mean reversion of its corresponding portfolio. The largest eigenvalue corresponds to the most stationary portfolio (shortest half-life).\n- **Eigenvectors**: Each eigenvector is a vector of hedge ratios. The first eigenvector (corresponding to the largest eigenvalue) defines the weights for the most stable stationary portfolio.",
    "question": "1.  **`[Johansen Test Application]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a matrix of multiple price series, applies the Johansen test, and extracts the optimal hedge ratio vector for forming the most stationary portfolio.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FindOptimalHedgeRatioJohansen(price_series_matrix)\n// INPUTS:\n//   - price_series_matrix: An N x K matrix where N is the number of time steps\n//     and K is the number of assets.\n// OUTPUTS:\n//   - A K x 1 vector of hedge ratios for the most stationary portfolio.\n//\n// ASSUMES:\n//   - A library function `RunJohansenTest(matrix)` exists. This function\n//     returns a result object containing two properties:\n//     - `eigenvalues`: A sorted array of eigenvalues (largest first).\n//     - `eigenvectors`: A matrix where columns are the corresponding eigenvectors.\n//\n// BEGIN\n//   // 1. Execute the Johansen test on the input price data.\n//   // The test's complex internal mathematics are handled by a library function.\n//   johansen_results = RunJohansenTest(price_series_matrix)\n//\n//   // 2. Identify the optimal hedge ratio vector.\n//   // The eigenvectors are typically ordered in correspondence with the eigenvalues\n//   // (largest to smallest). Therefore, the first eigenvector corresponds to the\n//   // largest eigenvalue and represents the most stable cointegrating relationship.\n//   optimal_hedge_vector = johansen_results.eigenvectors[:, 0] // Select the first column\n//\n//   // 3. Return the extracted vector.\n//   // This vector contains the number of shares of each asset to hold to form\n//   // the most mean-reverting portfolio.\n//   RETURN optimal_hedge_vector\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 61,
    "text": "### 1. Framework Overview\n- **[Definition] Bollinger Bands**: A practical mean-reversion trading strategy that generates discrete entry and exit signals based on price deviations from a moving average. Unlike a linear strategy that continuously scales position size, the Bollinger Band approach maintains a fixed position size (e.g., one unit long or short) or is flat, simplifying capital allocation and risk management.\n\n### 2. Key Components\n- **Lookback Period**: A specified number of recent time steps used to calculate the moving average and moving standard deviation of the price series.\n- **[Definition] Z-Score**: A normalized measure of how far the current price deviates from its moving average, expressed in units of standard deviations.\n\n  `zScore = (currentPrice - movingAverage) / movingStandardDeviation`\n\n- **[Definition] entryZscore**: A positive threshold. A position is entered when the absolute value of the Z-Score exceeds this value.\n- **[Definition] exitZscore**: A positive threshold, typically less than `entryZscore`. A position is exited when the Z-Score reverts back towards the mean and crosses this threshold.\n\n### 3. Signal Generation Logic\nAt each time step, four logical conditions are evaluated to determine trading action:\n\n- **Long Entry**: Occurs when the price is significantly below the mean. The condition is `zScore < -entryZscore`.\n- **Long Exit**: Occurs when a long position is open and the price has reverted towards the mean. The condition is `zScore >= -exitZscore`.\n- **Short Entry**: Occurs when the price is significantly above the mean. The condition is `zScore > entryZscore`.\n- **Short Exit**: Occurs when a short position is open and the price has reverted towards the mean. The condition is `zScore <= exitZscore`.\n\n### 4. Position State Management\nTo implement the strategy, the algorithm must track the current position (long, short, or flat). A common approach is to use a state variable that is updated at each time step:\n- If a long entry signal occurs, the position becomes 1 (long).\n- If a short entry signal occurs, the position becomes -1 (short).\n- If an exit signal corresponding to the current position occurs (e.g., a long exit while long), the position becomes 0 (flat).\n- If no entry or exit signals occur, the position from the previous time step is carried forward.",
    "question": "Provide the pseudocode for a function that generates a time series of trading positions (1 for long, -1 for short, 0 for flat) based on the Bollinger Band logic described.",
    "answer": "```\n// --- BEGIN PSEUCOCODE ---\n//\n// FUNCTION GenerateBollingerPositions(price_series, lookback, entryZ, exitZ)\n// INPUTS:\n//   - price_series: An array of prices.\n//   - lookback: An integer for the moving window size.\n//   - entryZ: A positive float for the entry Z-Score threshold.\n//   - exitZ: A positive float for the exit Z-Score threshold (exitZ < entryZ).\n// OUTPUTS:\n//   - An array representing the position at each time step (1 for long, -1 for short, 0 for flat).\n//\n// BEGIN\n//   Initialize positions_array of the same size as price_series with all zeros.\n//\n//   Calculate moving_avg series from price_series using the lookback window.\n//   Calculate moving_std series from price_series using the lookback window.\n//\n//   Calculate z_score_series = (price_series - moving_avg) / moving_std.\n//\n//   FOR t FROM 1 TO length(price_series) - 1\n//     // Determine previous day's position\n//     previous_position = positions_array[t-1]\n//\n//     // Default to carrying forward the position\n//     positions_array[t] = previous_position\n//\n//     // Check for entry signals (only if flat)\n//     IF previous_position == 0 THEN\n//       IF z_score_series[t] < -entryZ THEN\n//         positions_array[t] = 1 // Long Entry\n//       ELSE IF z_score_series[t] > entryZ THEN\n//         positions_array[t] = -1 // Short Entry\n//       END IF\n//\n//     // Check for exit signals (only if in a position)\n//     ELSE IF previous_position == 1 THEN\n//       IF z_score_series[t] >= -exitZ THEN\n//         positions_array[t] = 0 // Long Exit\n//       END IF\n//     ELSE IF previous_position == -1 THEN\n//       IF z_score_series[t] <= exitZ THEN\n//         positions_array[t] = 0 // Short Exit\n//       END IF\n//     END IF\n//   END FOR\n//\n//   RETURN positions_array\n// END\n//\n// --- END PSEUCOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 62,
    "text": "### 1. Conceptual Framework\n- **[Definition] Kalman Filter**: An optimal recursive algorithm that estimates the state of a dynamic system from a series of noisy measurements. For pairs trading, it provides a superior alternative to moving-window regression for estimating a time-varying hedge ratio, as it gives more weight to recent data without an arbitrary cutoff and produces smoother estimates.\n\n### 2. State-Space Model Specification\nTo apply the Kalman filter, we define a state-space model that describes the relationship between two asset price series, `y(t)` and `x(t)`.\n\n- **[Definition] State-Space Model**: A mathematical representation of a physical system with inputs, outputs, and state variables. It consists of a measurement equation and a state transition equation.\n\n- **Hidden State Vector `灏?t)`**: A 2x1 vector containing the unobservable true parameters we want to estimate at time `t`. It includes the hedge ratio (slope) and the spread's mean (intercept).\n\n- **[Definition] Measurement Equation**: Relates the observable variable `y(t)` to the hidden state `灏?t)` and the other observable `x(t)`.\n\n  `y(t) = x_aug(t) * 灏?t) + 钄?t)` (Equation 1)\n  *   `y(t)`: The price of asset Y at time `t` (observable variable).\n  *   `x_aug(t)`: A 1x2 augmented vector `[x(t), 1]` (observation model).\n  *   `灏?t)`: The 2x1 hidden state vector `[slope, intercept]`.\n  *   `钄?t)`: Gaussian measurement noise with variance `V_钄歚.\n\n- **[Definition] State Transition Equation**: Describes how the hidden state evolves over time. We assume it follows a random walk.\n\n  `灏?t) = 灏?t-1) + 锠?t-1)` (Equation 2)\n  *   `灏?t-1)`: The state at the previous time step.\n  *   `锠?t-1)`: Gaussian process noise with covariance matrix `V_锠卄.\n\n### 3. The Iterative Kalman Filter Equations\nGiven the state estimate `灏綺hat(t-1|t-1)` and its covariance `R(t-1|t-1)` from the previous step, the algorithm iterates through a two-step process: Prediction and Update.\n\n**Prediction Step (a priori estimates):**\n1.  **Predict State**: `灏綺hat(t|t-1) = 灏綺hat(t-1|t-1)` (Equation 3)\n2.  **Predict State Covariance**: `R(t|t-1) = R(t-1|t-1) + V_锠卄 (Equation 4)\n3.  **Predict Measurement**: `y_hat(t) = x_aug(t) * 灏綺hat(t|t-1)` (Equation 5)\n4.  **Predict Measurement Variance**: `Q(t) = x_aug(t) * R(t|t-1) * x_aug(t)' + V_钄歚 (Equation 6)\n\n**Update Step (a posteriori estimates after observing `y(t)`):**\n5.  **Calculate Forecast Error**: `e(t) = y(t) - y_hat(t)`\n6.  **Calculate [Definition] Kalman Gain `K(t)`**: Determines how much the forecast error `e(t)` should correct the state estimate.\n    `K(t) = R(t|t-1) * x_aug(t)' / Q(t)` (Equation 7)\n7.  **Update State Estimate**: `灏綺hat(t|t) = 灏綺hat(t|t-1) + K(t) * e(t)` (Equation 8)\n8.  **Update State Covariance**: `R(t|t) = R(t|t-1) - K(t) * x_aug(t) * R(t|t-1)` (Equation 9)",
    "question": "Provide the pseudocode for a function that takes two price series and Kalman filter parameters as input, and returns the time series of the estimated hidden state vector (hedge ratio and intercept).",
    "answer": "```\n// --- BEGIN PSEUCOCODE ---\n//\n// FUNCTION KalmanFilterHedgeRatio(y_series, x_series, delta, Ve)\n// INPUTS:\n//   - y_series: An array of prices for the dependent variable.\n//   - x_series: An array of prices for the independent variable.\n//   - delta: A float (e.g., 0.0001) to compute process noise covariance.\n//   - Ve: A float for the measurement noise variance.\n// OUTPUTS:\n//   - A Tx2 array where each row contains the estimated [slope, intercept] at time t.\n//\n// BEGIN\n//   T = length(y_series)\n//   x_aug = augment x_series with a column of ones -> becomes a Tx2 matrix.\n//\n//   // Initialize state variables\n//   beta_series = new Tx2 array initialized to zeros.\n//   beta_current = new 2x1 vector [0, 0].\n//   P_current = new 2x2 identity matrix.\n//\n//   // Define noise covariance matrices\n//   Vw = (delta / (1 - delta)) * (new 2x2 identity matrix).\n//\n//   // Main iterative loop\n//   FOR t FROM 0 TO T - 1\n//     // --- PREDICTION STEP ---\n//     // State prediction is trivial as per Equation 3: beta_predicted = beta_current\n//     // State covariance prediction (Equation 4)\n//     R_predicted = P_current + Vw\n//\n//     // --- UPDATE STEP ---\n//     // Get current observation model vector\n//     x_t = row t of x_aug (as a 1x2 vector)\n//\n//     // Measurement variance prediction (Equation 6)\n//     Q_t = (x_t * R_predicted * transpose(x_t)) + Ve\n//\n//     // Kalman Gain calculation (Equation 7)\n//     K_t = (R_predicted * transpose(x_t)) / Q_t\n//\n//     // Measurement prediction (Equation 5)\n//     y_hat_t = x_t * beta_current\n//\n//     // Measurement prediction error\n//     error_t = y_series[t] - y_hat_t\n//\n//     // State update (Equation 8)\n//     beta_current = beta_current + (K_t * error_t)\n//\n//     // State covariance update (Equation 9)\n//     P_current = R_predicted - (K_t * x_t * R_predicted)\n//\n//     // Store the updated state\n//     beta_series[t] = transpose(beta_current)\n//   END FOR\n//\n//   RETURN beta_series\n// END\n//\n// --- END PSEUCOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 63,
    "text": "### Strategy Rationale\nThe Buy-on-Gap model is an intraday mean-reversion strategy designed to capitalize on temporary panic selling at the market open. The core idea is that stocks that gap down significantly at the open, despite being in a longer-term uptrend, are likely to recover some of their losses during the trading day. The strategy is purely mechanical and executed on a daily basis.\n\n### Trading Rules\nThe algorithm must implement the following four rules in sequence at the market open each day:\n\n1.  **Gap-Down Filter**: Identify all stocks whose opening price creates a negative return from the *previous day's low* that is greater in magnitude than one standard deviation. The standard deviation is calculated based on the stock's daily close-to-close returns over the last 90 days.\n2.  **Momentum Filter**: From the list generated in Rule 1, select only those stocks whose current opening price is *higher* than the 20-day simple moving average of their closing prices.\n3.  **Ranking and Selection**: From the filtered list generated in Rule 2, rank the stocks by their gap-down return (from previous day's low to today's open), from most negative to least negative. Select the top 10 stocks with the most negative returns for purchase. If the list contains fewer than 10 stocks, select all of them.\n4.  **Holding Period**: All selected positions are to be bought at the open and liquidated at the market close on the same day.\n\n### Key Concepts\n*   **[Definition] Gap Down**: A situation where a stock's opening price is significantly lower than its previous day's trading range, often indicated by the price opening below the prior day's low.\n*   **[Definition] Momentum Filter**: A rule used to confirm that a short-term counter-trend signal (like a gap down) is occurring within the context of a longer-term positive trend. Here, requiring the price to be above a moving average serves this purpose.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Buy-on-Gap Selection Algorithm]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the selection logic of the Buy-on-Gap model. The function should process daily market data and, for a given day, return a list of stock symbols to be purchased at the open.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION SelectBuyOnGapStocks(current_day, stocks_data, max_positions)\n// INPUTS:\n//   - current_day: The date for which to run the selection.\n//   - stocks_data: A data structure containing historical daily open, low, and close prices for all stocks in the universe.\n//   - max_positions: The maximum number of stocks to select (e.g., 10).\n// OUTPUTS:\n//   - A list of stock symbols to be purchased at the open for the current_day.\n//\n// BEGIN\n//   Initialize an empty list: qualified_stocks\n//\n//   FOR EACH stock IN stocks_data:\n//     // Rule 1: Gap-Down Filter\n//     Let prev_day_low = GetLowPrice(stock, current_day - 1)\n//     Let current_open = GetOpenPrice(stock, current_day)\n//     Let gap_return = (current_open - prev_day_low) / prev_day_low\n//\n//     // Calculate 90-day standard deviation of close-to-close returns\n//     Let close_prices_90d = GetClosePrices(stock, from: current_day - 91, to: current_day - 1)\n//     Let returns_90d = CalculateDailyReturns(close_prices_90d)\n//     Let stdev_returns = StandardDeviation(returns_90d)\n//\n//     // Check if the gap down is more than one standard deviation\n//     IF gap_return < -stdev_returns THEN\n//       // Rule 2: Momentum Filter\n//       Let close_prices_20d = GetClosePrices(stock, from: current_day - 21, to: current_day - 1)\n//       Let ma_20d = Mean(close_prices_20d)\n//\n//       IF current_open > ma_20d THEN\n//         // Stock qualifies, add it to our list with its gap return for sorting\n//         Add (stock_symbol, gap_return) to qualified_stocks\n//       END IF\n//     END IF\n//   END FOR\n//\n//   // Rule 3: Ranking and Selection\n//   Sort qualified_stocks in ascending order based on gap_return.\n//\n//   Let num_to_select = Minimum(max_positions, Count(qualified_stocks))\n//   Let final_selection = Take the first num_to_select stock symbols from the sorted qualified_stocks list.\n//\n//   RETURN final_selection\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 64,
    "text": "### Framework Overview\nThis strategy seeks to profit from temporary price discrepancies between an ETF and a custom-built portfolio of its underlying component stocks. Instead of holding all the ETF's components, the goal is to select a smaller, more manageable subset of stocks that, as a group, cointegrate strongly with the ETF. The process is divided into a 'training' phase for portfolio construction and a 'testing' phase for trading.\n\n### Key Concepts\n*   **[Definition] Index Arbitrage**: A strategy that attempts to profit from price differences between a basket of securities and a related derivative, such as an index future or an ETF.\n*   **[Definition] Johansen Test**: A statistical procedure for identifying the presence of cointegrating relationships among multiple time series. It returns both a test statistic to determine significance and an eigenvector that can be used to form a stationary, mean-reverting portfolio.\n*   **[Definition] Cointegrating Vector (Eigenvector)**: A set of coefficients (weights) that, when applied to a linear combination of non-stationary time series, results in a stationary series. In this context, it provides the hedge ratios for the portfolio.\n\n### Phase 1: Portfolio Selection Algorithm (Training Phase)\nThe portfolio construction follows a rigorous, multi-step process performed on a historical training dataset (e.g., one year of daily data).\n\n1.  **Individual Component Screening**: For each stock in the ETF's universe (e.g., S&P 500 components for the SPY ETF), perform a Johansen test between the individual stock's price series and the ETF's price series. A stock is considered a candidate if the test indicates cointegration at a specified significance level (e.g., 90% probability).\n2.  **Candidate Portfolio Formation**: Create an equal-capital portfolio composed of all the candidate stocks identified in Step 1. The daily value of this portfolio is calculated based on the sum of the log prices of its components, assuming daily rebalancing to equal weights.\n3.  **Portfolio Cointegration Validation**: Perform a final Johansen test between the time series of the candidate portfolio's value (from Step 2) and the ETF's log price series. This step is crucial to confirm that the collection of individually cointegrating stocks also cointegrates as a group.\n4.  **Hedge Ratio Determination**: If the final test in Step 3 confirms cointegration, the first eigenvector from the Johansen test results provides the hedge ratio between the stock portfolio and the ETF, which will be used for trading.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[ETF Arbitrage Portfolio Construction]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the entire **Phase 1: Portfolio Selection Algorithm**. The function should take a universe of stock prices and an ETF's price series over a training period and return the final list of selected stocks that form a cointegrating portfolio.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ConstructCointegratingPortfolio(stock_prices, etf_prices, significance_level)\n// INPUTS:\n//   - stock_prices: A map or dictionary where keys are stock symbols and values are their historical price series for the training period.\n//   - etf_prices: The historical price series for the target ETF for the training period.\n//   - significance_level: The confidence level for the Johansen test (e.g., 0.90).\n// OUTPUTS:\n//   - A list of stock symbols that form the final cointegrating portfolio. Returns an empty list if no valid portfolio is found.\n//\n// BEGIN\n//   // Step 1: Individual Component Screening\n//   Initialize an empty list: candidate_stocks\n//   FOR EACH stock_symbol, stock_series IN stock_prices:\n//     // Perform Johansen test on the pair (stock_series, etf_prices)\n//     johansen_result = JohansenTest(stock_series, etf_prices)\n//     IF johansen_result.is_coint_at_level(significance_level) THEN\n//       Add stock_symbol to candidate_stocks\n//     END IF\n//   END FOR\n//\n//   IF Count(candidate_stocks) is zero THEN\n//     RETURN empty list\n//   END IF\n//\n//   // Step 2: Candidate Portfolio Formation\n//   Initialize an empty series: portfolio_log_value\n//   FOR EACH day in the training period:\n//     daily_log_sum = 0\n//     FOR EACH stock_symbol IN candidate_stocks:\n//       daily_log_sum = daily_log_sum + Log(GetPrice(stock_prices[stock_symbol], day))\n//     END FOR\n//     Append daily_log_sum to portfolio_log_value\n//   END FOR\n//\n//   Let etf_log_prices = Log(etf_prices)\n//\n//   // Step 3: Portfolio Cointegration Validation\n//   final_johansen_result = JohansenTest(portfolio_log_value, etf_log_prices)\n//\n//   // Step 4: Final Decision\n//   IF final_johansen_result.is_coint_at_level(significance_level) THEN\n//     RETURN candidate_stocks\n//   ELSE\n//     RETURN empty list\n//   END IF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 65,
    "text": "### Core Concept\n*   **[Definition] Cross-Sectional Mean Reversion**: A trading strategy based on the principle that the *relative* performance of stocks within a universe is serially anti-correlated. It assumes that stocks that recently outperformed their peers will tend to underperform next, and vice versa. Unlike time-series mean reversion, it does not assume that a stock's price will revert to its own historical mean.\n\n### Weight Calculation Formula\nThis strategy rebalances daily, assigning a capital weight to every stock in a given universe (e.g., S&P 500). The weight for each stock is determined by its return relative to the average return of the entire universe. The formula for the capital weight \\(w_i\\) allocated to the \\(i^{th}\\) stock is:\n\n$$ w_{i} = -\\frac{r_{i} - \\langle r_{j} \\rangle}{\\sum_{k}|r_{k} - \\langle r_{j} \\rangle|} \\quad \\text{Equation 1} $$\n\nWhere:\n*   \\(w_i\\) is the capital weight for stock \\(i\\). A positive value means a long position, and a negative value means a short position.\n*   \\(r_i\\) is the daily return of stock \\(i\\).\n*   \\(\\langle r_j \\rangle\\) is the equal-weighted average daily return of all stocks (\\(j\\)) in the universe for that day.\n*   The numerator, \\(-(r_i - \\langle r_j \\rangle)\\), is the negative of the stock's relative return. This ensures we buy underperformers and sell outperformers.\n*   The denominator, \\(\\sum_{k}|r_{k} - \\langle r_{j} \\rangle|\\), is a normalization factor. It is the sum of the absolute values of all stocks' relative returns. Dividing by this factor ensures that the sum of the absolute values of all weights, \\(\\sum_i |w_i|\\), equals 1, representing a constant gross capital.\n\n### Implementation Logic\n*   **[Definition] Dollar Neutral**: A portfolio is dollar-neutral if the total capital allocated to long positions equals the total capital allocated to short positions. The sum of the weights in this model, \\(\\sum_i w_i\\), is mathematically zero, satisfying this condition.\n\nThe implementation requires calculating daily returns for all stocks, finding the cross-sectional average return, computing relative returns, and then applying Equation 1 to determine the final weights.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Cross-Sectional Weighting Algorithm]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a matrix of daily closing prices for a universe of stocks and computes the corresponding matrix of portfolio weights for the *next* day's positions, according to the cross-sectional mean reversion formula.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateCrossSectionalWeights(closing_prices)\n// INPUTS:\n//   - closing_prices: A T x N matrix, where T is the number of days and N is the number of stocks.\n// OUTPUTS:\n//   - A (T-1) x N matrix of capital weights to be held on day t, calculated from returns on day t-1.\n//\n// BEGIN\n//   // Calculate daily returns. The resulting matrix will have T-1 rows.\n//   Let returns = (closing_prices[1:end,:] - closing_prices[0:end-1,:]) / closing_prices[0:end-1,:]\n//\n//   Let num_days = Number of rows in returns\n//   Let num_stocks = Number of columns in returns\n//   Initialize an empty matrix: weights of size num_days x num_stocks\n//\n//   FOR EACH day t FROM 0 TO num_days - 1:\n//     // Calculate the equal-weighted average return for the current day\n//     Let daily_returns_row = returns[t, :]\n//     Let market_return = Mean(daily_returns_row)\n//\n//     // Calculate relative returns for each stock\n//     Let relative_returns = daily_returns_row - market_return\n//\n//     // Calculate the normalization factor (denominator of Equation 1)\n//     Let normalization_factor = Sum(AbsoluteValue(relative_returns))\n//\n//     // Calculate the final weights for this day\n//     IF normalization_factor > 0 THEN\n//       Let daily_weights = -relative_returns / normalization_factor\n//     ELSE\n//       // Handle case where all returns are identical (rare)\n//       Let daily_weights = Zeros(num_stocks)\n//     END IF\n//\n//     // Store the weights for the portfolio to be held on the *next* day (t+1)\n//     weights[t, :] = daily_weights\n//   END FOR\n//\n//   RETURN weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 66,
    "text": "### Framework Overview\n\nWhen backtesting currency strategies that hold positions overnight (past 5:00 p.m. ET), simply using the price change is insufficient. The total return must include the net interest earned or paid, known as the rollover interest. Accurate calculation of excess return, which is essential for metrics like the Sharpe Ratio, requires incorporating this interest.\n\n### Key Concepts\n\n1.  **[Definition] Rollover Interest**: The interest differential between the two currencies in a pair, which is credited or debited to an account for holding a position overnight. For a long position in `B.Q`, the interest is based on `i_B - i_Q`, where `i_B` and `i_Q` are the respective daily interest rates.\n\n2.  **Weekend and Holiday Rollovers**: Currency settlement systems dictate how weekend interest is applied. The standard rollover interest is multiplied to account for non-trading days.\n    *   **T+2 Settlement**: For most currency pairs, settlement occurs two business days after the trade. To account for the weekend (Saturday, Sunday), a position held past 5 p.m. ET on a Wednesday accrues three times the daily rollover interest.\n    *   **T+1 Settlement**: For specific pairs like `USD.CAD` and `USD.MXN`, settlement is on the next business day. For these pairs, the triple rollover interest is applied to positions held past 5 p.m. ET on a Thursday.\n\n### Computational Steps\n\nThe excess log return for holding a long position in the pair `B.Q` from time `t` to `t+1` is calculated by adding the log interest rate differential to the log price return.\n\n**Equation 1**: `r(t+1) = {log(y(t+1)) - log(y(t))} + {log(1 + i_B(t)) - log(1 + i_Q(t))}`\n\nWhere:\n*   `r(t+1)`: The total excess log return.\n*   `y(t)`: The quote for `B.Q` at time `t`.\n*   `i_B(t)`: The effective daily interest rate for the base currency at time `t`.\n*   `i_Q(t)`: The effective daily interest rate for the quote currency at time `t`.\n\nNote that `i_B(t)` and `i_Q(t)` must be adjusted for the weekend rollover rules before being used in the formula.",
    "question": "Provide the pseudocode for a function that calculates the daily excess log return for a long position in a currency pair. The function must correctly apply the triple rollover interest adjustment based on the day of the week and the pair's settlement type.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateExcessLogReturn(price_t1, price_t, base_rate_t, quote_rate_t, date_t, settlement_type)\n// INPUTS:\n//   - price_t1: The currency pair's price at time t+1.\n//   - price_t: The currency pair's price at time t.\n//   - base_rate_t: The daily interest rate for the base currency at time t.\n//   - quote_rate_t: The daily interest rate for the quote currency at time t.\n//   - date_t: The date at time t, used to determine the day of the week.\n//   - settlement_type: A string, either 'T+2' or 'T+1'.\n// OUTPUTS:\n//   - The total excess log return for the period [t, t+1].\n//\n// BEGIN\n//   // Initialize effective interest rates\n//   effective_base_rate = base_rate_t\n//   effective_quote_rate = quote_rate_t\n//\n//   // Determine the day of the week from date_t (e.g., 1=Monday, ..., 5=Friday)\n//   day_of_week = GetDayOfWeek(date_t)\n//\n//   // Apply weekend rollover rules based on settlement type\n//   IF settlement_type == 'T+2' AND day_of_week == 3 // Wednesday\n//     effective_base_rate = 3 * effective_base_rate\n//     effective_quote_rate = 3 * effective_quote_rate\n//   ELSE IF settlement_type == 'T+1' AND day_of_week == 4 // Thursday\n//     effective_base_rate = 3 * effective_base_rate\n//     effective_quote_rate = 3 * effective_quote_rate\n//   END IF\n//\n//   // Calculate the log return from price change\n//   price_log_return = Log(price_t1) - Log(price_t)\n//\n//   // Calculate the log return from interest rate differential\n//   interest_log_return = Log(1 + effective_base_rate) - Log(1 + effective_quote_rate)\n//\n//   // Calculate total excess return\n//   total_excess_return = price_log_return + interest_log_return\n//\n//   RETURN total_excess_return\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 67,
    "text": "### Framework Overview\n\nThe total return of a futures contract can be decomposed into two distinct parts: the spot return, driven by changes in the underlying asset's price, and the roll return, resulting from the price difference between contracts of different maturities. Understanding this decomposition is critical, as the roll return can dominate the total return and invalidate strategies based solely on spot price intuition.\n\n### Key Concepts\n\n1.  **[Definition] Roll Return (Roll Yield)**: The return generated as a futures contract's price converges to the spot price over time. It is an intrinsic component of a futures' total return.\n2.  **[Definition] Backwardation vs. Contango**:\n    *   **Backwardation**: A market state where near-term futures contracts are more expensive than far-term contracts. This typically results in a positive roll return.\n    *   **Contango**: A market state where far-term futures contracts are more expensive than near-term contracts. This typically results in a negative roll return.\n\n### The Futures Price Model\n\nA simplified model for the price of a future, `F(t,T)`, at current time `t` with expiration time `T` is:\n\n**Equation 1**: `F(t,T) = S(t) * exp(绾?* (t - T))`\n\nWhere `S(t)` is the spot price and `绾琡 is the compounded roll return. Assuming the spot price itself grows at a constant compounded rate `浼猔:\n\n**Equation 2**: `S(t) = c * exp(浼?* t)`\n\nCombining these gives the full model:\n\n**Equation 3**: `F(t,T) = c * exp(浼?* t) * exp(绾?* (t - T))`\n\nFrom this model, we can see that the total log return is `浼?+ 绾琡, and the roll return is `绾琡.\n\n### Computational Steps for Estimation\n\nThis model allows for the estimation of `浼猔 (spot return) and `绾琡 (roll return) using linear regression.\n\n1.  **Estimate Spot Return (`浼猔)**: Perform a single linear regression of the log of the spot price series against a time index `t`. The slope of this regression is the estimated spot return `浼猔.\n    *   `log(S(t)) = 浼?t + log(c)`\n\n2.  **Estimate Roll Return (`绾琡)**: For each day, fit a *forward curve*. This involves performing a linear regression of the log-prices of available futures contracts against their time-to-maturity. The negative of the slope of this regression is the estimated roll return `绾琡 for that day.\n    *   From Equation 1, taking the log: `log(F(t,T)) = log(S(t)) - 绾?T + 绾?t`. For a fixed `t`, this is a linear relationship between `log(F(t,T))` and `T` with slope `-绾琡.",
    "question": "Provide the pseudocode for a function that takes time series data for spot prices and multiple futures contracts, and returns the estimated daily roll return (`gamma`) and the single average spot return (`alpha`).",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION EstimateSpotAndRollReturns(spot_prices, futures_prices, futures_maturities)\n// INPUTS:\n//   - spot_prices: A T x 1 array of daily spot prices.\n//   - futures_prices: A T x M array of daily prices for M futures contracts.\n//   - futures_maturities: A 1 x M array of expiration times/dates for the M contracts.\n// OUTPUTS:\n//   - A tuple containing (alpha, gamma_series):\n//     - alpha: A single float value for the average annualized spot return.\n//     - gamma_series: A T x 1 array of daily annualized roll returns.\n//\n// BEGIN\n//   // --- Part 1: Estimate Average Spot Return (alpha) ---\n//   time_index = [1, 2, ..., length(spot_prices)]\n//   log_spot_prices = Log(spot_prices)\n//   // Perform OLS: log_spot_prices ~ beta_0 + beta_1 * time_index\n//   spot_regression = OLS(y=log_spot_prices, X=[ones, time_index])\n//   daily_alpha = spot_regression.beta[1]\n//   alpha = daily_alpha * 252 // Annualize\n//\n//   // --- Part 2: Estimate Daily Roll Return (gamma) ---\n//   num_days = length(spot_prices)\n//   gamma_series = array of NaNs of size num_days\n//\n//   FOR t FROM 1 TO num_days\n//     // Get prices and maturities for day t\n//     prices_t = futures_prices[t,:]\n//     // Find indices of the 5 nearest consecutive, non-NaN contracts\n//     valid_contracts_indices = FindFirstFiveConsecutiveContracts(prices_t)\n//\n//     IF valid_contracts_indices is not empty THEN\n//       // Prepare data for regression\n//       log_prices_t = Log(prices_t[valid_contracts_indices])\n//       // Time-to-maturity in years\n//       time_to_maturity = (futures_maturities[valid_contracts_indices] - date_at_t) / 365.25\n//\n//       // Perform OLS: log_prices_t ~ beta_0 + beta_1 * time_to_maturity\n//       roll_regression = OLS(y=log_prices_t, X=[ones, time_to_maturity])\n//       // Gamma is the negative of the slope. The model uses compounded returns, so no annualization factor is needed if T is in years.\n//       gamma_series[t] = -roll_regression.beta[1]\n//     END IF\n//   END FOR\n//\n//   RETURN (alpha, gamma_series)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 68,
    "text": "## Framework Overview\nTo identify optimal parameters for a time series momentum strategy, one must systematically test various combinations of look-back and holding periods. The goal is to find the pair that yields the highest positive correlation between past and future returns, indicating a strong momentum effect. A critical aspect of this analysis is ensuring that the data used for correlation calculations is non-overlapping to avoid statistical bias.\n\n## Key Concepts\n- **[Definition] Time Series Momentum**: The empirical observation that a price series' past returns are positively correlated with its future returns.\n- **[Definition] Look-back Period**: The length of the historical window (e.g., 250 days) used to calculate the past return. This return is used as the predictive signal.\n- **[Definition] Holding Period**: The length of the future window (e.g., 25 days) over which a position is held. The return over this period is what the signal aims to predict.\n- **[Definition] Non-Overlapping Data**: A method of sampling data to ensure that each pair of (past return, future return) is statistically independent. If the data periods used to calculate these pairs overlap, the correlation estimates can be artificially inflated.\n\n## Computational Steps\nFor each pair of `lookback` and `holddays` periods to be tested:\n\n1.  **Calculate Return Series**: Generate two time series:\n    *   `ret_lag`: The series of past returns, calculated over the `lookback` period.\n    *   `ret_fut`: The series of future returns, calculated over the `holddays` period.\n2.  **Handle Missing Data**: Remove any time steps where either `ret_lag` or `ret_fut` is undefined (e.g., due to insufficient historical data at the beginning of the series).\n3.  **Ensure Independence**: To prevent data overlap, create an independent sample set by selecting data points with a specific stride. The stride is determined by the larger of the `lookback` and `holddays` periods.\n    *   If `lookback >= holddays`, the stride should be `lookback` days.\n    *   If `holddays > lookback`, the stride should be `holddays` days.\n4.  **Compute Correlation**: Using the independent, non-overlapping data samples, calculate the Pearson correlation coefficient and its corresponding p-value between `ret_lag` and `ret_fut`.\n5.  **Evaluate Results**: Analyze the output to find pairs of (`lookback`, `holddays`) that show a high positive correlation and a low p-value (e.g., p < 0.05), as shown in the example `Table 1`.\n\n**Table 1: Example Correlations for TU Futures**\n| Look-back | Holding days | Correlation coefficient | p-value |\n|:---:|:---:|:---:|:---:|\n| 60 | 10 | 0.1718 | 0.0169 |\n| 60 | 25 | 0.2592 | 0.0228 |\n| 250 | 10 | 0.1784 | 0.0185 |\n| 250 | 25 | 0.2719 | 0.0238 |\n| 250 | 60 | 0.4245 | 0.0217 |",
    "question": "Provide the pseudocode for a function that systematically tests pairs of look-back and holding periods for a given price series, ensuring non-overlapping data, and returns the correlation results.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ScanMomentumParameters(price_series, lookback_periods, holding_periods)\n// INPUTS:\n//   - price_series: A 1D array of asset closing prices.\n//   - lookback_periods: A list of integer look-back periods to test.\n//   - holding_periods: A list of integer holding periods to test.\n// OUTPUTS:\n//   - A list of records, where each record contains {lookback, holding, correlation, p_value}.\n//\n// BEGIN\n//   results = []\n//\n//   FOR each lookback IN lookback_periods\n//     FOR each holddays IN holding_periods\n//       // Step 1: Calculate past and future returns for the entire series\n//       ret_lag = (price_series - SHIFT(price_series, lookback)) / SHIFT(price_series, lookback)\n//       ret_fut = (SHIFT(price_series, -holddays) - price_series) / price_series\n//\n//       // Step 2: Align and clean data\n//       // Create a combined dataset and remove rows with any NaN values\n//       combined_data = CREATE_TABLE(ret_lag, ret_fut)\n//       cleaned_data = REMOVE_NAN_ROWS(combined_data)\n//\n//       // Step 3: Ensure independence by creating non-overlapping samples\n//       IF lookback >= holddays THEN\n//         step_size = lookback\n//       ELSE\n//         step_size = holddays\n//       END IF\n//\n//       // Select data points using the calculated step size\n//       independent_indices = SEQUENCE(1, LENGTH(cleaned_data), step_size)\n//       independent_data = SELECT_ROWS(cleaned_data, independent_indices)\n//\n//       // Step 4: Compute Correlation\n//       IF LENGTH(independent_data) > 1 THEN\n//         // Extract columns for correlation calculation\n//         independent_lag = GET_COLUMN(independent_data, 1)\n//         independent_fut = GET_COLUMN(independent_data, 2)\n//\n//         // Compute correlation and p-value\n//         [corr_coeff, p_val] = CORRELATION_COEFFICIENT(independent_lag, independent_fut)\n//\n//         // Store the result\n//         ADD {lookback, holddays, corr_coeff, p_val} TO results\n//       END IF\n//\n//     END FOR\n//   END FOR\n//\n//   RETURN results\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 69,
    "text": "## Strategy Overview\nA simple and effective time series momentum strategy involves taking a position based on the sign of an asset's long-term past return. For example, using a 250-day look-back and a 25-day holding period, the strategy is to buy if the 250-day return is positive and sell if it is negative.\n\nA key modification to this approach is to stagger the entries. Instead of investing the full capital on the day a signal is generated, the capital is split into equal fractions (e.g., 1/25th) and deployed daily over the entire holding period. This smooths out entries and diversifies risk across time.\n\n## Key Parameters\n- **[Definition] Look-back Period (`lookback`)**: The number of days used to calculate the historical return that generates the signal (e.g., 250 days).\n- **[Definition] Holding Period (`holddays`)**: The number of days a position initiated on a given day is held (e.g., 25 days). This also determines the number of fractions the capital is divided into.\n- **[Definition] Staggered Entry**: An execution tactic where a new fraction of the total desired position is initiated each day over the holding period. For a 25-day holding period, on any given day, the total position is the sum of the positions initiated over the last 25 days.\n\n## Implementation Logic (Example 1)\nThe core of the implementation is to build a final daily position vector (`pos`) that reflects the aggregation of staggered entries.\n\n1.  **Generate Daily Signals**: For each day, determine the raw signal:\n    *   `longs`: A boolean series, `True` if `price[t] > price[t-lookback]`.\n    *   `shorts`: A boolean series, `True` if `price[t] < price[t-lookback]`.\n2.  **Aggregate Positions**: Initialize a position vector `pos` of the same length as the price series, filled with zeros.\n3.  **Loop through Holding Period**: Iterate with a lag `h` from `0` to `holddays - 1`.\n    *   For each `h`, shift the `longs` and `shorts` signal series forward by `h` days.\n    *   Where the shifted `longs` signal is `True`, add `+1` to the `pos` vector.\n    *   Where the shifted `shorts` signal is `True`, add `-1` to the `pos` vector.\n4.  **Final Position**: After the loop completes, `pos[t]` will contain the sum of all active signals for day `t`. For a holding period of 25, the value of `pos[t]` can range from -25 to +25. The final return is then calculated based on this position vector, normalized by `holddays`.",
    "question": "Provide the pseudocode for a function that takes a price series and momentum parameters, and generates a daily position vector based on the staggered entry logic.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateStaggeredMomentumPositions(price_series, lookback_period, holding_period)\n// INPUTS:\n//   - price_series: A 1D array of asset closing prices.\n//   - lookback_period: The integer look-back period for the signal.\n//   - holding_period: The integer holding period for staggering positions.\n// OUTPUTS:\n//   - A 1D array representing the daily position size.\n//\n// BEGIN\n//   num_days = LENGTH(price_series)\n//\n//   // Step 1: Generate daily raw long/short signals\n//   price_lagged = SHIFT(price_series, lookback_period)\n//   long_signals = (price_series > price_lagged)\n//   short_signals = (price_series < price_lagged)\n//\n//   // Step 2: Initialize an empty position vector\n//   positions = ZEROS(num_days)\n//\n//   // Step 3: Loop through the holding period to aggregate staggered positions\n//   FOR h FROM 0 TO holding_period - 1\n//     // Create lagged versions of the signals for this iteration\n//     longs_for_h = SHIFT(long_signals, h)\n//     shorts_for_h = SHIFT(short_signals, h)\n//\n//     // Clean NaN values that result from shifting\n//     REPLACE_NAN(longs_for_h, FALSE)\n//     REPLACE_NAN(shorts_for_h, FALSE)\n//\n//     // Add this day's fractional position to the total position vector\n//     // For days where longs_for_h is TRUE, add 1 to positions\n//     positions = positions + CAST_TO_INTEGER(longs_for_h)\n//\n//     // For days where shorts_for_h is TRUE, subtract 1 from positions\n//     positions = positions - CAST_TO_INTEGER(shorts_for_h)\n//   END FOR\n//\n//   // Step 4: Return the final aggregated position vector\n//   RETURN positions\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 70,
    "text": "## Strategy Overview\nCross-sectional momentum is a powerful strategy that builds a market-neutral portfolio by buying recent top-performing assets and shorting recent bottom-performing assets from a defined universe. The core idea is that assets that have outperformed their peers will continue to do so, and vice-versa.\n\n## Key Parameters\n- **[Definition] Cross-Sectional Momentum**: A strategy that ranks assets based on their past performance relative to other assets in a universe, rather than their own individual time series.\n- **[Definition] Look-back Period (`lookback`)**: The historical window for calculating returns used for ranking (e.g., 252 trading days).\n- **[Definition] Holding Period (`holddays`)**: The duration for which a position is maintained (e.g., 25 trading days). This strategy uses a staggered approach, meaning the final portfolio on any given day is an aggregation of positions initiated over the last `holddays`.\n- **[Definition] Market-Neutral Portfolio**: A portfolio constructed to have zero net exposure to the overall market, achieved by balancing long and short positions.\n\n## Implementation Logic\nThe strategy is implemented by generating daily target positions and then aggregating them over the holding period to create the final portfolio.\n\n1.  **Daily Ranking and Signal Generation**: For each day `t` in the time series:\n    *   Calculate the return for every asset over the past `lookback` period.\n    *   Rank all assets based on this return, from lowest to highest.\n    *   Generate a `longs` signal for the top `N` assets and a `shorts` signal for the bottom `N` assets.\n2.  **Staggered Position Aggregation**: The final position on any day `t` is the sum of the signals generated on day `t`, `t-1`, `t-2`, ..., `t-holddays+1`. This is achieved algorithmically:\n    *   Initialize a `positions` matrix (with dimensions `T` days x `N` assets) to all zeros.\n    *   Loop with a lag `h` from `0` to `holddays - 1`.\n    *   For each `h`, shift the daily `longs` and `shorts` signal matrices forward by `h` days.\n    *   Add `+1` to the `positions` matrix for the shifted long signals.\n    *   Subtract `-1` from the `positions` matrix for the shifted short signals.\n3.  **Portfolio Construction**: The resulting `positions` matrix gives the desired allocation for each asset on each day. For example, if `positions[t, asset_k] = 10`, it means that on day `t`, asset `k` should be held long as a result of 10 separate long signals initiated over the previous `holddays`.",
    "question": "Provide the pseudocode for a function that generates a daily position matrix for a universe of assets based on the cross-sectional momentum logic with staggered holdings.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateCrossSectionalMomentumPositions(price_matrix, lookback_period, holding_period, num_top_assets)\n// INPUTS:\n//   - price_matrix: A T x N matrix of closing prices (T days, N assets).\n//   - lookback_period: The integer look-back period for ranking.\n//   - holding_period: The integer holding period for staggering.\n//   - num_top_assets: The number of assets to go long/short (e.g., top decile).\n// OUTPUTS:\n//   - A T x N matrix representing the daily position size for each asset.\n//\n// BEGIN\n//   [num_days, num_assets] = GET_DIMENSIONS(price_matrix)\n//\n//   // --- Step 1: Daily Ranking and Signal Generation ---\n//   returns_lookback = (price_matrix - SHIFT(price_matrix, lookback_period)) / SHIFT(price_matrix, lookback_period)\n//\n//   long_signals = ZEROS_BOOLEAN(num_days, num_assets)\n//   short_signals = ZEROS_BOOLEAN(num_days, num_assets)\n//\n//   FOR t FROM lookback_period TO num_days - 1\n//     // Get returns for all assets on day t\n//     daily_returns = GET_ROW(returns_lookback, t)\n//\n//     // Rank assets by return, getting their column indices\n//     // Ignore assets with NaN returns\n//     ranked_indices = SORT_INDICES(daily_returns, 'ascend', 'ignore_nan')\n//\n//     // Assign long signals to top N assets\n//     long_indices = GET_LAST_N(ranked_indices, num_top_assets)\n//     SET_VALUES(long_signals, t, long_indices, TRUE)\n//\n//     // Assign short signals to bottom N assets\n//     short_indices = GET_FIRST_N(ranked_indices, num_top_assets)\n//     SET_VALUES(short_signals, t, short_indices, TRUE)\n//   END FOR\n//\n//   // --- Step 2: Staggered Position Aggregation ---\n//   positions = ZEROS_INTEGER(num_days, num_assets)\n//\n//   FOR h FROM 0 TO holding_period - 1\n//     // Lag the daily signals by h days\n//     longs_lagged = SHIFT(long_signals, h)\n//     shorts_lagged = SHIFT(short_signals, h)\n//\n//     // Aggregate the lagged signals into the final position matrix\n//     positions = positions + CAST_TO_INTEGER(longs_lagged)\n//     positions = positions - CAST_TO_INTEGER(shorts_lagged)\n//   END FOR\n//\n//   RETURN positions\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 71,
    "text": "## Factor Rationale\nStock price momentum can be driven by non-fundamental forces, such as forced asset sales or purchases by large institutions. Mutual funds experiencing large capital outflows (redemptions) are often forced to sell their existing holdings, creating downward price pressure. Conversely, funds with large inflows tend to buy more of their existing holdings, creating upward pressure. This effect, known as an \"asset fire sale\" (or purchase), can be quantified into a predictive factor.\n\n## Mathematical Formulation\nA `PRESSURE` factor can be constructed to measure the net buying or selling pressure on a stock from the mutual fund universe. The formula is defined as:\n\n`Equation 1:`\n`PRESSURE(i, t) = (鍗?Buy(j,i,t) - 鍗?Sell(j,i,t)) / 鍗?Own(j,i,t-1)`\n\nThis calculation is performed for each stock `i` at the end of each quarter `t`.\n\n## Component Definitions\n- **[Definition] PRESSURE(i, t)**: The final factor value for stock `i` at the end of quarter `t`.\n- `j`: An index representing a specific mutual fund.\n- `flow(j, t)`: The net capital flow for fund `j` during quarter `t`, expressed as a percentage of the fund's starting Net Asset Value (NAV).\n- `Buy(j, i, t)`: A binary indicator. It equals `1` if fund `j` increased its holding in stock `i` during quarter `t` AND the fund's inflow was greater than 5% of its NAV (`flow(j, t) > 0.05`). Otherwise, it is `0`.\n- `Sell(j, i, t)`: A binary indicator. It equals `1` if fund `j` decreased its holding in stock `i` during quarter `t` AND the fund's outflow was greater than 5% of its NAV (`flow(j, t) < -0.05`). Otherwise, it is `0`.\n- `鍗?Own(j, i, t-1)`: The total *number of mutual funds* that held any position in stock `i` at the beginning of quarter `t` (i.e., the end of quarter `t-1`). This serves as the normalization denominator.",
    "question": "Provide the pseudocode for a function that calculates the `PRESSURE` factor for a single stock at a specific quarter, based on data from a universe of mutual funds.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculatePressureFactor(stock_id, quarter_t, fund_universe_data)\n// INPUTS:\n//   - stock_id: The identifier for the target stock.\n//   - quarter_t: The identifier for the target quarter (e.g., '2023-Q1').\n//   - fund_universe_data: A data structure containing quarterly holdings and flows for all funds.\n// OUTPUTS:\n//   - The calculated PRESSURE factor for the stock in that quarter (a float).\n//\n// BEGIN\n//   total_buy_signals = 0\n//   total_sell_signals = 0\n//   total_owning_funds_prior_quarter = 0\n//\n//   // Define the prior quarter for the ownership check\n//   quarter_t_minus_1 = GET_PREVIOUS_QUARTER(quarter_t)\n//\n//   // Iterate through every fund in the universe\n//   FOR each fund_j IN fund_universe_data\n//     // Check ownership at the beginning of the quarter\n//     was_owner = fund_j.HadHolding(stock_id, quarter_t_minus_1)\n//     IF was_owner THEN\n//       total_owning_funds_prior_quarter = total_owning_funds_prior_quarter + 1\n//     END IF\n//\n//     // Get fund flow for the current quarter\n//     fund_flow_pct = fund_j.GetFlow(quarter_t)\n//\n//     // Get change in holdings for the current quarter\n//     holding_change = fund_j.GetHoldingChange(stock_id, quarter_t)\n//\n//     // Check for a Buy signal\n//     IF fund_flow_pct > 0.05 AND holding_change > 0 THEN\n//       total_buy_signals = total_buy_signals + 1\n//     END IF\n//\n//     // Check for a Sell signal\n//     IF fund_flow_pct < -0.05 AND holding_change < 0 THEN\n//       total_sell_signals = total_sell_signals + 1\n//     END IF\n//   END FOR\n//\n//   // Calculate the final factor value\n//   IF total_owning_funds_prior_quarter == 0 THEN\n//     RETURN 0.0\n//   ELSE\n//     pressure_value = (total_buy_signals - total_sell_signals) / total_owning_funds_prior_quarter\n//     RETURN pressure_value\n//   END IF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 72,
    "text": "## Framework Overview\n\nThe Opening Gap strategy is an intraday momentum strategy designed for futures and currencies. Unlike mean-reversion gap strategies common with stocks, this approach assumes that a significant price gap between the previous day's close and the current day's open signifies strong momentum that will continue for the remainder of the trading day. The position is entered at the open and liquidated at the close.\n\n## Key Concepts\n\n*   **[Definition] Opening Gap**: The price difference between the previous trading session's closing (or high/low) price and the current session's opening price. It represents the accumulation of news and order flow during the time the market was closed.\n*   **[Definition] Breakout**: A price movement where an asset's price moves outside a defined support or resistance level. In this strategy, the previous day's high and low act as the resistance and support levels, respectively.\n\n## Computational Steps\n\nThe core of the strategy is to determine if the opening price constitutes a significant breakout. Significance is measured not in absolute price terms, but relative to the instrument's recent volatility. The logic is detailed in Example 1.\n\n**Example 1: Opening Gap Signal Generation**\n\nLet's assume we have the following time-series data for a futures contract:\n*   `op`: An array of opening prices for each day `t`.\n*   `hi`: An array of high prices for each day `t`.\n*   `lo`: An array of low prices for each day `t`.\n*   `cl`: An array of closing prices for each day `t`.\n\nThe trading signals are generated as follows:\n\n1.  **Calculate Historical Volatility**: First, compute the standard deviation of daily close-to-close returns over a 90-day lookback period. Let's call this `std_ret_c2c_90d`. This value is calculated for each day, using data from the preceding 90 days.\n\n2.  **Define Entry Thresholds**: The entry thresholds are not fixed price levels but are dynamically calculated based on the previous day's high/low and the historical volatility. A sensitivity parameter, `entryZscore`, is used to scale the volatility.\n    *   `long_threshold = prev_day_high * (1 + entryZscore * std_ret_c2c_90d)`\n    *   `short_threshold = prev_day_low * (1 - entryZscore * std_ret_c2c_90d)`\n\n3.  **Generate Signals**: On any given day, compare the opening price `op` to the calculated thresholds.\n    *   A **long signal** is generated if: `op > long_threshold`\n    *   A **short signal** is generated if: `op < short_threshold`\n\n4.  **Position Sizing**: For simplicity, a position of `+1` is taken for a long signal and `-1` for a short signal. If neither condition is met, the position is `0`.",
    "question": "Provide the pseudocode for a function that generates daily trading positions (`+1` for long, `-1` for short, `0` for flat) based on the Opening Gap momentum strategy.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GenerateOpeningGapPositions(op, hi, lo, cl, lookback, entryZscore)\n// INPUTS:\n//   - op: A Tx1 array of opening prices.\n//   - hi: A Tx1 array of high prices.\n//   - lo: A Tx1 array of low prices.\n//   - cl: A Tx1 array of close prices.\n//   - lookback: An integer for the moving standard deviation window (e.g., 90).\n//   - entryZscore: A float multiplier for the volatility threshold (e.g., 0.1).\n// OUTPUTS:\n//   - positions: A Tx1 array with values of 1 (long), -1 (short), or 0 (flat).\n//\n// BEGIN\n//   // Step 1: Calculate historical volatility of close-to-close returns.\n//   daily_returns_c2c = calculate_returns(cl) // (cl[t] / cl[t-1]) - 1\n//   std_ret_c2c = moving_std(daily_returns_c2c, lookback)\n//\n//   // Shift all previous day's data to align with the current day's open.\n//   prev_hi = backshift(hi, 1)\n//   prev_lo = backshift(lo, 1)\n//   prev_std_ret_c2c = backshift(std_ret_c2c, 1)\n//\n//   // Step 2: Define dynamic entry thresholds for each day.\n//   long_threshold = prev_hi * (1 + entryZscore * prev_std_ret_c2c)\n//   short_threshold = prev_lo * (1 - entryZscore * prev_std_ret_c2c)\n//\n//   // Step 3: Generate long and short signals.\n//   long_signals = (op > long_threshold)\n//   short_signals = (op < short_threshold)\n//\n//   // Step 4: Assign positions based on signals.\n//   num_days = length(op)\n//   positions = create_array(num_days, 0) // Initialize with zeros.\n//\n//   FOR t FROM 1 TO num_days\n//     IF long_signals[t] IS TRUE THEN\n//       positions[t] = 1\n//     ELSE IF short_signals[t] IS TRUE THEN\n//       positions[t] = -1\n//     END IF\n//   END FOR\n//\n//   RETURN positions\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 73,
    "text": "## Framework Overview\n\nThe Post-Earnings Announcement Drift (PEAD) strategy capitalizes on the persistent price movement in a single direction following a corporate earnings announcement. This implementation focuses on a short-term, intraday version of the strategy. The core idea is to let the market's initial reaction to the news (the overnight price gap) determine the direction of the trade, which is then held only for that trading day.\n\n## Key Concepts\n\n*   **[Definition] Post-Earnings Announcement Drift (PEAD)**: The observed tendency for a stock's cumulative abnormal returns to drift in the direction of an earnings surprise for several weeks or months following an earnings announcement. This strategy targets the initial, intraday portion of that drift.\n*   **[Definition] Overnight Return (Close-to-Open)**: The return calculated from the previous trading day's closing price to the current day's opening price. It captures the market's reaction to news released after market hours, such as an earnings announcement.\n\n## Computational Steps\n\nThe algorithm identifies stocks that have made an earnings announcement overnight and then measures if the market's reaction is significant enough to warrant a trade. Significance is determined by comparing the overnight return to its historical volatility.\n\n**Example 1: Intraday PEAD Signal Generation**\n\nAssume the following data matrices are available for a universe of `N` stocks over `T` days:\n*   `op`: A `T x N` matrix of opening prices.\n*   `cl`: A `T x N` matrix of closing prices.\n*   `earnann`: A `T x N` boolean matrix, where `earnann[t, n]` is `true` if stock `n` had an earnings announcement before the open on day `t`, and `false` otherwise.\n\nSignal generation proceeds as follows:\n\n1.  **Calculate Overnight Return**: For each stock and each day, compute the close-to-open return (`retC2O`).\n    *   `retC2O[t, n] = (op[t, n] - cl[t-1, n]) / cl[t-1, n]`\n\n2.  **Calculate Volatility Benchmark**: Compute the 90-day moving standard deviation of the `retC2O` for each stock. This serves as a benchmark for what constitutes a \"surprising\" overnight move.\n    *   `stdC2O[t, n] = MovingStd(retC2O[1:t, n], lookback=90)`\n\n3.  **Generate Signals**: A trade is triggered only if there was an earnings announcement AND the overnight return exceeds a certain multiple (e.g., 0.5) of its historical standard deviation.\n    *   **Long Signal**: `retC2O[t, n] >= 0.5 * stdC2O[t, n]` AND `earnann[t, n]` is `true`.\n    *   **Short Signal**: `retC2O[t, n] <= -0.5 * stdC2O[t, n]` AND `earnann[t, n]` is `true`.\n\n4.  **Assign Positions**: Assign `+1` for a long signal, `-1` for a short signal, and `0` otherwise.",
    "question": "Provide the pseudocode for a function that generates daily trading positions for a universe of stocks based on the intraday PEAD strategy.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GeneratePEADPositions(op, cl, earnann, lookback, z_threshold)\n// INPUTS:\n//   - op: A T x N matrix of opening prices.\n//   - cl: A T x N matrix of closing prices.\n//   - earnann: A T x N boolean matrix indicating overnight earnings announcements.\n//   - lookback: An integer for the moving standard deviation window (e.g., 90).\n//   - z_threshold: A float multiplier for the volatility threshold (e.g., 0.5).\n// OUTPUTS:\n//   - positions: A T x N matrix with values of 1 (long), -1 (short), or 0 (flat).\n//\n// BEGIN\n//   // Step 1: Calculate overnight (close-to-open) returns.\n//   prev_cl = backshift(cl, 1) // Shift close prices by one day.\n//   retC2O = (op - prev_cl) / prev_cl\n//\n//   // Step 2: Calculate the moving standard deviation of overnight returns.\n//   // This function should operate column-wise for each stock.\n//   stdC2O = smart_moving_std(retC2O, lookback)\n//\n//   // Initialize positions matrix with all zeros.\n//   [T, N] = size(cl)\n//   positions = create_matrix(T, N, 0)\n//\n//   // Step 3: Generate long and short signals based on the conditions.\n//   // These operations are performed element-wise on the matrices.\n//   long_signals = (retC2O >= z_threshold * stdC2O) AND (earnann == true)\n//   short_signals = (retC2O <= -z_threshold * stdC2O) AND (earnann == true)\n//\n//   // Step 4: Assign positions based on the generated signals.\n//   // Iterate through the boolean signal matrices to set positions.\n//   FOR t FROM 1 TO T\n//     FOR n FROM 1 TO N\n//       IF long_signals[t, n] IS TRUE THEN\n//         positions[t, n] = 1\n//       ELSE IF short_signals[t, n] IS TRUE THEN\n//         positions[t, n] = -1\n//       END IF\n//     END FOR\n//   END FOR\n//\n//   RETURN positions\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 74,
    "text": "### Framework Overview\nThe Kelly Formula provides a mathematical framework for determining the optimal leverage to maximize the long-term compounded growth rate of equity, under the assumption that strategy returns follow a Gaussian distribution.\n\n### 1. Key Concepts\n- **[Definition] Kelly Formula**: A formula used to determine the optimal size of a series of bets or investments to maximize long-term growth. In trading, it prescribes the leverage that should be applied to a strategy or portfolio.\n- **[Definition] Gross Leverage**: The total market value of a portfolio's positions (sum of absolute values of long and short positions) divided by the account's equity. It represents the total exposure to the market.\n- **[Definition] Mean Excess Return**: The average return of a strategy or asset in excess of the risk-free rate.\n\n### 2. Mathematical Formulation\n\n**Single-Strategy Case**\nFor a single strategy, the optimal leverage `f` is given by:\n\n$$ f = m / s^2 \\quad (Equation 1) $$\n\nWhere:\n- `f`: The optimal leverage.\n- `m`: The mean excess return of the strategy.\n- `s^2`: The variance of the strategy's excess returns.\n\n**Multi-Strategy Case**\nFor allocating capital across multiple strategies, the formula is expressed in matrix form:\n\n$$ F = C^{-1}M \\quad (Equation 2) $$\n\nWhere:\n- `F`: A column vector where each element `F_i` is the optimal leverage for strategy `i`.\n- `C`: The covariance matrix of the excess returns of the strategies.\n- `C^{-1}`: The inverse of the covariance matrix.\n- `M`: A column vector of the mean excess returns for each strategy.\n\n### 3. Handling Leverage Constraints\nIf a broker imposes a maximum gross leverage `F_max`, and the sum of the absolute values of the calculated optimal leverages `鍗眧F_i|` exceeds this limit, a common approach is to scale down all leverages proportionally. The scaling factor is `F_max / 鍗眧F_i|`, ensuring the total gross leverage matches the constraint.",
    "question": "Provide the pseudocode for a function that calculates the optimal leverage for a set of strategies using the multi-strategy Kelly formula and adjusts them based on a maximum gross leverage constraint.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateKellyLeverages(mean_returns, cov_matrix, max_gross_leverage)\n// INPUTS:\n//   - mean_returns: A column vector (M) of mean excess returns for N strategies.\n//   - cov_matrix: An N x N covariance matrix (C) of strategy excess returns.\n//   - max_gross_leverage: A scalar value (F_max) for the maximum allowed gross leverage.\n// OUTPUTS:\n//   - A column vector (F_final) of final, constrained leverages for each strategy.\n//\n// BEGIN\n//   // Step 1: Calculate the inverse of the covariance matrix.\n//   inv_cov_matrix = Inverse(cov_matrix)\n//\n//   // Step 2: Calculate the unconstrained optimal leverages using Equation 2.\n//   unconstrained_leverages = DotProduct(inv_cov_matrix, mean_returns)\n//\n//   // Step 3: Calculate the current gross leverage.\n//   current_gross_leverage = Sum(AbsoluteValue(unconstrained_leverages))\n//\n//   // Step 4: Check if the leverage constraint is violated.\n//   IF current_gross_leverage > max_gross_leverage THEN\n//     // Step 5a: Calculate the scaling factor.\n//     scaling_factor = max_gross_leverage / current_gross_leverage\n//\n//     // Step 5b: Apply the scaling factor to get the final leverages.\n//     final_leverages = unconstrained_leverages * scaling_factor\n//   ELSE\n//     // Step 6: If constraint is not violated, use the unconstrained leverages.\n//     final_leverages = unconstrained_leverages\n//   END IF\n//\n//   RETURN final_leverages\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 75,
    "text": "### Framework Overview\nWhen the assumption of Gaussian returns is unreliable (e.g., due to fat tails), the standard Kelly formula can be misleading. A more robust approach is to numerically optimize the expected compounded growth rate using Monte Carlo simulation. This involves generating a large number of random returns from a distribution that better fits the historical data.\n\n### 1. Key Concepts\n- **[Definition] Monte Carlo Simulation**: A computational technique that uses repeated random sampling to obtain numerical results. In this context, it's used to simulate many possible future return paths.\n- **[Definition] Pearson System**: A family of continuous probability distributions that can model a wide variety of shapes. It is parameterized by the first four statistical moments (mean, standard deviation, skewness, and kurtosis) of an empirical distribution.\n- **[Definition] Compounded Growth Rate**: The average logarithmic return of a strategy, which represents its long-term growth potential.\n\n### 2. Mathematical Formulation\nThe expected value of the compounded growth rate, `g(f)`, as a function of leverage `f` is given by:\n\n$$ g(f) = \\langle \\log (1 + fR)\\rangle \\quad (Equation 1) $$ \n\nWhere:\n- `g(f)`: The expected compounded growth rate for a given leverage `f`.\n- `f`: The leverage applied to the strategy.\n- `R`: The unlevered return-per-bar of the strategy.\n- `閴?..閴勩兗: Denotes the average taken over a large number of randomly sampled returns `R`.\n\n### 3. Computational Steps\n1.  **Calculate Moments**: Compute the first four moments (mean, standard deviation, skewness, kurtosis) from the historical series of strategy returns.\n2.  **Simulate Returns**: Use the Pearson system, parameterized by these moments, to generate a large number (e.g., 100,000) of simulated returns.\n3.  **Numerical Optimization**: Find the leverage `f` that maximizes the growth rate function `g(f)` when applied to the simulated returns. This is typically done using a numerical optimization algorithm.",
    "question": "Provide the pseudocode for a function that implements the Monte Carlo leverage optimization process. The function should take historical returns, calculate their moments, generate simulated returns via a Pearson system, and find the optimal leverage.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION OptimizeLeverageMonteCarlo(historical_returns, num_simulations, search_bounds)\n// INPUTS:\n//   - historical_returns: A vector of historical unlevered returns (R).\n//   - num_simulations: The number of random returns to generate.\n//   - search_bounds: A tuple (min_f, max_f) defining the search range for the optimal leverage.\n// OUTPUTS:\n//   - The optimal leverage (f_opt) that maximizes the expected growth rate.\n//\n// BEGIN\n//   // Step 1: Calculate the first four statistical moments of the historical returns.\n//   mean_ret = Mean(historical_returns)\n//   std_dev_ret = StandardDeviation(historical_returns)\n//   skew_ret = Skewness(historical_returns)\n//   kurt_ret = Kurtosis(historical_returns)\n//   moments = [mean_ret, std_dev_ret, skew_ret, kurt_ret]\n//\n//   // Step 2: Generate simulated returns using a Pearson system.\n//   // Assumes existence of a function that generates returns from moments.\n//   simulated_returns = GeneratePearsonReturns(moments, num_simulations)\n//\n//   // Step 3: Define the objective function to be maximized.\n//   FUNCTION GrowthRate(leverage, returns)\n//     // Calculate the compounded growth rate from Equation 1.\n//     // Filter out any instances that would lead to ruin (equity <= 0).\n//     valid_levered_returns = 1 + leverage * returns\n//     IF any(valid_levered_returns <= 0) THEN\n//       RETURN -Infinity // Penalize leverages that cause ruin.\n//     END IF\n//     RETURN Mean(Log(valid_levered_returns))\n//   END FUNCTION\n//\n//   // Step 4: Use a numerical optimizer to find the leverage that maximizes the growth rate.\n//   // The optimizer will search for 'f' within 'search_bounds' to maximize 'GrowthRate'.\n//   optimal_leverage = FindMaximum(objective_function=GrowthRate, parameters=[simulated_returns], bounds=search_bounds)\n//\n//   RETURN optimal_leverage\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 76,
    "text": "### Framework Overview\nInstead of modeling a return distribution and using simulation, a simpler approach is to directly optimize the compounded growth rate on the historical series of returns from a backtest. This method finds the leverage that would have maximized growth over that specific historical path.\n\n### 1. Key Concepts\n- **[Definition] Historical Growth Rate Optimization**: A method for finding optimal leverage by numerically maximizing the compounded growth rate function directly on the sequence of realized historical returns.\n- **[Definition] Data-Snooping Bias**: A statistical bias that occurs when a model is developed based on searching through data for patterns. The resulting model may appear to perform well on the historical data but fail on new data because it has been over-fitted to past noise.\n\n### 2. Core Formula\nThe historical compounded growth rate `g(f)` for a given leverage `f` is calculated as:\n\n$$ g(f) = \\frac{1}{N} \\sum_{t=1}^{N} \\log(1 + fR_t) \\quad (Equation 1) $$ \n\nWhere:\n- `g(f)`: The historical compounded growth rate.\n- `f`: The leverage applied to the strategy.\n- `R_t`: The historical unlevered return at time `t`.\n- `N`: The total number of historical returns.\n\n### 3. Implementation Caveats\n- **Risk of Ruin**: A critical check is required during optimization. If, for any historical return `R_t`, the term `1 + f*R_t` is less than or equal to zero, that leverage level `f` would have resulted in a total loss of capital (ruin). The optimization process must heavily penalize or avoid such leverage values.\n- **Overfitting**: This method is prone to data-snooping bias, as the optimal leverage is perfectly tailored to one specific historical path and may not be optimal for the future.",
    "question": "Provide the pseudocode for a function that takes a series of historical returns and finds the optimal leverage by directly maximizing the historical compounded growth rate. The function must include logic to prevent selecting a leverage that would have caused ruin.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION OptimizeLeverageHistorical(historical_returns, search_bounds)\n// INPUTS:\n//   - historical_returns: A vector of historical unlevered strategy returns (R).\n//   - search_bounds: A tuple (min_f, max_f) defining the search range for the optimal leverage.\n// OUTPUTS:\n//   - The optimal leverage (f_opt) that maximizes the historical growth rate.\n//\n// BEGIN\n//   // Step 1: Define the objective function for historical growth rate.\n//   FUNCTION HistoricalGrowthRate(leverage, returns)\n//     // Step 2: Check for risk of ruin.\n//     // For a given leverage, the equity after any single return must be positive.\n//     levered_returns = 1 + leverage * returns\n//     IF any(levered_returns <= 0) THEN\n//       // This leverage causes ruin. Return a value that the optimizer will avoid.\n//       RETURN -Infinity\n//     END IF\n//\n//     // Step 3: If no ruin, calculate the compounded growth rate using Equation 1.\n//     num_returns = Length(returns)\n//     growth_rate = Sum(Log(levered_returns)) / num_returns\n//     RETURN growth_rate\n//   END FUNCTION\n//\n//   // Step 4: Use a numerical optimizer to find the leverage that maximizes the objective function.\n//   // The optimizer will search for 'f' within 'search_bounds' to maximize 'HistoricalGrowthRate'.\n//   optimal_leverage = FindMaximum(objective_function=HistoricalGrowthRate, parameters=[historical_returns], bounds=search_bounds)\n//\n//   RETURN optimal_leverage\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 77,
    "text": "### Framework Overview\nIn Bayesian statistics, a powerful technique for simplifying inference is the use of conjugate priors. This approach is particularly useful for online learning scenarios where beliefs about a parameter, such as the probability of an asset price increase, must be updated as new data arrives.\n\n### Key Concepts\n1.  **[Definition] Conjugate Prior**: A prior probability distribution is considered conjugate to a likelihood function if the resulting posterior probability distribution belongs to the same family of distributions as the prior. This property provides a closed-form solution for the posterior, making updates computationally efficient.\n\n2.  **[Definition] Beta-Binomial Model**: This is a classic conjugate prior pairing. When observing binary outcomes (e.g., success/failure, up/down) that follow a Bernoulli or Binomial distribution (the likelihood), a Beta distribution can be used as the prior for the probability of success. The resulting posterior distribution will also be a Beta distribution.\n\n3.  **[Definition] Beta Distribution**: A continuous probability distribution defined on the interval [0, 1], parameterized by two positive shape parameters, denoted as `a` (alpha) and `b` (beta). It is a flexible distribution for modeling beliefs about a probability.\n\n4.  **[Definition] Uninformative Prior**: When there is no strong initial belief about the parameter, an uninformative or 'flat' prior is used. For a Beta distribution, setting `a = 1` and `b = 1` results in a Uniform distribution over [0, 1], meaning all probabilities are considered equally likely before observing any data.\n\n### Computational Steps\nThe core of the dynamic update process is remarkably simple due to conjugacy. Given a Beta prior distribution with parameters `a_prior` and `b_prior`, and a new set of binary observations containing `successes` and `failures`:\n\n*   The posterior parameter `a_posterior` is calculated as: `a_posterior = a_prior + successes`\n*   The posterior parameter `b_posterior` is calculated as: `b_posterior = b_prior + failures`\n\nThe updated Beta distribution, defined by `(a_posterior, b_posterior)`, represents the new belief about the success probability, which can then serve as the prior for the next batch of data.",
    "question": "1.  **`[Beta-Binomial Update Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that initializes with prior Beta distribution parameters and updates these parameters based on a new list of binary outcomes (where 1 is a success and 0 is a failure).",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateBetaPosterior(prior_a, prior_b, new_outcomes)\n// INPUTS:\n//   - prior_a: The alpha parameter of the prior Beta distribution.\n//   - prior_b: The beta parameter of the prior Beta distribution.\n//   - new_outcomes: An array of binary outcomes (0s and 1s).\n// OUTPUTS:\n//   - A tuple containing the updated posterior parameters (posterior_a, posterior_b).\n//\n// BEGIN\n//   // 1. Count the number of successes (1s) in the new data.\n//   successes = SUM(new_outcomes)\n//\n//   // 2. Count the number of failures (0s) in the new data.\n//   total_observations = LENGTH(new_outcomes)\n//   failures = total_observations - successes\n//\n//   // 3. Update the prior parameters to get the posterior parameters.\n//   // This is the core of the Beta-Binomial conjugate update rule.\n//   posterior_a = prior_a + successes\n//   posterior_b = prior_b + failures\n//\n//   // 4. Return the new posterior parameters.\n//   RETURN (posterior_a, posterior_b)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 78,
    "text": "### 1. Core Concept\nComparing the performance of two trading strategies or assets based on a single point estimate of their Sharpe Ratios can be misleading. A Bayesian approach provides a more robust comparison by estimating the full posterior distribution of the Sharpe Ratio for each series, allowing for a probabilistic assessment of their difference.\n\n### 2. Key Concepts\n*   **[Definition] Bayesian Sharpe Ratio**: An estimation of the Sharpe Ratio where its components (mean and standard deviation of returns) are treated as random variables with their own probability distributions. The result is not a single value, but a full posterior distribution of credible Sharpe Ratio values.\n*   **[Definition] Student's t-distribution**: A probability distribution that is used to model asset returns, as it has 'fat tails' compared to the Normal distribution. It is characterized by three parameters: mean (`娓璥), scale/standard deviation (`锜絗), and degrees of freedom (`璋揱). Lower values of `璋揱 result in fatter tails.\n\n### 3. Probabilistic Model for a Single Series\nTo model the Sharpe Ratio probabilistically, we first model the returns and then derive the Sharpe Ratio from the return distribution's parameters.\n1.  **Likelihood**: The daily returns are assumed to follow a Student's t-distribution. `returns ~ StudentT(娓? 锜? 璋?`.\n2.  **Priors**: We must define priors for the three parameters of the t-distribution:\n    *   **Mean (`娓璥)**: A Normal prior is suitable, centered around the empirical mean of the returns. `娓?~ Normal(mean_prior, std_prior)`.\n    *   **Standard Deviation (`锜絗)**: A Uniform prior over a wide positive range can be used. `锜?~ Uniform(low, high)`.\n    *   **Degrees of Freedom (`璋揱)**: An Exponential prior is often used for `璋揱, as it favors smaller values, thereby encouraging the fat-tailed property. `璋?~ Exponential(浣?`.\n3.  **Deterministic Sharpe Ratio**: The annualized Sharpe Ratio is then calculated deterministically from the posterior samples of the mean and standard deviation. `sharpe = (娓?/ 锜? * sqrt(252)`.\n\n### 4. Model for Comparing Two Series\nTo compare two return series (e.g., Strategy A vs. Strategy B), the model is extended by defining two independent sets of the components described above閳ユ攼ne for each series. The model will thus have `娓璤A`, `锜絖A`, `璋揰A` and `娓璤B`, `锜絖B`, `璋揰B`. After defining the deterministic Sharpe Ratios for each (`sharpe_A`, `sharpe_B`), a final deterministic variable is created to capture their difference: `difference = sharpe_A - sharpe_B`. Analyzing the posterior distribution of this `difference` variable allows one to calculate, for example, the probability that Strategy A has a higher Sharpe Ratio than Strategy B.",
    "question": "1.  **`[Comparative Sharpe Ratio Model Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that defines the complete probabilistic model for comparing the Sharpe Ratios of two return series. The model must include separate priors for all parameters of each series and the deterministic calculations for each Sharpe Ratio and their difference.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DefineComparativeSharpeModel(returns_A, returns_B)\n// INPUTS:\n//   - returns_A: An array of daily returns for the first series.\n//   - returns_B: An array of daily returns for the second series.\n// OUTPUTS:\n//   - A complete probabilistic model specification.\n//\n// BEGIN\n//   // --- MODEL FOR SERIES A ---\n//   // 1. Define priors for the parameters of the Student's t-distribution for Series A.\n//   mean_A = Normal('mean_A', mu=EMPIRICAL_MEAN(returns_A), sd=EMPIRICAL_STD(returns_A))\n//   std_A = Uniform('std_A', lower=0.0001, upper=100.0)\n//   nu_A = Exponential('nu_A', lam=1/29.0) // Prior favors fat tails\n//\n//   // 2. Define the likelihood for the observed returns of Series A.\n//   likelihood_A = StudentT('returns_A', nu=nu_A, mu=mean_A, sd=std_A, observed=returns_A)\n//\n//   // 3. Define the deterministic (calculated) Sharpe Ratio for Series A.\n//   sharpe_A = Deterministic('sharpe_A', (mean_A / std_A) * SQRT(252))\n//\n//   // --- MODEL FOR SERIES B ---\n//   // 4. Define priors for the parameters of the Student's t-distribution for Series B.\n//   mean_B = Normal('mean_B', mu=EMPIRICAL_MEAN(returns_B), sd=EMPIRICAL_STD(returns_B))\n//   std_B = Uniform('std_B', lower=0.0001, upper=100.0)\n//   nu_B = Exponential('nu_B', lam=1/29.0)\n//\n//   // 5. Define the likelihood for the observed returns of Series B.\n//   likelihood_B = StudentT('returns_B', nu=nu_B, mu=mean_B, sd=std_B, observed=returns_B)\n//\n//   // 6. Define the deterministic Sharpe Ratio for Series B.\n//   sharpe_B = Deterministic('sharpe_B', (mean_B / std_B) * SQRT(252))\n//\n//   // --- COMPARISON ---\n//   // 7. Define the deterministic difference between the two Sharpe Ratios.\n//   sharpe_difference = Deterministic('sharpe_difference', sharpe_A - sharpe_B)\n//\n//   RETURN MODEL(mean_A, std_A, nu_A, mean_B, std_B, nu_B, sharpe_A, sharpe_B, sharpe_difference)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 79,
    "text": "### 1. Objective: Dynamic Hedge Ratios\nIn pairs trading, the relationship between two cointegrated assets, represented by the hedge ratio, is often non-stationary and can change over time. A standard linear regression provides only a single, static hedge ratio for the entire period. A Bayesian rolling regression offers a more adaptive approach by modeling the regression coefficients themselves as time-varying processes.\n\n### 2. Key Concepts\n*   **[Definition] Pairs Trading Hedge Ratio**: The slope coefficient (`beta`) from a linear regression of one asset's price (or return) onto another's. It indicates the number of units of the independent asset to short for every unit of the dependent asset held long.\n*   **[Definition] Gaussian Random Walk**: A stochastic process where the value at time `t` is equal to the value at time `t-1` plus a random step drawn from a Gaussian (Normal) distribution. It is a simple way to model a variable that drifts randomly over time.\n\n### 3. Probabilistic Specification\nTo create a dynamic regression model, we assume that the intercept (`alpha`) and the slope (`beta`) evolve according to a random walk. This allows the model to capture changes in the baseline price level and the hedge ratio over time.\n\nThe model is specified as follows, where `y` is the price of one asset and `x` is the price of the other:\n\n**Equation 1: Time-Varying Intercept**\n`alpha_t ~ Normal(mean = alpha_{t-1}, sd = sigma_alpha)`\n\n**Equation 2: Time-Varying Slope (Hedge Ratio)**\n`beta_t ~ Normal(mean = beta_{t-1}, sd = sigma_beta)`\n\nHere, `alpha_t` and `beta_t` are the intercept and slope at time `t`. The parameters `sigma_alpha` and `sigma_beta` control the volatility of the random walk; larger values allow the coefficients to change more rapidly. Instead of fixing these values, we treat them as unknown parameters and assign them priors, typically a weakly informative prior like an Exponential distribution.\n\nFinally, the observed asset price `y_t` is modeled with a Normal likelihood, where the mean is determined by the dynamic regression equation:\n\n**Equation 3: Likelihood**\n`y_t ~ Normal(mean = alpha_t + beta_t * x_t, sd = sigma_obs)`\n\nHere, `sigma_obs` represents the observation noise, which is also given a prior (e.g., a HalfNormal distribution).",
    "question": "1.  **`[Random Walk Regression Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that specifies the complete probabilistic model for a Bayesian rolling regression, where both the intercept (alpha) and slope (beta) follow a Gaussian Random Walk.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DefineRandomWalkRegression(x_series, y_series)\n// INPUTS:\n//   - x_series: An array of prices for the independent asset.\n//   - y_series: An array of prices for the dependent asset.\n// OUTPUTS:\n//   - A complete probabilistic model specification.\n//\n// BEGIN\n//   // 1. Define priors for the standard deviations of the random walks.\n//   // These control how quickly the intercept and slope can change.\n//   sigma_alpha = Exponential('sigma_alpha', lam=50.0)\n//   sigma_beta = Exponential('sigma_beta', lam=50.0)\n//\n//   // 2. Define the time-varying intercept and slope as Gaussian Random Walks.\n//   // The 'shape' parameter corresponds to the number of time steps.\n//   num_timesteps = LENGTH(x_series)\n//   alpha = GaussianRandomWalk('alpha', sd=sigma_alpha, shape=num_timesteps)\n//   beta = GaussianRandomWalk('beta', sd=sigma_beta, shape=num_timesteps)\n//\n//   // 3. Define the regression equation.\n//   // The mean of the likelihood is a function of the time-varying coefficients.\n//   regression_mean = alpha + beta * x_series\n//\n//   // 4. Define a prior for the observation noise.\n//   observation_sd = HalfNormal('observation_sd', sd=0.1)\n//\n//   // 5. Define the likelihood for the observed dependent variable.\n//   // The observed y_series is modeled as a Normal distribution around the regression mean.\n//   likelihood = Normal('y_observed', mu=regression_mean, sd=observation_sd, observed=y_series)\n//\n//   RETURN MODEL(sigma_alpha, sigma_beta, alpha, beta, observation_sd, likelihood)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 80,
    "text": "### 1. Core Concept\nAsset returns exhibit time-varying volatility, characterized by periods of high and low variance known as volatility clustering. Bayesian stochastic volatility models capture this phenomenon by treating volatility not as a fixed parameter but as an unobserved (latent) variable that evolves over time according to a stochastic process.\n\n### 2. Key Concepts\n*   **[Definition] Stochastic Volatility**: A modeling approach where the variance of a time series is itself a random process that changes over time. This contrasts with models like GARCH where volatility is a deterministic function of past values.\n*   **[Definition] Latent Variable**: A variable that is not directly observed but is inferred from other variables that are observed. In this model, the true log-volatility at each time step is a latent variable.\n\n### 3. Probabilistic Model Specification\nThe model is defined by specifying the distributions for the observed returns and the latent volatility process.\n\n1.  **Latent Volatility Process**: The log-volatility, `s_t`, is assumed to follow a Gaussian Random Walk. This means the log-volatility at time `t` is centered around the value at `t-1`.\n    *   **Equation 1**: `s_t ~ Normal(mean = s_{t-1}, sd = step_size)`\n    The `step_size` parameter (`锜絗 in some notations) determines how quickly the volatility can change. It is treated as a random variable and is given its own prior, typically an Exponential distribution to keep it positive.\n    *   **Equation 2**: `step_size ~ Exponential(浣?`\n\n2.  **Observed Returns Likelihood**: The observed log returns, `log(r_t)`, are modeled using a Student's t-distribution to account for the heavy tails commonly seen in financial data. The distribution is centered at zero (assuming returns have a zero mean) and its scale is determined by the latent volatility process.\n    *   **Equation 3**: `log(r_t) ~ StudentT(nu = 璋? mu = 0, lam = exp(-2 * s_t))`\n    Note: The scale/precision parameter `lam` is related to the standard deviation. Here, `exp(-2 * s_t)` is used to ensure the scale is positive, where `s_t` is the log-volatility.\n\n3.  **Degrees of Freedom Prior**: The degrees of freedom parameter of the t-distribution, `璋揱, controls the 'fatness' of the tails. It is also treated as a random variable and given a prior, often an Exponential distribution that favors smaller values (and thus fatter tails).\n    *   **Equation 4**: `璋?~ Exponential(浣?`",
    "question": "1.  **`[Stochastic Volatility Model Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that specifies the complete Bayesian stochastic volatility model, including the latent random walk for log-volatility and the Student's t-distribution for observed log returns.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DefineStochasticVolatilityModel(log_returns)\n// INPUTS:\n//   - log_returns: An array of observed log returns.\n// OUTPUTS:\n//   - A complete probabilistic model specification.\n//\n// BEGIN\n//   // 1. Define a prior for the standard deviation of the volatility's random walk.\n//   // This 'step_size' controls how rapidly the latent volatility can change.\n//   step_size = Exponential('step_size', lam=50.0)\n//\n//   // 2. Define the latent log-volatility process as a Gaussian Random Walk.\n//   // The length of the random walk matches the number of observations.\n//   num_timesteps = LENGTH(log_returns)\n//   s = GaussianRandomWalk('s_log_volatility', sd=step_size, shape=num_timesteps)\n//\n//   // 3. Define a prior for the degrees of freedom of the Student's t-distribution.\n//   // An Exponential prior favors smaller values, which correspond to fatter tails.\n//   nu = Exponential('nu_degrees_of_freedom', lam=0.1)\n//\n//   // 4. Define the likelihood for the observed log returns.\n//   // The returns follow a Student's t-distribution with a scale determined by the\n//   // exponentiated latent log-volatility process 's'.\n//   // The precision 'lam' is related to the variance, hence the exp(-2*s) term.\n//   likelihood = StudentT('observed_returns', \n//                         nu=nu, \n//                         lam=EXP(-2 * s), \n//                         observed=log_returns)\n//\n//   RETURN MODEL(step_size, s, nu, likelihood)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 81,
    "text": "## Framework Overview: Recursive Binary Splitting\n\nDecision trees are a class of machine learning models that predict a target variable by learning a sequence of hierarchical rules from data. The core algorithm used to construct a decision tree is known as Recursive Binary Splitting.\n\n### Key Concepts\n\n- **[Definition] Decision Tree**: A model that uses a tree-like structure of decisions. It starts with a root node representing the entire dataset and branches out into subsequent nodes, each representing a decision rule applied to a single feature. The final nodes, which do not split further, are called leaf nodes and contain the predictions.\n- **[Definition] Feature Space**: The multi-dimensional space defined by the set of all possible values for the input features, denoted as \\(X_{1}, X_{2}, \\ldots, X_{p}\\). Decision trees work by partitioning this space into distinct, non-overlapping regions.\n- **[Definition] Recursive Binary Splitting**: A top-down, greedy algorithm for partitioning the feature space. It is the fundamental process for training a decision tree.\n\n### Algorithmic Properties\n\nThe Recursive Binary Splitting process has three key properties:\n1.  **Top-Down**: It begins at the root of the tree with all observations in a single region and successively splits the feature space into smaller regions.\n2.  **Greedy**: At each step, the algorithm chooses the best possible split (i.e., the feature and threshold combination) based on the immediate reduction in a loss function (e.g., Mean Squared Error for regression, Gini Impurity for classification). It does not consider whether this split will lead to a better tree in subsequent steps.\n3.  **Recursive**: The splitting process is applied repeatedly to the new regions created by previous splits. This continues until a stopping criterion is met, such as a maximum tree depth or a minimum number of samples per leaf.\n\n### Prediction Mechanism\n\nOnce the tree is built, making a prediction for a new observation involves traversing the tree from the root down to a leaf node based on the learned rules. The prediction is then derived from the training samples that fell into that specific leaf node:\n- For **regression trees**, the prediction is the mean of the target values of the training samples in the leaf.\n- For **classification trees**, the prediction is the mode (most frequent class) of the training samples in the leaf.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Recursive Binary Splitting Logic]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the greedy logic of finding the single best feature and threshold to split a given node (i.e., a subset of the dataset). The function should iterate through all features and all possible split points to find the one that minimizes a generic loss function.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FindBestSplit(node_data, features)\n// INPUTS:\n//   - node_data: A dataset subset at the current node, containing features and a target variable.\n//   - features: A list of feature names to consider for splitting.\n// OUTPUTS:\n//   - A tuple containing (best_feature, best_threshold).\n//\n// BEGIN\n//   INITIALIZE best_split_loss = infinity\n//   INITIALIZE best_feature = null\n//   INITIALIZE best_threshold = null\n//\n//   // Iterate through each feature to find the best one for splitting.\n//   FOR EACH feature in features:\n//     // Get all unique values of the feature to use as potential split thresholds.\n//     unique_values = GetUniqueValues(node_data[feature])\n//\n//     // Iterate through each unique value as a potential threshold.\n//     FOR EACH threshold in unique_values:\n//       // Split the data into two subsets based on the feature and threshold.\n//       left_subset, right_subset = SplitData(node_data, feature, threshold)\n//\n//       // Skip splits that don't produce two children nodes.\n//       IF left_subset is empty OR right_subset is empty:\n//         CONTINUE\n//       END IF\n//\n//       // Calculate the weighted loss for the current split.\n//       // The CalculateSplitLoss function would use a metric like MSE or Gini Impurity.\n//       current_split_loss = CalculateSplitLoss(left_subset, right_subset)\n//\n//       // If this split is better than the best one found so far, update the bests.\n//       IF current_split_loss < best_split_loss:\n//         best_split_loss = current_split_loss\n//         best_feature = feature\n//         best_threshold = threshold\n//       END IF\n//     END FOR\n//   END FOR\n//\n//   RETURN (best_feature, best_threshold)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 82,
    "text": "## 1. Regression Tree Fundamentals\n\nA regression tree is a type of decision tree used to predict a continuous target variable, such as asset returns. The core principle is to partition the feature space into regions and assign a single predicted value to all observations that fall within the same region.\n\n- **[Definition] Regression Tree**: A decision tree where the target variable is continuous. For any observation that lands in a specific leaf node, the tree's prediction is the mean of the target values of the training samples contained within that leaf.\n\n## 2. The Splitting Criterion: Mean Squared Error\n\nTo build the tree, the algorithm must decide which feature and threshold to use for each split. In a regression tree, this decision is typically based on minimizing the Mean Squared Error (MSE).\n\n- **[Definition] Mean Squared Error (MSE)**: A common loss function for regression problems. For a set of \\(n\\) observations, it is the average of the squared differences between the predicted value (\\(\\hat{y}\\)) and the actual values (\\(y_i\\)). For a single node, the prediction \\(\\hat{y}\\) is the mean of the target values in that node.\n\nThe goal of the splitting algorithm is to find a feature \\(X_i\\) and a threshold \\(s_j\\) that create two child nodes (a left subset \\(\\{X|X_i < s_j\\}\\) and a right subset \\(\\{X|X_i \\ge s_j\\}\\)) such that the weighted average of the MSE of the two child nodes is minimized. This is equivalent to maximizing the reduction in the total sum of squared residuals from the parent node to its children.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Split Evaluation Function Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that evaluates the quality of a potential split using the weighted Mean Squared Error (MSE) of the two resulting child nodes. This function is a critical component of the `FindBestSplit` logic.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateNodeMSE(target_values)\n// HELPER FUNCTION to calculate MSE for a single node.\n// INPUTS:\n//   - target_values: An array of continuous target values for a single node.\n// OUTPUTS:\n//   - The Mean Squared Error for that node.\n// BEGIN\n//   IF target_values is empty:\n//     RETURN 0\n//   END IF\n//   mean_value = Average(target_values)\n//   squared_errors = (target_values - mean_value)^2\n//   RETURN Average(squared_errors)\n// END\n//\n// FUNCTION EvaluateSplitMSE(left_targets, right_targets)\n// PRIMARY FUNCTION to evaluate a split.\n// INPUTS:\n//   - left_targets: An array of target values for the left child node.\n//   - right_targets: An array of target values for the right child node.\n// OUTPUTS:\n//   - The weighted MSE for the split.\n//\n// BEGIN\n//   // Get the number of samples in each child node.\n//   n_left = Count(left_targets)\n//   n_right = Count(right_targets)\n//   total_samples = n_left + n_right\n//\n//   // Handle case of an invalid split.\n//   IF total_samples == 0:\n//     RETURN 0\n//   END IF\n//\n//   // Calculate the MSE for each child node using the helper function.\n//   mse_left = CalculateNodeMSE(left_targets)\n//   mse_right = CalculateNodeMSE(right_targets)\n//\n//   // Calculate the weighted average of the child node MSEs.\n//   weight_left = n_left / total_samples\n//   weight_right = n_right / total_samples\n//   weighted_mse = (weight_left * mse_left) + (weight_right * mse_right)\n//\n//   RETURN weighted_mse\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 83,
    "text": "## 1. Classification Tree Fundamentals\n\nA classification tree is a decision tree used to predict a categorical target variable, such as the direction of an asset's price movement ('Up' or 'Down'). Unlike regression trees that predict a mean value, classification trees predict the most common class within a leaf node.\n\n- **[Definition] Classification Tree**: A decision tree where the target variable is categorical. The prediction for a given leaf node is typically the mode (most frequent class) of the training samples in that region.\n- **[Definition] Node Purity**: A measure of the homogeneity of class labels within a node. A node is considered 'pure' if all samples within it belong to the same class. The goal of the splitting algorithm is to create child nodes that are purer than the parent node.\n\n## 2. Measuring Node Impurity with Gini Impurity\n\nTo decide on the best split, a classification tree needs a loss function that quantifies node impurity. While several metrics exist, Gini Impurity is a popular and computationally efficient choice.\n\nIt measures the probability of incorrectly classifying a randomly chosen element in the dataset if it were randomly labeled according to the class distribution in the node. A Gini Impurity of 0 represents a perfectly pure node.\n\nThe formula for Gini Impurity for a given node \\(m\\) with \\(K\\) classes is given by:\n\n**Equation 1: Gini Impurity**\n\\[\n\\text{Gini}_m = \\sum_{k=1}^{K} p_{mk}(1 - p_{mk})\n\\]\n\nWhere:\n- \\(p_{mk}\\) is the proportion of training samples of class \\(k\\) in node \\(m\\).",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Gini Impurity Calculation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the Gini Impurity for a given node. The function should take the class counts within the node as input.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateGiniImpurity(class_counts)\n// INPUTS:\n//   - class_counts: A map or dictionary where keys are class labels and values are the number of samples for that class in the node (e.g., {'Up': 80, 'Down': 20}).\n// OUTPUTS:\n//   - A float representing the Gini Impurity score for the node.\n//\n// BEGIN\n//   // Calculate the total number of samples in the node.\n//   total_samples = Sum(values of class_counts)\n//\n//   // If the node is empty, its impurity is zero.\n//   IF total_samples == 0:\n//     RETURN 0.0\n//   END IF\n//\n//   INITIALIZE impurity = 0.0\n//\n//   // Iterate through each class to calculate its contribution to the impurity.\n//   FOR EACH class_label in class_counts:\n//     count = class_counts[class_label]\n//     proportion = count / total_samples\n//\n//     // Add the term p_k * (1 - p_k) to the total impurity.\n//     impurity = impurity + (proportion * (1 - proportion))\n//   END FOR\n//\n//   RETURN impurity\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 84,
    "text": "## 1. Concept of Feature Importance\n\nAfter training a decision tree, it is crucial to understand which features were most influential in making predictions. Feature importance provides a score for each feature, quantifying its overall contribution to the model.\n\n- **[Definition] Feature Importance**: A measure that represents the total contribution of a feature to the predictive power of the model. In decision trees, it is calculated based on how much the splits using that feature improve the purity of the nodes.\n\n## 2. Calculation Method: Impurity Reduction\n\nThe importance of a feature is calculated as the total reduction in the model's loss function (or impurity metric) that is achieved by splits made on that feature. Features used higher up in the tree, which affect a larger number of samples, will naturally have a greater impact on the final importance score.\n\nThe contribution of a single split to a feature's importance is the decrease in node impurity, weighted by the number of samples in the parent node.\n\n**Equation 1: Importance Contribution of a Split**\n\\[\n\\text{Importance Gain} = N_p \\times \\left( I_p - \\frac{N_l}{N_p} I_l - \\frac{N_r}{N_p} I_r \\right)\n\\]\n\nWhere:\n- \\(N_p\\), \\(N_l\\), and \\(N_r\\) are the number of samples in the parent, left child, and right child nodes, respectively.\n- \\(I_p\\), \\(I_l\\), and \\(I_r\\) are the impurity values (e.g., Gini Impurity) of the parent, left child, and right child nodes, respectively.\n\nThe total importance for a feature is the sum of the `Importance Gain` from all splits made on that feature across the entire tree.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Feature Importance Update]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the importance contribution of a single split and updates a global feature importance tracker. This function would be called every time a new split is made during the tree's construction.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateFeatureImportance(feature_importances, split_feature, parent_impurity, left_impurity, right_impurity, parent_samples, left_samples, right_samples)\n// INPUTS:\n//   - feature_importances: A map or dictionary storing the current importance score for each feature (e.g., {'feature_A': 0.2, 'feature_B': 0.5}). This map is updated in place.\n//   - split_feature: The name of the feature used for the current split.\n//   - parent_impurity: The impurity of the node before the split.\n//   - left_impurity: The impurity of the left child node after the split.\n//   - right_impurity: The impurity of the right child node after the split.\n//   - parent_samples: The number of samples in the parent node.\n//   - left_samples: The number of samples in the left child node.\n//   - right_samples: The number of samples in the right child node.\n// OUTPUTS:\n//   - None. The function modifies the feature_importances map directly.\n//\n// BEGIN\n//   // Calculate the reduction in impurity from parent to children.\n//   // This is the core of the importance calculation.\n//   impurity_reduction = parent_impurity - (left_samples / parent_samples) * left_impurity - (right_samples / parent_samples) * right_impurity\n//\n//   // Weight the impurity reduction by the number of samples it affects.\n//   importance_gain = parent_samples * impurity_reduction\n//\n//   // Add the calculated gain to the total importance score for the feature used in the split.\n//   IF split_feature is not in feature_importances:\n//     feature_importances[split_feature] = 0.0\n//   END IF\n//   feature_importances[split_feature] = feature_importances[split_feature] + importance_gain\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 85,
    "text": "## 1. Random Forest Overview\n\nA Random Forest is a sophisticated ensemble learning method that builds upon the principles of bagging to create a collection of decorrelated decision trees, leading to improved predictive accuracy and reduced variance.\n\n- **[Definition] Random Forest**: An ensemble model consisting of a large number of individual decision trees that are trained on bootstrapped data samples and use random feature subsets for splitting. The final prediction is an aggregation of the predictions from all trees.\n\n## 2. Key Component 1: Bootstrap Aggregation (Bagging)\n\nLike standard bagging, each tree in a Random Forest is trained on a unique bootstrap sample created by drawing observations with replacement from the original training dataset. This ensures that the individual trees in the forest are diverse.\n\n## 3. Key Component 2: Random Feature Subspacing\n\nThis is the critical addition that distinguishes Random Forests from bagged decision trees. To further decorrelate the trees, the algorithm introduces randomness into the feature selection process itself.\n\n- **[Definition] Random Feature Subspacing**: At each node in the decision tree, when searching for the best split, the algorithm does not consider all available features. Instead, it randomly selects a smaller subset of features and only evaluates split candidates from within that subset. This process is repeated independently at every split point in every tree.\n\nBy preventing any single powerful feature from dominating the structure of all trees, this technique forces the ensemble to explore a wider variety of predictive patterns, making the trees less correlated and the final averaged prediction more robust.\n\n## 4. Algorithm Summary\n\nThe training process for a Random Forest can be summarized as follows:\n1.  For each of the `n_estimators` trees to be built:\n    a.  Create a bootstrap sample of the training data.\n    b.  Grow a decision tree on this sample. At each node, before finding the best split, randomly select a subset of `max_features` from the available features. The best split is then chosen only from this random subset.\n2.  To make a prediction, aggregate the results from all `n_estimators` trees (e.g., by averaging for regression).",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Random Forest Training Logic]`**:\n    *   **Task**: Provide the pseudocode for a main function that trains a Random Forest. This function should orchestrate the creation of multiple decorrelated trees, each trained on a bootstrapped data sample and using random feature subspacing at each split.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION TrainRandomForest(training_data, n_estimators, max_features, tree_hyperparams)\n// INPUTS:\n//   - training_data: The full dataset with features and targets.\n//   - n_estimators: The number of trees to build in the forest.\n//   - max_features: The number of features to randomly sample at each split.\n//   - tree_hyperparams: A dictionary of other tree parameters (e.g., max_depth).\n// OUTPUTS:\n//   - A list of trained, decorrelated decision tree models.\n//\n// BEGIN\n//   INITIALIZE forest = empty list\n//\n//   // Main loop to build each tree in the forest.\n//   FOR i FROM 1 TO n_estimators:\n//     // Step 1: Create a bootstrap sample of the data.\n//     bootstrap_sample = CreateBootstrapSample(training_data)\n//\n//     // Step 2: Train a single decision tree with feature randomization.\n//     // The tree-growing function must be modified to accept 'max_features'.\n//     tree_model = GrowDecorrelatedTree(bootstrap_sample, max_features, tree_hyperparams)\n//\n//     // Step 3: Add the trained tree to the forest.\n//     APPEND tree_model TO forest\n//   END FOR\n//\n//   RETURN forest\n// END\n//\n//\n// FUNCTION GrowDecorrelatedTree(data, max_features, hyperparams)\n// HELPER FUNCTION (conceptual) for growing a single tree.\n// This function would be recursive.\n// BEGIN\n//   // At each node to be split:\n//   available_features = GetFeatures(data)\n//   // Key step: Randomly select a subset of features.\n//   feature_subset = RandomlySelect(available_features, count=max_features)\n//\n//   // Find the best split, but only search within the selected subset.\n//   best_split = FindBestSplit(data, feature_subset)\n//\n//   // Create child nodes and recurse...\n//   ...\n//   RETURN trained_tree_node\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 86,
    "text": "### Framework Overview\n\nAdaptive Boosting, or AdaBoost, is an ensemble learning algorithm that constructs a strong classifier by sequentially combining multiple weak learners. Unlike methods that train learners independently (like bagging), AdaBoost is adaptive: it iteratively adjusts the weights of training observations based on the errors of the current ensemble. This process forces subsequent weak learners to focus on the most difficult-to-classify samples, progressively improving the overall model's accuracy.\n\n### Key Concepts\n\n- **[Definition] Weak Learner**: A classifier that performs only slightly better than random guessing. In the context of AdaBoost, these are often simple models like decision stumps.\n- **[Definition] Decision Stump**: A decision tree with only a single split. These are high-bias, low-variance models, making them ideal base learners for boosting.\n- **[Definition] Ensemble Weight (浼?**: A scalar value assigned to each weak learner that represents its importance in the final ensemble prediction. Learners with lower error rates are given higher weights.\n\n### The AdaBoost Algorithm\n\nThe AdaBoost algorithm is designed for an ensemble of M base learners, \\(h_m(x)\\), predicting discrete classes \\(y \\in \\{-1, 1\\}\\) for N training observations. The process can be summarized in the following steps:\n\n1.  **Initialization**: All N training samples are assigned an equal initial weight, \\(w_i = 1/N\\).\n\n2.  **Iterative Training**: For each of the M base classifiers (from \\(m=1\\) to \\(M\\)):\n    a. A weak learner, \\(h_m(x)\\), is trained on the data using the current sample weights \\(w_i\\).\n    b. The weighted error rate, \\(\\epsilon_m\\), of the learner is computed. This is the sum of weights of the misclassified samples.\n    c. The learner's ensemble weight, \\(\\alpha_m\\), is calculated as a function of its error rate. Learners with error rates close to 0 receive high positive weights, while those with errors near 0.5 (random guessing) receive weights close to 0.\n\n    **Equation 1: Learner Ensemble Weight**\n    $$ \\alpha_{m} = \\log \\left(\\frac{1 - \\epsilon_{m}}{\\epsilon_{m}}\\right) $$\n    *Where:*\n    - \\(\\alpha_m\\): The weight for the m-th weak learner.\n    - \\(\\epsilon_m\\): The weighted error rate of the m-th weak learner.\n\n    d. The sample weights \\(w_i\\) are updated. The weights of misclassified samples are increased by a factor of \\(exp(\\alpha_m)\\), while the weights of correctly classified samples are effectively decreased (or left unchanged, depending on the implementation, before normalization). The weights are then renormalized to sum to 1.\n\n3.  **Final Prediction**: The final prediction for a new observation \\(x\\) is made by taking a weighted vote of all M weak learners. The sign of the weighted sum determines the predicted class.\n\n    **Equation 2: Final Ensemble Prediction**\n    $$ H(x) = \\mathrm{sign}\\left(\\sum_{m = 1}^{M} \\alpha_{m}h_{m}(x) \\right) $$\n    *Where:*\n    - \\(H(x)\\): The final prediction of the ensemble.\n    - \\(\\alpha_m\\): The weight of the m-th weak learner.\n    - \\(h_m(x)\\): The prediction of the m-th weak learner.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[AdaBoost Training Logic]`**:\n    *   **Task**: Provide the pseudocode for the main training function of the AdaBoost algorithm. The function should take training data and the number of desired weak learners as input, and return the trained learners along with their corresponding ensemble weights.\n    *   **Format**: Your answer should be the implementation using the Pseudocode Template.",
    "answer": "```\n// --- BEGIN PSEUODCODE ---\n//\n// FUNCTION AdaBoostTrainer(features, labels, M_learners)\n// INPUTS:\n//   - features: A matrix of N observations and K features.\n//   - labels: An array of N labels, where each label is in {-1, 1}.\n//   - M_learners: The total number of weak learners to train for the ensemble.\n// OUTPUTS:\n//   - A list of trained weak learners.\n//   - A list of corresponding alpha weights for each learner.\n//\n// BEGIN\n//   N = number of observations in features\n//   Initialize sample_weights as an array of size N, with all values set to 1/N\n//\n//   Initialize trained_learners as an empty list\n//   Initialize alpha_weights as an empty list\n//\n//   FOR m FROM 1 TO M_learners:\n//     // 1. Fit a weak learner to the weighted training data\n//     weak_learner = new WeakLearner()\n//     weak_learner.fit(features, labels, sample_weights)\n//\n//     // 2. Compute the weighted error rate of the learner\n//     predictions = weak_learner.predict(features)\n//     misclassified_mask = (predictions != labels)\n//     weighted_error = sum(sample_weights[misclassified_mask])\n//\n//     // 3. Compute the learner's ensemble weight (alpha)\n//     // Add a small epsilon to avoid division by zero if error is 0\n//     alpha = log((1 - weighted_error) / (weighted_error + 1e-10))\n//\n//     // 4. Update the sample weights\n//     // Increase weights for misclassified samples\n//     FOR i FROM 0 TO N-1:\n//       IF misclassified_mask[i] is TRUE:\n//         sample_weights[i] = sample_weights[i] * exp(alpha)\n//\n//     // 5. Normalize the sample weights to sum to 1\n//     total_weight = sum(sample_weights)\n//     sample_weights = sample_weights / total_weight\n//\n//     // 6. Store the trained learner and its weight\n//     APPEND weak_learner to trained_learners\n//     APPEND alpha to alpha_weights\n//\n//   RETURN trained_learners, alpha_weights\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 87,
    "text": "### Framework Overview\n\nModern high-performance gradient boosting implementations like XGBoost and LightGBM achieve significant speedups through several algorithmic innovations. A key innovation is moving beyond simple gradient descent to a method resembling Newton's method, which utilizes second-order derivatives (the Hessian) of the loss function. This allows for a more accurate approximation of the model's objective function, leading to faster and more effective training, particularly in finding the optimal values for the leaves of each new tree.\n\n### Key Algorithmic Innovations\n\n- **[Definition] Second-Order Approximation**: At each step of building the ensemble, the loss function is approximated using a second-order Taylor expansion. This transforms the problem of finding the best new tree into optimizing a more straightforward quadratic function at each step.\n\n- **[Definition] Regularization Penalty (鎯?**: To prevent overfitting, a penalty term is added to the objective function. This term penalizes model complexity, typically based on the number of leaves in a tree and the magnitude of the leaf weights.\n\n- **[Definition] Leaf-wise vs. Depth-wise Growth**: `Leaf-wise` growth (used by LightGBM) splits the node that results in the largest reduction in loss, leading to potentially unbalanced but efficient trees. `Depth-wise` growth (used by XGBoost) grows the tree level by level, resulting in more balanced structures.\n\n### The Objective Function\n\nAt each iteration `m`, the algorithm seeks to add a new tree \\(h_m\\) that minimizes the overall objective function. The objective \\(\\mathcal{L}^{(m)}\\) is approximated using the first-order gradient (\\(g_i\\)) and second-order gradient or Hessian (\\(h_i\\)) of the loss function with respect to the previous iteration's predictions.\n\n**Equation 1: Second-Order Approximation of the Objective**\n$$ \\mathcal{L}^{(m)} \\simeq \\sum_{i=1}^{n} \\left[ g_i f_m(x_i) + \\frac{1}{2} h_i f_m^2(x_i) \\right] + \\Omega(h_m) $$\n*Where:*\n- \\(g_i\\): The first-order gradient of the loss function for observation \\(i\\).\n- \\(h_i\\): The second-order gradient (Hessian) of the loss function for observation \\(i\\).\n- \\(f_m(x_i)\\): The output of the new tree for observation \\(i\\).\n- \\(\\Omega(h_m)\\): The regularization penalty for the new tree \\(h_m\\).\n\nThe regularization penalty for a single tree is defined as:\n\n**Equation 2: Regularization Penalty**\n$$ \\Omega(h) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^{T} w_j^2 $$\n*Where:*\n- \\(\\gamma\\): The penalty for adding a new leaf node.\n- \\(T\\): The total number of leaves in the tree.\n- \\(\\lambda\\): The L2 regularization penalty on the leaf weights.\n- \\(w_j\\): The score (or weight) of the j-th leaf.\n\nBy optimizing this objective, we can derive a quality score for any given tree structure, which allows the algorithm to efficiently evaluate potential splits. The gain from a split is calculated as the score of the two resulting children nodes minus the score of the parent node, adjusted for the penalty of adding a new leaf.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Split Gain Calculation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the quality score (information gain) of a potential split in a gradient boosting tree. This function should take the gradients and Hessians of the samples in the parent node and the proposed left/right child nodes as input, along with regularization parameters, and return the gain of making that split.\n    *   **Format**: Your answer should be the implementation using the Pseudocode Template.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateSplitGain(G_parent, H_parent, G_left, H_left, G_right, H_right, gamma, lambda)\n// INPUTS:\n//   - G_parent: Sum of first-order gradients for all samples in the parent node.\n//   - H_parent: Sum of second-order gradients (Hessians) for all samples in the parent node.\n//   - G_left: Sum of first-order gradients for samples in the proposed left child node.\n//   - H_left: Sum of second-order gradients for samples in the proposed left child node.\n//   - G_right: Sum of first-order gradients for samples in the proposed right child node.\n//   - H_right: Sum of second-order gradients for samples in the proposed right child node.\n//   - gamma: The regularization parameter for the number of leaves.\n//   - lambda: The L2 regularization parameter for the leaf weights.\n// OUTPUTS:\n//   - The gain value for the proposed split. A higher value indicates a better split.\n//\n// BEGIN\n//   // This function assumes G_parent = G_left + G_right and H_parent = H_left + H_right\n\n//   // Calculate the quality score for the proposed left child node.\n//   // The score measures how well the node contributes to minimizing the loss.\n//   score_left = (G_left * G_left) / (H_left + lambda)\n\n//   // Calculate the quality score for the proposed right child node.\n//   score_right = (G_right * G_right) / (H_right + lambda)\n\n//   // Calculate the quality score for the parent node (before the split).\n//   score_parent = (G_parent * G_parent) / (H_parent + lambda)\n\n//   // The gain is the improvement in the objective function from the split.\n//   // It's the sum of the children's scores minus the parent's score.\n//   // The 'gamma' term is a penalty for adding a new leaf node (a split adds one leaf).\n//   // The 0.5 factor comes from the derivation of the optimal objective value.\n//   gain = 0.5 * (score_left + score_right - score_parent) - gamma\n\n//   RETURN gain\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 88,
    "text": "## Framework Overview\n\nTraditional risk factor models, like the Fama-French model, rely on pre-specified economic factors. An alternative, data-driven approach is to treat risk factors as latent variables and extract them directly from asset returns using statistical techniques like Principal Component Analysis (PCA). This method has the advantage of not requiring prior knowledge about the empirical behavior of asset returns.\n\n## Key Concepts\n\n- **[Definition] Principal Component Analysis (PCA)**: A linear dimensionality reduction technique that transforms a set of correlated variables into a smaller set of uncorrelated variables called principal components. The first principal component accounts for the largest possible variance in the data, and each succeeding component has the largest possible variance under the constraint that it is orthogonal to (i.e., uncorrelated with) the preceding components.\n- **[Definition] Latent Variables**: Variables that are not directly observed but are rather inferred (through a mathematical model) from other variables that are observed (directly measured).\n- **[Definition] Winsorizing**: The process of limiting extreme values in statistical data to reduce the effect of potentially spurious outliers. It involves setting all data points below a certain percentile to that percentile's value, and all data points above another percentile to that percentile's value.\n\n## Computational Steps\n\nThe process of deriving data-driven risk factors from a raw asset returns matrix involves a sequence of data preparation steps followed by the application of PCA.\n\n1.  **Handle Outliers**: PCA is sensitive to outliers. To mitigate this, winsorize the returns data at specified quantiles (e.g., the 2.5% and 97.5% quantiles) to cap extreme values.\n\n2.  **Handle Missing Data (Assets)**: PCA does not permit missing values. First, address assets with insufficient data by removing any asset (column) that does not have data for a minimum percentage of the time period (e.g., 95%).\n\n3.  **Handle Missing Data (Timestamps)**: After removing sparse assets, address timestamps with insufficient data by removing any trading day (row) that does not have observations for a minimum percentage of the remaining assets (e.g., 95%).\n\n4.  **Impute Remaining Missing Values**: For the few missing values that may remain, impute them using a simple method. A common approach is to fill any remaining `NaN` for a given day with the average return of all assets on that same day.\n\n5.  **Apply PCA**: Once the data is cleaned, fit a PCA model to the prepared returns matrix. The resulting principal components are the data-driven risk factors. The first component, which explains the most variance, is often interpreted as the 'market' factor.",
    "question": "Provide the pseudocode for a function that implements the complete data pipeline for deriving statistical risk factors. The function should take a raw asset returns matrix and output the top `N` principal components (the risk factors).",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION DeriveRiskFactors(raw_returns, n_factors, outlier_quantiles, asset_thresh, time_thresh)\n// INPUTS:\n//   - raw_returns: A 2D matrix (DataFrame) of asset returns with dates as rows and tickers as columns.\n//   - n_factors: An integer specifying the number of top principal components to return.\n//   - outlier_quantiles: A tuple (e.g., (0.025, 0.975)) for winsorizing.\n//   - asset_thresh: A float (e.g., 0.95) for minimum non-NaN data per asset.\n//   - time_thresh: A float (e.g., 0.95) for minimum non-NaN data per timestamp.\n// OUTPUTS:\n//   - A 2D matrix (DataFrame) containing the top n_factors (principal components).\n//\n// BEGIN\n//   // Step 1: Handle Outliers\n//   lower_bound = raw_returns.quantile(outlier_quantiles[0])\n//   upper_bound = raw_returns.quantile(outlier_quantiles[1])\n//   winsorized_returns = raw_returns.clip(lower_bound, upper_bound, axis=1)\n//\n//   // Step 2: Handle Missing Data (Assets)\n//   min_obs_per_asset = winsorized_returns.rows.count * asset_thresh\n//   cleaned_returns = winsorized_returns.dropna(axis='columns', threshold=min_obs_per_asset)\n//\n//   // Step 3: Handle Missing Data (Timestamps)\n//   min_obs_per_time = cleaned_returns.columns.count * time_thresh\n//   cleaned_returns = cleaned_returns.dropna(axis='rows', threshold=min_obs_per_time)\n//\n//   // Step 4: Impute Remaining Missing Values\n//   daily_average_returns = cleaned_returns.mean(axis=1)\n//   imputed_returns = cleaned_returns.apply(lambda col: col.fillna(daily_average_returns))\n//\n//   // Step 5: Apply PCA\n//   pca_model = new PCA()\n//   pca_model.fit(imputed_returns)\n//   transformed_data = pca_model.transform(imputed_returns)\n//\n//   // Extract the top N factors\n//   risk_factors = transformed_data[:, 0 to n_factors-1]\n//\n//   RETURN risk_factors\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 89,
    "text": "## Core Concept\n\n- **[Definition] Eigenportfolio**: A portfolio constructed using the principal components (eigenvectors) of an asset return covariance matrix. Each eigenportfolio is, by construction, uncorrelated with the others. The first eigenportfolio corresponds to the component with the highest variance, the second corresponds to the component with the second-highest variance, and so on.\n\n## Framework Overview\n\nEigenportfolios are a direct application of Principal Component Analysis (PCA) in portfolio construction. By decomposing the covariance matrix of asset returns, we can identify orthogonal sources of risk. The principal components (eigenvectors) of this matrix can be interpreted as portfolio weights. These portfolios capture the primary directions of covariation among assets in descending order of importance.\n\n## Key Concepts\n\n- **[Definition] Covariance Matrix**: A square matrix giving the covariance between each pair of elements of a given random vector. For a set of asset returns, the diagonal elements are the variances of each asset, and the off-diagonal elements are the covariances between pairs of assets.\n\n## Computational Steps\n\nThe algorithm to construct eigenportfolios from a matrix of asset returns is as follows:\n\n1.  **Data Preparation**: The input asset returns should be pre-processed. This typically involves handling outliers (e.g., winsorizing) and normalizing the returns for each asset (e.g., scaling to have a mean of 0 and a standard deviation of 1). This ensures that all assets contribute equally to the covariance calculation, regardless of their individual volatility.\n\n2.  **Covariance Matrix Calculation**: Compute the sample covariance matrix from the prepared (normalized) asset returns.\n\n3.  **Principal Component Analysis**: Fit a PCA model to the covariance matrix. This will yield the principal components (eigenvectors) and their corresponding explained variances (eigenvalues).\n\n4.  **Component Selection**: Select the top `N` principal components that you wish to use for constructing portfolios. These are typically the components that explain the most variance.\n\n5.  **Weight Normalization**: Each selected principal component is a vector of weights, one for each asset. To make these weights usable as a portfolio, they must be normalized. A common method is to divide each weight in the component vector by the sum of all weights in that vector, ensuring the resulting portfolio weights sum to 1.",
    "question": "Provide the pseudocode for a function that takes a pre-processed asset returns matrix and an integer `N`, and returns the normalized portfolio weights for the top `N` eigenportfolios.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ConstructEigenportfolios(normed_returns, n_portfolios)\n// INPUTS:\n//   - normed_returns: A 2D matrix (DataFrame) of pre-processed and normalized asset returns.\n//   - n_portfolios: The number of top eigenportfolios to construct.\n// OUTPUTS:\n//   - A 2D matrix (DataFrame) where each row represents an eigenportfolio and columns are asset weights.\n//\n// BEGIN\n//   // Step 1: Data Preparation is assumed to be complete (input is normed_returns).\n//\n//   // Step 2: Covariance Matrix Calculation\n//   covariance_matrix = normed_returns.covariance()\n//\n//   // Step 3: Principal Component Analysis\n//   pca_model = new PCA()\n//   pca_model.fit(covariance_matrix)\n//   principal_components = pca_model.components_\n//\n//   // Step 4: Component Selection\n//   top_n_components = principal_components[0 to n_portfolios-1]\n//\n//   // Step 5: Weight Normalization\n//   // Initialize an empty structure to hold the final portfolio weights.\n//   eigenportfolio_weights = new DataFrame(rows=n_portfolios, columns=normed_returns.columns)\n//\n//   FOR i FROM 0 TO n_portfolios-1\n//     // Get the current component vector\n//     component_vector = top_n_components[i]\n//\n//     // Calculate the sum of the vector's elements\n//     vector_sum = component_vector.sum()\n//\n//     // Normalize the vector so that its elements sum to 1\n//     normalized_weights = component_vector / vector_sum\n//\n//     // Assign the normalized weights to the corresponding row in the output DataFrame\n//     eigenportfolio_weights.set_row(i, normalized_weights)\n//   END FOR\n//\n//   RETURN eigenportfolio_weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 90,
    "text": "### 1. Framework Overview: The spaCy NLP Pipeline\n\nTo extract meaningful signals from text, raw documents must be processed through a Natural Language Processing (NLP) pipeline. The spaCy library provides an efficient, object-oriented approach to this task. When a text string is processed by a spaCy language model (e.g., `nlp = spacy.load('en')`), it returns a `Doc` object. This object is not just a string but a rich, annotated container where the text has been segmented into tokens, and each token is enriched with a variety of linguistic attributes.\n\n### 2. Core Pipeline Components\n\nThe default spaCy pipeline includes several components that perform sequential annotations:\n\n- **[Definition] Tokenization**: The process of segmenting a text string into individual units, or tokens, such as words, numbers, and punctuation marks.\n- **[Definition] Part-of-Speech (POS) Tagging**: The process of assigning a grammatical category (like noun, verb, adjective) to each token.\n- **[Definition] Syntactic Parsing**: The process of analyzing the grammatical structure of a sentence to determine the relationships between tokens (e.g., subject, object).\n- **[Definition] Named Entity Recognition (NER)**: The process of identifying and categorizing named entities in text into pre-defined categories such as persons, organizations, and locations.\n\n### 3. Key Token Attributes\n\nOnce a `Doc` object is created, you can iterate through its tokens. Each token object has numerous attributes that are essential for feature engineering. For this problem, the most relevant attributes are:\n\n- `.text`: The original, verbatim text of the token.\n- `.lemma_`: The base or root form of the token. For example, the lemma of \"looking\" is \"look\", and the lemma of \"is\" is \"be\". This is a form of normalization.\n- `.pos_`: The simple, universal part-of-speech tag (e.g., 'VERB', 'NOUN', 'ADJ').\n- `.is_stop`: A boolean flag that is `True` if the token is a common \"stop word\" (e.g., \"the\", \"a\", \"is\"), which often carries little semantic weight.\n- `.is_punct`: A boolean flag that is `True` if the token is a punctuation mark.",
    "question": "Provide the pseudocode for a function that takes a raw text string and a loaded spaCy language model object as input. The function should process the text and return a list of tuples. Each tuple must contain the text, lemma, and part-of-speech tag for every token that is **NOT** a stop word and **NOT** punctuation.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ExtractTokenFeatures(raw_text, spacy_model)\n// INPUTS:\n//   - raw_text: A string containing the document to be processed.\n//   - spacy_model: A loaded spaCy language model object (e.g., from spacy.load('en')).\n// OUTPUTS:\n//   - A list of tuples, where each tuple contains (text, lemma, pos_tag) for filtered tokens.\n//\n// BEGIN\n//   1. Initialize an empty list called 'feature_list'.\n//\n//   2. Process the input 'raw_text' using the 'spacy_model' to create a Doc object.\n//      LET doc = spacy_model(raw_text)\n//\n//   3. Iterate through each token in the 'doc' object.\n//      FOR EACH token IN doc:\n//\n//        // 4. Check if the token is neither a stop word nor punctuation.\n//        IF (token.is_stop IS FALSE) AND (token.is_punct IS FALSE) THEN\n//\n//          // 5. If the condition is met, create a tuple with the required attributes.\n//          LET current_features = (token.text, token.lemma_, token.pos_)\n//\n//          // 6. Append the tuple to the 'feature_list'.\n//          APPEND current_features TO feature_list\n//\n//        END IF\n//\n//      END FOR\n//\n//   7. Return the 'feature_list'.\n//   RETURN feature_list\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 91,
    "text": "### 1. Framework Overview: TextBlob for Sentiment Analysis\n\nTextBlob is a high-level Python library that simplifies common NLP tasks. For sentiment analysis, it provides a straightforward, dictionary-based (or lexicon-based) approach. It contains pre-compiled dictionaries that map specific words and phrases to sentiment scores. When a document is processed, TextBlob averages the scores of the relevant words it contains to produce an overall sentiment estimate for the entire document.\n\n### 2. Key Sentiment Metrics\n\nProcessing a document with TextBlob yields a `Sentiment` object with two primary attributes:\n\n- **[Definition] Sentiment Polarity**: A floating-point value within the range `[-1.0, 1.0]`. A score of `-1.0` indicates a highly negative sentiment, `+1.0` indicates a highly positive sentiment, and a score around `0.0` suggests neutral sentiment.\n\n- **[Definition] Subjectivity**: A floating-point value within the range `[0.0, 1.0]`. A score of `0.0` indicates that the text is very objective (e.g., factual news reporting), while a score of `1.0` indicates that the text is very subjective (e.g., an opinion piece or a product review). This metric is useful for filtering out factual statements from opinionated ones when building a sentiment-based signal.",
    "question": "Provide the pseudocode for a function that processes a list of text documents. For each document, it should calculate the sentiment polarity and subjectivity using a TextBlob-like object. The function must return a list of dictionaries, where each dictionary contains the original text, its polarity, its subjectivity, and a boolean flag `is_highly_subjective` which is `True` if the subjectivity score is greater than `0.75`.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION AnalyzeBatchSentiment(document_list)\n// INPUTS:\n//   - document_list: A list of strings, where each string is a document.\n// OUTPUTS:\n//   - A list of dictionaries, each with keys {text, polarity, subjectivity, is_highly_subjective}.\n//\n// BEGIN\n//   1. Initialize an empty list called 'results'.\n//\n//   2. Iterate through each document in the 'document_list'.\n//      FOR EACH doc_text IN document_list:\n//\n//        // 3. Create a TextBlob object from the document text.\n//        LET parsed_doc = CREATE_TEXTBLOB_OBJECT(doc_text)\n//\n//        // 4. Extract polarity and subjectivity scores.\n//        LET pol_score = parsed_doc.sentiment.polarity\n//        LET subj_score = parsed_doc.sentiment.subjectivity\n//\n//        // 5. Determine if the document is highly subjective.\n//        LET highly_subjective_flag = FALSE\n//        IF subj_score > 0.75 THEN\n//          SET highly_subjective_flag = TRUE\n//        END IF\n//\n//        // 6. Create a dictionary to store the results for the current document.\n//        LET doc_result = {\n//          \"text\": doc_text,\n//          \"polarity\": pol_score,\n//          \"subjectivity\": subj_score,\n//          \"is_highly_subjective\": highly_subjective_flag\n//        }\n//\n//        // 7. Append the result dictionary to the 'results' list.\n//        APPEND doc_result TO results\n//\n//      END FOR\n//\n//   8. Return the final list of results.\n//   RETURN results\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 92,
    "text": "### 1. The Bag-of-Words Model\n\nThe Bag-of-Words (BoW) model is a fundamental method for converting text into numerical features. It represents each document as a vector, disregarding grammar and word order but keeping track of word frequencies. This collection of vectors for an entire corpus forms a Document-Term Matrix.\n\n- **[Definition] Document-Term Matrix (DTM)**: A matrix where each row represents a document from a corpus, each column represents a unique term (token) from the corpus vocabulary, and each cell `(i, j)` contains a weight indicating the importance of term `j` in document `i`.\n\n### 2. The TF-IDF Weighting Scheme\n\nSimply counting word occurrences (Term Frequency) can be misleading, as common words like \"the\" or \"is\" would dominate. The Term Frequency-Inverse Document Frequency (TF-IDF) method refines these counts by down-weighting terms that appear frequently across many documents, thus highlighting terms that are more specific and potentially more informative for a particular document.\n\n- **[Definition] Term Frequency (TF)**: The number of times a term `t` appears in a document `d`. It is denoted as `tf(d, t)`.\n\n- **[Definition] Inverse Document Frequency (IDF)**: A measure of how much information a word provides. It is calculated as the logarithm of the total number of documents divided by the number of documents containing the term. This gives a higher weight to rarer terms.\n\n### 3. Mathematical Formulation\n\nThe final TF-IDF score for a term `t` in a document `d` is the product of its TF and IDF scores: `tfidf(d, t) = tf(d, t) * idf(t)`.\n\nThe formula for Inverse Document Frequency, incorporating smoothing to prevent division-by-zero errors for terms that might appear in all documents, is given by:\n\n**Equation 1: Inverse Document Frequency (IDF) with Smoothing**\n$$ \n\\mathrm{idf}(t) = \\log \\frac{1 + n_d}{1 + \\mathrm{df}(t)} + 1 \n$$\n\nWhere:\n- `idf(t)`: The Inverse Document Frequency score for term `t`.\n- `n_d`: The total number of documents in the corpus.\n- `df(t)`: The document frequency of term `t`, which is the number of documents in the corpus that contain the term `t`.",
    "question": "Provide the pseudocode for a function that calculates the TF-IDF matrix for a given corpus of documents. The function should first compute the Term Frequency (TF) matrix (raw counts) and the Document Frequency (DF) for each term. Then, using these, it must calculate the IDF vector based on **Equation 1**. Finally, it should compute and return the final TF-IDF matrix.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateTfIdfMatrix(corpus)\n// INPUTS:\n//   - corpus: A list of documents (strings).\n// OUTPUTS:\n//   - tfidf_matrix: A 2D matrix where rows are documents and columns are terms, with TF-IDF weights.\n//\n// BEGIN\n//   // 1. Build vocabulary and compute Term Frequency (TF) matrix.\n//   LET vocabulary = BuildVocabulary(corpus)\n//   LET num_documents = length(corpus)\n//   LET num_terms = length(vocabulary)\n//   INITIALIZE tf_matrix as a (num_documents x num_terms) matrix of zeros.\n//\n//   FOR i from 0 to num_documents - 1:\n//     LET document = corpus[i]\n//     LET term_counts = CountTermsInDocument(document)\n//     FOR term in term_counts:\n//       LET j = GetIndexInVocabulary(term, vocabulary)\n//       tf_matrix[i][j] = term_counts[term]\n//     END FOR\n//   END FOR\n//\n//   // 2. Compute Document Frequency (DF) vector.\n//   INITIALIZE df_vector as a (1 x num_terms) vector of zeros.\n//   FOR j from 0 to num_terms - 1:\n//     LET count = 0\n//     FOR i from 0 to num_documents - 1:\n//       IF tf_matrix[i][j] > 0 THEN\n//         count = count + 1\n//       END IF\n//     END FOR\n//     df_vector[j] = count\n//   END FOR\n//\n//   // 3. Calculate Inverse Document Frequency (IDF) vector using Equation 1.\n//   INITIALIZE idf_vector as a (1 x num_terms) vector.\n//   LET n_d = num_documents\n//   FOR j from 0 to num_terms - 1:\n//     idf_vector[j] = Log((1 + n_d) / (1 + df_vector[j])) + 1\n//   END FOR\n//\n//   // 4. Compute the final TF-IDF matrix.\n//   INITIALIZE tfidf_matrix as a (num_documents x num_terms) matrix.\n//   FOR i from 0 to num_documents - 1:\n//     FOR j from 0 to num_terms - 1:\n//       tfidf_matrix[i][j] = tf_matrix[i][j] * idf_vector[j]\n//     END FOR\n//   END FOR\n//\n//   // 5. Return the result.\n//   RETURN tfidf_matrix\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 93,
    "text": "### 1. Pipeline Overview\n\nBuilding a machine learning classifier for text involves a standardized sequence of steps to ensure robust training and objective evaluation. The goal is to create a pipeline that transforms raw text data into numerical features, trains a model on a portion of this data, and evaluates its performance on unseen data.\n\n- **[Definition] Multinomial Naive Bayes**: A specialized version of the Naive Bayes classifier designed to handle integer feature counts, making it highly effective for text classification tasks where the features are word counts from a Document-Term Matrix.\n\n### 2. Key Steps in the Workflow\n\nA complete training and evaluation workflow consists of the following critical stages:\n\n1.  **Data Splitting**: The dataset (documents and their corresponding labels) is divided into a training set and a testing set. A common split is 75% for training and 25% for testing. To ensure that the class distribution is similar in both sets, which is crucial for reliable evaluation, *stratification* based on the labels is used.\n\n2.  **Vectorization**: Text documents are converted into a numerical format. The `CountVectorizer` is a standard tool for this, creating a Document-Term Matrix where each cell contains the raw count of a term in a document. It is critical to learn the vocabulary (`fit`) only from the training data and then apply the same transformation (`transform`) to both the training and testing data to prevent information leakage from the test set.\n\n3.  **Model Training**: An instance of the `MultinomialNB` classifier is created. The `.fit()` method is then called on the vectorized training data (`X_train_dtm`) and the training labels (`y_train`).\n\n4.  **Prediction and Evaluation**: The trained model's `.predict()` method is used on the vectorized test data (`X_test_dtm`) to generate predictions. Finally, an evaluation metric, such as accuracy, is computed by comparing the model's predictions to the true test labels (`y_test`).",
    "question": "Provide the pseudocode for a function that implements the complete workflow for training and evaluating a Multinomial Naive Bayes news classifier. The function should accept a list of documents and a corresponding list of labels, perform a stratified 75/25 train-test split, vectorize the text using a count vectorizer, train the model, and return both the trained classifier object and its accuracy score on the test set.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION TrainAndEvaluateNewsClassifier(documents, labels)\n// INPUTS:\n//   - documents: A list of raw text strings (news articles).\n//   - labels: A list of corresponding class labels for each document.\n// OUTPUTS:\n//   - A tuple containing (trained_model, test_accuracy_score).\n//\n// BEGIN\n//   // 1. Perform a stratified 75/25 train-test split.\n//   LET (train_docs, test_docs, train_labels, test_labels) = TrainTestSplit(documents, labels, test_size=0.25, stratify=labels)\n//\n//   // 2. Initialize the vectorizer.\n//   LET vectorizer = new CountVectorizer()\n//\n//   // 3. Fit the vectorizer on the training data and transform both sets.\n//   LET train_dtm = vectorizer.fit_transform(train_docs)\n//   LET test_dtm = vectorizer.transform(test_docs)\n//\n//   // 4. Initialize the Multinomial Naive Bayes model.\n//   LET model = new MultinomialNB()\n//\n//   // 5. Train the model on the vectorized training data.\n//   model.fit(train_dtm, train_labels)\n//\n//   // 6. Make predictions on the vectorized test data.\n//   LET predictions = model.predict(test_dtm)\n//\n//   // 7. Calculate the accuracy of the predictions.\n//   LET accuracy = AccuracyScore(test_labels, predictions)\n//\n//   // 8. Return the trained model and its test accuracy.\n//   RETURN (model, accuracy)\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 94,
    "text": "## Framework Overview\n\nLatent Semantic Indexing (LSI), also known as Latent Semantic Analysis (LSA), is a technique used to model the relationships between documents and terms to uncover latent topics. It addresses the issue of synonymy (different words with similar meanings) by operating in a reduced-dimensional 'topic' space rather than the original word space.\n\n## Key Concepts\n\n- **[Definition] Document-Term Matrix (DTM)**: A matrix where rows represent documents, columns represent unique terms (words) in the corpus, and each cell `(i, j)` contains a weight (e.g., TF-IDF score) indicating the importance of term `j` in document `i`.\n- **[Definition] Singular Value Decomposition (SVD)**: A fundamental matrix factorization technique from linear algebra. For any real matrix `A` of size `M x N`, its SVD is a factorization of the form `A = U鍗盫宀偓`, where `U` is an `M x M` orthogonal matrix, `鍗盽 is an `M x N` rectangular diagonal matrix with non-negative real numbers on the diagonal, and `V宀偓` is the transpose of an `N x N` orthogonal matrix.\n\n## Computational Steps\n\nThe core of LSI is the application of SVD to the DTM to find the best lower-rank approximation. This process identifies a set of uncorrelated indexing variables, or 'topics'.\n\n1.  **Decomposition**: The DTM, let's call it `A` (size `M` documents by `N` terms), is decomposed using SVD: `A = U鍗盫宀偓`.\n    *   `U`: The left singular vectors (`M x M`), representing the document-topic relationships.\n    *   `鍗盽: The singular values (`M x N`), representing the 'strength' or importance of each topic.\n    *   `V`: The right singular vectors (`N x N`), representing the term-topic relationships.\n\n2.  **Dimensionality Reduction**: The key insight of LSI is that the singular values in `鍗盽 are ordered by magnitude. By keeping only the `k` largest singular values, we can create a compressed, lower-rank approximation of the original DTM that captures the most significant relationships while filtering out noise. We select the first `k` columns of `U` (let's call it `U_k`), the top-left `k x k` block of `鍗盽 (`鍗盻k`), and the first `k` columns of `V` (`V_k`).\n\n3.  **Topic Space Projection**: The final outputs represent the documents and terms in the new, `k`-dimensional latent topic space.\n    *   **Document-Topic Matrix**: This is given by `U_k * 鍗盻k`. The rows of this matrix are the vector representations of the original documents in the `k`-dimensional topic space.\n    *   **Term-Topic Matrix**: This is given by `V_k`. The rows of this matrix are the vector representations of the terms in the `k`-dimensional topic space.",
    "question": "Provide the pseudocode for a function that takes a document-term matrix (DTM) and a desired number of topics `k` as input, and performs Latent Semantic Indexing to output the document-topic and term-topic matrices.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION LatentSemanticIndexing(DTM, k)\n// INPUTS:\n//   - DTM: A matrix of size (M documents x N terms).\n//   - k: An integer representing the number of topics to extract.\n// OUTPUTS:\n//   - A tuple containing (document_topic_matrix, term_topic_matrix).\n//\n// BEGIN\n//   // Step 1: Decompose the DTM using Singular Value Decomposition.\n//   // U will have dimensions (M x M), S will be a vector of singular values of length min(M, N),\n//   // and VT will have dimensions (N x N).\n//   U, S, VT = SVD(DTM)\n//\n//   // Step 2: Reduce the dimensionality by selecting the top k components.\n//   // Truncate U to its first k columns.\n//   U_k = U[:, 0:k]\n//\n//   // Truncate S to its first k singular values and form a diagonal matrix.\n//   Sigma_k = create_diagonal_matrix(S[0:k])\n//\n//   // Truncate VT (V Transpose) to its first k rows.\n//   // This is equivalent to taking the first k columns of V and transposing.\n//   VT_k = VT[0:k, :]\n//\n//   // The term-topic matrix is the transpose of VT_k, or the first k columns of V.\n//   term_topic_matrix = transpose(VT_k)\n//\n//   // Step 3: Project documents into the latent topic space.\n//   // This is achieved by multiplying the truncated U matrix by the truncated Sigma matrix.\n//   document_topic_matrix = matrix_multiply(U_k, Sigma_k)\n//\n//   // Return the resulting matrices.\n//   RETURN (document_topic_matrix, term_topic_matrix)\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 95,
    "text": "## Framework Overview\n\nProbabilistic Latent Semantic Analysis (pLSA) provides a statistical foundation for topic modeling, addressing the theoretical limitations of LSI. It models the probability of a word appearing in a document as a mixture of conditionally independent multinomial distributions involving latent topics.\n\n## Key Concepts\n\n- **[Definition] Generative Model**: A statistical model that describes how a dataset is generated. For pLSA, it assumes documents are mixtures of topics, and topics are mixtures of words.\n- **[Definition] Non-negative Matrix Factorization (NMF)**: A group of algorithms in multivariate analysis and linear algebra where a matrix `V` is factorized into two matrices, `W` and `H`, with the property that all three matrices have no negative elements. `V 閳?W * H`.\n- **[Definition] Kullback-Leibler (KL) Divergence**: A measure of how one probability distribution is different from a second, reference probability distribution. In the context of NMF, it is used as a loss function to measure the reconstruction error between the original matrix and its factorized approximation.\n\n## Mathematical Formulation\n\npLSA models the joint probability of observing a word `w` in a document `d`, `P(w,d)`, as a mixture of `T` topics. The asymmetric formulation, which is most common, is given by:\n\n**Equation 1**: `P(w,d) = P(d) * 鍗盻t P(t|d) * P(w|t)`\n\nWhere:\n- `P(d)` is the probability of selecting document `d`.\n- `P(t|d)` is the probability of topic `t` being present in document `d`.\n- `P(w|t)` is the probability of word `w` being generated from topic `t`.\n\n## Implementation via NMF\n\npLSA is mathematically equivalent to performing Non-negative Matrix Factorization (NMF) on the document-term matrix (DTM) when using the Kullback-Leibler divergence as the objective function. The factorization is as follows:\n\n`DTM 閳?W * H`\n\n- **DTM**: The input document-term matrix of size `M documents x N terms`.\n- **W**: An `M x T` matrix, interpreted as the document-topic distribution `P(t|d)`. Each row represents a document and its affinity to each of the `T` topics.\n- **H**: A `T x N` matrix, interpreted as the topic-word distribution `P(w|t)`. Each row represents a topic and the probability of each word belonging to it.\n\nThe goal of the NMF algorithm is to find `W` and `H` that minimize the KL divergence between `DTM` and `W * H`.",
    "question": "Provide the pseudocode for a function that implements pLSA by leveraging a conceptual Non-negative Matrix Factorization (NMF) solver. The function should take a document-term matrix (DTM) and a number of topics `T` as input and return the document-topic and topic-word probability distributions.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ProbabilisticLatentSemanticAnalysis(DTM, num_topics)\n// INPUTS:\n//   - DTM: A non-negative matrix of size (M documents x N terms).\n//   - num_topics: An integer T representing the number of latent topics.\n// OUTPUTS:\n//   - A tuple containing (document_topic_dist, topic_word_dist).\n//\n// BEGIN\n//   // Define the parameters for the NMF solver.\n//   // The core of this problem is recognizing that pLSA can be solved via NMF.\n//   nmf_parameters = {\n//     'n_components': num_topics,\n//     'loss_function': 'kullback-leibler',\n//     'max_iterations': 1000\n//   }\n//\n//   // Initialize an NMF solver with the specified parameters.\n//   // This solver is assumed to find non-negative matrices W and H\n//   // that minimize the KL divergence between DTM and W*H.\n//   nmf_solver = initialize_NMF_solver(nmf_parameters)\n//\n//   // Fit the solver to the input Document-Term Matrix.\n//   // The solver will compute the factorized matrices W and H.\n//   W, H = nmf_solver.fit_transform(DTM)\n//\n//   // W represents the document-topic distributions, size (M x T).\n//   // H represents the topic-word distributions, size (T x N).\n//\n//   // Normalize the rows of W so they sum to 1, representing P(t|d).\n//   // For each row in W, divide each element by the sum of the row.\n//   document_topic_dist = normalize_rows(W)\n//\n//   // Normalize the rows of H so they sum to 1, representing P(w|t).\n//   // For each row in H, divide each element by the sum of the row.\n//   topic_word_dist = normalize_rows(H)\n//\n//   // Return the resulting probability distribution matrices.\n//   RETURN (document_topic_dist, topic_word_dist)\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 96,
    "text": "In text preprocessing for word embeddings, it is crucial to identify multi-word expressions (e.g., \"New York City\", \"interest rates\") and treat them as single tokens. This process is known as phrase detection. Scoring methods are used to determine if two adjacent words occur together more often than would be expected by chance.\n\n### 1. Scoring Methods\n\n- **[Definition] Lift Scoring Method**: A simple scoring method that identifies a bigram (a pair of words `w_i`, `w_j`) if their joint count, adjusted by a discount factor, is significantly higher than what would be expected if they were independent.\n\n**Equation 1: Lift Score**\n```\nscore(w_i, w_j) = (count(w_i, w_j) - 鏈? / (count(w_i) * count(w_j))\n```\nWhere:\n- `count(w_i, w_j)`: The number of times `w_i` and `w_j` appear consecutively.\n- `count(w_i)`: The total count of word `w_i`.\n- `鏈猔: A discount factor to prevent promoting very rare phrases.\n\n- **[Definition] Normalized Pointwise Mutual Information (NPMI)**: A more accurate but computationally intensive score that measures the association between two words. It normalizes the Pointwise Mutual Information (PMI) to a range of [-1, +1]. A score of +1 indicates perfect association, 0 indicates independence, and -1 indicates the words never appear together.\n\n**Equation 2: NPMI Score**\n```\nNPMI(w_i, w_j) = ln(P(w_i, w_j) / (P(w_i) * P(w_j))) / -ln(P(w_i, w_j))\n```\nWhere:\n- `P(w_i, w_j)`: The probability of words `w_i` and `w_j` occurring together. Calculated as `count(w_i, w_j) / N`, where N is the total number of bigrams in the corpus.\n- `P(w_i)`: The probability of word `w_i` occurring. Calculated as `count(w_i) / M`, where M is the total number of words in the corpus.",
    "question": "Provide the pseudocode for a function that calculates the NPMI score for a given pair of words, `w_i` and `w_j`, based on their individual and joint counts within a corpus.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateNPMI(count_wi, count_wj, count_wi_wj, total_words, total_bigrams)\n// INPUTS:\n//   - count_wi: Integer, total frequency of word w_i.\n//   - count_wj: Integer, total frequency of word w_j.\n//   - count_wi_wj: Integer, frequency of the bigram (w_i, w_j).\n//   - total_words: Integer, total number of tokens in the corpus.\n//   - total_bigrams: Integer, total number of bigrams in the corpus.\n// OUTPUTS:\n//   - A float representing the NPMI score, ranging from -1 to 1.\n//\n// BEGIN\n//   // Handle the case where the words never appear together.\n//   IF count_wi_wj == 0 THEN\n//     RETURN -1.0\n//   END IF\n//\n//   // Calculate probabilities.\n//   prob_wi = count_wi / total_words\n//   prob_wj = count_wj / total_words\n//   prob_wi_wj = count_wi_wj / total_bigrams\n//\n//   // Calculate the numerator (Pointwise Mutual Information).\n//   pmi = log(prob_wi_wj / (prob_wi * prob_wj))\n//\n//   // Calculate the denominator for normalization.\n//   normalizer = -log(prob_wi_wj)\n//\n//   // The NPMI score is the ratio of PMI to the normalizer.\n//   // If prob_wi_wj is 1 (the only bigram), log(1)=0, so handle division by zero.\n//   IF normalizer == 0 THEN\n//     RETURN 1.0\n//   ELSE\n//     RETURN pmi / normalizer\n//   END IF\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 97,
    "text": "Word embeddings generated by models like word2vec capture semantic relationships between words. A powerful method for evaluating the quality of these embeddings is the semantic analogy task. This task tests whether the geometric relationships between word vectors correspond to semantic relationships.\n\n### 1. Core Concept: Vector Arithmetic for Analogies\nThe fundamental principle is that analogies can be solved using vector arithmetic. For an analogy \"a is to b as c is to d\" (e.g., \"Athens is to Greece as Baghdad is to Iraq\"), the relationship can be expressed as:\n\n`vector(b) - vector(a) 閳?vector(d) - vector(c)`\n\nTo find the unknown word `d`, we can rearrange the equation:\n\n`vector(d) 閳?vector(c) + vector(b) - vector(a)`\n\n- **[Definition] Semantic Arithmetic**: The process of performing mathematical operations (addition, subtraction) on word vectors to solve analogy problems or explore semantic relationships.\n\n### 2. Evaluation Framework\nThe evaluation process involves:\n1.  Calculating a `target_vector` using the formula `vector(c) + vector(b) - vector(a)`.\n2.  Searching through the entire vocabulary to find the word whose vector is closest to the `target_vector`. Closeness is typically measured by cosine similarity.\n3.  If the closest word found is the expected word `d`, the test for that analogy is considered a success.\n\nAn example set of analogy categories is shown below:\n\n| Category | a | b | c | d (expected) |\n| :--- | :--- | :--- | :--- | :--- |\n| Capital-Country | athens | greece | baghdad | iraq |\n| Past Tense | dancing | danced | decreasing | decreased |\n| Plural | banana | bananas | bird | birds |",
    "question": "Provide the pseudocode for a function that solves the analogy task. The function should take three words (`a`, `b`, `c`) and a dictionary of all word embeddings, and return the word `d` that best completes the analogy `a:b :: c:d`.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION SolveAnalogy(word_a, word_b, word_c, embedding_map)\n// INPUTS:\n//   - word_a: String, the first word in the analogy base (e.g., 'athens').\n//   - word_b: String, the second word in the analogy base (e.g., 'greece').\n//   - word_c: String, the first word in the analogy target (e.g., 'baghdad').\n//   - embedding_map: A dictionary mapping words (strings) to their vector representations (arrays of floats).\n// OUTPUTS:\n//   - A string representing the word 'd' that best solves the analogy.\n//\n// BEGIN\n//   // 1. Retrieve the vectors for the input words.\n//   vec_a = embedding_map[word_a]\n//   vec_b = embedding_map[word_b]\n//   vec_c = embedding_map[word_c]\n//\n//   // 2. Calculate the target vector using semantic arithmetic.\n//   target_vector = vec_c + (vec_b - vec_a)\n//\n//   // 3. Initialize variables to track the best match.\n//   best_word = NULL\n//   max_similarity = -INFINITY\n//   input_words = {word_a, word_b, word_c}\n//\n//   // 4. Iterate through the entire vocabulary to find the closest vector.\n//   FOR each (word, vector) in embedding_map:\n//     // Constraint: Exclude the input words from the search.\n//     IF word is NOT in input_words THEN\n//       // Calculate cosine similarity between the current word's vector and the target vector.\n//       similarity = CosineSimilarity(target_vector, vector)\n//\n//       IF similarity > max_similarity THEN\n//         max_similarity = similarity\n//         best_word = word\n//       END IF\n//     END IF\n//   END FOR\n//\n//   // 5. Return the word with the highest similarity.\n//   RETURN best_word\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 98,
    "text": "Instead of training word embeddings from scratch, it is often effective to use vectors pre-trained on massive, general-purpose corpora. GloVe (Global Vectors for Word Representation) is a popular source for such embeddings. The Gensim library provides tools to easily load and work with these vectors.\n\n### 1. Key Concepts\n- **[Definition] GloVe (Global Vectors for Word Representation)**: An unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus.\n- **[Definition] Gensim `KeyedVectors`**: A Gensim object specifically designed to store and query word embeddings. It provides efficient methods for similarity lookups and analogy tasks.\n\n### 2. Implementation Steps\nThe process of using pre-trained GloVe vectors in Gensim typically involves two main steps:\n\n1.  **Format Conversion**: The standard GloVe distribution is a text file. Gensim's `word2vec` format is more optimized for memory and speed. A utility script, `glove2word2vec`, is used to convert the GloVe text file into the word2vec format.\n    \n2.  **Model Loading**: Once converted, the vectors can be loaded into a `KeyedVectors` object using the `load_word2vec_format` method.\n    \n3.  **Validation**: After loading, the quality of the embeddings can be quantitatively assessed using a standard analogy test file (e.g., `questions-words.txt`). The `wv.accuracy` function in Gensim runs this test and reports the percentage of correctly solved analogies.",
    "question": "Provide the pseudocode for a function that automates the process of loading GloVe vectors. The function should take the file path to a GloVe vector file and an analogy test file, perform the necessary conversion, load the model, evaluate its accuracy, and return the model and score.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION LoadAndValidateGloVe(glove_input_path, analogy_test_path)\n// INPUTS:\n//   - glove_input_path: String, the file path to the pre-trained GloVe vectors (e.g., 'glove.6B.100d.txt').\n//   - analogy_test_path: String, the file path to the analogy questions file (e.g., 'questions-words.txt').\n// OUTPUTS:\n//   - A tuple containing (loaded_model, accuracy_results).\n//     - loaded_model: A Gensim KeyedVectors object.\n//     - accuracy_results: A structure or dictionary containing the accuracy score.\n//\n// BEGIN\n//   // 1. Define a temporary path for the converted word2vec format file.\n//   w2v_output_path = 'glove.word2vec.txt'\n//\n//   // 2. Convert the GloVe file to word2vec format.\n//   // This is a placeholder for an external library call like gensim.scripts.glove2word2vec.\n//   CALL glove2word2vec(glove_input_file=glove_input_path, word2vec_output_file=w2v_output_path)\n//\n//   // 3. Load the converted vectors into a KeyedVectors object.\n//   // The 'binary=False' flag is used because the converted file is text-based.\n//   model = KeyedVectors.load_word2vec_format(w2v_output_path, binary=False)\n//\n//   // 4. Evaluate the loaded model's performance on the analogy task.\n//   // Restrict vocabulary for speed and use case-insensitivity for robustness.\n//   accuracy = model.wv.accuracy(analogy_test_path, restrict_vocab=300000, case_insensitive=True)\n//\n//   // 5. Return the loaded model and the accuracy results.\n//   RETURN (model, accuracy)\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 99,
    "text": "To train a supervised machine learning model that predicts stock price movements from text data (like SEC filings), each document must be associated with a quantitative label. A common and effective label is the stock's price return over a specific period following the document's publication.\n\n### 1. Objective\nThe goal is to create a function that, for each filing, calculates the forward return. For example, a 1-month forward return is the percentage change in the stock's price from the filing date to one month after the filing date.\n\n### 2. Required Inputs\n- **Filings Data**: A structured list or dataframe containing information for each filing, minimally including the company's `ticker` and the `filing_date`.\n- **Price Data**: A comprehensive dataset of historical daily stock prices, typically structured as a dataframe where the index is the date and columns correspond to different tickers.\n\n### 3. Computational Logic\nThe process for labeling a single filing is as follows:\n1.  Identify the `ticker` and `start_date` (the filing date).\n2.  Calculate the `target_end_date` by adding the desired time horizon (e.g., one month) to the `start_date`.\n3.  From the price data, retrieve the price series for the specified `ticker`.\n4.  Find the `start_price` on the `start_date` and the `end_price` on the `target_end_date`.\n5.  Calculate the return using the formula: `return = (end_price / start_price) - 1`.",
    "question": "Provide the pseudocode for a function that takes a dataframe of filings (containing tickers and dates) and a dataframe of daily prices, and generates a series of 1-month forward returns as labels for each filing.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION LabelFilingsWithForwardReturns(filings_df, prices_df, horizon_months)\n// INPUTS:\n//   - filings_df: A dataframe with columns 'ticker' and 'datefiled'.\n//   - prices_df: A dataframe of adjusted close prices, indexed by date, with tickers as columns.\n//   - horizon_months: Integer, the number of months for the forward return window (e.g., 1).\n// OUTPUTS:\n//   - A pandas Series containing the calculated forward return for each filing, indexed identically to filings_df.\n//\n// BEGIN\n//   Initialize an empty list `all_returns`.\n//\n//   FOR each row in filings_df:\n//     GET ticker = row['ticker']\n//     GET start_date = row['datefiled']\n//\n//     // Calculate the target end date.\n//     target_end_date = start_date + relative_delta(months=horizon_months)\n//\n//     // Select the price series for the specific ticker.\n//     price_series = prices_df[ticker]\n//\n//     // Slice the relevant date range from the price series.\n//     relevant_prices = price_series.slice(start_date, target_end_date)\n//\n//     // Robustly find the first and last valid prices in the window.\n//     // This handles non-trading days (weekends, holidays).\n//     IF relevant_prices is not empty THEN\n//       start_price = relevant_prices.first_valid_value()\n//       end_price = relevant_prices.last_valid_value()\n//\n//       // Ensure both a start and end price were found.\n//       IF start_price is not NULL AND end_price is not NULL THEN\n//         calculated_return = (end_price / start_price) - 1\n//         APPEND calculated_return to all_returns\n//       ELSE\n//         // Append NULL if data is insufficient in the window.\n//         APPEND NULL to all_returns\n//       END IF\n//     ELSE\n//       // Append NULL if no price data exists for the entire window.\n//       APPEND NULL to all_returns\n//     END IF\n//   END FOR\n//\n//   // Create a Series from the results with the original index.\n//   return_series = CreateSeries(data=all_returns, index=filings_df.index)\n//\n//   RETURN return_series\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 100,
    "text": "### Framework Overview: Momentum Optimization\n\nStandard gradient descent can be slow to converge, especially in areas of the loss surface that resemble long, narrow ravines. It tends to oscillate across the steep sides of the ravine rather than moving efficiently along the bottom towards the minimum. Momentum is a technique designed to accelerate convergence by dampening these oscillations and speeding up progress in the relevant direction.\n\n### Computational Steps\n\n1.  **[Definition] Velocity Term**: Momentum introduces a 'velocity' variable, `v`, which accumulates an exponentially decaying moving average of past gradients. This term represents the direction and speed of the parameter updates.\n\n2.  **Update Rule**: At each iteration `t`, the velocity `v_t` is updated based on its previous value `v_{t-1}` and the current gradient. The model's parameters `鑳僠 are then updated using this new velocity.\n\n    The update is a two-step process:\n\n    **Equation 1: Velocity Update**\n    `v_t = 绾?* v_{t-1} + 鐣?* 閳樂鑳?J(鑳?`\n\n    **Equation 2: Parameter Update**\n    `鑳?= 鑳?- v_t`\n\n    -   `鑳僠: The model parameters (weights) being optimized.\n    -   `v_t`: The velocity vector at time step `t`.\n    -   `绾琡 (gamma): The momentum term, a hyperparameter typically set to a value like 0.9. It controls the contribution of the previous velocity.\n    -   `鐣廯 (eta): The learning rate.\n    -   `閳樂鑳?J(鑳?`: The gradient of the cost function `J` with respect to the parameters `鑳僠.\n\n3.  **[Definition] Nesterov Momentum**: A variation where the gradient is calculated not at the current parameter position, but at an intermediate, projected position based on the current momentum. This 'lookahead' step can correct for overshooting.",
    "question": "Provide the pseudocode for a function that performs a single parameter update step using the standard Momentum optimization algorithm as described by Equation 1 and Equation 2.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateWithMomentum(parameters, gradients, velocity, learning_rate, gamma)\n// INPUTS:\n//   - parameters: A dictionary or list of the model's current weight matrices.\n//   - gradients: A dictionary or list of the gradients corresponding to each parameter matrix.\n//   - velocity: A dictionary or list of the current velocity matrices for each parameter.\n//   - learning_rate: The learning rate hyperparameter (鐣?.\n//   - gamma: The momentum hyperparameter (绾?.\n// OUTPUTS:\n//   - updated_parameters: The model parameters after the update.\n//   - updated_velocity: The new velocity matrices to be used in the next iteration.\n//\n// BEGIN\n//   // Initialize containers for the results\n//   updated_parameters = new empty dictionary or list\n//   updated_velocity = new empty dictionary or list\n//\n//   // Iterate through each parameter matrix (e.g., weights_hidden, weights_output)\n//   FOR each param_key in parameters:\n//     // Retrieve current values for this parameter\n//     current_param = parameters[param_key]\n//     current_grad = gradients[param_key]\n//     current_velo = velocity[param_key]\n//\n//     // Equation 1: Update the velocity\n//     // v_t = 绾?* v_{t-1} + 鐣?* gradient\n//     new_velo = (gamma * current_velo) + (learning_rate * current_grad)\n//\n//     // Equation 2: Update the parameters by subtracting the new velocity\n//     // 鑳?= 鑳?- v_t\n//     new_param = current_param - new_velo\n//\n//     // Store the updated values\n//     updated_parameters[param_key] = new_param\n//     updated_velocity[param_key] = new_velo\n//   ENDFOR\n//\n//   RETURN updated_parameters, updated_velocity\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 101,
    "text": "### Framework Overview: AdaGrad\n\nAdaGrad (Adaptive Gradient Algorithm) is an optimizer that adapts the learning rate for each parameter individually. It performs larger updates for infrequent parameters and smaller updates for frequent parameters, making it well-suited for sparse data.\n\n### Computational Steps\n\nThe core idea is to scale the learning rate for each parameter inversely proportional to the square root of the sum of all its historical squared gradients.\n\n1.  **[Definition] Gradient Accumulator**: A variable, often called a cache or `G`, is maintained for each parameter. This variable accumulates the sum of the squares of the gradients for that parameter over all previous time steps.\n\n2.  **Update Rule**: At each iteration `t`, for each parameter `鑳僟i`:\n\n    **Equation 1: Accumulate Squared Gradient**\n    `G_t = G_{t-1} + g_t^2`\n    where `g_t` is the gradient of the loss function with respect to parameter `鑳僟i` at time `t`.\n\n    **Equation 2: Parameter Update**\n    `鑳僟{t+1} = 鑳僟t - (鐣?/ (閳?G_t) + 钄?) * g_t`\n\n    -   `鑳僟t`: The value of a single parameter at time step `t`.\n    -   `G_t`: The accumulated sum of squared gradients for that parameter up to time `t`.\n    -   `g_t`: The gradient for that parameter at time `t`.\n    -   `鐣廯 (eta): A global learning rate.\n    -   `钄歚 (epsilon): A small constant (e.g., 1e-8) to prevent division by zero.\n\n    **Note**: A key drawback of AdaGrad is that the accumulator `G_t` can grow indefinitely, causing the effective learning rate to shrink to near zero, which can prematurely stop the learning process.",
    "question": "Provide the pseudocode for a function that performs a single parameter update step using the AdaGrad optimization algorithm.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateWithAdaGrad(parameters, gradients, gradient_accumulator, learning_rate, epsilon)\n// INPUTS:\n//   - parameters: A dictionary or list of the model's current weight matrices.\n//   - gradients: A dictionary or list of the gradients corresponding to each parameter matrix.\n//   - gradient_accumulator: A dictionary or list storing the sum of squared gradients for each parameter.\n//   - learning_rate: The global learning rate hyperparameter (鐣?.\n//   - epsilon: A small constant to avoid division by zero (钄?.\n// OUTPUTS:\n//   - updated_parameters: The model parameters after the update.\n//   - updated_accumulator: The new accumulator values to be used in the next iteration.\n//\n// BEGIN\n//   // Initialize containers for the results\n//   updated_parameters = new empty dictionary or list\n//   updated_accumulator = new empty dictionary or list\n//\n//   // Iterate through each parameter matrix\n//   FOR each param_key in parameters:\n//     // Retrieve current values for this parameter\n//     current_param = parameters[param_key]\n//     current_grad = gradients[param_key]\n//     current_acc = gradient_accumulator[param_key]\n//\n//     // Equation 1: Accumulate the square of the current gradient\n//     // Note: The operation is element-wise\n//     new_acc = current_acc + (current_grad * current_grad)\n//\n//     // Equation 2: Compute the parameter update\n//     // The scaling factor is computed element-wise\n//     adaptive_lr = learning_rate / (sqrt(new_acc) + epsilon)\n//     param_update = adaptive_lr * current_grad\n//     new_param = current_param - param_update\n//\n//     // Store the updated values\n//     updated_parameters[param_key] = new_param\n//     updated_accumulator[param_key] = new_acc\n//   ENDFOR\n//\n//   RETURN updated_parameters, updated_accumulator\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 102,
    "text": "### Framework Overview: RMSProp\n\nRMSProp (Root Mean Square Propagation) is an adaptive learning rate optimization algorithm designed to resolve AdaGrad's main shortcoming: its aggressively and monotonically decreasing learning rate. RMSProp prevents this by using an exponentially weighted moving average of squared gradients instead of accumulating all past squared gradients.\n\n### Computational Steps\n\n1.  **[Definition] Exponentially Weighted Average**: Instead of summing all past squared gradients, RMSProp maintains a moving average. This gives more weight to recent gradients and allows the influence of older gradients to decay over time.\n\n2.  **Update Rule**: At each iteration `t`, for each parameter `鑳僟i`:\n\n    **Equation 1: Update Moving Average of Squared Gradients**\n    `S_t = 灏?* S_{t-1} + (1 - 灏? * g_t^2`\n    where `g_t` is the gradient of the loss function with respect to parameter `鑳僟i` at time `t`.\n\n    **Equation 2: Parameter Update**\n    `鑳僟{t+1} = 鑳僟t - (鐣?/ (閳?S_t) + 钄?) * g_t`\n\n    -   `鑳僟t`: The value of a single parameter at time step `t`.\n    -   `S_t`: The moving average of squared gradients for that parameter at time `t`.\n    -   `g_t`: The gradient for that parameter at time `t`.\n    -   `灏綻 (beta): The decay rate or moving average parameter, a hyperparameter typically set to a value like 0.9 or 0.99.\n    -   `鐣廯 (eta): A global learning rate.\n    -   `钄歚 (epsilon): A small constant (e.g., 1e-8) to prevent division by zero.",
    "question": "Provide the pseudocode for a function that performs a single parameter update step using the RMSProp optimization algorithm.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateWithRMSProp(parameters, gradients, squared_grad_avg, learning_rate, decay_rate, epsilon)\n// INPUTS:\n//   - parameters: A dictionary or list of the model's current weight matrices.\n//   - gradients: A dictionary or list of the gradients corresponding to each parameter matrix.\n//   - squared_grad_avg: A dictionary or list storing the moving average of squared gradients (S_t).\n//   - learning_rate: The global learning rate hyperparameter (鐣?.\n//   - decay_rate: The moving average hyperparameter (灏?.\n//   - epsilon: A small constant to avoid division by zero (钄?.\n// OUTPUTS:\n//   - updated_parameters: The model parameters after the update.\n//   - updated_squared_avg: The new moving average values to be used in the next iteration.\n//\n// BEGIN\n//   // Initialize containers for the results\n//   updated_parameters = new empty dictionary or list\n//   updated_squared_avg = new empty dictionary or list\n//\n//   // Iterate through each parameter matrix\n//   FOR each param_key in parameters:\n//     // Retrieve current values for this parameter\n//     current_param = parameters[param_key]\n//     current_grad = gradients[param_key]\n//     current_avg = squared_grad_avg[param_key]\n//\n//     // Equation 1: Update the moving average of squared gradients\n//     // Note: All operations are element-wise\n//     // S_t = 灏?* S_{t-1} + (1 - 灏? * g_t^2\n//     new_avg = (decay_rate * current_avg) + ((1 - decay_rate) * (current_grad * current_grad))\n//\n//     // Equation 2: Compute the parameter update\n//     // 鑳僟{t+1} = 鑳僟t - (鐣?/ (sqrt(S_t) + 钄?) * g_t\n//     param_update = (learning_rate / (sqrt(new_avg) + epsilon)) * current_grad\n//     new_param = current_param - param_update\n//\n//     // Store the updated values\n//     updated_parameters[param_key] = new_param\n//     updated_squared_avg[param_key] = new_avg\n//   ENDFOR\n//\n//   RETURN updated_parameters, updated_squared_avg\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 103,
    "text": "### Framework Overview: Adam Optimizer\n\nAdam (Adaptive Moment Estimation) is a popular and robust optimization algorithm that combines the key ideas of two other optimizers: Momentum and RMSProp. It computes adaptive learning rates for each parameter by using estimates of both the first moment (the mean, like Momentum) and the second moment (the uncentered variance, like RMSProp) of the gradients.\n\n### Key Hyperparameters\n\n-   **`alpha`**: The learning rate (step size), often defaulted to 0.001.\n-   **`beta1`**: The exponential decay rate for the first moment estimates (like momentum), typically 0.9.\n-   **`beta2`**: The exponential decay rate for the second-moment estimates (like RMSProp), typically 0.999.\n-   **`epsilon`**: A very small number (e.g., 1e-8) to prevent division by zero.\n\n### Computational Steps\n\nAt each time step `t` for each parameter:\n\n1.  **Update First Moment (Momentum):**\n    `m_t = beta1 * m_{t-1} + (1 - beta1) * g_t`\n\n2.  **Update Second Moment (RMSProp):**\n    `v_t = beta2 * v_{t-1} + (1 - beta2) * g_t^2`\n\n3.  **[Definition] Bias Correction**: In the initial steps of training, `m_t` and `v_t` are biased towards zero. Adam corrects for this bias:\n    `m_hat_t = m_t / (1 - beta1^t)`\n    `v_hat_t = v_t / (1 - beta2^t)`\n    (where `t` is the current iteration number, starting from 1)\n\n4.  **Parameter Update:**\n    `鑳僟t = 鑳僟{t-1} - alpha * m_hat_t / (sqrt(v_hat_t) + epsilon)`",
    "question": "Provide the pseudocode for a function that performs a single parameter update step using the Adam optimization algorithm, including the crucial bias-correction steps.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateWithAdam(parameters, gradients, m, v, t, alpha, beta1, beta2, epsilon)\n// INPUTS:\n//   - parameters: A dictionary of the model's current weight matrices.\n//   - gradients: A dictionary of the gradients for each parameter matrix.\n//   - m: A dictionary storing the first moment estimates for each parameter.\n//   - v: A dictionary storing the second moment estimates for each parameter.\n//   - t: The current time step (iteration number, starting at 1).\n//   - alpha: The learning rate.\n//   - beta1: The decay rate for the first moment.\n//   - beta2: The decay rate for the second moment.\n//   - epsilon: A small constant to avoid division by zero.\n// OUTPUTS:\n//   - updated_parameters: The model parameters after the update.\n//   - updated_m: The new first moment estimates.\n//   - updated_v: The new second moment estimates.\n//\n// BEGIN\n//   // Initialize containers for the results\n//   updated_parameters = new empty dictionary\n//   updated_m = new empty dictionary\n//   updated_v = new empty dictionary\n//\n//   // Iterate through each parameter matrix\n//   FOR each param_key in parameters:\n//     // Retrieve current values\n//     param = parameters[param_key]\n//     grad = gradients[param_key]\n//     m_prev = m[param_key]\n//     v_prev = v[param_key]\n//\n//     // Step 1: Update biased first moment estimate\n//     m_t = (beta1 * m_prev) + ((1 - beta1) * grad)\n//\n//     // Step 2: Update biased second moment estimate (element-wise square)\n//     v_t = (beta2 * v_prev) + ((1 - beta2) * (grad * grad))\n//\n//     // Step 3: Compute bias-corrected moment estimates\n//     m_hat = m_t / (1 - (beta1^t))\n//     v_hat = v_t / (1 - (beta2^t))\n//\n//     // Step 4: Update parameters\n//     param_update = (alpha * m_hat) / (sqrt(v_hat) + epsilon)\n//     updated_param = param - param_update\n//\n//     // Store the updated values\n//     updated_parameters[param_key] = updated_param\n//     updated_m[param_key] = m_t\n//     updated_v[param_key] = v_t\n//   ENDFOR\n//\n//   RETURN updated_parameters, updated_m, updated_v\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 104,
    "text": "### Framework Overview: Backpropagation\n\nBackpropagation is the core algorithm for training neural networks. It works by first performing a forward pass to compute the output and the loss, and then a backward pass to compute the gradients of the loss with respect to each network parameter. These gradients are then used by an optimizer (like SGD) to update the parameters.\n\n### Network Architecture\n-   **Input Layer**: `X` (N samples, 2 features)\n-   **Hidden Layer**: 3 neurons with sigmoid activation. `W_h` (2x3), `b_h` (1x3)\n-   **Output Layer**: 2 neurons with softmax activation. `W_o` (3x2), `b_o` (1x2)\n\n### Forward Propagation\n1.  **Hidden Layer Activation**: `H = sigmoid(X 璺?W_h + b_h)`\n2.  **Output Layer Activation**: `Y_hat = softmax(H 璺?W_o + b_o)`\n\n### Backward Propagation (Gradient Calculation)\n\n**[Definition] Backpropagation**: A method for computing gradients by applying the chain rule recursively. It starts from the output layer and propagates the error gradient backward through the network to compute the gradients for the hidden layer parameters.\n\n1.  **Loss Gradient (Output Layer Error)**:\n    *   **Equation 1**: `鏈猒o = Y_hat - Y_true`\n    *   This is the gradient of the cross-entropy loss with respect to the output layer's pre-activation values.\n\n2.  **Output Layer Parameter Gradients**:\n    *   **Equation 2 (Weights)**: `閳樂{W_o} J = H^T 璺?鏈猒o`\n    *   **Equation 3 (Bias)**: `閳樂{b_o} J = sum(鏈猒o, axis=0)`\n\n3.  **Hidden Layer Gradient (Hidden Layer Error)**:\n    *   **Equation 4**: `鏈猒h = (鏈猒o 璺?W_o^T) 閳?(H 閳?(1 - H))`\n    *   This propagates the error from the output layer back to the hidden layer, scaled by the derivative of the sigmoid activation function (`H 閳?(1 - H)`). The `閳 symbol denotes element-wise multiplication.\n\n4.  **Hidden Layer Parameter Gradients**:\n    *   **Equation 5 (Weights)**: `閳樂{W_h} J = X^T 璺?鏈猒h`\n    *   **Equation 6 (Bias)**: `閳樂{b_h} J = sum(鏈猒h, axis=0)`",
    "question": "Provide the pseudocode for a function that executes a single, complete backpropagation pass. The function should take the network inputs, true labels, and current parameters, and return the gradients for all weights and biases.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ComputeGradients(X, Y_true, W_h, b_h, W_o, b_o)\n// INPUTS:\n//   - X: The input data matrix.\n//   - Y_true: The true labels matrix (one-hot encoded).\n//   - W_h, b_h: The weights and bias for the hidden layer.\n//   - W_o, b_o: The weights and bias for the output layer.\n// OUTPUTS:\n//   - A list or dictionary containing the computed gradients: [grad_W_h, grad_b_h, grad_W_o, grad_b_o].\n//\n// BEGIN\n//   // --- FORWARD PASS ---\n//   // 1. Compute hidden layer activations\n//   Z_h = dot(X, W_h) + b_h\n//   H = sigmoid(Z_h)\n//\n//   // 2. Compute output layer activations (predictions)\n//   Z_o = dot(H, W_o) + b_o\n//   Y_hat = softmax(Z_o)\n//\n//   // --- BACKWARD PASS ---\n//   // 1. Compute Loss Gradient (Output Layer Error)\n//   // Equation 1: 鏈猒o = Y_hat - Y_true\n//   delta_o = Y_hat - Y_true\n//\n//   // 2. Compute Output Layer Parameter Gradients\n//   // Equation 2: Gradient for output weights\n//   grad_W_o = dot(transpose(H), delta_o)\n//   // Equation 3: Gradient for output bias\n//   grad_b_o = sum(delta_o, axis=0)\n//\n//   // 3. Compute Hidden Layer Gradient (Hidden Layer Error)\n//   // Equation 4: 鏈猒h = (鏈猒o 璺?W_o^T) 閳?(H 閳?(1 - H))\n//   sigmoid_derivative = H * (1 - H) // Element-wise multiplication\n//   error_from_output = dot(delta_o, transpose(W_o))\n//   delta_h = error_from_output * sigmoid_derivative // Element-wise multiplication\n//\n//   // 4. Compute Hidden Layer Parameter Gradients\n//   // Equation 5: Gradient for hidden weights\n//   grad_W_h = dot(transpose(X), delta_h)\n//   // Equation 6: Gradient for hidden bias\n//   grad_b_h = sum(delta_h, axis=0)\n//\n//   // Return all computed gradients\n//   RETURN [grad_W_h, grad_b_h, grad_W_o, grad_b_o]\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 105,
    "text": "### Framework Overview: Keras Sequential API\n\nThe Keras Sequential API is a high-level interface for building neural networks layer-by-layer. It is the simplest way to get started with Keras and is ideal for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n\n### Key Steps for Model Creation\n\n1.  **[Definition] Model Initialization**: A `Sequential` model is instantiated. This object will act as a container for the layers.\n    `model = Sequential()`\n\n2.  **[Definition] Adding Layers**: Layers are added to the model in the order of computation using the `model.add()` method.\n    -   `Dense`: A standard, fully-connected neural network layer. Key arguments include `units` (number of neurons) and `activation` (the activation function to use).\n    -   The first layer in the model must receive an `input_shape` argument to inform the model about the dimensionality of the input data (e.g., the number of features).\n\n3.  **[Definition] Model Compilation**: Before the model can be trained, it must be compiled. The `model.compile()` method configures the model for training.\n    -   `optimizer`: The algorithm used to update the weights (e.g., 'adam', 'rmsprop').\n    -   `loss`: The objective function that the model will try to minimize (e.g., 'mean_squared_error' for regression, 'binary_crossentropy' for binary classification).\n    -   `metrics`: A list of metrics to be evaluated by the model during training and testing (e.g., ['accuracy']).\n\n4.  **Model Training**: The model is trained using the `model.fit()` method, providing the training data, number of epochs, batch size, etc.",
    "question": "Provide the pseudocode to define and compile a Keras Sequential model with the following architecture: an input layer accepting 64 features, a first hidden layer with 32 neurons and 'relu' activation, a second hidden layer with 16 neurons and 'relu' activation, and a final output layer with a single neuron for regression. The model should be compiled with the 'adam' optimizer and 'mean_squared_error' loss.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CreateAndCompileRegressionNN(num_features)\n// INPUTS:\n//   - num_features: The number of input features for the model (e.g., 64).\n// OUTPUTS:\n//   - A compiled Keras Sequential model.\n//\n// BEGIN\n//   // Import necessary libraries\n//   IMPORT Sequential from tensorflow.keras.models\n//   IMPORT Dense from tensorflow.keras.layers\n//\n//   // Step 1: Initialize the Sequential model\n//   model = Sequential()\n//\n//   // Step 2: Add layers to the model\n//\n//   // Add the first hidden layer\n//   // It has 32 neurons, uses 'relu' activation, and specifies the input shape.\n//   model.add(Dense(units=32, activation='relu', input_shape=(num_features,)))\n//\n//   // Add the second hidden layer\n//   // It has 16 neurons and uses 'relu' activation.\n//   model.add(Dense(units=16, activation='relu'))\n//\n//   // Add the output layer\n//   // It has a single neuron for the continuous prediction. No activation function is needed for standard regression.\n//   model.add(Dense(units=1))\n//\n//   // Step 3: Compile the model\n//   // Configure the optimizer, loss function, and any metrics.\n//   model.compile(optimizer='adam', loss='mean_squared_error')\n//\n//   // Optional: Print a summary of the model architecture\n//   model.summary()\n//\n//   RETURN model\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 106,
    "text": "### Framework Overview: Building Models in PyTorch\n\nPyTorch provides a flexible, Python-centric framework for building and training neural networks. The process involves three main stages: preparing the data, defining the network architecture, and implementing the training loop.\n\n### Key Components\n\n1.  **[Definition] DataLoader**: A PyTorch utility that wraps a dataset and provides an iterable over it. It handles batching, shuffling, and parallel data loading, making it easy to feed data to the network during training.\n\n2.  **[Definition] Custom Network Class (`nn.Module`)**: The standard way to define a network architecture in PyTorch. A custom class is created that inherits from `torch.nn.Module`. \n    -   The `__init__` method is used to define the layers of the network (e.g., `nn.Linear`, `nn.LogSigmoid`).\n    -   The `forward` method defines the computation performed at every call. It takes the input data and passes it through the defined layers to produce the output.\n\n3.  **[Definition] Training Loop**: The process of training the model. For each epoch (a full pass over the dataset), the loop iterates through batches of data provided by the `DataLoader`.\n    The steps inside the batch loop are:\n    a.  **Zero Gradients**: `optimizer.zero_grad()` is called to clear the gradients from the previous iteration.\n    b.  **Forward Pass**: The input features are passed through the network to get predictions: `outputs = net(features)`.\n    c.  **Compute Loss**: The predictions are compared to the true labels using a loss function: `loss = criterion(outputs, labels)`.\n    d.  **Backward Pass**: `loss.backward()` is called to compute the gradients of the loss with respect to all model parameters.\n    e.  **Update Weights**: `optimizer.step()` is called to update the model's weights based on the computed gradients.",
    "question": "Provide the pseudocode for a complete PyTorch training loop that runs for a single epoch. Assume a network `net`, a `dataloader`, a loss function `criterion`, and an `optimizer` have already been defined.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION TrainOneEpoch(net, dataloader, criterion, optimizer)\n// INPUTS:\n//   - net: An instance of a PyTorch model class (inheriting from nn.Module).\n//   - dataloader: A PyTorch DataLoader providing batches of training data.\n//   - criterion: The loss function (e.g., nn.CrossEntropyLoss).\n//   - optimizer: The optimization algorithm (e.g., torch.optim.Adam).\n// OUTPUTS:\n//   - running_loss: The total loss accumulated over the epoch.\n//\n// BEGIN\n//   // Set the model to training mode. This is important for layers like Dropout or BatchNorm.\n//   net.train()\n//\n//   // Initialize a variable to track the loss\n//   running_loss = 0.0\n//\n//   // Iterate over the data provided by the DataLoader\n//   FOR each batch_index, (features, labels) in enumerate(dataloader):\n//     // Ensure features and labels are in the correct format/device (e.g., float tensors)\n//     // (This step is assumed)\n//\n//     // a. Zero the parameter gradients\n//     optimizer.zero_grad()\n//\n//     // b. Forward pass: compute predicted outputs by passing inputs to the model\n//     outputs = net(features)\n//\n//     // c. Calculate the batch loss\n//     loss = criterion(outputs, labels)\n//\n//     // d. Backward pass: compute gradient of the loss with respect to model parameters\n//     loss.backward()\n//\n//     // e. Update weights: perform a single optimization step\n//     optimizer.step()\n//\n//     // Update the total loss for the epoch\n//     running_loss += loss.item()\n//   ENDFOR\n//\n//   PRINT \"Epoch finished. Total Loss: \", running_loss\n//   RETURN running_loss\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 107,
    "text": "### Framework Overview\nDeep Q-Learning is a reinforcement learning technique that uses a neural network to approximate the optimal action-value function, denoted as Q*(s, a). This allows an agent to learn the best policy (i.e., which action to take in a given state) in complex environments.\n\n### Key Concepts\n- **[Definition] Deep Q-Network (DQN)**: A multi-layered neural network that takes a state `s` as input and outputs a vector of Q-values, one for each possible action `a`. The network's weights are denoted by `鑳僠.\n- **[Definition] Epsilon-Greedy Policy**: An exploration strategy where the agent chooses a random action with a small probability `钄歚 (epsilon) and otherwise chooses the action with the highest estimated Q-value.\n\n### Computational Steps\nThe core of the learning process involves minimizing a loss function using stochastic gradient descent (SGD). This is done by comparing the network's current prediction with a more accurate target value.\n\n1.  **Calculate the Q-Target**:\nThe target value, `y_i`, is calculated using the Bellman equation. It represents the sum of the immediate reward `r` and the discounted maximum Q-value achievable from the next state `s'`. For stability, older network weights (`鑳僟{i-1}`) are often used to calculate this target.\n\n    *Equation 1: Q-Target Calculation*\n    ```\ny_{i} = E[r + 绾?* max_{a'} Q(s', a'; 鑳僟{i-1}) | s, a]\n    ```\n    - `y_i`: The target Q-value for the i-th transition.\n    - `r`: The reward received after taking action `a` in state `s`.\n    - `绾琡 (gamma): The discount factor (between 0 and 1), which determines the importance of future rewards.\n    - `s'`: The state observed after taking action `a`.\n    - `a'`: All possible actions in the next state `s'`.\n    - `鑳僟{i-1}`: The weights of the Q-network from a previous iteration.\n\n2.  **Calculate the Loss**:\nThe loss function, `L_i(鑳僟i)`, is the squared difference between the Q-Target (`y_i`) and the Q-value predicted by the current network (`Q(s, a; 鑳?`). This difference is also known as the Temporal-Difference (TD) Error.\n\n    *Equation 2: Loss Function*\n    ```\nL_{i}(鑳僟{i}) = (y_{i} - Q(s, a; 鑳?)^2\n    ```\n    - `L_i(鑳僟i)`: The loss for the i-th transition with current weights `鑳僟i`.\n    - `Q(s, a; 鑳?`: The Q-value predicted by the current network for the state-action pair `(s, a)`.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[DQN Loss Calculation Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the Mean Squared Error loss for a batch of DQN transitions. The function should use a dedicated target network (with weights `鑳僟{i-1}`) to compute the Q-Targets and the online network (with weights `鑳僠) for the current predictions.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateDqnLoss(online_network, target_network, states, actions, rewards, next_states, dones, gamma)\n// INPUTS:\n//   - online_network: The DQN with current weights 鑳?\n//   - target_network: The DQN with older weights 鑳僟{i-1} for stable target calculation.\n//   - states: A batch of current state observations.\n//   - actions: A batch of actions taken in the corresponding states.\n//   - rewards: A batch of rewards received.\n//   - next_states: A batch of resulting state observations.\n//   - dones: A batch of boolean flags indicating if an episode terminated.\n//   - gamma: The discount factor.\n// OUTPUTS:\n//   - A single scalar value representing the mean squared error loss for the batch.\n//\n// BEGIN\n//   // 1. Use the target network to predict Q-values for the next states.\n//   q_values_next_target = target_network.predict(next_states)\n//\n//   // 2. Find the maximum Q-value for each of the next states.\n//   max_q_next = max(q_values_next_target, axis=1) // Get the max Q-value along the action axis.\n//\n//   // 3. Calculate the Q-Target (y_i). If a state is terminal (done=true), future rewards are zero.\n//   // The 'dones' array is converted to 0 for terminal states and 1 for non-terminal states.\n//   q_targets = rewards + gamma * max_q_next * (1 - dones)\n//\n//   // 4. Use the online network to predict Q-values for the original states.\n//   q_values_current_online = online_network.predict(states)\n//\n//   // 5. Select the specific Q-values that correspond to the actions that were actually taken.\n//   // This gathers the Q(s, a; 鑳? values for the batch.\n//   action_q_values = gather_elements(q_values_current_online, actions)\n//\n//   // 6. Calculate the Mean Squared Error between the targets and the predicted action values.\n//   loss = mean((q_targets - action_q_values)^2)\n//\n//   RETURN loss\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 108,
    "text": "### The Problem: Moving Targets\nIn standard Q-learning, the network used to predict the current Q-value is the same one used to calculate the target Q-value. This creates a feedback loop: as the network's weights (`鑳僠) are updated, the target values also shift. This instability is like trying to hit a moving target and can cause the learning process to oscillate or diverge.\n\n### The Target Network Solution\nTo stabilize training, an extension to the DQN algorithm introduces a second, separate neural network called the target network.\n\n- **[Definition] Online Q-Network**: The main network that is continuously updated via gradient descent at each training step. Its weights are denoted as `鑳僠.\n- **[Definition] Target Network**: A clone of the online network. Its weights, denoted `鑳冮垿绫? are held constant for a fixed number of steps (`锜縛) and are only updated by periodically copying the weights from the online network. This provides a stable, consistent target for the online network to learn towards.\n\n### Mathematical Formulation\nThe target network is used exclusively for calculating the Q-Target in the loss function. This decouples the target calculation from the immediate updates being made to the online network.\n\n*Equation 1: Target Calculation with Target Network*\n```\ny_{i} = E[r + 绾?* max_{a'} Q(s', a'; 鑳冮垿? | s, a]\n```\n- `y_i`: The target Q-value for the i-th transition.\n- `r`: The reward received.\n- `绾琡 (gamma): The discount factor.\n- `s'`: The next state observed.\n- `a'`: All possible actions in the next state `s'`.\n- `鑳冮垿绫? The weights of the separate, slow-moving **target network**.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Target Network Update Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function or logic block that updates the target network's weights from the online network's weights. This update should only occur when a global step counter is a multiple of a given frequency parameter, `锜縛.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION UpdateTargetNetwork(online_network, target_network, global_step_counter, tau)\n// INPUTS:\n//   - online_network: The main Q-network being actively trained.\n//   - target_network: The stable target Q-network.\n//   - global_step_counter: An integer tracking the total number of training steps performed.\n//   - tau: The integer frequency for updating the target network (e.g., update every 100 steps).\n// OUTPUTS:\n//   - None. The function modifies the target_network in-place.\n//\n// BEGIN\n//   // Check if the global step counter indicates it's time for an update.\n//   // The modulo operator (%) returns the remainder of a division.\n//   // If the remainder is 0, it means the counter is an exact multiple of tau.\n//   // We also ensure the counter is not zero to avoid updating at the very start.\n//   IF global_step_counter > 0 AND (global_step_counter MODULO tau) == 0 THEN\n//     // 1. Retrieve the current weights from the online network.\n//     online_weights = online_network.get_weights()\n//\n//     // 2. Set the target network's weights to be an exact copy of the online network's weights.\n//     target_network.set_weights(online_weights)\n//\n//     PRINT \"Target network updated at step: \" + global_step_counter\n//   END IF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 109,
    "text": "### The Overestimation Problem in Q-Learning\nStandard Deep Q-Learning (DQN) suffers from a systematic issue where it tends to overestimate the value of actions. This happens because the `max` operator, used to select the best action and evaluate its value, is applied to the same set of Q-value estimates. If some action values are erroneously high due to estimation noise, the `max` operator will preferentially select them, leading to an upward bias in the learned values.\n\n- **[Definition] Q-Learning Overestimation Bias**: The tendency of the Q-learning algorithm to produce action-value estimates that are larger than the true values, caused by using the maximum of noisy estimates as an estimate of the maximum expected value.\n\n### The Double DQN Solution\nTo mitigate this bias, Double Deep Q-Learning (DDQN) decouples the process of selecting the best action from the process of evaluating that action's value. It achieves this by using two different networks: one for selection and one for evaluation.\n\n- **[Definition] Double DQN (DDQN)**: An enhancement to the DQN algorithm that reduces overestimation bias by using the online network to choose the best action for the next state, and the target network to provide the Q-value estimate for that chosen action.\n\n### Mathematical Formulation\nThe most efficient implementation of DDQN leverages the existing online network (with weights `鑳僟t`) and target network (with weights `鑳?_t`). The online network determines *which* action is best for the next state, while the target network provides the value *of* that action.\n\n*Equation 1: Double DQN Target Calculation*\n```\ny_{i} = E[r + 绾?* Q(s', argmax_{a'} Q(s', a; 鑳僟t); 鑳?_t)]\n```\n- `y_i`: The DDQN target Q-value.\n- `r`: The reward received.\n- `绾琡 (gamma): The discount factor.\n- `s'`: The next state observed.\n- `argmax_{a'} Q(s', a; 鑳僟t)`: This inner part uses the **online network** (weights `鑳僟t`) to find the *action* `a'` that has the highest Q-value for the next state `s'`.\n- `Q(..., 鑳?_t)`: This outer part uses the **target network** (weights `鑳?_t`) to get the Q-value for the action selected by the online network.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[DDQN Target Calculation Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the DDQN target value for a batch of transitions, correctly decoupling action selection and evaluation as described.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateDdqnTarget(online_network, target_network, rewards, next_states, dones, gamma)\n// INPUTS:\n//   - online_network: The DQN with current weights 鑳僟t, used for action selection.\n//   - target_network: The DQN with older weights 鑳?_t, used for action evaluation.\n//   - rewards: A batch of rewards received.\n//   - next_states: A batch of resulting state observations.\n//   - dones: A batch of boolean flags indicating if an episode terminated.\n//   - gamma: The discount factor.\n// OUTPUTS:\n//   - An array of target Q-values for the batch.\n//\n// BEGIN\n//   // 1. Use the ONLINE network to predict Q-values for the next states.\n//   // The purpose of this step is ONLY to determine the best actions.\n//   q_values_next_online = online_network.predict(next_states)\n//\n//   // 2. Find the index of the best action for each next state according to the ONLINE network.\n//   best_actions = argmax(q_values_next_online, axis=1)\n//\n//   // 3. Use the TARGET network to predict Q-values for the next states.\n//   // This provides the values we will use for our target calculation.\n//   q_values_next_target = target_network.predict(next_states)\n//\n//   // 4. Select the Q-values from the TARGET network's predictions that correspond to the\n//   // best actions chosen by the ONLINE network. This is the core DDQN step.\n//   selected_target_q_values = gather_elements(q_values_next_target, best_actions)\n//\n//   // 5. Calculate the final DDQN target. If a state is terminal (done=true), future rewards are zero.\n//   targets = rewards + gamma * selected_target_q_values * (1 - dones)\n//\n//   RETURN targets\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 110,
    "text": "### DDQN Agent Architecture\nA Double Deep Q-Network (DDQN) agent is typically implemented as a class that encapsulates all the necessary components for learning and acting. This includes the neural networks, the experience memory, and the logic for training and decision-making.\n\n### Component 1: Network Construction (`build_model`)\nThe agent requires two neural networks with identical architectures:\n- **[Definition] Online Network**: This is the primary network that learns the policy. Its weights are updated frequently (typically at every step) via gradient descent.\n- **[Definition] Target Network**: A copy of the online network whose weights are updated only periodically. It provides stable targets for the online network, as described in the DDQN algorithm.\n\n### Component 2: Storing Experience (`memorize_transition`)\nTo learn effectively, the agent must store its experiences. A dedicated method is used to add transition tuples閳ユ摽(state, action, reward, next_state, done)`閳ユ敄o a memory buffer.\n- **[Definition] Experience Replay Buffer**: A data structure, often a deque with a fixed maximum size, that stores a large number of past transitions. When the buffer is full, older transitions are discarded as new ones are added.\n\n### Component 3: Learning from Experience (`experience_replay`)\nThis is the core training function where learning occurs. It orchestrates several key steps:\n1.  **Sampling**: A random mini-batch of transitions is drawn from the experience replay buffer.\n2.  **Target Calculation**: For each transition in the batch, the DDQN target value is computed. This involves using the online network to select the best action for the next state and the target network to evaluate that action's value.\n3.  **Training**: The online network is trained for a single step. The input (`X`) is the batch of `states`, and the desired output (`y`) is the batch of Q-values where the value for the action taken has been replaced by the calculated DDQN target.\n4.  **Target Network Update**: Periodically, the weights of the online network are copied over to the target network.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Experience Replay Implementation]`**:\n    *   **Task**: Provide the pseudocode for the `experience_replay` method, which orchestrates a single, complete training step for a DDQN agent. The logic should include sampling from memory, calculating the DDQN target, and training the online network.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ExperienceReplay(agent)\n// INPUTS:\n//   - agent: An object containing all necessary components:\n//     - agent.experience_buffer: The memory buffer of transitions.\n//     - agent.batch_size: The number of transitions to sample.\n//     - agent.online_network: The main network to be trained.\n//     - agent.target_network: The stable network for target calculation.\n//     - agent.gamma: The discount factor.\n// OUTPUTS:\n//   - The scalar loss value from the training step.\n//\n// BEGIN\n//   // 1. Ensure there are enough samples in memory to form a full batch.\n//   IF length(agent.experience_buffer) < agent.batch_size THEN\n//     RETURN // Not enough experience to train yet.\n//   END IF\n//\n//   // 2. Sample a random minibatch of transitions from the experience buffer.\n//   minibatch = sample(agent.experience_buffer, agent.batch_size)\n//   states, actions, rewards, next_states, dones = unpack(minibatch)\n//\n//   // 3. Calculate the DDQN target values for the minibatch.\n//   //    a. Use the online network to find the best actions for the next states.\n//   q_values_next_online = agent.online_network.predict(next_states)\n//   best_actions_next = argmax(q_values_next_online, axis=1)\n//\n//   //    b. Use the target network to get the Q-values for the next states.\n//   q_values_next_target = agent.target_network.predict(next_states)\n//\n//   //    c. Select the target Q-values corresponding to the best actions chosen by the online network.\n//   selected_target_q_values = gather_elements(q_values_next_target, best_actions_next)\n//\n//   //    d. Compute the final target value.\n//   targets = rewards + agent.gamma * selected_target_q_values * (1 - dones)\n//\n//   // 4. Prepare the training data (X, y).\n//   //    a. Get the online network's current Q-value predictions for the original states.\n//   q_values_current = agent.online_network.predict(states)\n//\n//   //    b. Create a copy of these predictions to serve as the training target `y`.\n//   training_targets = copy(q_values_current)\n//\n//   //    c. For each sample in the batch, update the Q-value for the action that was actually taken\n//   //       to be the newly computed DDQN target.\n//   FOR i FROM 0 TO agent.batch_size - 1:\n//     training_targets[i, actions[i]] = targets[i]\n//   END FOR\n//\n//   // 5. Train the online network for a single step.\n//   loss = agent.online_network.train_on_batch(x=states, y=training_targets)\n//\n//   RETURN loss\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 111,
    "text": "## Framework Overview\n\nTo forecast a univariate time series like the S&P 500 index using a Recurrent Neural Network (RNN), the raw data must be transformed into a specific format. This process involves three main steps: scaling the data, creating autoregressive sequences, and shaping the result into a 3D tensor.\n\n### 1. Data Scaling\n\nNeural networks typically perform better when input values are normalized. The time series data is first scaled to a fixed range, commonly [0, 1], to prevent features with larger magnitudes from dominating the learning process.\n\n### 2. Autoregressive Windowing\n\n- **[Definition] Autoregressive Sequence Pattern**: A data structuring technique where a sequence of past observations (a \"window\") from a time series is used as the set of input features to predict the single next observation. This transforms a time series forecasting problem into a supervised learning problem.\n\nFor a given `window_size` (e.g., 63 days), we slide this window over the time series one step at a time. For each window, the data within the window becomes one sample of our input features (`X`), and the data point immediately following the window becomes the corresponding label (`y`).\n\n### 3. Final Tensor Shaping\n\n- **[Definition] 3D Input Tensor**: The required input shape for Keras RNN layers like LSTM. The dimensions represent `(Batch Size, Time Steps, Features)`.\n    - **Batch Size**: The number of sequences (samples) in a batch. This is often left undefined until training.\n    - **Time Steps**: The length of each sequence, which corresponds to the `window_size`.\n    - **Features**: The number of variables observed at each time step. For a univariate series, this is 1.\n\nAfter creating the 2D matrix of windowed sequences (where rows are samples and columns are time steps), it must be reshaped into a 3D tensor to meet the LSTM layer's input requirements.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Univariate RNN Data Preparation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a raw univariate time series (as a 1D array or list) and a `window_size`, and returns the scaled and shaped `X` (3D tensor) and `y` (1D vector) ready for training an LSTM model.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PrepareUnivariateRNNData(raw_time_series, window_size)\n// INPUTS:\n//   - raw_time_series: A 1D array of numerical time series data.\n//   - window_size: An integer defining the number of past time steps to use as input.\n// OUTPUTS:\n//   - A tuple containing (X_tensor, y_vector).\n//     - X_tensor: A 3D tensor of shape (num_samples, window_size, 1).\n//     - y_vector: A 1D vector of corresponding target values.\n//\n// BEGIN\n//   // Step 1: Scale the data to the [0, 1] range.\n//   scaler = new MinMaxScaler(feature_range=(0, 1))\n//   scaled_data = scaler.fit_transform(raw_time_series.reshape(-1, 1))\n//\n//   // Step 2: Create autoregressive input-output pairs.\n//   X_list = []\n//   y_list = []\n//   num_observations = length(scaled_data)\n//\n//   FOR i FROM 0 TO num_observations - window_size - 1\n//     // Extract the window of past observations.\n//     input_window = scaled_data[i : i + window_size]\n//     // Extract the target value immediately following the window.\n//     target_value = scaled_data[i + window_size]\n//\n//     APPEND input_window TO X_list\n//     APPEND target_value TO y_list\n//   END FOR\n//\n//   // Convert lists to arrays.\n//   X_array = convert_to_array(X_list)\n//   y_vector = convert_to_array(y_list).squeeze()\n//\n//   // Step 3: Reshape the input array to a 3D tensor.\n//   num_samples = X_array.shape[0]\n//   X_tensor = X_array.reshape(num_samples, window_size, 1)\n//\n//   RETURN (X_tensor, y_vector)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 112,
    "text": "## Framework for Multivariate RNN Data Preparation\n\nRecurrent Neural Networks are well-suited for modeling and forecasting multiple time series simultaneously, capturing potential interdependencies between them. This approach requires transforming the data into a specific tensor format.\n\n### Key Concepts\n- **[Definition] Multivariate Time Series**: A dataset containing observations of more than one time-dependent variable recorded over a period of time. The key assumption is that the variables may influence each other.\n- **Stationarity and Scaling**: Before creating sequences, each time series in the dataset should be made stationary (e.g., by differencing) and then scaled (e.g., to a [0, 1] range). This ensures that all series contribute equally to the model's training process, regardless of their original scale.\n\n### Input and Output Tensor Shaping\n\nFor a multivariate problem with `n_series` variables, the goal is to use a window of past observations from *all* series to predict the next observation for *all* series.\n\n- **Input Tensor (`X`)**: The input must be a 3D tensor with the shape `(n_samples, window_size, n_series)`.\n    - `n_samples`: The total number of sliding windows created from the data.\n    - `window_size`: The number of past time steps in each window.\n    - `n_series`: The number of time series variables (features) in the dataset.\n\n- **Output Tensor (`y`)**: The output must be a 2D tensor with the shape `(n_samples, n_series)`. Each row corresponds to the values of all `n_series` variables at the time step immediately following the respective input window.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Multivariate RNN Data Preparation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a preprocessed DataFrame of multiple time series (where columns are series and rows are time steps) and a `window_size`. The function should return the `X` and `y` tensors suitable for training a multivariate LSTM model.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PrepareMultivariateRNNData(data_frame, window_size)\n// INPUTS:\n//   - data_frame: A 2D array or DataFrame where columns represent different time series\n//                 and rows represent time steps. Assumed to be pre-scaled.\n//   - window_size: An integer for the length of the input sequence.\n// OUTPUTS:\n//   - A tuple containing (X_tensor, y_tensor).\n//     - X_tensor: A 3D tensor of shape (n_samples, window_size, n_series).\n//     - y_tensor: A 2D tensor of shape (n_samples, n_series).\n//\n// BEGIN\n//   // Convert DataFrame to a numerical array.\n//   data_array = data_frame.to_values()\n//   n_rows = data_array.shape[0]\n//   n_series = data_array.shape[1]\n//\n//   // Initialize lists to hold the samples.\n//   X_list = []\n//   y_list = []\n//\n//   // Create sliding windows.\n//   FOR i FROM 0 TO n_rows - window_size - 1\n//     // The input is a window of size `window_size` across all series.\n//     input_window = data_array[i : i + window_size, :]\n//     // The output is the single time step immediately following the window, across all series.\n//     output_step = data_array[i + window_size, :]\n//\n//     APPEND input_window TO X_list\n//     APPEND output_step TO y_list\n//   END FOR\n//\n//   // Convert lists to tensors/arrays of the correct shape.\n//   X_tensor = stack(X_list)  // Stacks into (n_samples, window_size, n_series)\n//   y_tensor = stack(y_list)  // Stacks into (n_samples, n_series)\n//\n//   RETURN (X_tensor, y_tensor)\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 113,
    "text": "## Framework Overview\n\nLeveraging pre-trained word embeddings, such as GloVe, allows a model to benefit from linguistic knowledge learned from a massive text corpus. The process involves loading these external vectors and integrating them into a non-trainable `Embedding` layer within your model.\n\n### Step 1: Text Tokenization\n\nFirst, the text data for your specific task must be processed. A `Tokenizer` is used to build a vocabulary (a word-to-index mapping) based on the training documents. The documents are then converted into sequences of integers, where each integer represents a specific word from the vocabulary.\n\n### Step 2: Loading Pre-trained Vectors\n\nThe pre-trained GloVe vectors are loaded from their source file into a dictionary that maps each word (token) to its corresponding numerical vector.\n\n### Step 3: Creating the Embedding Matrix\n\nThis is the crucial step that connects the pre-trained vectors to your dataset's vocabulary.\n\n- **[Definition] Embedding Matrix**: A matrix of shape `(vocabulary_size, embedding_dimension)` where the i-th row contains the pre-trained vector for the i-th word in your dataset's vocabulary. This matrix serves as the initial weight matrix for the Keras `Embedding` layer.\n\nThe process is as follows:\n1.  Initialize a zero matrix with the required shape.\n2.  Iterate through the items (word, index) in your tokenizer's word-to-index map.\n3.  For each word, look up its vector in the loaded GloVe dictionary.\n4.  If the word exists in the GloVe dictionary, place its vector into the `index`-th row of the embedding matrix. Words in your vocabulary but not in GloVe will remain as zero vectors.\n\n### Step 4: Defining the Frozen Embedding Layer\n\nFinally, the `Embedding` layer in the Keras model is defined. The custom embedding matrix is passed to the `weights` argument, and the `trainable` argument is set to `False`. This ensures that the pre-trained weights are used and are not modified during model training, effectively \"freezing\" them.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Pre-trained Embedding Initialization]`**:\n    *   **Task**: Provide the pseudocode for a function that creates an embedding matrix to align a dataset's vocabulary with pre-trained GloVe vectors. The function should then use this matrix to initialize a frozen (non-trainable) Keras `Embedding` layer.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CreateFrozenGloveEmbeddingLayer(word_index, glove_vectors, embedding_dim, max_seq_length)\n// INPUTS:\n//   - word_index: A dictionary mapping words to integer indices (from a Tokenizer).\n//   - glove_vectors: A dictionary mapping words to their pre-trained GloVe vectors.\n//   - embedding_dim: The dimensionality of the GloVe vectors (e.g., 100).\n//   - max_seq_length: The length of the input sequences for the model.\n// OUTPUTS:\n//   - A Keras Embedding layer object, initialized and frozen.\n//\n// BEGIN\n//   // Step 1: Determine the size of the vocabulary.\n//   vocab_size = length(word_index) + 1\n//\n//   // Step 2: Create an empty embedding matrix.\n//   embedding_matrix = create_zero_matrix(rows=vocab_size, cols=embedding_dim)\n//\n//   // Step 3: Populate the embedding matrix.\n//   FOR each word, index IN word_index.items()\n//     vector = glove_vectors.get(word)\n//     IF vector IS NOT NULL THEN\n//       // If the word is found in GloVe, place its vector at the correct index.\n//       embedding_matrix[index] = vector\n//     END IF\n//   END FOR\n//\n//   // Step 4: Create the Keras Embedding layer.\n//   embedding_layer = new Embedding(\n//     input_dim = vocab_size,\n//     output_dim = embedding_dim,\n//     input_length = max_seq_length,\n//     weights = [embedding_matrix], // Initialize with the created matrix\n//     trainable = False           // Freeze the layer weights\n//   )\n//\n//   RETURN embedding_layer\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 114,
    "text": "## Framework Overview\n\nThe NASDAQ TotalView-ITCH data feed provides a granular, real-time stream of all order activity for NASDAQ-listed securities. By processing this stream of binary messages, an algorithmic trader can reconstruct the Limit Order Book (LOB) for any stock at any point in time. This reconstruction is critical for strategies that rely on market microstructure signals, such as liquidity and order flow imbalances.\n\n## Key Concepts\n\n1.  **[Definition] Limit Order Book (LOB)**: A record of all outstanding limit orders for a particular security. It is organized by price level and shows the total number of shares (market depth) available to be bought (bid side) or sold (ask side) at each price point.\n\n2.  **[Definition] ITCH Message Protocol**: A specification that defines the structure and meaning of various binary messages sent by the NASDAQ exchange. Each message type corresponds to a specific event, such as a new order submission, an execution, or a cancellation.\n\n## Core Message Types for LOB Reconstruction\n\nTo maintain the state of the order book, you must process several key message types. Each message contains an `Order Reference Number` that uniquely identifies an order.\n\n*   **Type 'A' (Add Order)**: Signals a new limit order has been added to the book. It includes the order reference number, a buy/sell indicator, the number of shares, the stock symbol, and the price.\n\n*   **Type 'F' (Add Attributed Order)**: Functionally similar to the 'Add Order' message but includes a market participant identifier.\n\n*   **Type 'E' (Order Executed)**: Indicates that an order on the book has been partially or fully executed. It provides the reference number of the order that was executed and the number of shares executed.\n\n*   **Type 'C' (Order Executed with Price)**: Similar to 'Order Executed' but is used when the execution occurs at a price different from the initial display price. It also includes the execution price.\n\n*   **Type 'X' (Order Cancel)**: Indicates that a portion of an order has been canceled. It provides the reference number and the number of shares canceled.\n\n*   **Type 'D' (Order Delete)**: Indicates that an entire order has been removed from the book. It provides the reference number of the order to be deleted.\n\n*   **Type 'U' (Order Replace)**: A compound message that replaces an existing order with a new one. It contains the reference number of the original order and the details (reference number, shares, price) of the new replacement order. This is effectively a cancellation followed by an addition.",
    "question": "1.  **`[LOB Reconstruction Logic]`**:\n    *   **Task**: Provide the pseudocode for a function that processes a single ITCH message and updates the state of a limit order book. The order book can be represented as two dictionaries (bids and asks) where keys are price levels and values are the total volume at that level. The function should also track individual orders by their reference number.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ProcessITCHMessage(message, order_book, individual_orders)\n// INPUTS:\n//   - message: A structured object representing a single parsed ITCH message.\n//   - order_book: A structure containing two dictionaries, 'bids' and 'asks'.\n//                 Keys are prices, values are total shares at that price.\n//   - individual_orders: A dictionary mapping Order Reference Numbers to their details (price, shares, side).\n// OUTPUTS:\n//   - Modifies order_book and individual_orders in place.\n//\n// BEGIN\n//   // Store order details for future reference (executions, cancels)\n//   IF message.type IS 'A' OR message.type IS 'F' THEN\n//     price = message.price\n//     shares = message.shares\n//     side = message.side // 'B' for Buy, 'S' for Sell\n//     order_ref = message.order_reference_number\n//\n//     // Add to individual order tracking\n//     individual_orders[order_ref] = {price: price, shares: shares, side: side}\n//\n//     // Update aggregate order book\n//     IF side IS 'B' THEN\n//       order_book.bids[price] = order_book.bids.get(price, 0) + shares\n//     ELSE\n//       order_book.asks[price] = order_book.asks.get(price, 0) + shares\n//     END IF\n//   END IF\n//\n//   // Handle Executions (reduce shares)\n//   IF message.type IS 'E' OR message.type IS 'C' THEN\n//     order_ref = message.order_reference_number\n//     executed_shares = message.executed_shares\n//\n//     IF order_ref IN individual_orders THEN\n//       order = individual_orders[order_ref]\n//       price = order.price\n//       side = order.side\n//\n//       // Update aggregate book\n//       IF side IS 'B' THEN\n//         order_book.bids[price] = order_book.bids[price] - executed_shares\n//       ELSE\n//         order_book.asks[price] = order_book.asks[price] - executed_shares\n//       END IF\n//\n//       // Clean up price level if volume is zero\n//       IF (side IS 'B' AND order_book.bids[price] <= 0) THEN DELETE order_book.bids[price]\n//       IF (side IS 'S' AND order_book.asks[price] <= 0) THEN DELETE order_book.asks[price]\n//\n//       // Update individual order\n//       order.shares = order.shares - executed_shares\n//       IF order.shares <= 0 THEN DELETE individual_orders[order_ref]\n//     END IF\n//   END IF\n//\n//   // Handle Deletions/Cancellations\n//   IF message.type IS 'D' OR message.type IS 'X' THEN\n//     order_ref = message.order_reference_number\n//     // For 'X', canceled_shares; for 'D', get full share amount from tracking\n//     canceled_shares = 0\n//     IF message.type IS 'X' THEN\n//       canceled_shares = message.canceled_shares\n//     ELSE // Type 'D'\n//       IF order_ref IN individual_orders THEN\n//         canceled_shares = individual_orders[order_ref].shares\n//       END IF\n//     END IF\n//\n//     IF order_ref IN individual_orders AND canceled_shares > 0 THEN\n//       order = individual_orders[order_ref]\n//       price = order.price\n//       side = order.side\n//\n//       // Update aggregate book\n//       IF side IS 'B' THEN\n//         order_book.bids[price] = order_book.bids[price] - canceled_shares\n//       ELSE\n//         order_book.asks[price] = order_book.asks[price] - canceled_shares\n//       END IF\n//\n//       // Clean up price level if volume is zero\n//       IF (side IS 'B' AND order_book.bids[price] <= 0) THEN DELETE order_book.bids[price]\n//       IF (side IS 'S' AND order_book.asks[price] <= 0) THEN DELETE order_book.asks[price]\n//\n//       // Delete from individual tracking if fully canceled\n//       IF message.type IS 'D' THEN DELETE individual_orders[order_ref]\n//       ELSE // Type 'X'\n//         order.shares = order.shares - canceled_shares\n//         IF order.shares <= 0 THEN DELETE individual_orders[order_ref]\n//       END IF\n//     END IF\n//   END IF\n//\n//   // NOTE: Type 'U' (Replace) can be handled as a 'D' for the original order\n//   // followed by an 'A' for the new order.\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 115,
    "text": "## Framework Overview\n\nHigh-frequency trade data, often called tick data, arrives at irregular intervals and contains significant noise (e.g., bid-ask bounce). To make this data useful for analysis and model building, it must be regularized into a standard format. Time bars are the most common method for this regularization.\n\n## Key Concepts\n\n1.  **[Definition] Tick Data**: A stream of records where each record represents a single trade, containing at a minimum a timestamp, price, and volume (number of shares).\n\n2.  **[Definition] Time Bars**: A data structure where tick data is aggregated into fixed time intervals (e.g., 1 minute, 5 minutes, 1 hour). Each bar summarizes the trading activity within its interval.\n\n## Computational Steps\n\nThe process of creating time bars from a series of trades involves grouping the trades by a fixed time frequency and then computing summary statistics for each group.\n\n1.  **Grouping**: All trades that occur within a specific time window (e.g., from 09:30:00 to 09:30:59 for one-minute bars) are collected together.\n\n2.  **Open, High, Low, Close (OHLC)**: For each group of trades:\n    *   **Open**: The price of the *first* trade in the interval.\n    *   **High**: The *maximum* trade price in the interval.\n    *   **Low**: The *minimum* trade price in the interval.\n    *   **Close**: The price of the *last* trade in the interval.\n\n3.  **Volume**: The sum of the number of shares for all trades within the interval.\n\n4.  **Volume-Weighted Average Price (VWAP)**: The average price of trades in the interval, weighted by their volume. It is calculated as:\n\n    *Equation 1: VWAP Calculation*\n    ```\n    VWAP = 鍗?Price_i * Volume_i) / 鍗?Volume_i)\n    ```\n    Where:\n    *   `Price_i` is the price of trade `i`.\n    *   `Volume_i` is the volume (shares) of trade `i`.\n    *   The summation is over all trades `i` within the time interval.",
    "question": "1.  **`[Time Bar Aggregation Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a list of tick trades and a time frequency (e.g., '1Min') and returns a list of time bars, where each bar contains the open, high, low, close, volume, and VWAP for that interval.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CreateTimeBars(ticks, frequency)\n// INPUTS:\n//   - ticks: A list of trade objects, where each object has {timestamp, price, shares}.\n//   - frequency: A string representing the time interval (e.g., '1Min', '5Min').\n// OUTPUTS:\n//   - A list of bar objects, where each object has {timestamp, open, high, low, close, volume, vwap}.\n//\n// BEGIN\n//   IF ticks is empty THEN RETURN empty list\n//\n//   // Group ticks by the specified time frequency\n//   grouped_ticks = GroupByTime(ticks, frequency)\n//\n//   time_bars = []\n//   // Iterate through each time interval group\n//   FOR each group in grouped_ticks:\n//     // Ensure the group is not empty\n//     IF group is not empty THEN\n//       // 1. Calculate OHLC\n//       open_price = group[0].price\n//       close_price = group[last].price\n//       high_price = max(trade.price for trade in group)\n//       low_price = min(trade.price for trade in group)\n//\n//       // 2. Calculate Total Volume\n//       total_volume = sum(trade.shares for trade in group)\n//\n//       // 3. Calculate VWAP\n//       total_value = sum(trade.price * trade.shares for trade in group)\n//       vwap = total_value / total_volume IF total_volume > 0 ELSE close_price\n//\n//       // 4. Create the bar object\n//       bar = {\n//         timestamp: group.start_time, // The timestamp for the beginning of the bar interval\n//         open: open_price,\n//         high: high_price,\n//         low: low_price,\n//         close: close_price,\n//         volume: total_volume,\n//         vwap: vwap\n//       }\n//       APPEND bar to time_bars\n//     END IF\n//   END FOR\n//\n//   RETURN time_bars\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 116,
    "text": "## Framework Overview\n\nStandard time bars can be problematic because market activity is not uniform over time. During periods of low activity, a time bar might contain very few trades and little information. Conversely, during high activity, a single time bar might obscure significant price movements by aggregating too many events. Volume bars address this by sampling data based on market activity.\n\n## Key Concepts\n\n1.  **[Definition] Order Fragmentation**: The practice of splitting a single large order into multiple smaller trades for execution. This can cause a burst of trading activity that is not necessarily driven by new information.\n\n2.  **[Definition] Volume Bars**: A data structure where tick data is aggregated into bars that each contain a fixed, predetermined amount of total traded volume (shares). The time duration of each bar is variable; bars complete faster during high-activity periods and slower during low-activity periods.\n\n## Computational Steps\n\nThe process of creating volume bars requires iterating through tick data and accumulating trades until a volume threshold is met.\n\n1.  **Define Threshold**: Determine the target volume for each bar. This can be a fixed number (e.g., 100,000 shares) or calculated dynamically (e.g., the average volume traded per minute on a typical day).\n\n2.  **Iterate and Accumulate**: Process trades sequentially. For each trade, add its volume to a running counter for the current bar being built. Collect all trades belonging to the current bar.\n\n3.  **Bar Completion**: Once the accumulated volume in the running counter meets or exceeds the defined threshold, the current bar is considered complete.\n\n4.  **Calculate Statistics**: For the collection of trades that form the completed bar, calculate the standard summary statistics: Open, High, Low, Close (OHLC), total volume, and Volume-Weighted Average Price (VWAP).\n\n5.  **Reset and Continue**: After a bar is formed, reset the volume counter and begin accumulating trades for the next bar. Any excess volume from the trade that completed the previous bar is carried over to start the new bar.",
    "question": "1.  **`[Volume Bar Aggregation Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a list of tick trades and a target volume-per-bar, and returns a list of volume bars. The logic should correctly handle the creation of bars once the volume threshold is reached.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CreateVolumeBars(ticks, volume_per_bar)\n// INPUTS:\n//   - ticks: A list of trade objects, where each object has {timestamp, price, shares}.\n//   - volume_per_bar: An integer representing the target volume for each bar.\n// OUTPUTS:\n//   - A list of bar objects, where each object has {timestamp, open, high, low, close, volume, vwap}.\n//\n// BEGIN\n//   IF ticks is empty THEN RETURN empty list\n//\n//   volume_bars = []\n//   current_bar_ticks = []\n//   accumulated_volume = 0\n//\n//   // Iterate through each tick\n//   FOR each tick in ticks:\n//     accumulated_volume = accumulated_volume + tick.shares\n//     APPEND tick to current_bar_ticks\n//\n//     // Check if the bar completion threshold is met or exceeded\n//     IF accumulated_volume >= volume_per_bar THEN\n//       // Calculate statistics for the completed bar\n//       open_price = current_bar_ticks[0].price\n//       close_price = current_bar_ticks[last].price\n//       high_price = max(trade.price for trade in current_bar_ticks)\n//       low_price = min(trade.price for trade in current_bar_ticks)\n//       total_volume = sum(trade.shares for trade in current_bar_ticks)\n//       total_value = sum(trade.price * trade.shares for trade in current_bar_ticks)\n//       vwap = total_value / total_volume\n//\n//       // Create the bar object\n//       bar = {\n//         timestamp: current_bar_ticks[last].timestamp, // Timestamp of the last trade in the bar\n//         open: open_price,\n//         high: high_price,\n//         low: low_price,\n//         close: close_price,\n//         volume: total_volume,\n//         vwap: vwap\n//       }\n//       APPEND bar to volume_bars\n//\n//       // Reset for the next bar\n//       current_bar_ticks = []\n//       accumulated_volume = 0\n//     END IF\n//   END FOR\n//\n//   // Note: Any remaining ticks that did not form a full bar are discarded in this implementation.\n//\n//   RETURN volume_bars\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 117,
    "text": "## Framework Overview\n\nWhile volume bars improve upon time bars by sampling based on activity, they can be distorted by large price changes or corporate actions like stock splits. For example, 100,000 shares of a $10 stock represents a much smaller market value than 100,000 shares of a $500 stock. Dollar bars (or value bars) provide a more stable alternative by aggregating trades based on the total value exchanged, making them robust to such changes.\n\n## Key Concepts\n\n1.  **[Definition] Traded Value**: For a single trade, this is the product of the trade price and the number of shares (`Price * Volume`). It represents the total dollar amount of the transaction.\n\n2.  **[Definition] Dollar Bars**: A data structure where tick data is aggregated into bars that each contain a fixed, predetermined amount of total traded value. Like volume bars, the time duration of each dollar bar is variable, adapting to market activity and price levels.\n\n## Computational Steps\n\nThe logic for creating dollar bars is very similar to that for volume bars, but the accumulation is based on value instead of shares.\n\n1.  **Define Threshold**: Determine the target traded value for each bar. This could be a fixed number (e.g., $1,000,000) or calculated dynamically (e.g., the average value traded per minute on a typical day).\n\n2.  **Iterate and Accumulate**: Process trades sequentially. For each trade, calculate its value (`price * shares`) and add it to a running counter for the current bar being built. Collect all trades belonging to the current bar.\n\n3.  **Bar Completion**: Once the accumulated value in the running counter meets or exceeds the defined threshold, the current bar is considered complete.\n\n4.  **Calculate Statistics**: For the collection of trades that form the completed bar, calculate the standard summary statistics: Open, High, Low, Close (OHLC), total volume (sum of shares), and Volume-Weighted Average Price (VWAP).\n\n5.  **Reset and Continue**: After a bar is formed, reset the value counter and begin accumulating trades for the next bar.",
    "question": "1.  **`[Dollar Bar Aggregation Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a list of tick trades and a target dollar-value-per-bar, and returns a list of dollar bars. The logic must correctly accumulate the traded value to determine bar boundaries.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CreateDollarBars(ticks, value_per_bar)\n// INPUTS:\n//   - ticks: A list of trade objects, where each object has {timestamp, price, shares}.\n//   - value_per_bar: A float representing the target traded value for each bar.\n// OUTPUTS:\n//   - A list of bar objects, where each object has {timestamp, open, high, low, close, volume, vwap}.\n//\n// BEGIN\n//   IF ticks is empty THEN RETURN empty list\n//\n//   dollar_bars = []\n//   current_bar_ticks = []\n//   accumulated_value = 0.0\n//\n//   // Iterate through each tick\n//   FOR each tick in ticks:\n//     trade_value = tick.price * tick.shares\n//     accumulated_value = accumulated_value + trade_value\n//     APPEND tick to current_bar_ticks\n//\n//     // Check if the bar completion threshold is met or exceeded\n//     IF accumulated_value >= value_per_bar THEN\n//       // Calculate statistics for the completed bar\n//       open_price = current_bar_ticks[0].price\n//       close_price = current_bar_ticks[last].price\n//       high_price = max(trade.price for trade in current_bar_ticks)\n//       low_price = min(trade.price for trade in current_bar_ticks)\n//       total_volume = sum(trade.shares for trade in current_bar_ticks)\n//       total_value_in_bar = sum(trade.price * trade.shares for trade in current_bar_ticks)\n//       vwap = total_value_in_bar / total_volume IF total_volume > 0 ELSE close_price\n//\n//       // Create the bar object\n//       bar = {\n//         timestamp: current_bar_ticks[last].timestamp, // Timestamp of the last trade in the bar\n//         open: open_price,\n//         high: high_price,\n//         low: low_price,\n//         close: close_price,\n//         volume: total_volume,\n//         vwap: vwap\n//       }\n//       APPEND bar to dollar_bars\n//\n//       // Reset for the next bar\n//       current_bar_ticks = []\n//       accumulated_value = 0.0\n//     END IF\n//   END FOR\n//\n//   // Note: Any remaining ticks that did not form a full bar are discarded.\n//\n//   RETURN dollar_bars\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 118,
    "text": "## Framework Overview\n\nFundamental analysis is a cornerstone of many trading strategies. By systematically processing public financial filings from the SEC, an algorithmic trader can construct time series of key financial metrics. Combining this fundamental data with market price data allows for the creation of valuation ratios, such as the Price-to-Earnings (P/E) ratio, which can be used as trading signals.\n\n## Key Concepts\n\n1.  **[Definition] EDGAR (Electronic Data Gathering, Analysis, and Retrieval)**: The SEC's system for collecting, validating, and disseminating corporate filings. It is the primary source for fundamental data on U.S. public companies.\n\n2.  **[Definition] XBRL (eXtensible Business Reporting Language)**: A standardized, XML-based format for electronic business reporting. The SEC requires filings to be submitted in XBRL, which allows for automated extraction of specific data points (e.g., revenue, net income) using predefined tags.\n\n3.  **[Definition] Price-to-Earnings (P/E) Ratio**: A valuation metric calculated by dividing a company's stock price by its earnings per share (EPS). A trailing P/E ratio uses the sum of the last four quarters of EPS.\n\n## Computational Steps\n\nBuilding a historical P/E ratio series involves a multi-stage data processing pipeline:\n\n1.  **Data Acquisition**: Download and parse historical quarterly (10-Q) and annual (10-K) filings for a target company from the SEC's FSN (Financial Statement and Notes) datasets.\n\n2.  **EPS Extraction**: From the parsed numerical data, filter for the specific XBRL tag corresponding to 'EarningsPerShareDiluted'. Ensure that only quarterly values (qtrs=1) are selected to avoid double-counting.\n\n3.  **Corporate Action Adjustment**: Historical per-share data must be adjusted for events like stock splits to be comparable over time. For a stock split (e.g., a 7-for-1 split), all EPS values *before* the split date must be divided by the split ratio (7).\n\n4.  **Trailing 12-Month (TTM) EPS Calculation**: Calculate a rolling sum of the last four adjusted quarterly EPS values. This creates a smooth, trailing 12-month EPS series.\n\n5.  **Integration with Market Data**: Obtain historical daily stock prices for the same company. Align the price data with the TTM EPS data. Since EPS is reported quarterly, the most recent TTM EPS value should be forward-filled until a new value is reported.\n\n6.  **P/E Ratio Calculation**: Divide the daily stock price by the corresponding forward-filled TTM EPS value to get the final daily P/E ratio time series.",
    "question": "1.  **`[P/E Ratio Pipeline Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that orchestrates the creation of a P/E ratio time series. The function should take raw quarterly EPS data, historical price data, and stock split information as inputs and produce a final daily P/E series.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION GeneratePERatioSeries(quarterly_eps, daily_prices, stock_split_info)\n// INPUTS:\n//   - quarterly_eps: A list of {date, eps_value} objects, one for each quarter.\n//   - daily_prices: A list of {date, close_price} objects.\n//   - stock_split_info: An object containing {split_date, split_ratio}, e.g., {date: '2014-06-04', ratio: 7.0}.\n// OUTPUTS:\n//   - A time series (list of {date, pe_ratio}) of the daily P/E ratio.\n//\n// BEGIN\n//   // Step 1: Adjust historical EPS for stock splits\n//   adjusted_eps = []\n//   FOR each record in quarterly_eps:\n//     IF record.date < stock_split_info.split_date THEN\n//       adjusted_value = record.eps_value / stock_split_info.ratio\n//     ELSE\n//       adjusted_value = record.eps_value\n//     END IF\n//     APPEND {date: record.date, eps_value: adjusted_value} to adjusted_eps\n//   END FOR\n//\n//   // Step 2: Calculate Trailing 12-Month (TTM) EPS\n//   // Assumes adjusted_eps is sorted by date\n//   ttm_eps_series = []\n//   FOR i from 3 to length(adjusted_eps) - 1:\n//     // Sum the current quarter and the previous three\n//     ttm_value = adjusted_eps[i].eps_value + adjusted_eps[i-1].eps_value + adjusted_eps[i-2].eps_value + adjusted_eps[i-3].eps_value\n//     APPEND {date: adjusted_eps[i].date, ttm_eps: ttm_value} to ttm_eps_series\n//   END FOR\n//\n//   // Step 3: Combine price data with forward-filled TTM EPS\n//   combined_series = []\n//   current_ttm_eps = NULL\n//   ttm_eps_index = 0\n//\n//   FOR each price_record in daily_prices:\n//     // Update the current TTM EPS if we pass a new reporting date\n//     IF ttm_eps_index < length(ttm_eps_series) AND price_record.date >= ttm_eps_series[ttm_eps_index].date THEN\n//       current_ttm_eps = ttm_eps_series[ttm_eps_index].ttm_eps\n//       ttm_eps_index = ttm_eps_index + 1\n//     END IF\n//\n//     // Only start calculating once we have a valid TTM EPS\n//     IF current_ttm_eps IS NOT NULL AND current_ttm_eps > 0 THEN\n//       pe_ratio = price_record.close_price / current_ttm_eps\n//       APPEND {date: price_record.date, pe_ratio: pe_ratio} to combined_series\n//     END IF\n//   END FOR\n//\n//   RETURN combined_series\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 119,
    "text": "### 1. Framework Overview\nAn autoencoder is a neural network trained to reconstruct its input. It consists of two main parts: an encoder that compresses the input into a lower-dimensional latent representation (encoding), and a decoder that reconstructs the original input from this encoding. This process forces the network to learn the most salient features of the data.\n\n- **[Definition] Autoencoder**: A neural network architecture used for unsupervised learning of efficient data codings. It learns a compressed representation (encoding) for a set of data, typically for the purpose of dimensionality reduction or feature learning.\n- **[Definition] Denoising Autoencoder**: A variant of the autoencoder that receives a corrupted data sample as input and is trained to reconstruct the original, uncorrupted sample. This forces the model to learn robust features and ignore noise.\n\n### 2. Convolutional Autoencoder Architecture\nFor data with a grid-like structure, such as images or certain financial time series representations, convolutional autoencoders are particularly effective. They leverage convolutional layers to capture spatial hierarchies and local patterns.\n\n- **[Definition] Convolutional Autoencoder**: An autoencoder that uses convolutional layers in the encoder to capture spatial features and transposed convolutions or upsampling layers in the decoder to reconstruct the spatial structure.\n\n### 3. Implementation Details\nThe model will be built with a symmetric encoder-decoder structure. The input is a 2D grid (e.g., a 28x28 image).\n\n**A. The Encoder:**\nThe encoder's role is to reduce the spatial dimensions of the input while increasing the number of feature maps (filters). This creates a dense, feature-rich encoding.\n1.  **Input Layer**: Accepts the initial 2D data.\n2.  **Convolutional Blocks**: A sequence of `Convolutional Layer` followed by a `Max Pooling Layer`. Each block reduces the height and width of the feature maps.\n    *   Example Block 1: `Conv2D` with 32 filters -> `MaxPooling2D`.\n    *   Example Block 2: `Conv2D` with 16 filters -> `MaxPooling2D`.\n    *   Example Block 3: `Conv2D` with 8 filters -> `MaxPooling2D`.\n\n**B. The Decoder:**\nThe decoder's role is to reverse the encoder's process. It takes the compressed feature representation and reconstructs the original input dimensions.\n1.  **Upsampling Blocks**: A sequence of a `Convolutional Layer` followed by an `Upsampling Layer`. Each block increases the height and width of the feature maps, progressively rebuilding the original spatial dimensions.\n    *   Example Block 1: `Conv2D` with 8 filters -> `UpSampling2D`.\n    *   Example Block 2: `Conv2D` with 16 filters -> `UpSampling2D`.\n    *   Example Block 3: `Conv2D` with 32 filters -> `UpSampling2D`.\n2.  **Output Layer**: A final `Convolutional Layer` with a single filter and a `sigmoid` activation function to produce the reconstructed output, ensuring pixel values are between 0 and 1.\n\n**C. Training:**\nTo train a standard autoencoder, the model is compiled with a loss function like Mean Squared Error (MSE), using the same dataset for both inputs and target outputs. For a denoising autoencoder, the model is trained on noisy inputs with the original, clean data as the target output.",
    "question": "Based on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Convolutional Autoencoder Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that constructs and returns a deep convolutional autoencoder model. The model should accept a 2D input shape and follow the symmetric encoder-decoder structure described in the text.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION BuildConvolutionalAutoencoder(input_shape)\n// INPUTS:\n//   - input_shape: A tuple representing the dimensions of the input data (e.g., (28, 28, 1)).\n// OUTPUTS:\n//   - A compiled autoencoder model.\n//\n// BEGIN\n//   // Define the input layer\n//   SET input_layer = Input(shape = input_shape)\n\n//   // --- Encoder Architecture ---\n//   // First convolutional block\n//   SET x = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\n//   SET x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n//   // Second convolutional block\n//   SET x = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(x)\n//   SET x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n//   // Third convolutional block (creates the encoded representation)\n//   SET x = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(x)\n//   SET encoded = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n\n//   // --- Decoder Architecture ---\n//   // First upsampling block\n//   SET x = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(encoded)\n//   SET x = UpSampling2D(size=(2,2))(x)\n//   // Second upsampling block\n//   SET x = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(x)\n//   SET x = UpSampling2D(size=(2,2))(x)\n//   // Third upsampling block\n//   SET x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x) // Note: 'same' padding might not be needed here depending on exact dimensions\n//   SET x = UpSampling2D(size=(2,2))(x)\n\n//   // Output layer to reconstruct the original image dimensions\n//   SET decoded = Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(x)\n\n//   // --- Model Compilation ---\n//   // Create the autoencoder model by specifying inputs and outputs\n//   SET autoencoder = Model(inputs=input_layer, outputs=decoded)\n//   // Compile the model with an optimizer and loss function\n//   autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n\n//   RETURN autoencoder\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 120,
    "text": "### Framework Overview\n\nA Generative Adversarial Network (GAN) is a system of two competing neural networks used in unsupervised machine learning. The goal is to generate new, synthetic instances of data that are indistinguishable from real data.\n\n- **[Definition] Generator**: A neural network that learns to create plausible data. It takes a random noise vector as input and upsamples it to produce a sample (e.g., an image) that resembles the training data.\n- **[Definition] Discriminator**: A neural network that learns to distinguish between real data from the training set and fake data produced by the generator. It acts as a binary classifier.\n- **[Definition] Adversarial Training**: The process where the Generator and Discriminator are trained simultaneously in a zero-sum game. The Generator's objective is to fool the Discriminator, while the Discriminator's objective is to correctly identify the Generator's fakes. Over time, the Generator becomes proficient at creating realistic data.\n\n### Loss Functions\n\nThe competitive dynamic is managed through specialized loss functions:\n\n1.  **Generator Loss**: This loss quantifies how well the Generator is fooling the Discriminator. It is calculated using binary cross-entropy between the Discriminator's predictions on fake images and a target of all ones (since the Generator *wants* the Discriminator to think the fake images are real).\n\n    ```\n    function generator_loss(discriminator_output_on_fake_data):\n        target_labels = create_tensor_of_ones(shape_of(discriminator_output_on_fake_data))\n        return binary_cross_entropy(targets=target_labels, predictions=discriminator_output_on_fake_data)\n    ```\n\n2.  **Discriminator Loss**: This loss is the sum of two components:\n    *   The loss for correctly identifying real images (predictions on real images vs. a target of ones).\n    *   The loss for correctly identifying fake images (predictions on fake images vs. a target of zeros).\n\n    ```\n    function discriminator_loss(discriminator_output_on_real_data, discriminator_output_on_fake_data):\n        real_loss = binary_cross_entropy(targets=ones, predictions=discriminator_output_on_real_data)\n        fake_loss = binary_cross_entropy(targets=zeros, predictions=discriminator_output_on_fake_data)\n        return real_loss + fake_loss\n    ```\n\n### The Adversarial Training Step\n\nA single training step encapsulates one round of this competition. It consists of five sequential operations:\n\n1.  **Input Provision**: Generate a batch of random noise for the Generator and retrieve a batch of real images from the dataset.\n2.  **Model Forward Pass**: Pass the noise through the Generator to create fake images. Then, pass both the real and fake images through the Discriminator to get its predictions.\n3.  **Loss Calculation**: Compute the Generator's loss and the Discriminator's loss using their respective outputs from the forward pass.\n4.  **Gradient Calculation**: Compute the gradients of each model's loss with respect to its own trainable parameters (weights and biases).\n5.  **Weight Update**: Apply the computed gradients to update each model's parameters using an optimizer (e.g., Adam), which constitutes one step of backpropagation for each network.",
    "question": "Provide the pseudocode for a function that executes a single, complete training step for a Deep Convolutional Generative Adversarial Network (DCGAN), encompassing both the generator and discriminator updates.",
    "answer": "```\n// --- BEGIN PSEUCOCODE ---\n//\n// FUNCTION train_step(real_images, generator, discriminator, gen_optimizer, disc_optimizer, batch_size, noise_dim)\n// INPUTS:\n//   - real_images: A batch of real images from the training dataset.\n//   - generator: The generator model.\n//   - discriminator: The discriminator model.\n//   - gen_optimizer: The optimizer for the generator.\n//   - disc_optimizer: The optimizer for the discriminator.\n//   - batch_size: The number of samples in a batch.\n//   - noise_dim: The dimensionality of the random noise vector for the generator.\n// OUTPUTS:\n//   - gen_loss: The calculated loss for the generator in this step.\n//   - disc_loss: The calculated loss for the discriminator in this step.\n//\n// BEGIN\n//   // Step 1: Provide minibatch inputs\n//   noise = generate_random_normal_vector(shape=[batch_size, noise_dim])\n//\n//   // Use a gradient tape to record operations for automatic differentiation\n//   START_GRADIENT_TAPE for generator as gen_tape\n//   START_GRADIENT_TAPE for discriminator as disc_tape\n//\n//     // Step 2: Get models' outputs\n//     generated_images = generator.predict(noise, training=True)\n//\n//     real_output = discriminator.predict(real_images, training=True)\n//     fake_output = discriminator.predict(generated_images, training=True)\n//\n//     // Step 3: Compute the loss for each model\n//     gen_loss = calculate_generator_loss(fake_output)\n//     disc_loss = calculate_discriminator_loss(real_output, fake_output)\n//\n//   // Step 4: Obtain the gradients for the loss\n//   grad_generator = gen_tape.compute_gradient(gen_loss, generator.trainable_variables)\n//   grad_discriminator = disc_tape.compute_gradient(disc_loss, discriminator.trainable_variables)\n//\n//   // Step 5: Apply the gradients to update model weights\n//   gen_optimizer.apply_gradients(grad_generator, generator.trainable_variables)\n//   disc_optimizer.apply_gradients(grad_discriminator, discriminator.trainable_variables)\n//\n//   RETURN gen_loss, disc_loss\n//\n// END\n//\n// --- END PSEUCOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 121,
    "text": "### MDP Framework\n\nReinforcement learning problems can often be formalized as a Markov Decision Process (MDP), which provides a mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker.\n\n- **[Definition] Markov Decision Process (MDP)**: An MDP is defined by a set of states (S), a set of actions (A), a transition probability function P(s'|s, a) that gives the probability of transitioning to state s' from state s after taking action a, and a reward function R(s, a, s').\n- **[Definition] State-Value Function v(s)**: The state-value function represents the expected cumulative discounted reward an agent can achieve starting from a state 's' and following a specific policy. The optimal state-value function, denoted v*(s), is the maximum possible expected return from state 's'.\n\n### The Bellman Optimality Equation\n\nThe optimal state-value function v*(s) is unique and satisfies a special recursive relationship known as the Bellman optimality equation. It states that the value of a state under an optimal policy must equal the expected return for the best action from that state.\n\n- **[Definition] Bellman Optimality Equation**: The equation expresses the value of a state as the reward obtained from the optimal action plus the discounted value of the successor state.\n\n**Equation 1: Bellman Optimality for v*(s)**\n```\nv*(s) = max_a 鍗盻{s'} P(s'|s, a) [R(s, a, s') + 绾?* v*(s')]\n```\nWhere:\n- `v*(s)` is the optimal value of the current state `s`.\n- `max_a` denotes the maximum value over all possible actions `a`.\n- `鍗盻{s'}` is the sum over all possible next states `s'`.\n- `P(s'|s, a)` is the probability of transitioning to state `s'` from `s` given action `a`.\n- `R(s, a, s')` is the immediate reward received.\n- `绾琡 (gamma) is the discount factor (0 閳?绾?閳?1).\n\n### Value Iteration Algorithm\n\nValue Iteration is a dynamic programming algorithm that solves the Bellman optimality equation iteratively. It starts with an arbitrary value function and repeatedly updates it until it converges to the optimal value function v*.\n\nThe core of the algorithm is the iterative update rule, which is a direct application of the Bellman optimality equation:\n\n**Equation 2: Value Iteration Update Rule**\n```\nv_{k+1}(s) 閳?max_a 鍗盻{s'} P(s'|s, a) [R(s, a, s') + 绾?* v_k(s')]\n```\nThe algorithm terminates when the value function changes by a negligible amount between iterations, defined by a small threshold 钄?(epsilon).",
    "question": "Provide the pseudocode for the Value Iteration algorithm to compute the optimal state-value function for a finite MDP, given the complete dynamics of the environment.",
    "answer": "```\n// --- BEGIN PSEUCOCODE ---\n//\n// FUNCTION ValueIteration(states, actions, transition_probabilities, rewards, gamma, epsilon)\n// INPUTS:\n//   - states: The set of all possible states in the MDP.\n//   - actions: The set of all possible actions.\n//   - transition_probabilities: A mapping P(s'|s, a) for all s, a, s'.\n//   - rewards: A mapping R(s, a, s') for all s, a, s'.\n//   - gamma: The discount factor (e.g., 0.99).\n//   - epsilon: A small positive number for the convergence threshold (e.g., 1e-5).\n// OUTPUTS:\n//   - V: The optimal state-value function.\n//\n// BEGIN\n//   // Initialize the value function for all states to zero (or randomly)\n//   V = initialize_array_with_zeros(size=number_of_states)\n//\n//   LOOP indefinitely:\n//     // Store the old value function to check for convergence\n//     V_old = copy(V)\n//     max_change = 0\n//\n//     // Iterate over every state\n//     FOR EACH state s IN states:\n//       // Find the best action by looking one step ahead\n//       action_values = create_empty_array()\n//       FOR EACH action a IN actions:\n//         // Calculate the expected value of taking this action\n//         expected_value = 0\n//         FOR EACH next_state s_prime IN states:\n//           prob = transition_probabilities[s, a, s_prime]\n//           reward = rewards[s, a, s_prime]\n//           expected_value += prob * (reward + gamma * V_old[s_prime])\n//         END FOR\n//         add expected_value to action_values\n//       END FOR\n//\n//       // Update the value of the current state with the max action value\n//       V[s] = max(action_values)\n//\n//       // Track the maximum change in the value function in this iteration\n//       max_change = max(max_change, absolute(V[s] - V_old[s]))\n//     END FOR\n//\n//     // Check for convergence\n//     IF max_change < epsilon THEN\n//       BREAK LOOP\n//     END IF\n//   END LOOP\n//\n//   RETURN V\n//\n// END\n//\n// --- END PSEUCOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 122,
    "text": "### Core Concept: Q-Learning\n\n- **[Definition] Q-Learning**: A model-free, off-policy reinforcement learning algorithm that learns an optimal action-value function, denoted Q*(s, a). This function represents the maximum expected future reward an agent can get by taking action 'a' in state 's'. Unlike model-based methods, Q-learning does not require knowledge of the environment's transition probabilities or reward functions.\n\n- **[Definition] Temporal Difference (TD) Learning**: The core learning mechanism in Q-learning. Instead of waiting for the final outcome of an episode, TD learning updates its value estimates based on the value estimates of subsequent states. This process of updating an estimate using another learned estimate is called bootstrapping.\n\n### The Q-Learning Update Rule\n\nThe algorithm iteratively updates its Q-value estimates using the Bellman equation. After taking action A_t in state S_t and observing the reward R_{t+1} and next state S_{t+1}, the Q-value is updated as follows:\n\n**Equation 1: Q-Value Update**\n```\nQ(S_t, A_t) 閳?Q(S_t, A_t) + 浼?* [R_{t+1} + 绾?* max_a Q(S_{t+1}, a) - Q(S_t, A_t)]\n```\nWhere:\n- `Q(S_t, A_t)` is the current Q-value for the state-action pair.\n- `浼猔 (alpha) is the learning rate, controlling how much new information overrides old information.\n- `R_{t+1}` is the immediate reward received.\n- `绾琡 (gamma) is the discount factor.\n- `max_a Q(S_{t+1}, a)` is the agent's estimate of the optimal future value from the next state (the TD target).\n\n### Balancing Exploration and Exploitation\n\nTo ensure the agent discovers the optimal policy, it must balance exploring new actions with exploiting known good actions.\n\n- **[Definition] Epsilon-Greedy Policy (钄?greedy)**: A simple and effective strategy for balancing this trade-off. With probability `钄歚 (epsilon), the agent chooses a random action (exploration). With probability `1-钄歚, the agent chooses the action with the highest current Q-value for the given state (exploitation). Typically, `钄歚 is set to a higher value at the beginning of training and gradually decayed.",
    "question": "Provide the pseudocode for the main training loop of a Q-Learning agent. The algorithm should run for a specified number of episodes and use an 钄?greedy policy for action selection.",
    "answer": "```\n// --- BEGIN PSEUCOCODE ---\n//\n// FUNCTION QLearningTrainingLoop(environment, num_episodes, alpha, gamma, epsilon)\n// INPUTS:\n//   - environment: The agent's environment, with functions like reset() and step().\n//   - num_episodes: The total number of episodes to train for.\n//   - alpha: The learning rate.\n//   - gamma: The discount factor.\n//   - epsilon: The probability for choosing a random action (exploration).\n// OUTPUTS:\n//   - Q_table: The learned action-value function, mapping state-action pairs to values.\n//\n// BEGIN\n//   // Initialize the Q-table with zeros for all state-action pairs.\n//   Q_table = initialize_table_with_zeros(states, actions)\n//\n//   // Loop for each episode\n//   FOR episode from 1 to num_episodes:\n//     // Reset the environment and get the initial state\n//     state = environment.reset()\n//     done = false\n//\n//     // Loop for each step of the episode\n//     WHILE not done:\n//       // 1. Choose an action using the Epsilon-Greedy policy\n//       IF random_uniform(0, 1) < epsilon THEN\n//         // Exploration: Select a random action\n//         action = environment.sample_random_action()\n//       ELSE\n//         // Exploitation: Select the best known action for the current state\n//         action = argmax(Q_table[state])\n//       END IF\n//\n//       // 2. Take the action and observe the outcome\n//       next_state, reward, done = environment.step(action)\n//\n//       // 3. Update the Q-table using the Bellman equation\n//       old_value = Q_table[state, action]\n//       next_max = max(Q_table[next_state])\n//\n//       // The core Q-learning update rule\n//       new_value = old_value + alpha * (reward + gamma * next_max - old_value)\n//       Q_table[state, action] = new_value\n//\n//       // 4. Update the state\n//       state = next_state\n//     END WHILE\n//   END FOR\n//\n//   RETURN Q_table\n//\n// END\n//\n// --- END PSEUCOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 123,
    "text": "## Computational Steps\nEngineering predictive features from raw price data is a foundational step in quantitative trading. The process involves transforming a simple time series of prices into a rich dataset containing historical returns, lagged features, and forward-looking targets.\n\n### 1. Initial Data Preparation\n- **[Definition] Wide vs. Long Format**: Price data is often in a 'wide' format, with timestamps as rows and asset tickers as columns. For many calculations, it's useful to work with this format. Subsequent analysis might require converting it to a 'long' format with a `MultiIndex` of (ticker, date).\n- **Resampling**: To analyze longer-term trends or reduce computational load, daily data can be resampled to a lower frequency, such as monthly, by taking the last price of the period.\n\n### 2. Calculating Multi-Period Returns\nThe `pct_change(periods)` method is used to calculate returns over a given number of periods (lags).\n- **Normalization**: For comparing returns over different time horizons (e.g., 3-month vs. 12-month), it is crucial to normalize them to a common periodicity. This is achieved by calculating the geometric average return.\n    - The formula for a normalized return over `L` periods is: `((P_t / P_{t-L}) ^ (1/L)) - 1`\n- **Outlier Capping (Winsorization)**: To reduce the impact of extreme outliers, returns can be clipped at specific quantiles (e.g., the 1st and 99th percentiles).\n\n### 3. Creating Lagged and Forward Returns\n- **Lagged Features**: To use past returns as predictive features for the current observation, the `.shift(t)` method is used. A positive `t` shifts data forward, making past data align with the current time step.\n- **Forward Returns (Targets)**: To create labels for a machine learning model, we need to calculate future returns. The `.shift(-t)` method is used to pull future returns back to the current time step, aligning them as a target for the current set of features.",
    "question": "1.  **`[Time-Series Feature Engineering Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a wide-format DataFrame of monthly asset prices and generates a long-format DataFrame containing normalized multi-period historical returns, lagged 1-month returns, and multi-period forward returns.",
    "answer": "```pseudocode\nFUNCTION GenerateTimeSeriesFeatures(monthly_prices_df, historical_lags, forward_periods, lagged_features_count)\n// INPUTS:\n//   - monthly_prices_df: A DataFrame with DatetimeIndex and asset tickers as columns.\n//   - historical_lags: An array of integers for historical return periods (e.g., [1, 3, 6, 12]).\n//   - forward_periods: An array of integers for forward return (target) periods (e.g., [1, 3, 6]).\n//   - lagged_features_count: An integer for the number of lagged 1-month returns to create.\n// OUTPUTS:\n//   - A long-format DataFrame with a MultiIndex (ticker, date) and columns for each generated feature.\n\nBEGIN\n  CREATE an empty DataFrame `features_df`.\n\n  // Step 1: Calculate normalized historical returns\n  FOR each lag in historical_lags:\n    // Calculate period return for all assets\n    period_returns = monthly_prices_df.pct_change(lag)\n\n    // Normalize to a 1-month geometric average\n    compounded_returns = (period_returns + 1).pow(1/lag) - 1\n\n    // Convert from wide to long format and store\n    features_df['return_' + lag + 'm'] = compounded_returns.stack()\n  END FOR\n\n  // Step 2: Create lagged 1-month return features\n  // Ensure data is sorted by ticker then date for correct shifting\n  features_df = features_df.sort_index()\n  one_month_returns = features_df['return_1m']\n  FOR t from 1 to lagged_features_count:\n     features_df['return_1m_t-' + t] = one_month_returns.groupby(level='ticker').shift(t)\n  END FOR\n\n  // Step 3: Create forward returns (targets)\n  FOR each period in forward_periods:\n    // Use the already calculated normalized return for the corresponding period\n    target_returns = features_df['return_' + period + 'm']\n    features_df['target_' + period + 'm'] = target_returns.groupby(level='ticker').shift(-period)\n  END FOR\n\n  // Clean up any rows with NaN values resulting from calculations\n  RETURN features_df.dropna()\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 124,
    "text": "## Framework Overview\nEstimating an asset's exposure to common systematic risk factors is crucial for both risk management and feature engineering. The Fama-French five-factor model is a standard benchmark for explaining asset returns. By calculating an asset's historical 'betas' to these factors, we can create powerful predictive features.\n\n### 1. The Fama-French Five-Factor Model\n- **[Definition] Fama-French Factors**: A set of five empirically identified risk factors that aim to explain the excess returns of stocks. They are:\n    1.  **Mkt-RF**: Market risk premium (market return minus risk-free rate).\n    2.  **SMB**: Size premium (Small Minus Big).\n    3.  **HML**: Value premium (High Minus Low book-to-market).\n    4.  **RMW**: Profitability premium (Robust Minus Weak).\n    5.  **CMA**: Investment premium (Conservative Minus Aggressive).\n\n### 2. Computational Process: Rolling Regression\nTo capture the time-varying nature of factor exposures, we use a rolling linear regression.\n- **[Definition] Rolling Linear Regression**: A statistical method that fits a linear regression model over a sliding window of time. For each time step `t`, the model is fit using data from `t-W` to `t`, where `W` is the window size. This produces a time series of model parameters (betas).\n\n### 3. Implementation Steps\n1.  **Data Acquisition**: Obtain historical daily or monthly returns for the Fama-French factors and for the universe of stocks to be analyzed.\n2.  **Data Alignment**: Combine the asset returns and factor returns into a single DataFrame, ensuring they are aligned by date. For each asset, you will have its excess return (dependent variable, `y`) and the five factor returns (independent variables, `X`).\n3.  **Grouped Application**: To compute betas for each stock individually, the combined data should be grouped by the stock's ticker.\n4.  **Rolling OLS**: Within each stock's group, apply a rolling Ordinary Least Squares (OLS) regression. For each window of data, regress the stock's excess return on the five factor returns. The coefficients from this regression are the factor betas for that time period.",
    "question": "1.  **`[Rolling Factor Beta Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the rolling 24-month betas for a universe of stocks against the five Fama-French factors.",
    "answer": "```pseudocode\nFUNCTION CalculateRollingFactorBetas(asset_returns_df, factor_returns_df, window_size)\n// INPUTS:\n//   - asset_returns_df: A long-format DataFrame with MultiIndex (ticker, date) and a 'return_1m' column.\n//   - factor_returns_df: A wide-format DataFrame with DatetimeIndex and columns for each Fama-French factor.\n//   - window_size: An integer for the rolling window length (e.g., 24 for 24 months).\n// OUTPUTS:\n//   - A DataFrame containing the time series of the five factor betas for each stock.\n\nBEGIN\n  // Step 1: Align asset and factor data\n  // Join the two DataFrames on the date index.\n  combined_data = asset_returns_df.join(factor_returns_df, on='date').sort_index()\n\n  CREATE an empty list `all_betas` to store results.\n\n  // Step 2: Group data by stock ticker\n  grouped_by_ticker = combined_data.groupby(level='ticker')\n\n  FOR each ticker, stock_data in grouped_by_ticker:\n    // Ensure there is enough data for at least one window\n    IF stock_data.count() < window_size:\n      CONTINUE // Skip to the next ticker\n    END IF\n\n    // Define dependent (y) and independent (X) variables\n    y = stock_data['return_1m']\n    X = stock_data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']]\n\n    // Step 3: Apply rolling OLS regression\n    CREATE an empty DataFrame `ticker_betas`.\n    FOR i from window_size to length(stock_data):\n      // Define the current window\n      window_y = y.slice(i - window_size, i)\n      window_X = X.slice(i - window_size, i)\n\n      // Fit OLS model on the window\n      // OLS_model = Fit_OLS(y=window_y, X=window_X)\n      // The coefficients are the betas for the factors at time `i`.\n      current_betas = OLS_model.coefficients\n      \n      // Store the betas for the current time step\n      APPEND current_betas to `ticker_betas` with the corresponding date.\n    END FOR\n\n    ADD `ticker_betas` to the `all_betas` list.\n  END FOR\n\n  // Step 4: Combine results into a single DataFrame\n  final_betas_df = concatenate(all_betas)\n\n  RETURN final_betas_df\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 125,
    "text": "## Framework Overview\nTechnical analysis involves using historical market data, primarily price and volume, to forecast future price movements. Libraries like TA-Lib provide standardized, high-performance implementations of popular technical indicators, streamlining the process of creating technical alpha factors.\n\n### 1. Key Technical Indicators\n- **[Definition] Bollinger Bands (BBands)**: A volatility indicator consisting of three lines plotted in relation to a security's price. \n    - **Middle Band**: A Simple Moving Average (SMA) of the price over a specified period (e.g., 21 days).\n    - **Upper Band**: The Middle Band plus a specified number of standard deviations (e.g., 2) of the price over the same period.\n    - **Lower Band**: The Middle Band minus the same number of standard deviations.\n    - Prices moving outside the bands can signal overbought (above upper band) or oversold (below lower band) conditions.\n\n- **[Definition] Relative Strength Index (RSI)**: A momentum oscillator that measures the speed and change of price movements on a scale of 0 to 100.\n    - It is calculated based on the ratio of average gains to average losses over a specified lookback period (e.g., 14 days).\n    - **Signal Levels**: Traditionally, an RSI value above 70 is considered 'overbought', suggesting a potential price reversal downwards. A value below 30 is considered 'oversold', suggesting a potential price reversal upwards.\n\n### 2. Implementation with TA-Lib\nTA-Lib functions typically take NumPy arrays or pandas Series of price data as input and return the calculated indicator values. For instance:\n- `BBANDS(price_series, timeperiod, nbdevup, nbdevdn)` returns three Series: the upper band, middle band, and lower band.\n- `RSI(price_series, timeperiod)` returns a single Series containing the RSI values.",
    "question": "1.  **`[Technical Indicators Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that accepts a pandas DataFrame with a 'close' price column for a single stock and calculates its 21-day Bollinger Bands (with 2 standard deviations) and its 14-day RSI. The function should return a new DataFrame containing the original close price and the computed indicator values.",
    "answer": "```pseudocode\nFUNCTION CalculateTechnicalIndicators(stock_data_df)\n// INPUTS:\n//   - stock_data_df: A pandas DataFrame with a DatetimeIndex and at least a 'close' price column.\n// OUTPUTS:\n//   - A new DataFrame containing the 'close' price, Bollinger Bands (Upper, Mid, Lower), and RSI.\n\nBEGIN\n  // Extract the close price series for calculations\n  close_prices = stock_data_df['close']\n\n  // --- Define Parameters ---\n  BBANDS_TIMEPERIOD = 21\n  BBANDS_STD_DEVS = 2\n  RSI_TIMEPERIOD = 14\n\n  // --- Calculations using TA-Lib Functions ---\n\n  // Step 1: Calculate Bollinger Bands\n  // The function returns three series: upper, middle, and lower bands.\n  upper_band, middle_band, lower_band = TA_LIB.BBANDS(close_prices, \n                                                     timeperiod=BBANDS_TIMEPERIOD, \n                                                     nbdevup=BBANDS_STD_DEVS, \n                                                     nbdevdn=BBANDS_STD_DEVS)\n\n  // Step 2: Calculate Relative Strength Index\n  rsi_values = TA_LIB.RSI(close_prices, timeperiod=RSI_TIMEPERIOD)\n\n  // --- Assemble the Output DataFrame ---\n\n  // Step 3: Create a new DataFrame to store the results\n  CREATE a new DataFrame `results_df`.\n  results_df['close'] = close_prices\n  results_df['BB_Upper'] = upper_band\n  results_df['BB_Mid'] = middle_band\n  results_df['BB_Lower'] = lower_band\n  results_df['RSI'] = rsi_values\n\n  // Return the combined DataFrame, dropping any initial rows with NaN values\n  RETURN results_df.dropna()\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 126,
    "text": "## Framework Overview\nThe Kalman filter is a powerful algorithm for estimating the state of a dynamic system from a series of incomplete and noisy measurements. In finance, it can be used to 'denoise' a price series, providing a smoother estimate of the underlying true value by filtering out random fluctuations.\n\n### 1. Core Concepts\n- **[Definition] Hidden State (x)**: The unobservable, true state of the system we want to estimate. In this context, it could be the 'true' price of an asset, which is obscured by market noise.\n- **[Definition] Observation (z)**: The noisy measurement we observe. In this context, this is the actual market price at each time step.\n- **Assumptions**: The standard Kalman filter assumes the system is linear and that all noise (both in the system's transition and in the measurements) is Gaussian.\n\n### 2. The Kalman Filter Algorithm\nThe algorithm operates recursively in a two-step cycle for each time step:\n1.  **Prediction Step**: The filter predicts the next state of the system based on its current state estimate and the system's dynamics. It also predicts the uncertainty (covariance) of this new state.\n    - `Predicted State Estimate`: `x_t_predicted = A * x_{t-1}_estimated + B * u_{t-1}` (where A is the transition matrix, B and u are control inputs, often ignored in simple models).\n    - `Predicted Covariance Estimate`: `P_t_predicted = A * P_{t-1}_estimated * A^T + Q` (where Q is the process noise covariance).\n2.  **Measurement Update Step**: The filter uses the latest observation to correct the predicted state. It computes a 'Kalman Gain' that determines how much the prediction should be adjusted based on the new measurement.\n    - `Kalman Gain (K)`: Determines the weight given to the observation vs. the prediction. A higher gain trusts the observation more.\n    - `Updated State Estimate`: `x_t_estimated = x_t_predicted + K * (z_t - C * x_t_predicted)` (where z_t is the observation and C is the observation matrix).\n    - `Updated Covariance Estimate`: `P_t_estimated = (I - K * C) * P_t_predicted`\n\n### 3. Model Parameters for a 1D Price Series\nFor a simple price smoothing model:\n- The state `x` and observation `z` are scalars (the price).\n- `transition_matrix (A)` is `[1]` (assumes the next true price is the same as the current true price, plus some noise).\n- `observation_matrix (C)` is `[1]` (assumes the observed price is the true price, plus some noise).\n- `transition_covariance (Q)`: Represents the noise in the price process itself (how much the true price can change between steps).\n- `observation_covariance (R)`: Represents the noise in our measurement (market noise).\n- The ratio of Q to R determines how smooth the filter's output will be. A smaller Q relative to R results in more smoothing.",
    "question": "1.  **`[Kalman Filter Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that applies a Kalman filter to a 1D time series of asset prices to produce a smoothed series. The function should iterate through the price series, performing the predict and update steps at each point in time.",
    "answer": "```pseudocode\nFUNCTION ApplyKalmanFilter1D(price_series, transition_covariance, observation_covariance)\n// INPUTS:\n//   - price_series: An array of observed asset prices.\n//   - transition_covariance (Q): A scalar representing the process noise.\n//   - observation_covariance (R): A scalar representing the measurement noise.\n// OUTPUTS:\n//   - An array of the smoothed (estimated) state means.\n\nBEGIN\n  // --- Initialization ---\n  // Set system matrices for a 1D random walk model\n  A = 1 // Transition Matrix\n  C = 1 // Observation Matrix\n\n  // Initialize state and covariance estimates\n  estimated_state = price_series[0]      // Start with the first observation\n  estimated_covariance = 1.0           // Initial guess for uncertainty\n\n  CREATE an empty list `smoothed_means`.\n\n  // --- Iteration ---\n  FOR each observed_price `z` in price_series:\n    // Step 1: Prediction\n    predicted_state = A * estimated_state\n    predicted_covariance = A * estimated_covariance * A + transition_covariance\n\n    // Step 2: Measurement Update\n    // Calculate Kalman Gain\n    kalman_gain = predicted_covariance * C / (C * predicted_covariance * C + observation_covariance)\n\n    // Update the state estimate with the new observation\n    estimated_state = predicted_state + kalman_gain * (z - C * predicted_state)\n\n    // Update the covariance estimate\n    estimated_covariance = (1 - kalman_gain * C) * predicted_covariance\n\n    // Store the updated state mean\n    APPEND estimated_state to `smoothed_means`.\n  END FOR\n\n  RETURN smoothed_means\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 127,
    "text": "## Framework Overview\nWavelet transforms are a powerful tool for signal processing that can decompose a signal into components at different scales or frequencies. This property makes them highly effective for denoising financial time series by isolating and removing high-frequency noise while preserving important underlying trends.\n\n### 1. Key Concepts\n- **[Definition] Wavelet**: A wave-like oscillation with an amplitude that begins at zero, increases, and then decreases back to zero. They are used as a basis to represent other functions.\n- **[Definition] Discrete Wavelet Transform (DWT)**: An implementation of the wavelet transform using a discrete set of wavelet scales and translations. It decomposes a signal into a set of coefficients representing its detail and approximation components at various levels.\n\n### 2. The Denoising Process\nThe process of denoising a signal using wavelets involves three main steps:\n1.  **Decomposition**: Apply a forward DWT to the noisy signal. This is done by choosing a specific wavelet (e.g., 'Daubechies 6' or 'db6') and a decomposition level. The result is a set of wavelet coefficients.\n    - **Approximation Coefficients**: Represent the low-frequency, coarse features of the signal.\n    - **Detail Coefficients**: Represent the high-frequency, fine features, which are often assumed to contain the noise.\n2.  **Thresholding**: Apply a thresholding rule to the detail coefficients. The assumption is that coefficients with small absolute values correspond to noise, while larger coefficients represent the important signal features.\n    - **[Definition] Soft Thresholding**: A common rule where coefficients below a certain threshold `T` are set to zero, and coefficients above the threshold are shrunk towards zero by `T`. `threshold(c) = sign(c) * max(0, |c| - T)`.\n3.  **Reconstruction**: Apply an inverse DWT using the modified (thresholded) coefficients. This reconstructs the signal, which should now have significantly less noise.\n\nThe choice of wavelet, decomposition level, and threshold value are critical parameters that affect the outcome of the denoising process.",
    "question": "1.  **`[Wavelet Denoising Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes a noisy signal (e.g., a series of asset returns), a specified wavelet type, and a threshold value, and returns the denoised signal using the three-step DWT process.",
    "answer": "```pseudocode\nFUNCTION DenoiseWithWavelets(signal_array, wavelet_type, threshold_value)\n// INPUTS:\n//   - signal_array: A 1D array representing the noisy signal.\n//   - wavelet_type: A string specifying the wavelet to use (e.g., 'db6').\n//   - threshold_value: A floating-point number for the thresholding cutoff.\n// OUTPUTS:\n//   - A 1D array representing the denoised signal.\n\nBEGIN\n  // Step 1: Decomposition\n  // Decompose the signal into wavelet coefficients using the specified wavelet.\n  // The result is typically a list of arrays, with the first being the approximation\n  // coefficients and the rest being the detail coefficients at different levels.\n  coefficients_list = DWT.wavedec(signal_array, wavelet_type)\n\n  // --- Create a new list for the modified coefficients ---\n  CREATE an empty list `thresholded_coefficients_list`.\n  // The approximation coefficients (the first element) are usually kept as is.\n  APPEND coefficients_list[0] to `thresholded_coefficients_list`.\n\n  // Step 2: Thresholding\n  // Iterate through the detail coefficients (all but the first element).\n  FOR each detail_coeffs_array in coefficients_list starting from the second element:\n    // Apply soft thresholding to each coefficient in the array.\n    modified_coeffs_array = DWT.threshold(detail_coeffs_array, \n                                          value=threshold_value, \n                                          mode='soft')\n    APPEND modified_coeffs_array to `thresholded_coefficients_list`.\n  END FOR\n\n  // Step 3: Reconstruction\n  // Reconstruct the signal from the thresholded coefficients.\n  reconstructed_signal = DWT.waverec(thresholded_coefficients_list, wavelet_type)\n\n  // Ensure the output signal has the same length as the input signal.\n  // Some wavelet transforms can alter length slightly, so trim if necessary.\n  reconstructed_signal = reconstructed_signal.slice(0, length(signal_array))\n\n  RETURN reconstructed_signal\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 128,
    "text": "## Framework Overview\nZipline is an event-driven backtesting library that enables the research and implementation of algorithmic trading strategies. A core component of Zipline is the Pipeline API, which allows for the efficient computation of alpha factors across a large universe of securities. To create a novel factor, you must subclass Zipline's `CustomFactor`.\n\n### 1. The `CustomFactor` Class\nA `CustomFactor` is a user-defined class that inherits from `zipline.pipeline.CustomFactor` and must implement a `compute` method. This structure allows for flexible and optimized calculations using NumPy.\n- **`inputs`**: A class attribute that defines the data required for the factor calculation. This is a list of Pipeline expressions, like `Returns(window_length=21)`.\n- **`window_length`**: A class attribute specifying the number of trailing days of data (from `inputs`) that should be passed to the `compute` method.\n- **`compute(self, today, assets, out, *inputs)`**: The core method where the factor logic is implemented.\n    - `today`: The current simulation datetime.\n    - `assets`: An array of integer asset identifiers for which to compute the factor.\n    - `out`: A pre-allocated NumPy array where the results of the computation must be stored.\n    - `*inputs`: The data specified in the `inputs` attribute, passed as NumPy arrays. Each array has dimensions `(window_length, num_assets)`.\n\n### 2. Case Study: A Mean-Reversion Factor\nA mean-reversion factor identifies assets that have recently deviated significantly from their historical average performance, with the expectation they will revert.\n- **[Definition] Z-Score**: A statistical measurement that describes a value's relationship to the mean of a group of values. A z-score is measured in terms of standard deviations from the mean. `Z = (X - 娓? / 锜絗.\n- **Logic**: The factor will calculate the z-score of the most recent monthly return relative to the distribution of monthly returns over the past year.\n    - `Latest Monthly Return`: The return over the last `MONTH` days.\n    - `Historical Mean`: The average of monthly returns over the last `YEAR` days.\n    - `Historical Std Dev`: The standard deviation of monthly returns over the last `YEAR` days.\nA high positive z-score indicates strong recent outperformance (a candidate for a short position in a reversal strategy), while a large negative z-score indicates underperformance (a candidate for a long position).",
    "question": "1.  **`[Zipline CustomFactor Implementation]`**:\n    *   **Task**: Provide the pseudocode for a `MeanReversion` class that inherits from `CustomFactor`. This class should be designed to calculate the z-score of the latest monthly return against the prior year's rolling monthly returns.",
    "answer": "```pseudocode\nCLASS MeanReversion INHERITS FROM CustomFactor\n\n  // --- Class Attributes ---\n  // Define the input data required: a history of daily returns.\n  // Note: The specific return calculation (e.g., daily vs monthly) is handled by the input factor.\n  // Here, we request returns calculated over a 21-day (1 month) period.\n  inputs = [Returns(window_length = 21)]\n  \n  // Define the lookback window for the compute method.\n  // We need ~1 year of monthly returns, so we request 252 days of data.\n  window_length = 252\n\n  // --- Compute Method ---\n  FUNCTION compute(self, today, assets, out, monthly_returns_array)\n  // INPUTS:\n  //   - today: The current simulation date.\n  //   - assets: The array of assets being processed.\n  //   - out: The output array to populate with factor values.\n  //   - monthly_returns_array: A NumPy array of shape (252, num_assets) containing the data from `inputs`.\n  // OUTPUTS:\n  //   - The `out` array is populated in-place.\n  \n  BEGIN\n    // The input array has time on axis 0 and assets on axis 1.\n\n    // Step 1: Extract the latest monthly return for each asset.\n    // This is the last row of the input array.\n    latest_monthly_return = monthly_returns_array[-1]\n\n    // Step 2: Calculate the mean of historical monthly returns for each asset.\n    // This is the mean along the time axis (axis 0).\n    mean_historical_return = mean(monthly_returns_array, axis=0)\n\n    // Step 3: Calculate the standard deviation of historical returns.\n    std_dev_historical_return = std_dev(monthly_returns_array, axis=0)\n\n    // Step 4: Compute the Z-Score.\n    // To avoid division by zero, replace zero standard deviations with NaN or a small number.\n    // For simplicity here, assume std_dev is non-zero.\n    z_score = (latest_monthly_return - mean_historical_return) / std_dev_historical_return\n\n    // Step 5: Assign the computed z-score to the output array.\n    out[:] = z_score\n  END FUNCTION\n\nEND CLASS\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 129,
    "text": "## Framework Overview\nSophisticated alpha signals are rarely derived from a single factor. Instead, they are typically constructed by combining multiple, diverse factors to create a more robust and predictive signal. The Zipline/Quantopian Pipeline API is designed to facilitate this process by allowing traders to compute and combine factors from various datasets efficiently.\n\n### 1. Pipeline Components\n- **[Definition] Universe**: A filter that defines the set of securities over which the pipeline will operate. A common choice is `QTradableStocksUS`, which provides a universe of liquid, tradable US equities.\n- **[Definition] Factors**: Columns in the pipeline that compute a numerical value for each security in the universe (e.g., `Returns`, `SimpleMovingAverage`).\n- **Data Sources**: The pipeline can access various built-in datasets.\n    - **Market Data**: `USEquityPricing` (for prices, volume).\n    - **Fundamental Data**: `morningstar.income_statement`, `morningstar.balance_sheet` (for metrics like gross profit, total assets, EBITDA).\n    - **Alternative Data**: `psychsignal.stocktwits` (for sentiment data like `bull_minus_bear`).\n\n### 2. Combining Factors\nA common and simple method for combining factors is through rank aggregation.\n1.  **Individual Factor Calculation**: Each desired factor is calculated for all securities in the defined universe.\n2.  **Ranking**: Each factor is then ranked using the `.rank()` method. This converts the absolute factor values into a cross-sectional ranking (e.g., from 1 to N, where N is the number of securities). The `mask` parameter of the `.rank()` method should be set to the universe to ensure ranking is performed only on the desired securities.\n3.  **Aggregation**: The ranks of the individual factors are simply summed together for each security. This creates a composite factor where securities that rank highly across multiple individual factors will have the highest overall score.\n\n### 3. Example Factors for Combination\n- **Profitability**: `gross_profit / total_assets`\n- **EBITDA Yield**: `EBITDA / market_cap` (approximated by `EBITDA / close_price`)\n- **Price Momentum**: `Returns(window_length=63)` (Quarterly return)\n- **Sentiment**: `SimpleMovingAverage(inputs=[stocktwits.bull_minus_bear], window_length=5)`\n\n### 4. Handling Data Frequency\n- **[Definition] AggregateFundamentals**: A custom factor class used to handle the mismatch between daily pricing data and lower-frequency fundamental data (e.g., quarterly). It ensures that the last reported fundamental value is carried forward and used for calculations on any given day, preventing lookahead bias.",
    "question": "1.  **`[Multi-Factor Pipeline Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that constructs and returns a Zipline Pipeline object. This pipeline should calculate and combine profitability, price momentum, and sentiment factors into a single composite alpha factor using rank summation.",
    "answer": "```pseudocode\nFUNCTION CreateMultiFactorPipeline()\n// INPUTS:\n//   - None\n// OUTPUTS:\n//   - A Zipline Pipeline object.\n\nBEGIN\n  // Step 1: Define the investment universe.\n  universe = QTradableStocksUS()\n\n  // --- Calculate Individual Factors ---\n\n  // Factor A: Profitability (Gross Profit / Total Assets)\n  // Note: Using a custom factor to get the latest reported fundamental data.\n  gross_profit = AggregateFundamentals(inputs=[income_statement.gross_profit], window_length=252)\n  total_assets = balance_sheet.total_assets.latest\n  profitability_factor = (gross_profit / total_assets)\n\n  // Factor B: Price Momentum (3-Month Returns)\n  // Assuming QTR = 63 trading days\n  momentum_factor = Returns(window_length=63)\n\n  // Factor C: Sentiment (5-day moving average of bull-minus-bear score)\n  sentiment_factor = SimpleMovingAverage(inputs=[stocktwits.bull_minus_bear], window_length=5)\n\n  // --- Rank and Combine Factors ---\n\n  // Step 2: Rank each factor individually across the universe.\n  profitability_rank = profitability_factor.rank(mask=universe)\n  momentum_rank = momentum_factor.rank(mask=universe)\n  sentiment_rank = sentiment_factor.rank(mask=universe)\n\n  // Step 3: Sum the ranks to create the composite alpha factor.\n  composite_alpha_factor = profitability_rank + momentum_rank + sentiment_rank\n\n  // --- Construct the final Pipeline object ---\n\n  CREATE a new Pipeline `p`.\n  SET the screen of `p` to `universe`.\n\n  // Add the final composite factor and individual factors as columns for analysis.\n  p.add_column('Profitability_Rank', profitability_rank)\n  p.add_column('Momentum_Rank', momentum_rank)\n  p.add_column('Sentiment_Rank', sentiment_rank)\n  p.add_column('Alpha_Factor', composite_alpha_factor)\n\n  RETURN p\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 130,
    "text": "## Framework Overview\nAlphalens is a Python library for analyzing the predictive power of alpha factors. To use its powerful visualization and statistical tools, raw data must be preprocessed into a specific format. The core of this process is aligning a time series of factor values with corresponding forward returns.\n\n### 1. Required Inputs for Analysis\n- **Factor Data**: A pandas Series or DataFrame with a `MultiIndex` of `(date, asset)` and factor values. This is typically the output of a Zipline pipeline.\n- **Price Data**: A pandas DataFrame in 'wide' format, with dates as the index and assets as columns, containing the prices used to calculate returns.\n\n### 2. The Data Preparation Process\nThe `alphalens.utils.get_clean_factor_and_forward_returns` function automates this, but understanding its logic is key.\n1.  **Aligning Factor and Prices**: The factor data (long format) needs to be unstacked to match the wide format of the price data, ensuring that dates and assets align perfectly.\n2.  **Calculating Forward Returns**: For each date and asset, calculate the returns that would be earned over specified future holding periods (e.g., 5, 10, 21 days). This is done by applying a percentage change calculation over a shifted price series. \n    - For a holding period `P`, the return at time `t` is `(Price_{t+P} / Price_t) - 1`.\n3.  **Binning Factor into Quantiles**: On each date (cross-sectionally), the raw factor values are converted into quantiles. For example, if `quantiles=5`, all assets are ranked on that day by their factor value and assigned an integer from 1 to 5.\n    - **[Definition] Quantiles**: Dividing the range of a probability distribution into continuous intervals with equal probabilities. For factor analysis, this groups assets into buckets (e.g., top 20%, next 20%, etc.) based on their factor scores.\n4.  **Merging and Stacking**: The factor values, factor quantiles, and multiple forward return series are merged into a single wide DataFrame and then stacked back into the required long format, creating a `MultiIndex` of `(date, asset)`.",
    "question": "1.  **`[Alphalens Data Preparation Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that mimics the core logic of `get_clean_factor_and_forward_returns`. It should take factor data (long format), price data (wide format), a list of holding periods, and the number of quantiles as input, and produce the final formatted DataFrame.",
    "answer": "```pseudocode\nFUNCTION PrepareAlphalensData(factor_data_long, prices_wide, holding_periods, num_quantiles)\n// INPUTS:\n//   - factor_data_long: A pandas Series with a MultiIndex (date, asset) and factor values.\n//   - prices_wide: A DataFrame with DatetimeIndex and asset tickers as columns.\n//   - holding_periods: An array of integers for forward return periods (e.g., [5, 10, 21]).\n//   - num_quantiles: An integer for the number of quantile bins (e.g., 5).\n// OUTPUTS:\n//   - A long-format DataFrame with a MultiIndex (date, asset) and columns for the factor, its quantile, and each forward return.\n\nBEGIN\n  // Step 1: Calculate Forward Returns for each period\n  CREATE an empty dictionary `forward_returns_dict`.\n  FOR each period in holding_periods:\n    // Shift prices *backwards* by 'period' days to calculate future returns.\n    // The return for date `t` is (price at `t+period` / price at `t`) - 1.\n    future_prices = prices_wide.shift(-period)\n    forward_return = (future_prices / prices_wide) - 1\n    \n    // Convert from wide to long format and store in the dictionary\n    forward_returns_dict[period + 'D'] = forward_return.stack()\n  END FOR\n  \n  // Combine all forward return series into a single DataFrame\n  forward_returns_df = DataFrame.from_dict(forward_returns_dict)\n\n  // Step 2: Bin factor values into quantiles\n  // Group factor data by date to perform cross-sectional ranking.\n  // The `qcut` function bins data into discrete intervals based on sample quantiles.\n  factor_quantiles = factor_data_long.groupby(level='date').apply(\n      lambda x: pd.qcut(x, num_quantiles, labels=False, duplicates='drop') + 1\n  )\n  factor_quantiles.name = 'factor_quantile'\n\n  // Step 3: Merge all data components\n  // Start with the original factor data\n  merged_df = DataFrame(factor_data_long)\n  merged_df.columns = ['factor']\n\n  // Join with factor quantiles\n  merged_df = merged_df.join(factor_quantiles)\n\n  // Join with the forward returns\n  merged_df = merged_df.join(forward_returns_df)\n\n  // Step 4: Clean the data\n  // The joins and shifts will produce NaNs. Remove any row with missing data.\n  final_df = merged_df.dropna()\n\n  RETURN final_df\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 131,
    "text": "## Framework Overview\nThe Information Coefficient (IC) is a primary metric for evaluating the predictive power of an alpha factor. It measures the correlation between the factor's values and the subsequent forward returns of the assets. A consistently positive IC indicates that the factor has predictive skill.\n\n### 1. Key Concepts\n- **[Definition] Information Coefficient (IC)**: The correlation between a factor's predictions and the actual asset returns over a subsequent period. A value of 1.0 implies perfect positive correlation, -1.0 implies perfect negative correlation, and 0 implies no correlation.\n- **[Definition] Spearman Rank Correlation**: A non-parametric measure of the monotonic relationship between two variables. It is preferred over the standard Pearson correlation for factor analysis because it is robust to outliers and does not assume a linear relationship. The Spearman correlation is calculated by converting the values of each variable to ranks and then computing the Pearson correlation on those ranks.\n- **[Definition] Risk-Adjusted IC**: Often referred to as the Information Ratio (IR) in this context, it is calculated as the mean of the IC time series divided by its standard deviation (`mean(IC) / std(IC)`). It measures the consistency of the factor's predictive power.\n\n### 2. Computational Process\nTo calculate the IC as a time series, the Spearman Rank Correlation must be computed for each day in the dataset.\n1.  **Input Data**: The required input is a long-format DataFrame, as prepared for Alphalens, containing at least three columns: `factor`, a specific forward return column (e.g., `5D`), and a `MultiIndex` of `(date, asset)`.\n2.  **Group by Date**: The DataFrame is grouped by the 'date' level of the index. This creates a separate group for each trading day, containing the factor values and forward returns for all assets on that day.\n3.  **Daily Correlation**: For each daily group, the Spearman Rank Correlation is calculated between the `factor` column and the chosen forward return column. This yields a single correlation value (the IC) for that day.\n4.  **Assemble Time Series**: The daily IC values are collected and assembled into a pandas Series indexed by date, forming the final IC time series.",
    "question": "1.  **`[Information Coefficient Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes the time series of the daily Information Coefficient for a given forward return period, using Spearman Rank Correlation.",
    "answer": "```pseudocode\nFUNCTION CalculateDailyIC(alphalens_data, forward_return_period)\n// INPUTS:\n//   - alphalens_data: A long-format DataFrame with a MultiIndex (date, asset) and columns 'factor' and forward returns.\n//   - forward_return_period: A string specifying the forward return column to use (e.g., '5D').\n// OUTPUTS:\n//   - A pandas Series indexed by date, containing the daily Information Coefficient values.\n\nBEGIN\n  // Step 1: Group the data by date\n  // This allows for a cross-sectional calculation for each day.\n  grouped_by_date = alphalens_data.groupby(level='date')\n\n  CREATE an empty dictionary `daily_ic_values` to store results.\n\n  // Step 2: Iterate through each daily group\n  FOR each date, daily_group in grouped_by_date:\n    // Extract the factor values and forward returns for the current day\n    factor_values = daily_group['factor']\n    return_values = daily_group[forward_return_period]\n\n    // Ensure there are enough data points to calculate correlation\n    IF length(factor_values) < 2:\n      CONTINUE // Skip to the next day\n    END IF\n\n    // Step 3: Calculate Spearman Rank Correlation for the day\n    // The function takes two series and returns the correlation coefficient.\n    correlation_coefficient = SpearmanRankCorrelation(factor_values, return_values)\n\n    // Store the result for the current date\n    daily_ic_values[date] = correlation_coefficient\n  END FOR\n\n  // Step 4: Assemble the final time series\n  // Convert the dictionary to a pandas Series.\n  ic_series = Series(daily_ic_values)\n\n  RETURN ic_series\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 132,
    "text": "## Framework Overview\nFactor turnover is a critical metric for assessing the practical viability of an alpha factor. A high-turnover factor may have strong predictive power but could be unprofitable after accounting for transaction costs. Therefore, measuring a factor's stability is essential.\n\n### 1. Key Stability Metrics\n- **[Definition] Quantile Turnover**: This metric measures the rate at which assets move in and out of a specific factor quantile from one period to the next. It is calculated as the fraction of assets in a quantile at time `t` that were not in that same quantile at time `t-1`. A high value (e.g., 0.8) means 80% of the assets in the quantile are new each period, implying high trading activity and costs.\n- **[Definition] Factor Rank Autocorrelation**: This metric measures the correlation of an asset's factor rank from one period to the next. It is calculated by taking the time series of factor ranks for all assets and computing the Spearman rank correlation between the ranks at time `t` and the ranks at time `t-1`. A high autocorrelation (close to 1.0) indicates high stability, while a value near zero suggests the ranks are highly unstable.\n\n### 2. Computational Process for Quantile Turnover\n1.  **Input Data**: Requires a long-format DataFrame with a `MultiIndex` of `(date, asset)` and a `factor_quantile` column.\n2.  **Group by Quantile**: The data is grouped by the `factor_quantile` value.\n3.  **Iterate Through Quantiles**: For each quantile group:\n    a.  For each date `t`, identify the set of assets in the quantile.\n    b.  For the previous date `t-1`, identify the set of assets that were in that same quantile.\n    c.  Calculate the intersection of the two sets.\n    d.  The turnover for date `t` is `1 - (size_of_intersection / size_of_set_at_t)`.\n4.  **Average Results**: The daily turnover rates are then averaged over time to get the mean turnover for that quantile.\n\n### 3. Computational Process for Rank Autocorrelation\n1.  **Input Data**: Requires a long-format DataFrame with a `MultiIndex` of `(date, asset)` and a `factor` column.\n2.  **Create Ranks**: For each date, convert the raw `factor` values into ranks.\n3.  **Shift Ranks**: Create a new column containing the ranks from the previous period by shifting the rank column forward in time for each asset group.\n4.  **Correlate**: For each date, calculate the Spearman rank correlation between the current ranks and the shifted (previous day's) ranks.",
    "question": "1.  **`[Factor Turnover Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the mean quantile turnover for a specific quantile (e.g., quantile 1). This function will take Alphalens-formatted data as input.",
    "answer": "```pseudocode\nFUNCTION CalculateMeanQuantileTurnover(alphalens_data, target_quantile)\n// INPUTS:\n//   - alphalens_data: A long-format DataFrame with a MultiIndex (date, asset) and a 'factor_quantile' column.\n//   - target_quantile: An integer specifying the quantile to analyze (e.g., 1 for the bottom quantile).\n// OUTPUTS:\n//   - A floating-point number representing the mean turnover for the specified quantile.\n\nBEGIN\n  // Step 1: Filter the data for the target quantile\n  quantile_data = alphalens_data[alphalens_data['factor_quantile'] == target_quantile]\n\n  // Step 2: Group the filtered data by date to get the set of assets per day\n  // The result is a dictionary-like structure mapping each date to a list/set of asset IDs.\n  assets_by_date = quantile_data.groupby(level='date')['asset'].apply(to_set)\n\n  // Get a sorted list of unique dates\n  sorted_dates = sort(assets_by_date.keys())\n\n  CREATE an empty list `daily_turnover_rates`.\n\n  // Step 3: Iterate through dates to calculate period-over-period turnover\n  FOR i from 1 to length(sorted_dates) - 1:\n    current_date = sorted_dates[i]\n    previous_date = sorted_dates[i-1]\n\n    // Get the set of assets for the current and previous period\n    assets_current = assets_by_date[current_date]\n    assets_previous = assets_by_date[previous_date]\n\n    // Handle cases where a set might be empty\n    IF length(assets_current) == 0:\n      CONTINUE\n    END IF\n\n    // Step 4: Calculate the intersection and the turnover rate\n    assets_intersection = assets_current.intersection(assets_previous)\n    num_retained = length(assets_intersection)\n    num_current = length(assets_current)\n\n    turnover = 1.0 - (num_retained / num_current)\n\n    APPEND turnover to `daily_turnover_rates`.\n  END FOR\n\n  // Step 5: Calculate the mean of the daily turnover rates\n  mean_turnover = mean(daily_turnover_rates)\n\n  RETURN mean_turnover\n\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 133,
    "text": "## Framework Overview\n\nMean Decrease Impurity (MDI) is a method used to evaluate feature importance specifically for tree-based models, such as Random Forests. It is widely used due to its computational efficiency and straightforward implementation.\n\n### Key Concepts\n\n- **[Definition] Mean Decrease Impurity (MDI)**: A measure of feature importance that is calculated as the weighted average of the impurity decrease contributed by a specific feature across all nodes and all trees in an ensemble. Features that cause a greater reduction in impurity are considered more important.\n\n### Known Flaws\n\nMDI has two primary weaknesses that must be considered:\n\n1.  **Substitution Effects**: MDI is known to be biased toward features that are highly correlated with other predictive features. If two features contain similar information, MDI may assign high importance to both, failing to recognize the redundancy.\n2.  **In-Sample Calculation**: The importance scores are computed using the same data the model was trained on (in-sample). This can lead to overfitting, where a feature appears important for the training set but has no predictive power on new, out-of-sample data.\n\n### Mathematical Formulation\n\nThe importance of a feature `f`, denoted as `I(f)`, is calculated using the following formula:\n\n**Equation 1:**\n`I(f) = 鍗盻{t 閳?T} p(t) * 铻杋(t, f)`\n\nWhere:\n- `I(f)`: The importance score for feature `f`.\n- `T`: The set of all nodes in a decision tree.\n- `p(t)`: The proportion of samples that reach node `t`.\n- `铻杋(t, f)`: The decrease in impurity at node `t` that results from splitting on feature `f`.",
    "question": "Provide the pseudocode for a function that computes the Mean Decrease Impurity (MDI) feature importance for a fitted tree-based ensemble model. The function should calculate the mean and standard deviation of importance scores across all trees and normalize the final mean scores.",
    "answer": "```pseudocode\n// FUNCTION CalculateMDI(fitted_ensemble_model, feature_names)\n// INPUTS:\n//   - fitted_ensemble_model: A trained ensemble model (e.g., RandomForest) with multiple tree estimators.\n//   - feature_names: A list of strings corresponding to the column names of the features.\n// OUTPUTS:\n//   - A data structure (e.g., DataFrame) containing columns for 'mean' and 'std' of feature importances, indexed by feature name.\n\nBEGIN\n  // 1. Initialize a data structure to store importances from each tree.\n  importance_matrix = an empty dictionary or map\n\n  // 2. Iterate through each tree estimator in the ensemble.\n  FOR i, tree IN enumerate(fitted_ensemble_model.estimators_)\n    // Each tree has a pre-computed 'feature_importances_' attribute.\n    importance_matrix[i] = tree.feature_importances_\n  END FOR\n\n  // 3. Convert the collected importances into a tabular format (e.g., DataFrame).\n  // Rows represent trees, columns represent features.\n  importance_df = DataFrame(importance_matrix).transpose()\n  importance_df.columns = feature_names\n\n  // 4. Calculate mean and standard deviation of importances across all trees for each feature.\n  mean_importances = importance_df.mean(axis=0)\n  std_importances = importance_df.std(axis=0) * (number of trees)^(-0.5) // Standard error of the mean\n\n  // 5. Combine results into a final importance table.\n  final_importances = DataFrame({'mean': mean_importances, 'std': std_importances})\n\n  // 6. Normalize the mean importance scores so they sum to 1.\n  total_mean_importance = final_importances['mean'].sum()\n  IF total_mean_importance > 0 THEN\n    final_importances['mean'] = final_importances['mean'] / total_mean_importance\n  END IF\n\n  RETURN final_importances\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 134,
    "text": "## Framework Overview\n\nMean Decrease Accuracy (MDA) is a robust, model-agnostic technique for determining feature importance. Unlike in-sample methods, it evaluates features based on their impact on model performance on unseen (out-of-sample) data, making it less prone to overfitting.\n\n### Key Concepts\n\n- **[Definition] Mean Decrease Accuracy (MDA)**: An out-of-sample feature importance method that measures the decline in a model's predictive score when the values of a single feature are randomly shuffled. A significant drop in performance implies the feature is important.\n\n### Known Flaws\n\n- **Underestimation**: MDA can sometimes underestimate the importance of a feature if it is highly correlated with other features. If a redundant feature exists, the model may rely on it when the original feature is shuffled, resulting in a smaller-than-expected performance drop.\n\n### Mathematical Formulation\n\nThe importance of a feature `f`, denoted as `I(f)`, is the difference between the baseline model score and the score after permuting the feature:\n\n**Equation 1:**\n`I(f) = E[s] - E[s_f]`\n\nWhere:\n- `I(f)`: The importance score for feature `f`.\n- `E[s]`: The expected score of the model on the original (unshuffled) out-of-sample data.\n- `E[s_f]`: The expected score of the model on the out-of-sample data after the values for feature `f` have been randomly shuffled.\n\n### Computational Steps\n\nThe algorithm proceeds as follows for each fold in a cross-validation scheme:\n1.  Split data into a training set and a testing set.\n2.  Train the model on the training set.\n3.  Calculate the model's score on the original (unshuffled) testing set. This is the baseline score for the fold.\n4.  For each feature in the dataset:\n    a. Create a copy of the testing set.\n    b. Randomly shuffle the values in the column corresponding to the current feature.\n    c. Calculate the model's score on this modified testing set.\n    d. The importance for that feature in this fold is the difference between the baseline score and the score from the shuffled data.\n5.  Aggregate the importance scores for each feature across all cross-validation folds.",
    "question": "Provide the pseudocode for a function that implements the Mean Decrease Accuracy (MDA) feature importance logic using a cross-validation generator. The function should calculate a baseline score and then a permuted score for each feature within each fold.",
    "answer": "```pseudocode\n// FUNCTION CalculateMDA(classifier, features_X, labels_y, cv_generator, scoring_function)\n// INPUTS:\n//   - classifier: The machine learning model to be evaluated.\n//   - features_X: A table of feature data.\n//   - labels_y: A series of corresponding labels.\n//   - cv_generator: A cross-validation object that yields train/test indices.\n//   - scoring_function: A function to evaluate model performance (e.g., accuracy, log_loss).\n// OUTPUTS:\n//   - A data structure (e.g., DataFrame) containing the mean and standard deviation of importance scores for each feature.\n\nBEGIN\n  // 1. Initialize data structures to store scores.\n  baseline_scores = an empty Series\n  permuted_scores = an empty DataFrame with columns matching feature_names\n\n  // 2. Loop through each cross-validation fold.\n  FOR i, (train_indices, test_indices) IN enumerate(cv_generator.split(features_X))\n    // 2a. Create train and test sets for this fold.\n    X_train, y_train = features_X[train_indices], labels_y[train_indices]\n    X_test, y_test = features_X[test_indices], labels_y[test_indices]\n\n    // 2b. Fit the classifier on the training data.\n    fitted_model = classifier.fit(X_train, y_train)\n\n    // 2c. Calculate and store the baseline score on the original test set.\n    baseline_scores[i] = scoring_function(fitted_model, X_test, y_test)\n\n    // 2d. Loop through each feature to calculate permuted scores.\n    FOR feature_name IN features_X.columns\n      X_test_permuted = X_test.copy()\n      // Randomly shuffle the values of the current feature column.\n      shuffle(X_test_permuted[feature_name])\n\n      // Calculate and store the score with the permuted feature.\n      permuted_scores.at[i, feature_name] = scoring_function(fitted_model, X_test_permuted, y_test)\n    END FOR\n  END FOR\n\n  // 3. Calculate the importance as the drop in score.\n  // Note: For scores where higher is better (e.g., accuracy), this is (baseline - permuted).\n  // For loss functions (e.g., neg_log_loss), it's (permuted - baseline) or (-permuted + baseline).\n  // Assuming higher is better for simplicity:\n  importances = baseline_scores.subtract(permuted_scores, axis='columns')\n\n  // 4. Normalize the importances for comparability.\n  // One common method is to divide by (1 - permuted_score) for accuracy, or by (-permuted_score) for log-loss.\n  // Assuming accuracy normalization:\n  normalized_importances = importances / (1.0 - permuted_scores)\n\n  // 5. Aggregate results across all folds.\n  mean_importances = normalized_importances.mean(axis=0)\n  std_importances = normalized_importances.std(axis=0) * (number of folds)^(-0.5)\n\n  // 6. Combine into a final results table.\n  final_result = DataFrame({'mean': mean_importances, 'std': std_importances})\n\n  RETURN final_result\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 135,
    "text": "## Core Concept\n\nTheil's U statistic is a measure of association between two categorical variables, `X` and `Y`. It is particularly useful because it is asymmetric, meaning it distinguishes between the predictability of `X` given `Y` and `Y` given `X`.\n\n- **[Definition] Theil's U Statistic `U(X|Y)`**: Quantifies the reduction in uncertainty (entropy) of variable `X` given knowledge of variable `Y`. It ranges from 0 to 1, where 0 indicates that `Y` provides no information about `X`, and 1 indicates that `Y` provides complete information about `X`.\n\n## Mathematical Formulation\n\nThe formula for Theil's U statistic is expressed in terms of entropy:\n\n**Equation 1:**\n`U(X|Y) = (H(X) - H(X|Y)) / H(X)`\n\nWhere:\n- `U(X|Y)`: Theil's U, measuring the uncertainty reduction in `X` from knowing `Y`.\n- **[Definition] Entropy `H(X)`**: A measure of the uncertainty or randomness of a single variable `X`. It is zero if all outcomes are the same and maximal when all outcomes are equally likely.\n- **[Definition] Conditional Entropy `H(X|Y)`**: The remaining uncertainty in variable `X` after the value of variable `Y` is known. The term `H(X) - H(X|Y)` is also known as the Mutual Information between `X` and `Y`.\n\nAn important edge case occurs when `H(X)` is zero. This happens when the variable `X` has only one unique value (no uncertainty). In this scenario, knowing `Y` cannot reduce the uncertainty of `X` any further, and the association `U(X|Y)` is defined as 1.",
    "question": "Provide the pseudocode for a function that computes Theil's U statistic, `U(X|Y)`, for two categorical variables `x` and `y`.",
    "answer": "```pseudocode\n// FUNCTION CalculateTheilsU(x, y)\n// INPUTS:\n//   - x: A series or list of categorical data (the dependent variable).\n//   - y: A series or list of categorical data (the independent variable).\n// OUTPUTS:\n//   - A float value representing Theil's U statistic U(X|Y).\n\n// HELPER FUNCTIONS (assumed to exist):\n//   - CalculateEntropy(series): Computes the entropy of a categorical series.\n//   - CalculateMutualInformation(series1, series2): Computes the mutual information between two categorical series.\n\nBEGIN\n  // 1. Calculate the entropy of the dependent variable x.\n  entropy_x = CalculateEntropy(x)\n\n  // 2. Handle the edge case where x has no uncertainty.\n  // If the entropy of x is zero, it means x has only one state.\n  // In this case, y perfectly 'predicts' x, so U(X|Y) is 1.\n  IF entropy_x == 0 THEN\n    RETURN 1.0\n  END IF\n\n  // 3. Calculate the mutual information between x and y.\n  // Mutual Information is equivalent to H(X) - H(X|Y).\n  mutual_info_xy = CalculateMutualInformation(x, y)\n\n  // 4. Compute Theil's U statistic using the formula.\n  theils_u = mutual_info_xy / entropy_x\n\n  RETURN theils_u\nEND\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 136,
    "text": "## Framework Overview\n\nThe Sharpe Ratio (SR) is a fundamental measure of risk-adjusted return. It quantifies the average return earned in excess of the risk-free rate per unit of volatility or total risk. A higher Sharpe Ratio indicates a better historical risk-adjusted performance.\n\n### 1. Mathematical Formulation\n\nThe ex-ante Sharpe Ratio is defined theoretically as:\n\n`Equation 1:` $$ \\mathrm{SR} = \\frac{E[R - R^f]}{\\sqrt{\\mathrm{Var}(R - R^f)}} = \\frac{\\mu - R_f}{\\sigma_{R^e}} $$\n\nWhere:\n- **[Definition] `E[...]`**: The expectation operator.\n- **[Definition] `Var(...)`**: The variance operator.\n- `R`: The random variable for the portfolio's return.\n- `R^f`: The risk-free rate.\n- `娓璥: The expected portfolio return, `E(R)`.\n- `锜絖Re`: The standard deviation of the portfolio's excess return, `R - R^f`.\n\n### 2. Estimation from Historical Data\n\nIn practice, the SR is estimated from a time series of historical returns. Given a series of `T` excess returns, `r_t^e = r_t - r_t^f`, the components are calculated as follows:\n\n`Equation 2: Estimated Mean Excess Return`\n$$ \\hat{\\mu}_{R^e} = \\frac{1}{T}\\sum_{t = 1}^{T}r_t^e $$\n\n`Equation 3: Estimated Variance of Excess Return`\n$$ \\hat{\\sigma}_{R^e}^2 = \\frac{1}{T - 1}\\sum_{t = 1}^{T}(r_t^e -\\hat{\\mu}_{R^e})^2 $$\n\n*Note: Using `T-1` in the denominator provides an unbiased estimate of the variance.*\n\nThe estimated Sharpe Ratio for the period is then the ratio of the mean excess return to the standard deviation of excess returns (the square root of the variance).\n\n`Equation 4: Estimated Sharpe Ratio (Periodic)`\n$$ \\mathrm{SR}_{period} = \\frac{\\hat{\\mu}_{R^e}}{\\hat{\\sigma}_{R^e}} $$\n\n### 3. Time Aggregation (Annualization)\n\nFinancial returns often do not follow an independently and identically distributed (IID) process. However, a common simplification for annualizing a Sharpe Ratio calculated from higher-frequency data (e.g., daily or monthly) is to scale it by the square root of the number of periods in a year.\n\n`Equation 5: Annualized Sharpe Ratio`\n$$ \\mathrm{SR}_{annual} = \\mathrm{SR}_{period} * \\sqrt{P} $$\n\nWhere:\n- `P`: The number of periods in a year (e.g., ~252 for daily, 12 for monthly, 4 for quarterly).\n\nThis scaling assumes that returns are IID, which can be a strong assumption. More advanced methods exist for non-IID returns, but this is the standard industry practice.",
    "question": "1.  **`[Sharpe Ratio Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the annualized Sharpe Ratio from a time series of portfolio returns and a corresponding risk-free rate.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateAnnualizedSharpeRatio(portfolio_returns, risk_free_rates, periods_per_year)\n// INPUTS:\n//   - portfolio_returns: An array or list of portfolio returns for a given frequency (e.g., daily, monthly).\n//   - risk_free_rates: An array, list, or single value representing the risk-free rate for each period.\n//   - periods_per_year: An integer representing the number of periods in a year (e.g., 252 for daily).\n// OUTPUTS:\n//   - A single float value representing the annualized Sharpe Ratio.\n//\n// BEGIN\n//   1. Calculate Excess Returns\n//   IF length of risk_free_rates is 1 THEN\n//     excess_returns = portfolio_returns - risk_free_rates[0]\n//   ELSE\n//     excess_returns = portfolio_returns - risk_free_rates\n//   END IF\n//\n//   2. Calculate Mean of Excess Returns\n//   mean_excess_return = AVERAGE(excess_returns)\n//\n//   3. Calculate Standard Deviation of Excess Returns\n//   // Use population standard deviation if returns represent the entire history,\n//   // or sample standard deviation (with N-1) for a sample.\n//   std_dev_excess_return = STANDARD_DEVIATION(excess_returns, use_sample_correction=true)\n//\n//   4. Handle division by zero\n//   IF std_dev_excess_return == 0 THEN\n//     RETURN 0.0\n//   END IF\n//\n//   5. Calculate Sharpe Ratio for the period\n//   periodic_sharpe_ratio = mean_excess_return / std_dev_excess_return\n//\n//   6. Annualize the Sharpe Ratio\n//   annualized_sharpe_ratio = periodic_sharpe_ratio * SQRT(periods_per_year)\n//\n//   RETURN annualized_sharpe_ratio\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 137,
    "text": "## Framework Overview\n\nThe Information Ratio (IR) is a measure of a portfolio manager's skill at generating returns in excess of a given benchmark. It is similar in structure to the Sharpe Ratio but replaces the risk-free rate with a benchmark portfolio (e.g., the S&P 500).\n\n### 1. Key Concepts\n\n- **[Definition] Alpha**: The excess return of an investment relative to the return of a benchmark index. It is the return generated by active management.\n- **[Definition] Tracking Error**: The standard deviation of the difference between the portfolio's returns and the benchmark's returns. It measures the volatility of the active return.\n\n### 2. Mathematical Formulation\n\nThe Information Ratio is calculated as the annualized active return divided by the annualized tracking error.\n\n`Equation 1:`\n$$ \\mathrm{IR} = \\frac{\\text{Alpha}}{\\text{Tracking Error}} = \\frac{E[R_p - R_b]}{\\sqrt{\\mathrm{Var}(R_p - R_b)}} $$\n\nWhere:\n- `R_p`: The portfolio's returns.\n- `R_b`: The benchmark's returns.\n- `E[R_p - R_b]`: The expected value of the active return (portfolio return minus benchmark return).\n- `\\sqrt{\\mathrm{Var}(R_p - R_b)}`: The standard deviation of the active return, also known as the tracking error.\n\n### 3. Estimation from Historical Data\n\nGiven a time series of portfolio returns `r_p` and benchmark returns `r_b` over `T` periods, the IR is estimated by:\n\n1.  **Calculate the Active Return Series**: For each period `t`, compute `active_return_t = r_{p,t} - r_{b,t}`.\n2.  **Calculate the Mean Active Return (Alpha)**: Compute the average of the active return series.\n3.  **Calculate the Tracking Error**: Compute the standard deviation of the active return series.\n4.  **Compute the Ratio**: Divide the mean active return by the tracking error.\n\nLike the Sharpe Ratio, the IR is often annualized by multiplying the periodic IR by the square root of the number of periods in a year.",
    "question": "1.  **`[Information Ratio Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the annualized Information Ratio from a time series of portfolio returns and benchmark returns.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateAnnualizedInformationRatio(portfolio_returns, benchmark_returns, periods_per_year)\n// INPUTS:\n//   - portfolio_returns: An array or list of portfolio returns for a given frequency.\n//   - benchmark_returns: An array or list of benchmark returns for the same frequency and length.\n//   - periods_per_year: An integer representing the number of periods in a year (e.g., 252 for daily).\n// OUTPUTS:\n//   - A single float value representing the annualized Information Ratio.\n//\n// BEGIN\n//   1. Validate inputs\n//   ASSERT that length of portfolio_returns equals length of benchmark_returns.\n//\n//   2. Calculate Active Return Series\n//   active_returns = portfolio_returns - benchmark_returns\n//\n//   3. Calculate Mean Active Return (Alpha)\n//   mean_active_return = AVERAGE(active_returns)\n//\n//   4. Calculate Tracking Error (Standard Deviation of Active Returns)\n//   tracking_error = STANDARD_DEVIATION(active_returns, use_sample_correction=true)\n//\n//   5. Handle division by zero\n//   IF tracking_error == 0 THEN\n//     RETURN 0.0\n//   END IF\n//\n//   6. Calculate Information Ratio for the period\n//   periodic_ir = mean_active_return / tracking_error\n//\n//   7. Annualize the Information Ratio\n//   annualized_ir = periodic_ir * SQRT(periods_per_year)\n//\n//   RETURN annualized_ir\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 138,
    "text": "## Framework Overview\n\nMean-Variance Optimization (MVO), pioneered by Harry Markowitz, is the cornerstone of modern portfolio theory. It provides a mathematical framework for constructing portfolios that achieve a desired risk-return trade-off. The core idea is to find the set of asset weights that either minimizes portfolio volatility for a given level of expected return or maximizes expected return for a given level of volatility.\n\n### 1. Key Inputs\n\nTo perform MVO, three inputs are required:\n1.  A vector of expected returns for each asset (`娓璥).\n2.  A vector of expected volatilities (standard deviations) for each asset.\n3.  A covariance matrix of returns for all assets (`鍗盽).\n\n### 2. Mathematical Formulation\n\nGiven a vector of portfolio weights `锠卄 (where the sum of weights is 1), the portfolio's expected return (`娓璤p`) and variance (`锜絖p^2`) are calculated as:\n\n`Equation 1: Portfolio Expected Return`\n$$ \\mu_p = \\omega^T \\mu $$\n\n`Equation 2: Portfolio Variance`\n$$ \\sigma_p^2 = \\omega^T \\Sigma \\omega $$\n\n- **[Definition] Covariance Matrix (`鍗盽)**: A square matrix where the entry in the `i`-th row and `j`-th column is the covariance between the returns of asset `i` and asset `j`.\n- **[Definition] Weight Vector (`锠卄)**: A column vector where each element `锠卂i` represents the proportion of the portfolio's total value invested in asset `i`.\n\n### 3. The Optimization Problem\n\nThe general MVO problem is to minimize the portfolio variance subject to a target expected return:\n\n`Equation 3: MVO Problem`\n$$ \\begin{array}{rl} \\underset{\\omega}{\\min} & \\sigma_p^2 = \\omega^T \\Sigma \\omega \\\\ \\text{s.t.} & \\omega^T \\mu = \\mu_{target} \\\\ & \\omega^T \\mathbf{1} = 1 \\end{array} $$\n\n### 4. Maximizing the Sharpe Ratio\n\nA common application of MVO is to find the specific portfolio that maximizes the Sharpe Ratio. This involves finding the weights `锠卄 that maximize `(娓璤p - r_f) / 锜絖p`. This is equivalent to minimizing the negative Sharpe Ratio, which can be solved using a numerical quadratic optimizer.\n\nThe objective function for the optimizer becomes:\n\n`Objective: Minimize` $$ -\\frac{\\omega^T \\mu - r_f}{\\sqrt{\\omega^T \\Sigma \\omega}} $$",
    "question": "1.  **`[Max Sharpe Ratio MVO Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that takes expected returns, a covariance matrix, and a risk-free rate, and returns the portfolio weights that maximize the Sharpe Ratio.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FindMaxSharpeRatioWeights(expected_returns, covariance_matrix, risk_free_rate)\n// INPUTS:\n//   - expected_returns: A vector of mean expected returns for N assets.\n//   - covariance_matrix: An N x N covariance matrix of asset returns.\n//   - risk_free_rate: A single float value for the risk-free rate.\n// OUTPUTS:\n//   - A vector of optimal portfolio weights for N assets that maximizes the Sharpe Ratio.\n//\n// BEGIN\n//   1. Define the Objective Function (Negative Sharpe Ratio)\n//   FUNCTION objective(weights):\n//     portfolio_return = DOT_PRODUCT(weights, expected_returns)\n//     portfolio_variance = DOT_PRODUCT(weights_transposed, DOT_PRODUCT(covariance_matrix, weights))\n//     portfolio_std_dev = SQRT(portfolio_variance)\n//\n//     IF portfolio_std_dev == 0 THEN RETURN infinity // Avoid division by zero\n//\n//     sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std_dev\n//     RETURN -sharpe_ratio // Optimizer will minimize this value\n//   END FUNCTION\n//\n//   2. Define Constraints\n//   // Constraint 1: Weights must sum to 1.\n//   sum_constraint = {type: 'equality', function: (weights) => SUM(weights) - 1}\n//\n//   3. Define Bounds for each weight\n//   // Example: No short-selling (weights between 0 and 1).\n//   num_assets = length of expected_returns\n//   bounds = TUPLE_OF_PAIRS((0, 1) for each asset in num_assets)\n//\n//   4. Set Initial Guess\n//   // An equal-weight portfolio is a common starting point.\n//   initial_weights = array of (1 / num_assets) for each asset\n//\n//   5. Run the Optimizer\n//   // Use a numerical solver (e.g., Sequential Least Squares Quadratic Programming - SLSQP).\n//   result = SOLVE(\n//     objective_function = objective,\n//     initial_guess = initial_weights,\n//     method = 'SLSQP',\n//     bounds = bounds,\n//     constraints = [sum_constraint]\n//   )\n//\n//   6. Extract and Return Optimal Weights\n//   optimal_weights = result.weights\n//   RETURN optimal_weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 139,
    "text": "## Framework Overview\n\nThe Global Minimum-Variance (GMV) portfolio is a special case of Mean-Variance Optimization that focuses exclusively on minimizing portfolio risk, as measured by variance. It is the portfolio on the efficient frontier with the lowest possible volatility. This approach is particularly valuable because asset covariances can be estimated with greater statistical reliability than expected returns.\n\n### 1. Core Concept\n\nThe objective of the GMV portfolio is to find the set of asset weights `锠卄 that minimizes the total portfolio variance, without any consideration for the portfolio's expected return.\n\n### 2. Mathematical Formulation\n\nThe portfolio variance is given by the quadratic form:\n\n`Equation 1: Portfolio Variance`\n$$ \\sigma_p^2 = \\omega^T \\Sigma \\omega $$\n\nWhere:\n- **[Definition] Weight Vector (`锠卄)**: A column vector where each element `锠卂i` represents the proportion of the portfolio's value invested in asset `i`.\n- **[Definition] Covariance Matrix (`鍗盽)**: An `N x N` matrix representing the covariance of returns between all pairs of `N` assets in the portfolio.\n\nThe optimization problem is to find the weights `锠卄 that solve the following:\n\n`Equation 2: GMV Optimization Problem`\n$$ \\begin{array}{rl} \\underset{\\omega}{\\min} & \\omega^T \\Sigma \\omega \\\\ \\text{s.t.} & \\omega^T \\mathbf{1} = 1 \\end{array} $$\n\nThis is a constrained quadratic optimization problem. The only constraint is that the weights must sum to one, ensuring the portfolio is fully invested. Additional constraints, such as no short-selling (`锠卂i >= 0` for all `i`), can also be added.",
    "question": "1.  **`[Minimum-Variance Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes the weights of the Global Minimum-Variance portfolio given an asset covariance matrix.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FindGlobalMinimumVarianceWeights(covariance_matrix, allow_shorting)\n// INPUTS:\n//   - covariance_matrix: An N x N covariance matrix of asset returns.\n//   - allow_shorting: A boolean flag (true/false) to indicate if short positions are permitted.\n// OUTPUTS:\n//   - A vector of optimal portfolio weights for N assets that minimizes portfolio variance.\n//\n// BEGIN\n//   1. Define the Objective Function (Portfolio Variance)\n//   FUNCTION objective(weights):\n//     portfolio_variance = DOT_PRODUCT(weights_transposed, DOT_PRODUCT(covariance_matrix, weights))\n//     RETURN portfolio_variance // Optimizer will minimize this value\n//   END FUNCTION\n//\n//   2. Define Constraints\n//   // Constraint: Weights must sum to 1.\n//   sum_constraint = {type: 'equality', function: (weights) => SUM(weights) - 1}\n//\n//   3. Define Bounds for each weight\n//   num_assets = number of rows in covariance_matrix\n//   IF allow_shorting IS true THEN\n//     // Allow weights to be negative (e.g., from -1 to 1).\n//     bounds = TUPLE_OF_PAIRS((-1, 1) for each asset in num_assets)\n//   ELSE\n//     // Constrain weights to be between 0 and 1 (no short-selling).\n//     bounds = TUPLE_OF_PAIRS((0, 1) for each asset in num_assets)\n//   END IF\n//\n//   4. Set Initial Guess\n//   // An equal-weight portfolio is a robust starting point.\n//   initial_weights = array of (1 / num_assets) for each asset\n//\n//   5. Run the Optimizer\n//   // Use a numerical solver suitable for quadratic programming (e.g., SLSQP).\n//   result = SOLVE(\n//     objective_function = objective,\n//     initial_guess = initial_weights,\n//     method = 'SLSQP',\n//     bounds = bounds,\n//     constraints = [sum_constraint]\n//   )\n//\n//   6. Extract and Return Optimal Weights\n//   optimal_weights = result.weights\n//   RETURN optimal_weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 140,
    "text": "## Framework Overview\n\nThe Kelly Criterion is a formula used to determine the optimal size for a series of bets to maximize the long-term logarithmic growth of capital. Originally developed for gambling, it has been adapted for financial markets to guide portfolio allocation and leverage decisions. For multiple assets with continuous returns, the criterion provides a direct calculation for the optimal allocation vector.\n\n### 1. Core Concept\n\nThe goal is to find the fraction of capital `f` to allocate to each asset to maximize the expected geometric growth rate `G` of the portfolio. This approach inherently balances return and risk, as maximizing log-wealth avoids scenarios that lead to total ruin (`log(0)` is negative infinity).\n\n### 2. Single Asset Formulation (Continuous)\n\nFor a single asset with a distribution of returns `r`, the objective is to find the fraction `f*` that maximizes the expected log-return:\n\n`Equation 1:`\n$$ E[G] = E[\\log(1 + f \\cdot r)] $$\n\nThis is solved by finding `f` where the derivative with respect to `f` is zero:\n\n`Equation 2:`\n$$ \\frac{d}{df} E[G] = E\\left[\\frac{r}{1 + f \\cdot r}\\right] = 0 $$\n\n### 3. Multi-Asset Formulation\n\nFor a portfolio of `N` assets, the Kelly Criterion provides a closed-form solution for the vector of optimal allocations, `f*`. This solution is equivalent to finding the portfolio that maximizes the Sharpe Ratio, but it also determines the optimal amount of leverage.\n\nThe calculation requires two key inputs:\n- `娓璥: A vector of expected excess returns (asset return minus risk-free rate).\n- `鍗盽: The `N x N` covariance matrix of asset returns.\n\nThe optimal allocation vector `f*` is computed as:\n\n`Equation 3:`\n$$ f^* = \\Sigma^{-1} \\mu $$\n\nWhere:\n- **[Definition] `鍗遍垿瀹︾ (Precision Matrix)**: The inverse of the covariance matrix. It captures the partial correlations between assets.\n\nMultiplying the precision matrix by the vector of mean excess returns yields the optimal fraction of capital to allocate to each asset. The sum of these fractions can be greater than 1 (indicating leverage) or less than 1 (indicating holding cash).",
    "question": "1.  **`[Multi-Asset Kelly Criterion Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that calculates the Kelly-optimal allocation fractions for a portfolio of multiple assets.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateMultiAssetKellyFractions(mean_excess_returns, covariance_matrix)\n// INPUTS:\n//   - mean_excess_returns: A vector of mean expected returns in excess of the risk-free rate for N assets.\n//   - covariance_matrix: An N x N covariance matrix of asset returns.\n// OUTPUTS:\n//   - A vector of Kelly-optimal allocation fractions for the N assets.\n//\n// BEGIN\n//   1. Validate Inputs\n//   num_assets = length of mean_excess_returns\n//   ASSERT that dimensions of covariance_matrix are (num_assets x num_assets).\n//\n//   2. Calculate the Precision Matrix\n//   // The precision matrix is the inverse of the covariance matrix.\n//   // This step may fail if the matrix is singular (not invertible), which requires handling.\n//   TRY:\n//     precision_matrix = INVERT(covariance_matrix)\n//   CATCH MatrixSingularError:\n//     // Handle the error, e.g., by using a pseudo-inverse or returning an error.\n//     PRINT \"Error: Covariance matrix is not invertible.\"\n//     RETURN empty_vector\n//   END TRY\n//\n//   3. Calculate Optimal Kelly Fractions\n//   // The optimal fractions are the dot product of the precision matrix and the mean excess returns vector.\n//   kelly_fractions = DOT_PRODUCT(precision_matrix, mean_excess_returns)\n//\n//   4. Return the result\n//   // Note: The sum of these fractions is not constrained to 1. A sum > 1 implies leverage.\n//   RETURN kelly_fractions\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 141,
    "text": "## Framework Overview\n\nRisk Parity is a portfolio allocation strategy that focuses on the allocation of risk rather than the allocation of capital. The goal is to construct a portfolio where each asset contributes equally to the total portfolio risk. This approach stands in contrast to traditional allocation methods that might be dominated by the risk of a single asset class, like equities.\n\n### 1. Core Concept\n\nInstead of assigning equal capital to each asset (like a 1/N portfolio), a Risk Parity portfolio assigns weights such that the risk contribution of each asset is equal. In its simplest form, this can be achieved without forecasting returns.\n\n- **[Definition] Risk Contribution**: The amount of total portfolio risk that is attributable to a single asset. In a risk parity portfolio, all assets have the same risk contribution.\n\n### 2. Simple Implementation: Inverse-Variance Weighting\n\nA straightforward and common implementation of Risk Parity ignores the effects of correlation between assets. In this simplified case, an asset's risk is measured purely by its own volatility (or variance).\n\nThe logic is as follows:\n1.  Calculate the variance (`锜絖i^2`) for each asset `i` in the portfolio based on its historical returns.\n2.  Assign an initial (unscaled) weight to each asset that is proportional to the inverse of its variance: `unscaled_weight_i 閳?1 / 锜絖i^2`.\n3.  Normalize these unscaled weights so that they sum to 1. This ensures the portfolio is fully invested.\n\n`Equation 1: Normalized Risk Parity Weight`\n$$ w_i = \\frac{1/\\sigma_i^2}{\\sum_{j=1}^{N} (1/\\sigma_j^2)} $$\n\nThis method gives lower weights to highly volatile assets and higher weights to less volatile assets, aiming to balance the risk contribution from each position.",
    "question": "1.  **`[Simple Risk Parity Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes portfolio weights according to the simple inverse-variance Risk Parity approach.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateInverseVarianceWeights(asset_returns)\n// INPUTS:\n//   - asset_returns: A matrix or data frame where each column represents the time series of returns for an asset.\n// OUTPUTS:\n//   - A vector of portfolio weights corresponding to each asset.\n//\n// BEGIN\n//   1. Calculate the variance for each asset\n//   // This computes the variance down each column of the input matrix.\n//   asset_variances = CALCULATE_VARIANCE(asset_returns, axis=column)\n//\n//   2. Calculate the inverse of each variance\n//   // Handle potential division by zero if an asset has zero variance.\n//   inverse_variances = []\n//   FOR variance IN asset_variances:\n//     IF variance > 0 THEN\n//       APPEND (1 / variance) TO inverse_variances\n//     ELSE\n//       APPEND 0 TO inverse_variances\n//     END IF\n//   END FOR\n//\n//   3. Calculate the sum of the inverse variances\n//   sum_of_inverse_variances = SUM(inverse_variances)\n//\n//   4. Normalize the weights\n//   // Each weight is the asset's inverse variance divided by the total sum,\n//   // ensuring all weights sum to 1.\n//   IF sum_of_inverse_variances == 0 THEN\n//     // If all variances were zero, return an equal-weight portfolio.\n//     num_assets = number of columns in asset_returns\n//     RETURN array of (1 / num_assets) for each asset\n//   END IF\n//\n//   risk_parity_weights = inverse_variances / sum_of_inverse_variances\n//\n//   5. Return the final weights\n//   RETURN risk_parity_weights\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 142,
    "text": "### Framework Overview\nWhen evaluating a regression model that predicts a continuous variable, such as asset returns, it is crucial to use a variety of error metrics to understand different aspects of its performance. Each metric penalizes errors differently, providing a more complete picture of the model's accuracy and reliability.\n\n### Key Concepts & Formulas\nLet `y` be the vector of `N` true outcome values and `娆 be the vector of `N` predicted values. The mean of the true outcomes is `鐦竊.\n\n1.  **[Definition] Mean Absolute Error (MAE)**: Measures the average magnitude of the errors in a set of predictions, without considering their direction. It is robust to outliers but does not heavily penalize large errors.\n    *   **Formula 1**: `MAE = (1/N) * 鍗?|y_i - 娆i|`\n\n2.  **[Definition] Root Mean Squared Error (RMSE)**: Calculates the square root of the average of the squared differences between predicted and actual values. It is sensitive to large errors due to the squaring term and is one of the most common metrics.\n    *   **Formula 2**: `RMSE = sqrt((1/N) * 鍗?(y_i - 娆i)铏? `\n\n3.  **[Definition] R-squared (R铏? Score**: Also known as the coefficient of determination, this metric represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It provides a measure of how well the model explains the variability of the outcome.\n    *   **Formula 3**: `R铏?= 1 - (鍗?(y_i - 娆i)铏? / (鍗?(y_i - 鐦?铏? `\n    *   The numerator is the Sum of Squared Residuals (errors), and the denominator is the Total Sum of Squares.",
    "question": "Provide the pseudocode for a function that accepts two arrays of equal length (one for true values, one for predicted values) and returns the MAE, RMSE, and R铏?score.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateRegressionMetrics(true_values, predicted_values)\n// INPUTS:\n//   - true_values: An array of N numeric actual outcome values.\n//   - predicted_values: An array of N numeric model-predicted values.\n// OUTPUTS:\n//   - A map or dictionary containing the calculated MAE, RMSE, and R2_score.\n//\n// BEGIN\n//   N = length of true_values\n//   IF N == 0 THEN RETURN {MAE: 0, RMSE: 0, R2_score: 0}\n//\n//   // Initialize accumulators\n//   sum_absolute_error = 0.0\n//   sum_squared_error = 0.0\n//   sum_true_values = 0.0\n//\n//   // First pass: Calculate error sums and mean of true values\n//   FOR i FROM 0 TO N-1\n//     error = true_values[i] - predicted_values[i]\n//     sum_absolute_error += absolute(error)\n//     sum_squared_error += error * error\n//     sum_true_values += true_values[i]\n//   END FOR\n//\n//   mean_true_value = sum_true_values / N\n//\n//   // Second pass: Calculate total sum of squares\n//   total_sum_of_squares = 0.0\n//   FOR i FROM 0 TO N-1\n//     total_sum_of_squares += (true_values[i] - mean_true_value)^2\n//   END FOR\n//\n//   // Calculate final metrics\n//   mae = sum_absolute_error / N\n//   rmse = sqrt(sum_squared_error / N)\n//\n//   // Avoid division by zero for R-squared\n//   IF total_sum_of_squares == 0 THEN\n//     r2_score = 1.0 // Perfect prediction if variance is zero\n//   ELSE\n//     r2_score = 1.0 - (sum_squared_error / total_sum_of_squares)\n//   END IF\n//\n//   RETURN {MAE: mae, RMSE: rmse, R2_score: r2_score}\n//\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 143,
    "text": "### Framework Overview\nMutual Information (MI) is a powerful tool for feature selection because it captures non-linear relationships between variables, unlike simple correlation. It measures how much information the presence of one variable provides about another. For a feature `X` and a target variable `Y`, a higher MI value implies that `X` is more informative for predicting `Y`.\n\n### Key Concepts\n1.  **[Definition] Entropy**: A measure of the uncertainty or randomness of a single random variable. For a variable `X`, its entropy `H(X)` is calculated as `H(X) = -鍗?p(x) * log(p(x))`, where `p(x)` is the probability of outcome `x`.\n\n2.  **[Definition] Mutual Information (MI)**: The MI of two discrete random variables `X` and `Y` measures their mutual dependence. It can be defined in terms of their joint and marginal probability distributions.\n    *   **Formula 1**: `I(X;Y) = 鍗盻y 鍗盻x p(x,y) * log( p(x,y) / (p(x)p(y)) )`\n\n### Computational Steps\nTo compute MI from data, you must first estimate the required probabilities from frequency counts:\n*   `p(x)`: The marginal probability of value `x` occurring in variable `X`. Calculated as `(count of x) / (total samples)`.\n*   `p(y)`: The marginal probability of value `y` occurring in variable `Y`.\n*   `p(x,y)`: The joint probability of `x` and `y` occurring together. Calculated as `(count of (x,y) pair) / (total samples)`.",
    "question": "Provide the pseudocode for a function that computes the Mutual Information between two discrete input arrays, `feature_vector` and `target_vector`.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateMutualInformation(feature_vector, target_vector)\n// INPUTS:\n//   - feature_vector: An array of N discrete values representing a feature.\n//   - target_vector: An array of N discrete values representing the target.\n// OUTPUTS:\n//   - A single float value representing the Mutual Information I(X;Y).\n//\n// BEGIN\n//   N = length of feature_vector\n//   IF N == 0 THEN RETURN 0.0\n//\n//   // Step 1: Estimate joint probability distribution p(x,y)\n//   joint_counts = new Map()\n//   FOR i FROM 0 TO N-1\n//     key = (feature_vector[i], target_vector[i])\n//     joint_counts[key] = joint_counts.get(key, 0) + 1\n//   END FOR\n//\n//   // Step 2: Estimate marginal probability distributions p(x) and p(y)\n//   feature_counts = new Map()\n//   target_counts = new Map()\n//   FOR key, count IN joint_counts\n//     x, y = key\n//     feature_counts[x] = feature_counts.get(x, 0) + count\n//     target_counts[y] = target_counts.get(y, 0) + count\n//   END FOR\n//\n//   // Step 3: Calculate Mutual Information using the formula\n//   mutual_information = 0.0\n//   FOR key, joint_count IN joint_counts\n//     x, y = key\n//     p_xy = joint_count / N\n//     p_x = feature_counts[x] / N\n//     p_y = target_counts[y] / N\n//\n//     // Ensure probabilities are non-zero to avoid log(0) errors\n//     IF p_xy > 0 AND p_x > 0 AND p_y > 0 THEN\n//       mutual_information += p_xy * log2(p_xy / (p_x * p_y))\n//     END IF\n//   END FOR\n//\n//   RETURN mutual_information\n//\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 144,
    "text": "### Framework Overview\nCross-validation (CV) is essential for estimating a model's out-of-sample performance. However, standard CV methods like K-Fold, which randomly shuffle data, are invalid for time-series data because they violate temporal causality閳ユ敆sing future data to train a model that predicts the past.\n\n### Key Concepts\n1.  **[Definition] Lookahead Bias**: A critical error in financial modeling where a model is inadvertently exposed to information that would not have been available at the time of prediction, leading to unrealistically optimistic performance estimates.\n\n2.  **[Definition] Time-Series Cross-Validation (Walk-Forward)**: A CV methodology that respects the temporal order of data. It works by creating a series of splits where the training set always occurs before the validation set.\n\n### The Expanding Window Method\nThis specific walk-forward approach works as follows for `k` splits:\n*   **Split 1**: Train on Fold 1, Validate on Fold 2.\n*   **Split 2**: Train on Folds 1-2, Validate on Fold 3.\n*   **Split 3**: Train on Folds 1-2-3, Validate on Fold 4.\n*   ...and so on.\n\nIn each step, the training set grows to include the previous validation set, simulating how a model would be retrained over time as new data becomes available. This ensures that at no point is the model trained on data that comes after the data it is being tested on.",
    "question": "Provide the pseudocode for a generator function that implements the logic of Time-Series Cross-Validation with an expanding window. The function should take the total number of data points and the desired number of splits as input.",
    "answer": "// --- BEGIN PSEUDOCODE ---\n//\n// GENERATOR FUNCTION TimeSeriesSplit(num_samples, n_splits)\n// INPUTS:\n//   - num_samples: The total number of observations in the dataset.\n//   - n_splits: The number of validation splits to generate.\n// OUTPUTS:\n//   - Yields a tuple of (train_indices, validation_indices) for each split.\n//\n// BEGIN\n//   // The total number of folds is n_splits + 1 (1 initial train fold + n_splits validation folds)\n//   num_folds = n_splits + 1\n//   fold_size = floor(num_samples / num_folds)\n//\n//   // Ensure there are enough samples for the requested splits\n//   IF n_splits >= num_samples THEN\n//     RAISE ERROR \"Cannot have n_splits >= num_samples\"\n//   END IF\n//\n//   indices = range(0, num_samples - 1)\n//   start_index = 0\n//\n//   // Loop to generate each of the n_splits\n//   FOR i FROM 1 TO n_splits\n//     // The training set ends where the validation set begins\n//     train_end_index = i * fold_size\n//\n//     // The validation set is the next fold\n//     validation_end_index = (i + 1) * fold_size\n//\n//     // Define the indices for the current split\n//     train_indices = indices from 0 up to (train_end_index - 1)\n//     validation_indices = indices from train_end_index up to (validation_end_index - 1)\n//\n//     // Yield the current split's indices\n//     YIELD (train_indices, validation_indices)\n//   END FOR\n//\n// END\n//\n// --- END PSEUDOCODE ---",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 145,
    "text": "### 1. Framework Overview\n\nFactor models are used to quantify the relationship between an asset's return and the sources of systematic risk that drive those returns. The Fama-Macbeth regression is a specialized method designed to estimate the risk premia associated with these factors using panel data (i.e., data with both time-series and cross-sectional dimensions).\n\n- **[Definition] Factor Model**: A model that explains asset returns through their exposure to a set of common risk factors (e.g., market risk, size, value).\n- **[Definition] Fama-Macbeth Regression**: A two-stage procedure used to estimate factor risk premia from panel data. It is designed to address issues like cross-sectional correlation in residuals that can invalidate standard errors in a single large regression.\n- **[Definition] Ordinary Least Squares (OLS)**: A method for estimating the parameters of a linear regression model by finding the coefficients that minimize the sum of the squared differences between the observed outcomes and the values predicted by the model. This is the regression technique used in both stages of the Fama-Macbeth procedure.\n\n### 2. The Two-Stage Process\n\nThe methodology consists of two distinct regression stages performed sequentially.\n\n#### Stage 1: Time-Series Regressions\n\nIn the first stage, we run a separate time-series OLS regression for each of the \\(N\\) assets in our universe. Each regression uses the \\(T\\) historical returns of a single asset against the \\(M\\) factor returns over the same period. The goal is to estimate the asset's sensitivity, or exposure, to each factor.\n\n- **[Definition] Factor Loading (Beta, \\(\\beta\\))**: The coefficient from the first-stage regression, representing an asset's sensitivity to a specific risk factor.\n\nFor each asset \\(i\\) (from 1 to \\(N\\)):\n\n**Equation 1: First-Stage Time-Series Regression**\n$$ r_{i,t} = \\alpha_i + \\sum_{j=1}^{M} \\beta_{i,j} F_{j,t} + \\epsilon_{i,t} \\quad \\text{for } t=1, \\dots, T $$\n\nThis stage produces a set of factor loadings (\\(\\beta_{i,1}, \\dots, \\beta_{i,M}\\)) for each of the \\(N\\) assets.\n\n#### Stage 2: Cross-Sectional Regressions\n\nIn the second stage, we run a separate cross-sectional OLS regression for each of the \\(T\\) time periods. For a single time period \\(t\\), we regress the returns of all \\(N\\) assets at that time against their corresponding factor loadings (\\(\\beta\\)'s) estimated in Stage 1. The goal is to estimate the return premium associated with each factor for that specific period.\n\n- **[Definition] Risk Premium (Lambda, \\(\\lambda\\))**: The coefficient from the second-stage regression. It represents the market's reward for a unit of exposure to a given risk factor during a specific time period.\n\nFor each time period \\(t\\) (from 1 to \\(T\\)):\n\n**Equation 2: Second-Stage Cross-Sectional Regression**\n$$ r_{i,t} = \\lambda_{0,t} + \\sum_{j=1}^{M} \\lambda_{j,t} \\hat{\\beta}_{i,j} + \\nu_{i,t} \\quad \\text{for } i=1, \\dots, N $$\n\nThis stage produces a set of risk premia (\\(\\lambda_{1,t}, \\dots, \\lambda_{M,t}\\)) for each of the \\(T\\) time periods. A crucial practical step here is to handle missing asset returns for period \\(t\\) by running the regression only on the subset of assets with available data for that period.\n\n### 3. Final Risk Premia Estimation\n\nThe final estimate for the risk premium of each factor is calculated by taking the time-series average of the period-specific premia (\\(\\lambda_j\\)'s) obtained from Stage 2. The statistical significance of each premium is then assessed using the standard error of its time series.\n\n**Equation 3: Final Risk Premium for Factor j**\n$$ \\hat{\\lambda}_j = \\frac{1}{T} \\sum_{t=1}^{T} \\hat{\\lambda}_{j,t} $$",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Fama-Macbeth Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the complete two-stage Fama-Macbeth regression to calculate the final, time-averaged factor risk premia from a panel of asset returns and factor returns.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION FamaMacbethRegression(asset_returns, factor_returns)\n// INPUTS:\n//   - asset_returns: A (T x N) matrix of asset excess returns, where T is number of time periods and N is number of assets.\n//   - factor_returns: A (T x M) matrix of factor returns, where M is number of factors.\n// OUTPUTS:\n//   - risk_premia: A (M x 1) vector of time-averaged risk premia for each factor.\n//\n// BEGIN\n//   // STAGE 1: Time-Series Regressions to get Factor Loadings (Betas)\n//   Initialize betas_matrix as an (N x M) matrix.\n//   FOR each asset i from 1 to N:\n//     // Get the time series of returns for asset i.\n//     y = asset_returns[:, i]\n//     // Prepare factor returns as the independent variables, adding an intercept.\n//     X = add_intercept_column(factor_returns)\n//     // Run an OLS regression of y on X.\n//     coefficients = OLS(y, X)\n//     // Store the slope coefficients (factor loadings), ignoring the intercept.\n//     betas_matrix[i, :] = coefficients[1:]\n//   END FOR\n\n//   // STAGE 2: Cross-Sectional Regressions to get Period-Specific Risk Premia (Lambdas)\n//   Initialize lambdas_matrix as a (T x M) matrix.\n//   FOR each time period t from 1 to T:\n//     // Get the cross-section of asset returns for period t.\n//     y = asset_returns[t, :]\n//     // Use the estimated betas as the independent variables.\n//     X = betas_matrix\n//     // Important: Handle missing asset returns for this period t.\n//     // Filter y and X to include only assets with non-missing returns at time t.\n//     valid_indices = find_non_missing_indices(y)\n//     y_valid = y[valid_indices]\n//     X_valid = X[valid_indices, :]\n//     // Run a cross-sectional OLS regression.\n//     // Note: In this stage, the regression is typically run without an intercept.\n//     coefficients = OLS(y_valid, X_valid)\n//     // Store the resulting coefficients (period-specific risk premia).\n//     lambdas_matrix[t, :] = coefficients\n//   END FOR\n\n//   // FINAL STEP: Compute Average Risk Premia\n//   // Calculate the time-series mean of each column in the lambdas_matrix.\n//   risk_premia = mean(lambdas_matrix, axis=0)\n\n//   RETURN risk_premia\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 146,
    "text": "### 1. The Overfitting Problem in Predictive Modeling\n\nWhen a linear regression model contains many correlated variables, the coefficient estimates can become unstable and have high variance. This means the model may fit the training data very well but perform poorly on new, unseen data閳ユ攣 phenomenon known as overfitting.\n\n- **[Definition] Regularization**: A technique used to prevent overfitting by adding a penalty term to the model's objective function. This penalty discourages the model from learning overly complex or extreme coefficient values.\n- **[Definition] Shrinkage**: The effect of regularization, where coefficient estimates are pushed, or \"shrunk,\" towards zero. This reduces model complexity and variance.\n\n### 2. The Regularized Regression Framework\n\nShrinkage models modify the standard OLS objective function by adding a penalty term, \\(\\lambda S(\\beta)\\), which is a function of the coefficient vector \\(\\beta\\). The model then minimizes the sum of the Residual Sum of Squares (RSS) and this penalty.\n\n**Equation 1: General Form of a Shrinkage Model**\n$$ \\hat{\\beta}^S = \\underset{\\beta^S}{\\operatorname{argmin}} \\left( \\sum_{i=1}^{N} (y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_j)^2 + \\lambda S(\\beta) \\right) $$\n\nWhere:\n- \\(\\lambda\\) (lambda): The regularization parameter, a non-negative hyperparameter that controls the strength of the penalty. If \\(\\lambda=0\\), it becomes standard OLS. If \\(\\lambda \\to \\infty\\), all coefficients are shrunk to zero.\n- \\(S(\\beta)\\): The penalty function, which differs between shrinkage methods.\n\n### 3. Ridge Regression (L2 Regularization)\n\n- **[Definition] Ridge Regression**: A shrinkage method that uses the L2 norm of the coefficient vector as its penalty function. The L2 norm is the sum of the squared coefficients.\n- **[Definition] L2 Norm**: For a vector \\(\\beta\\), the L2 norm is \\(\\|\\beta\\|_2^2 = \\sum_{j=1}^{p} \\beta_j^2\\).\n\n**Equation 2: Ridge Regression Objective Function**\n$$ \\hat{\\beta}^{\\text{Ridge}} = \\underset{\\beta}{\\operatorname{argmin}} \\left( (y - X\\beta)^T(y - X\\beta) + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\right) $$\n\nNote that the intercept (\\(\\beta_0\\)) is typically excluded from the penalty. Ridge regression has a convenient closed-form solution, similar to OLS.\n\n**Equation 3: Ridge Regression Closed-Form Solution**\n$$ \\hat{\\beta}^{\\text{Ridge}} = (X^T X + \\lambda I)^{-1} X^T y $$\n\nWhere:\n- \\(X\\): The design matrix of input features (with a leading column of 1s for the intercept).\n- \\(y\\): The vector of target values.\n- \\(I\\): The identity matrix.\n- \\(\\lambda\\): The regularization parameter.\n\nIt is crucial to standardize the input features before applying Ridge regression, as the penalty is sensitive to the scale of the predictors.\n\n### 4. Lasso Regression (L1 Regularization)\n\n- **[Definition] Lasso Regression**: A shrinkage method that uses the L1 norm of the coefficient vector as its penalty.\n- **[Definition] L1 Norm**: For a vector \\(\\beta\\), the L1 norm is \\(\\|\\beta\\|_1 = \\sum_{j=1}^{p} |\\beta_j|\\).\n\nLasso's penalty can shrink coefficients completely to zero, effectively performing feature selection. It does not have a closed-form solution and must be solved with numerical optimization algorithms.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Ridge Regression Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that computes the coefficient vector for a Ridge Regression model using its closed-form analytical solution (Equation 3). The function must correctly apply the regularization parameter and ensure the intercept term is not penalized.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION RidgeRegressionClosedForm(X_features, y_target, lambda)\n// INPUTS:\n//   - X_features: An (N x p) matrix of standardized input features, where N is number of samples and p is number of features.\n//   - y_target: An (N x 1) vector of target values.\n//   - lambda: A non-negative scalar representing the regularization strength.\n// OUTPUTS:\n//   - beta_vector: A ((p+1) x 1) vector of estimated coefficients, including the intercept.\n//\n// BEGIN\n//   // 1. Prepare the design matrix by adding an intercept column.\n//   N = number_of_rows(X_features)\n//   intercept_column = create_vector_of_ones(N)\n//   X_design = concatenate_columns(intercept_column, X_features)\n//   P = number_of_columns(X_design) // Total number of parameters (p + 1)\n\n//   // 2. Create the penalty matrix.\n//   // Start with an identity matrix of size P x P.\n//   I = create_identity_matrix(P)\n//   // Set the first diagonal element to zero to exclude the intercept from the penalty.\n//   I[0, 0] = 0\n\n//   // 3. Compute the terms of the closed-form solution.\n//   X_transpose = transpose(X_design)\n//   X_transpose_X = X_transpose * X_design\n//   X_transpose_y = X_transpose * y_target\n\n//   // 4. Apply the regularization and solve for the coefficients.\n//   // Add the scaled penalty matrix to X_transpose_X.\n//   term_to_invert = X_transpose_X + (lambda * I)\n//   // Compute the inverse.\n//   inverse_term = inverse(term_to_invert)\n//   // Compute the final coefficient vector.\n//   beta_vector = inverse_term * X_transpose_y\n\n//   RETURN beta_vector\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 147,
    "text": "### 1. From Regression to Classification\n\nWhile linear regression predicts a continuous value, classification models predict a qualitative, or categorical, response. A common task in trading is to predict the direction of a price move (e.g., up or down), which is a binary classification problem.\n\n- **[Definition] Classification**: The process of assigning an observation to a category, or class. In binary classification, there are two possible classes (e.g., 0 or 1, 'up' or 'down').\n\n### 2. The Logistic Regression Model\n\nLogistic regression models the probability that an observation belongs to a particular class. For a binary outcome \\(y\\) (taking values 0 or 1), it models the probability \\(P(y=1|x)\\).\n\n- **[Definition] Logistic Function (Sigmoid)**: A function that maps any real-valued number into the range [0, 1]. It produces an 'S'-shaped curve, making it suitable for modeling probabilities.\n\n**Equation 1: The Logistic Function**\n$$ p(x) = \\frac{e^{\\beta_0 + \\sum_{i=1}^{p} \\beta_i x_i}}{1 + e^{\\beta_0 + \\sum_{i=1}^{p} \\beta_i x_i}} = \\frac{1}{1 + e^{-(X\\beta)}} $$\n\nWhere \\(p(x)\\) is the predicted probability that \\(y=1\\), given the features \\(x\\) and coefficients \\(\\beta\\).\n\nBy manipulating this equation, we can see the model's linear core:\n\n- **[Definition] Odds**: The ratio of the probability of an event occurring to the probability of it not occurring, calculated as \\(p(x) / (1 - p(x))\\).\n- **[Definition] Logit (Log-Odds)**: The natural logarithm of the odds. Logistic regression models the logit as a linear function of the input features.\n\n**Equation 2: The Logit Transformation**\n$$ \\log\\left(\\frac{p(x)}{1 - p(x)}\\right) = \\beta_0 + \\sum_{i=1}^{p} \\beta_i x_i $$\n\n### 3. Model Training via Maximum Likelihood\n\nUnlike OLS, logistic regression coefficients are estimated using Maximum Likelihood Estimation (MLE).\n\n- **[Definition] Maximum Likelihood Estimation (MLE)**: A method for estimating model parameters by finding the parameter values that maximize the likelihood function. Maximizing the likelihood is equivalent to finding the parameters that make the observed data most probable.\n\nFor a binary classification problem, the goal is to find the \\(\\beta\\) vector that maximizes the joint probability of observing the actual outcomes in the training data. This is achieved by maximizing the log-likelihood function.\n\n**Equation 3: The Log-Likelihood Function**\n$$ \\log \\mathcal{L}(\\beta) = \\sum_{i=1}^{N} \\left( y_i \\log(p(x_i)) + (1 - y_i) \\log(1 - p(x_i)) \\right) $$\n\nWhere:\n- \\(N\\): The number of observations.\n- \\(y_i\\): The actual binary outcome (0 or 1) for observation \\(i\\).\n- \\(p(x_i)\\): The model's predicted probability for observation \\(i\\), calculated using Equation 1.\n\nOptimization algorithms like gradient descent are used to find the \\(\\beta\\) values that maximize this function.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Logistic Regression Core Functions]`**:\n    *   **Task**: Provide the pseudocode for two separate but related functions essential for a logistic regression model: \n        1. A function that takes features and coefficients to compute predicted probabilities using the logistic (sigmoid) function (Equation 1).\n        2. A function that computes the scalar value of the log-likelihood objective function (Equation 3) for a given set of features, actual outcomes, and coefficients.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION PredictProbabilities(X_features, beta_coefficients)\n// INPUTS:\n//   - X_features: An (N x P) matrix of input features, where N is number of samples and P is number of parameters (including intercept term).\n//   - beta_coefficients: A (P x 1) vector of model coefficients.\n// OUTPUTS:\n//   - probabilities: An (N x 1) vector of predicted probabilities, where each value is in the range [0, 1].\n//\n// BEGIN\n//   // 1. Compute the linear combination of features and coefficients.\n//   z = X_features * beta_coefficients\n\n//   // 2. Apply the logistic (sigmoid) function element-wise.\n//   probabilities = 1.0 / (1.0 + exp(-z))\n\n//   RETURN probabilities\n// END\n\n//\n// FUNCTION LogLikelihood(X_features, y_target, beta_coefficients)\n// INPUTS:\n//   - X_features: An (N x P) matrix of input features.\n//   - y_target: An (N x 1) vector of actual binary outcomes (0s and 1s).\n//   - beta_coefficients: A (P x 1) vector of model coefficients.\n// OUTPUTS:\n//   - log_likelihood_value: A single scalar value representing the log-likelihood of the data given the model.\n//\n// BEGIN\n//   // 1. Get the predicted probabilities from the model.\n//   p = PredictProbabilities(X_features, beta_coefficients)\n\n//   // 2. Calculate the log-likelihood using the formula.\n//   // This involves element-wise multiplication and then summation.\n//   term1 = y_target * log(p)\n//   term2 = (1 - y_target) * log(1 - p)\n//   log_likelihood_value = sum(term1 + term2)\n\n//   RETURN log_likelihood_value\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 148,
    "text": "## Framework Overview\n\nA vectorized backtest is a foundational technique for rapidly evaluating a trading strategy. Instead of simulating trades event by event, it uses linear algebra operations on entire datasets (vectors or matrices) to compute performance. This approach is computationally efficient but makes simplifying assumptions about the trading environment.\n\n## Key Concepts\n\n- **[Definition] Signal Vector**: A data structure (e.g., a row in a DataFrame) where each element corresponds to an asset and its value represents a trading signal (e.g., long, short, neutral) or a target position size for a specific time period.\n- **[Definition] Returns Vector**: A corresponding data structure where each element is the return of an asset over the investment horizon targeted by the signal vector.\n\n## Computational Steps\n\nThe process involves three main stages:\n\n1.  **Data Preparation**: Start with two wide-format DataFrames:\n    *   `predictions`: Contains the raw numerical predictions from a model. Rows represent dates, and columns represent asset tickers.\n    *   `fwd_returns`: Contains the forward returns for each asset over the period the predictions are meant to forecast (e.g., the next day's open-to-open return). This DataFrame must be perfectly aligned with the `predictions` DataFrame.\n\n2.  **Signal Generation**: Convert the raw `predictions` into binary trading signals. For a long-short strategy targeting the top N assets, this involves:\n    *   Separating positive (potential longs) and negative (potential shorts) predictions.\n    *   Ranking the positive predictions in descending order and the negative predictions in ascending order.\n    *   Creating binary masks (`long_signals`, `short_signals`) where a `1` indicates a position should be taken (e.g., for the top 10 ranked assets) and a `0` otherwise.\n\n3.  **Performance Calculation**: Compute the strategy's daily returns.\n    *   Calculate the returns from long positions by performing an element-wise multiplication of the `long_signals` mask and the `fwd_returns` DataFrame.\n    *   Calculate the returns from short positions by multiplying the `short_signals` mask with the *negative* `fwd_returns`.\n    *   For an equal-weighted portfolio, the daily return for the long and short books is the mean of the non-zero returns for that day.\n    *   The total daily strategy return is the sum of the long book's return and the short book's return.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Vectorized Backtest Implementation]`**:\n    *   **Task**: Provide the pseudocode for a function that implements the Vectorized Backtesting logic for an equal-weighted, market-neutral long-short strategy. The function should take the top 10 positive predictions for long positions and the top 10 negative predictions for short positions.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION VectorizedBacktest(predictions_df, forward_returns_df, n_positions)\n// INPUTS:\n//   - predictions_df: A DataFrame with dates as index and tickers as columns, containing model predictions.\n//   - forward_returns_df: A DataFrame with the same shape as predictions_df, containing forward returns.\n//   - n_positions: An integer for the number of top/bottom positions to take (e.g., 10).\n// OUTPUTS:\n//   - A Series of daily strategy returns.\n//\n// BEGIN\n//   // Step 1: Generate Long Signals\n//   positive_preds = predictions_df.where(predictions_df > 0)\n//   long_ranks = positive_preds.rank(axis=1, ascending=False)\n//   long_signals = long_ranks.where(long_ranks <= n_positions, 0).where(long_ranks > 0, 1) // 1 for top N, 0 otherwise\n\n//   // Step 2: Generate Short Signals\n//   negative_preds = predictions_df.where(predictions_df < 0)\n//   short_ranks = negative_preds.rank(axis=1, ascending=True)\n//   short_signals = short_ranks.where(short_ranks <= n_positions, 0).where(short_ranks > 0, 1) // 1 for top N, 0 otherwise\n\n//   // Step 3: Calculate Portfolio Returns\n//   // Element-wise multiplication gives returns for signaled positions\n//   long_position_returns = long_signals * forward_returns_df\n//   short_position_returns = short_signals * (-1 * forward_returns_df)\n\n//   // For an equal-weighted portfolio, take the mean of active positions for each day\n//   daily_long_returns = long_position_returns.mean(axis=1)\n//   daily_short_returns = short_position_returns.mean(axis=1)\n\n//   // Total strategy return is the sum of the long and short books\n//   strategy_returns = daily_long_returns + daily_short_returns\n\n//   RETURN strategy_returns\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 149,
    "text": "## Framework Overview\n\nThe `backtrader` library provides an event-driven backtesting engine orchestrated by a central controller called `Cerebro`. The core of a custom trading algorithm is encapsulated within a `Strategy` class, which defines how to react to market data on a bar-by-bar basis.\n\n## Key Concepts\n\n- **[Definition] Cerebro**: The main orchestrator in `backtrader`. It synchronizes data feeds, passes data to the `Strategy`, sends orders to the `Broker`, and tracks performance.\n- **[Definition] Strategy Object**: A Python class that inherits from `backtrader.Strategy`. Its methods contain the trading logic. The most important method is `.next()`, which is called by `Cerebro` for each bar of data once all data feeds are synchronized.\n- **[Definition] Data Feed**: An object that provides time-series data (e.g., OHLCV and custom signals like predictions) for a single asset to the `Cerebro` engine.\n\n## Strategy Logic Implementation\n\nThe trading logic is executed within the `.next()` method for each time step (e.g., each day). The goal is to build a market-neutral portfolio by going long the `N` assets with the highest positive predictions and short the `N` assets with the lowest negative predictions.\n\n1.  **Gather Signals**: On the current day, iterate through all available data feeds. For each asset, check if it has a `predicted` value for today. Collect all positive predictions into a `long_candidates` dictionary and all negative predictions into a `short_candidates` dictionary, mapping ticker names to prediction values.\n\n2.  **Select Targets**: Sort the candidate dictionaries to identify the top `N` longs (descending by prediction value) and top `N` shorts (ascending by prediction value). These become the target portfolio for the day.\n\n3.  **Manage Exits**: Identify currently held positions that are *not* in the new target lists (neither longs nor shorts). For each of these positions, place an `order_target_percent` order with a target of `0` to close the position.\n\n4.  **Manage Entries/Rebalancing**: For each ticker in the new target lists, place an `order_target_percent` order. The target for longs is `1 / N_longs` and for shorts is `-1 / N_shorts`, creating an equal-weighted portfolio on each side.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[backtrader Strategy .next() Implementation]`**:\n    *   **Task**: Provide the pseudocode for the `.next()` method of a `backtrader` `Strategy` class. The logic should implement the daily rebalancing for a long-short strategy based on external prediction signals attached to each data feed.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// METHOD next() of class MLStrategy\n// INPUTS: (Implicit from self)\n//   - self.datas: A list of all data feeds available to the strategy.\n//   - self.p.n_positions: A parameter for the number of long/short positions.\n//   - self.p.min_positions: A parameter for the minimum number of positions on each side to trade.\n// OUTPUTS:\n//   - Places orders via the broker.\n//\n// BEGIN\n//   // Get the current date from the primary data feed\n//   current_date = self.datas[0].datetime.date()\n\n//   // Get a list of tickers for all currently held positions\n//   current_positions = [d._name for d, pos in self.getpositions().items() if pos.size != 0]\n\n//   // Step 1: Gather signals for the current day\n//   long_candidates = {}\n//   short_candidates = {}\n//   FOR each data_feed in self.datas:\n//     IF data_feed.datetime.date() == current_date AND data_feed.predicted[0] is not NULL:\n//       ticker = data_feed._name\n//       prediction = data_feed.predicted[0]\n//       IF prediction > 0:\n//         long_candidates[ticker] = prediction\n//       ELSE IF prediction < 0:\n//         short_candidates[ticker] = prediction\n//       END IF\n//     END IF\n//   END FOR\n\n//   // Step 2: Select Targets\n//   target_longs = sorted(long_candidates, key=long_candidates.get, reverse=True)[:self.p.n_positions]\n//   target_shorts = sorted(short_candidates, key=short_candidates.get, ascending=True)[:self.p.n_positions]\n\n//   // Abort if minimum number of positions is not met\n//   IF length(target_longs) < self.p.min_positions OR length(target_shorts) < self.p.min_positions:\n//     target_longs = []\n//     target_shorts = []\n//   END IF\n\n//   target_portfolio = target_longs + target_shorts\n\n//   // Step 3: Manage Exits\n//   FOR ticker in current_positions:\n//     IF ticker NOT IN target_portfolio:\n//       self.order_target_percent(data=ticker, target=0.0) // Close position\n//     END IF\n//   END FOR\n\n//   // Step 4: Manage Entries/Rebalancing\n//   IF length(target_longs) > 0:\n//     long_weight = 1.0 / length(target_longs)\n//     FOR ticker in target_longs:\n//       self.order_target_percent(data=ticker, target=long_weight)\n//     END FOR\n//   END IF\n\n//   IF length(target_shorts) > 0:\n//     short_weight = -1.0 / length(target_shorts)\n//     FOR ticker in target_shorts:\n//       self.order_target_percent(data=ticker, target=short_weight)\n//     END FOR\n//   END IF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 150,
    "text": "## Framework Overview\n\nThe Zipline `TradingAlgorithm` provides a structured environment for backtesting. Its event-driven nature is managed through a schedule of specific functions. For efficient cross-sectional data processing, Zipline's Pipeline API is used. When trading signals are pre-computed and stored externally, they can be integrated into this pipeline using a `DataFrameLoader`.\n\n## Key Concepts\n\n- **[Definition] Pipeline API**: A Zipline tool for defining and efficiently computing cross-sectional data (alpha factors) over time. It optimizes calculations across the entire backtest period, separating factor computation from trading logic.\n- **[Definition] DataFrameLoader**: A mechanism to load external, time-indexed data (like model predictions) into the Pipeline API. It requires a custom `DataSet` class to define the data's structure.\n- **[Definition] CustomFactor**: A class within the Pipeline API that allows for arbitrary computations on input data arrays. It can be used to process raw data, such as signals from a `DataFrameLoader`, into a format suitable for filtering or ranking.\n\n## Algorithmic Implementation Steps\n\nA Zipline algorithm is structured around several key methods:\n\n1.  **`initialize(context)`**: This function runs once at the start of the backtest. Its purpose is to set up the algorithm's state and schedule future actions. This includes:\n    *   Setting parameters like the number of positions in the `context` object.\n    *   Configuring transaction costs (slippage and commission).\n    *   Creating an instance of the Pipeline using the custom signal data.\n    *   Attaching the pipeline to the algorithm using `attach_pipeline()` so it runs automatically.\n    *   Scheduling the `rebalance` function to run at a specific time each day (e.g., one hour after market open).\n\n2.  **`before_trading_start(context, data)`**: This function runs daily before the market opens. It is the ideal place to perform calculations needed for the upcoming day's trading. The primary task here is to:\n    *   Access the output of the pipeline for the current day using `pipeline_output()`.\n    *   Process this output to create a simple list or Series of target trades (e.g., mapping asset SIDs to 1 for long, -1 for short).\n    *   Store this list of trades in the `context` object for the `rebalance` function to use later.\n\n3.  **`rebalance(context, data)`**: This function is executed according to the schedule set in `initialize()`. It contains the logic for placing orders. Its steps are:\n    *   Retrieve the target trades from the `context` object.\n    *   Iterate through the target trades. For any asset that should be in the portfolio, place an `order_target_percent` order to establish or maintain the desired position weight.\n    *   For any currently held asset that is *not* in the day's target trades, place an `order_target` order with a size of `0` to liquidate the position.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Zipline Algorithm Implementation]`**:\n    *   **Task**: Provide the pseudocode for the `initialize`, `before_trading_start`, and `rebalance` functions of a Zipline algorithm. The algorithm should use a Pipeline to generate long/short signals from pre-computed predictions and execute trades based on those signals.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION initialize(context)\n// INPUTS:\n//   - context: A dictionary for storing state.\n// OUTPUTS:\n//   - None. Modifies context and schedules functions.\n//\n// BEGIN\n//   // Set strategy parameters\n//   context.n_positions = 10\n//   context.min_positions = 5\n\n//   // Configure broker settings\n//   set_commission(cost_per_share = 0.001)\n//   set_slippage(spread = 0.0005)\n\n//   // Create and attach the signal processing pipeline\n//   signal_pipeline = create_signal_pipeline() // Assumes this function is defined elsewhere\n//   attach_pipeline(signal_pipeline, 'signals')\n\n//   // Schedule the rebalancing function to run daily\n//   schedule_function(rebalance, date_rules.every_day(), time_rules.market_open(minutes=60))\n// END\n\n\n// FUNCTION before_trading_start(context, data)\n// INPUTS:\n//   - context: The algorithm's state dictionary.\n//   - data: An object providing access to market data.\n// OUTPUTS:\n//   - None. Updates context with the day's trading signals.\n//\n// BEGIN\n//   // Get the daily output from the attached pipeline\n//   pipeline_results = pipeline_output('signals')\n\n//   // Identify long and short targets from the pipeline boolean columns\n//   longs = pipeline_results[pipeline_results['longs'] == True].index\n//   shorts = pipeline_results[pipeline_results['shorts'] == True].index\n\n//   // Store the final list of trades in the context object\n//   context.target_longs = longs\n//   context.target_shorts = shorts\n// END\n\n\n// FUNCTION rebalance(context, data)\n// INPUTS:\n//   - context: The algorithm's state dictionary.\n//   - data: An object providing access to market data.\n// OUTPUTS:\n//   - Places orders via the broker.\n//\n// BEGIN\n//   // Retrieve targets from context\n//   target_longs = context.target_longs\n//   target_shorts = context.target_shorts\n//   target_portfolio = target_longs.union(target_shorts)\n\n//   // Exit positions that are no longer targets\n//   FOR asset in context.portfolio.positions:\n//     IF asset NOT IN target_portfolio:\n//       order_target(asset, 0)\n//     END IF\n//   END FOR\n\n//   // Execute new trades only if minimum position counts are met\n//   IF length(target_longs) >= context.min_positions AND length(target_shorts) >= context.min_positions:\n//     // Place orders for short positions\n//     short_weight = -1.0 / length(target_shorts)\n//     FOR asset in target_shorts:\n//       order_target_percent(asset, short_weight)\n//     END FOR\n\n//     // Place orders for long positions\n//     long_weight = 1.0 / length(target_longs)\n//     FOR asset in target_longs:\n//       order_target_percent(asset, long_weight)\n//     END FOR\n//   END IF\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 151,
    "text": "## Framework Overview\n\nTo create a truly adaptive strategy, a machine learning model can be retrained periodically during a backtest to incorporate new data. In Zipline, this complex logic can be encapsulated within a `CustomFactor`. This approach integrates feature processing, model training, and prediction generation into a single, reusable component within the Pipeline API.\n\n## Key Concepts\n\n- **[Definition] CustomFactor**: A user-defined class that inherits from `zipline.pipeline.CustomFactor`. It allows for arbitrary computations on historical data (`inputs`) over a specified `window_length` to produce a new cross-sectional output (an alpha factor).\n- **[Definition] Integrated Training**: The practice of embedding the model fitting logic (e.g., `model.fit()`) directly within the backtesting process, allowing the model to adapt to changing market conditions as the simulation progresses through time.\n\n## Custom Factor Implementation\n\nA `CustomFactor` for integrated training and prediction requires careful design, typically involving three main parts:\n\n1.  **`__init__()` Method**: The constructor for the factor class. It is executed only once when the pipeline is created. Its primary role is to initialize and store stateful objects that persist throughout the backtest, such as the machine learning model (e.g., `SGDRegressor`) and a data scaler (e.g., `StandardScaler`). It also defines a training schedule (e.g., a list of weekdays).\n\n2.  **`compute()` Method**: This is the main execution method, called by the Pipeline engine for each day of the backtest. It receives the current date (`today`), the list of assets, and NumPy arrays for each of the specified `inputs`.\n    *   **Training Check**: The first step within `compute` is to check if a retraining is scheduled for the current `today` (e.g., `if today.weekday() in self.train_on_weekday`).\n    *   **Delegation**: If training is required, it calls a dedicated private method (e.g., `_train_model`) to handle the complex training logic.\n    *   **Prediction**: After the potential training step, it uses the (potentially updated) model to generate predictions on the most recent slice of feature data and returns these predictions as its output.\n\n3.  **`_train_model()` Method**: A private helper method that contains the core training logic. This separation keeps the `compute` method clean. Its responsibilities are:\n    *   **Data Alignment**: Align the feature data (`inputs`) with the target variable (e.g., forward returns). This involves careful slicing and shifting of the NumPy arrays to prevent lookahead bias.\n    *   **Data Cleaning**: Handle missing values (`NaNs`) in both the features and the target variable.\n    *   **Scaling and Fitting**: Use the stored scaler to fit and transform the feature data, and then use the stored model to `fit` the scaled features to the outcome data.",
    "question": "## Question\nBased on the `Instruction` and `Text` provided, answer the following question:\n\n1.  **`[Integrated Training CustomFactor Implementation]`**:\n    *   **Task**: Provide the pseudocode for a Zipline `CustomFactor` class named `AdaptiveModelFactor`. This class should integrate rolling model training and prediction. It must include an initialization method, a main compute method that triggers training on a schedule, and a private method containing the training logic itself.",
    "answer": "## Answer\n\n```\n// --- BEGIN PSEUDOCODE ---\n//\n// CLASS AdaptiveModelFactor inherits from CustomFactor\n// INPUTS:\n//   - inputs: A list of pipeline factors to be used as features. The first must be forward returns.\n//   - window_length: The number of days of data to provide for training.\n//\n// BEGIN CLASS\n//   // Class-level attribute for training schedule\n//   train_on_weekday = [MONDAY, WEDNESDAY, FRIDAY]\n\n//   // Initialization method\n//   METHOD __init__(self, *args, **kwargs):\n//     // Call parent constructor\n//     super().__init__(*args, **kwargs)\n\n//     // Initialize stateful objects\n//     self.scaler = new StandardScaler()\n//     self.model = new LinearRegressionModel()\n//     self.is_trained = False\n//   END METHOD\n\n//   // Private training method\n//   METHOD _train_model(self, returns, features):\n//     // Align features with the future returns they are meant to predict\n//     // This involves shifting the returns data relative to the feature data\n//     outcome_data = returns[N_FORWARD_DAYS:]\n//     feature_data = features[:-N_FORWARD_DAYS]\n\n//     // Reshape and clean data to remove NaNs\n//     // (Detailed reshaping and NaN removal logic here)\n\n//     // Fit the scaler and transform the features\n//     scaled_features = self.scaler.fit_transform(feature_data)\n\n//     // Fit the model\n//     self.model.fit(scaled_features, outcome_data)\n//     self.is_trained = True\n//   END METHOD\n\n//   // Main compute method\n//   METHOD compute(self, today, assets, out, returns, *features):\n//     // Check if today is a scheduled training day or if the model has never been trained\n//     IF today.weekday() IN self.train_on_weekday OR self.is_trained == False:\n//       // Delegate to the training method\n//       self._train_model(returns, features)\n//     END IF\n\n//     // Generate predictions using the most recent feature data\n//     IF self.is_trained == True:\n//       // Get the latest slice of feature data (for today)\n//       latest_features = stack(features)[-1]\n//       // Handle any potential NaNs in the latest data\n//       latest_features = fill_na(latest_features, 0)\n\n//       // Scale the features and predict\n//       scaled_latest_features = self.scaler.transform(latest_features)\n//       predictions = self.model.predict(scaled_latest_features)\n\n//       // Assign predictions to the output array\n//       out[:] = predictions\n//     ELSE:\n//       // If not yet trained, output NaNs\n//       out[:] = NaN\n//     END IF\n//   END METHOD\n//\n// END CLASS\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 152,
    "text": "## Framework Overview\n\nTime-series data often contains a mixture of systematic patterns and unsystematic noise. A crucial preprocessing step is to decompose the series into its constituent components to isolate the signal from the noise. This allows for more targeted modeling efforts, particularly on the residual component after deterministic patterns are removed.\n\n### Key Concepts\n\n*   **[Definition] Time-Series Decomposition**: The process of separating a time series into several distinct components, each representing an underlying pattern category.\n*   **[Definition] Trend Component**: The long-term progression of the series (e.g., upward or downward slope).\n*   **[Definition] Seasonal Component**: A repeating, cyclical pattern within a fixed time period (e.g., monthly or quarterly patterns).\n*   **[Definition] Residual Component**: The remainder of the series after the trend and seasonal components have been removed. This component is often treated as random noise and is the target for further modeling.\n\n### The Additive Model\n\nThe components can be combined in different ways. The additive model assumes that the components sum together to form the original series. This is appropriate when the magnitude of the seasonal fluctuations or the variance of the residuals does not depend on the level of the time series.\n\nThe relationship is expressed as:\n\n*   `Original_Series(t) = Trend(t) + Seasonality(t) + Residual(t)`\n\nThe decomposition process uses moving averages to estimate the trend and seasonal components systematically.",
    "question": "Provide the pseudocode for a function that performs an additive decomposition on a given time series. The function should estimate the trend, seasonality, and residual components.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION AdditiveDecomposition(time_series, seasonal_period)\n// INPUTS:\n//   - time_series: An array or list of numerical values representing the time series.\n//   - seasonal_period: An integer representing the length of the seasonal cycle (e.g., 12 for monthly data).\n// OUTPUTS:\n//   - A structure or dictionary containing three arrays: 'trend', 'seasonal', 'residual'.\n//\n// BEGIN\n//   // Step 1: Estimate the Trend component using a centered moving average.\n//   // If seasonal_period is even, a 2x-moving average is needed for centering.\n//   // For simplicity, we assume a simple centered moving average here.\n//   SET window_size = seasonal_period\n//   SET trend = calculate_centered_moving_average(time_series, window_size)\n//\n//   // Step 2: Detrend the series to isolate the seasonal and residual components.\n//   SET detrended_series = time_series - trend\n//\n//   // Step 3: Estimate the Seasonal component.\n//   // Average the detrended values for each point in the seasonal cycle.\n//   CREATE an empty array 'seasonal_averages' of size seasonal_period.\n//   FOR i FROM 0 TO (seasonal_period - 1)\n//     SET seasonal_averages[i] = average of detrended_series at indices i, i+seasonal_period, i+2*seasonal_period, ...\n//   ENDFOR\n//   // Center the seasonal averages around zero.\n//   SET seasonal_averages = seasonal_averages - mean(seasonal_averages)\n//   // Construct the full seasonal series by repeating the cycle.\n//   SET seasonal = construct_full_seasonal_series(seasonal_averages, length(time_series))\n//\n//   // Step 4: Calculate the Residual component.\n//   SET residual = time_series - trend - seasonal\n//\n//   // Step 5: Return the components.\n//   RETURN { trend: trend, seasonal: seasonal, residual: residual }\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 153,
    "text": "## Framework Overview\n\nRolling window statistics are fundamental tools in time-series analysis for smoothing data and identifying changes in market behavior. Unlike a simple moving average that weights all past observations equally, the Exponential Moving Average (EMA) assigns more weight to recent data, making it more responsive to new information.\n\n### Key Concepts\n\n*   **[Definition] Rolling Window**: A fixed-size segment of sequential data that slides over a time series. Statistics are computed on the data within the window at each time step.\n*   **[Definition] Simple Moving Average (SMA)**: The unweighted mean of the previous `N` data points.\n*   **[Definition] Exponential Moving Average (EMA)**: A type of moving average that places a greater weight and significance on the most recent data points. The EMA is calculated recursively.\n\n### EMA Calculation\n\nThe EMA is defined by the following recursive formula:\n\n`EMA_t = (Price_t * 浼? + EMA_{t-1} * (1 - 浼?`\n\nWhere:\n*   `Price_t`: The price at the current time period `t`.\n*   `EMA_{t-1}`: The Exponential Moving Average of the preceding period.\n*   `浼猔: The smoothing factor, a constant that determines the rate of exponential decay. It is calculated as `浼?= 2 / (N + 1)`, where `N` is the lookback period of the EMA.\n\nTo begin the calculation, the `EMA` for the first period is often seeded with the SMA of the first `N` data points.",
    "question": "Provide the pseudocode for a function that calculates the Exponential Moving Average (EMA) for a given time series and lookback period `N`.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateEMA(time_series, period)\n// INPUTS:\n//   - time_series: An array of numerical values.\n//   - period: An integer for the lookback period (N).\n// OUTPUTS:\n//   - An array containing the EMA values.\n//\n// BEGIN\n//   // Step 1: Validate inputs.\n//   IF length(time_series) < period THEN\n//     RETURN empty array // Not enough data to compute.\n//   ENDIF\n//\n//   // Step 2: Calculate the smoothing factor (alpha).\n//   SET alpha = 2 / (period + 1)\n//\n//   // Step 3: Initialize the EMA calculation.\n//   // The first EMA value is the SMA of the first 'period' data points.\n//   CREATE an empty array 'ema_values'.\n//   SET initial_sum = sum of first 'period' elements in time_series.\n//   SET initial_sma = initial_sum / period.\n//   // Pad the beginning of the result array with nulls for non-computable values.\n//   FOR i FROM 0 TO (period - 2)\n//       APPEND null to ema_values\n//   ENDFOR\n//   APPEND initial_sma to ema_values\n//\n//   // Step 4: Recursively calculate the remaining EMA values.\n//   FOR i FROM period TO length(time_series) - 1\n//     SET current_price = time_series[i]\n//     SET prev_ema = ema_values[i-1]\n//     SET current_ema = (current_price * alpha) + (prev_ema * (1 - alpha))\n//     APPEND current_ema to ema_values\n//   ENDFOR\n//\n//   // Step 5: Return the result.\n//   RETURN ema_values\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 154,
    "text": "## Framework Overview\n\nAutocorrelation is a critical tool for identifying non-randomness and patterns within a time series. By measuring how a series correlates with its past values (lags), we can uncover dependencies that are essential for building predictive models like ARIMA.\n\n### Key Concepts\n\n*   **[Definition] Autocorrelation (Serial Correlation)**: The correlation of a time series with a delayed copy of itself. It measures the linear relationship between lagged values of a series.\n*   **[Definition] Autocorrelation Function (ACF)**: A function that gives the autocorrelation values of a time series as a function of the time lag. A plot of the ACF against the lags is called a correlogram.\n*   **[Definition] Partial Autocorrelation Function (PACF)**: Measures the correlation between a time-series observation and its value at a given lag, after controlling for the effects of all shorter lags.\n\n### Mathematical Formulation of ACF\n\nThe autocorrelation coefficient, `锜籣k`, for a given lag `k` is calculated as the ratio of the autocovariance at lag `k` to the variance of the series.\n\n**Equation 1: Autocorrelation Coefficient**\n\n`锜籣k = Cov(y_t, y_{t-k}) / Var(y_t)`\n\nWhich expands to:\n\n`锜籣k = ( 鍗盻{t=k+1 to T} [ (y_t - 鐦? * (y_{t-k} - 鐦? ] ) / ( 鍗盻{t=1 to T} [ (y_t - 鐦?^2 ] )`\n\nWhere:\n*   `y_t`: The value of the time series at time `t`.\n*   `鐦竊: The mean of the time series.\n*   `k`: The lag number (an integer > 0).\n*   `T`: The total number of observations in the series.",
    "question": "Provide the pseudocode for a function that computes the Autocorrelation Function (ACF) for a given time series up to a specified maximum lag `n`.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION CalculateACF(time_series, max_lag)\n// INPUTS:\n//   - time_series: An array of numerical values.\n//   - max_lag: The maximum lag 'k' for which to calculate the autocorrelation.\n// OUTPUTS:\n//   - An array of autocorrelation coefficients [锜籣0, 锜籣1, ..., 锜籣max_lag].\n//\n// BEGIN\n//   // Step 1: Get the total number of observations.\n//   SET T = length(time_series)\n//\n//   // Step 2: Calculate the mean of the series.\n//   SET series_mean = mean(time_series)\n//\n//   // Step 3: Calculate the variance of the series (the denominator in Equation 1).\n//   SET series_variance = 0\n//   FOR t FROM 0 TO T - 1\n//     series_variance = series_variance + (time_series[t] - series_mean)^2\n//   ENDFOR\n//\n//   // Step 4: Initialize the results array.\n//   CREATE an empty array 'acf_values'.\n//   // Autocorrelation at lag 0 is always 1.\n//   APPEND 1.0 to acf_values\n//\n//   // Step 5: Iterate through each lag from 1 to max_lag.\n//   FOR k FROM 1 TO max_lag\n//     // Calculate autocovariance for lag k (the numerator in Equation 1).\n//     SET autocovariance_k = 0\n//     FOR t FROM k TO T - 1\n//       autocovariance_k = autocovariance_k + ((time_series[t] - series_mean) * (time_series[t-k] - series_mean))\n//     ENDFOR\n//\n//     // Calculate autocorrelation coefficient 锜籣k.\n//     IF series_variance == 0 THEN\n//       SET rho_k = 0\n//     ELSE\n//       SET rho_k = autocovariance_k / series_variance\n//     ENDIF\n//\n//     APPEND rho_k to acf_values\n//   ENDFOR\n//\n//   // Step 6: Return the calculated ACF values.\n//   RETURN acf_values\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  },
  {
    "ID": 155,
    "text": "## Framework Overview\n\nMultivariate time-series models, like the Vector Autoregressive (VAR) model, are designed to capture the dynamic interdependencies among multiple time series. Unlike univariate models, a VAR model allows for the lagged values of each series to affect the current values of all other series in the system, providing a richer framework for forecasting.\n\n### Key Concepts\n\n*   **[Definition] Vector Autoregressive (VAR) Model**: A stochastic process model used to capture the linear interdependencies among multiple time series. A VAR(p) model explains the evolution of a set of `k` variables (a vector) over the same sample period as a linear function of their own `p` lagged values.\n\n### The VAR(1) Model for Two Time Series\n\nFor the simplest case of `k=2` variables (`y1`, `y2`) and a lag order of `p=1`, the VAR(1) model is a system of two equations:\n\n**Equation 1: System of Equations for VAR(1)**\n\n`y_1,t = c_1 + 浼猒11 * y_1,t-1 + 浼猒12 * y_2,t-1 + 钄歘1,t`\n\n`y_2,t = c_2 + 浼猒21 * y_1,t-1 + 浼猒22 * y_2,t-1 + 钄歘2,t`\n\nWhere:\n*   `y_1,t` and `y_2,t`: The values of the two time series at the current time `t`.\n*   `y_1,t-1` and `y_2,t-1`: The values of the two time series at the previous time `t-1`.\n*   `c_1`, `c_2`: The constant (intercept) terms for each equation.\n*   `浼猒11`, `浼猒12`, `浼猒21`, `浼猒22`: The autoregressive coefficients that capture the influence of each lagged variable on each current variable.\n*   `钄歘1,t`, `钄歘2,t`: The white noise error terms for each equation at time `t`.\n\nTo make a one-step-ahead forecast for time `t`, we use the known values at `t-1` and set the expected value of the error terms to zero.",
    "question": "Provide the pseudocode for a function that takes the estimated coefficients of a two-variable VAR(1) model and the last observed values of the two series to produce a one-step-ahead forecast.",
    "answer": "```\n// --- BEGIN PSEUDOCODE ---\n//\n// FUNCTION ForecastVAR1(coefficients, last_values)\n// INPUTS:\n//   - coefficients: A structure or dictionary containing the estimated model parameters:\n//       { c1, c2, alpha11, alpha12, alpha21, alpha22 }\n//   - last_values: A tuple or array containing the last observed values for the two series:\n//       (y1_t_minus_1, y2_t_minus_1)\n// OUTPUTS:\n//   - A tuple or array containing the one-step-ahead forecasts for the two series:\n//       (y1_forecast, y2_forecast)\n//\n// BEGIN\n//   // Step 1: Extract coefficients from the input structure.\n//   SET c1 = coefficients.c1\n//   SET c2 = coefficients.c2\n//   SET a11 = coefficients.alpha11\n//   SET a12 = coefficients.alpha12\n//   SET a21 = coefficients.alpha21\n//   SET a22 = coefficients.alpha22\n//\n//   // Step 2: Extract last observed values.\n//   SET y1_prev = last_values[0]\n//   SET y2_prev = last_values[1]\n//\n//   // Step 3: Calculate the forecast for the first series using its VAR(1) equation.\n//   // The expected value of the error term 钄歘1,t is zero.\n//   SET y1_forecast = c1 + (a11 * y1_prev) + (a12 * y2_prev)\n//\n//   // Step 4: Calculate the forecast for the second series using its VAR(1) equation.\n//   // The expected value of the error term 钄歘2,t is zero.\n//   SET y2_forecast = c2 + (a21 * y1_prev) + (a22 * y2_prev)\n//\n//   // Step 5: Return the forecasted values.\n//   RETURN (y1_forecast, y2_forecast)\n//\n// END\n//\n// --- END PSEUDOCODE ---\n```",
    "problem_type": "Algorithm Implementation Problem"
  }
]
